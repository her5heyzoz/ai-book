目 录
草 1 蒲 血 督 学 习
第 1 章 机器学习及监督学习概论 3
1.1 机器学习 3
1.2 机器学习的分类 5
1.2.1 基本分类 5
1.2.2 按模型分类 10
1.2.3 按算法分类 11
1.2.4 按技巧分类 12
1.3 机器学习方法主要素 13
1.3.1 模型 13
1.3.2 策略 14
1.3.3 算法 16
1.4 模型评估与模型选择 17
1.4.1 训练误差与测试误差 17
1.4.2 过拟合与模型选择 18
1.5 正则化与交叉验证 20
1.5.1 正则化 20
1.5.2 交叉验证 20
1.6 泛化能力 21
1.6.1 泛化误差 21
1.6.2 泛化误差上界 22
1.7 生成模型与判别模型 24
1.8 监督学习应用 24
1.8.1 分类问题 24
1.8.2 标注问题 26
1.8.3 回归问题 27
本章概要 28
继续阅读 29
习题 29
参考文献 29
VIII 机器学习方法
第 2 章 感知机 30
2.1 感知机模型 30
2.2 感知机学习策略 31
2.2.1 数据集的线性可分性 31
2.2.2 感知机学习策略 31
2.3 感知机学习算法 32
2.3.1 感知机学习算法的原始形式 33
2.3.2 算法的收敛性 35
2.3.3 感知机学习算法的对偶形式 37
本章概要 39
继续阅读 40
习题 40
参考文献 40
第 3 章 k 近邻法 41
3.1 k 近邻算法 41
3.2 k 近邻模型 42
3.2.1 模型 42
3.2.2 距离度量 42
3.2.3 k 值的选择 43
3.2.4 分类决策规则 44
3.3 k 近邻法的实现：kd 树 44
3.3.1 构造 kd 树 45
3.3.2 搜索 kd 树 46
本章概要 48
继续阅读 48
习题 48
参考文献 49
第 4 章 朴素贝叶斯法 50
4.1 朴素贝叶斯法的学习与分类 50
4.1.1 基本方法 50
4.1.2 后验概率最大化的含义 51
4.2 朴素贝叶斯法的参数估计 52
4.2.1 极大似然估计 52
4.2.2 学习与分类算法 53
4.2.3 贝叶斯估计 54
本章概要 55
继续阅读 56
目录 IX
习题 56
参考文献 56
第 5 章 决策树 57
5.1 决策树模型与学习 57
5.1.1 决策树模型 57
5.1.2 决策树与 if-then 规则 58
5.1.3 决策树与条件概率分布 58
5.1.4 决策树学习 58
5.2 特征选择 60
5.2.1 特征选择问题 60
5.2.2 信息增益 61
5.2.3 信息增益比 64
5.3 决策树的生成 64
5.3.1 ID3 算法 65
5.3.2 C4.5 的生成算法 66
5.4 决策树的剪枝 66
5.5 CART 算法 68
5.5.1 CART 生成 69
5.5.2 CART 剪枝 72
本章概要 74
继续阅读 75
习题 75
参考文献 75
第 6 章 逻辑斯谛回归与最大烟模型 77
6.1 逻辑斯谛回归模型 77
6.1.1 逻辑斯谛分布 77
6.1.2 二项逻辑斯谛回归模型 78
6.1.3 模型参数估计 79
6.1.4 多项逻辑斯谛回归 79
6.2 最大煽模型 80
6.2.1 最大煽原理 80
6.2.2 最大煽模型的定义 82
6.2.3 最大煽模型的学习 83
6.2.4 极大似然估计 86
6.3 模型学习的最优化算法 87
6.3.1 改进的迭代尺度法 87
6.3.2 拟牛顿法 90
X 机器学习方法
本章概要 91
继续阅读 92
习题 92
参考文献 93
第 7 章 支持向量机 94
7.1 线性可分支持向量机与硬间隔最大化 94
7.1.1 线性可分支持向量机 94
7.1.2 函数间隔和儿何间隔 96
7.1.3 间隔最大化 97
7.1.4 学习的对偶算法 101
7.2 线性支持向量机与软间隔最大化 106
7.2.1 线性支持向量机 106
7.2.2 学习的对偶算法 107
7.2.3 支持向量 110
7.2.4 合页损失函数 111
7.3 非线性支持向量机与核函数 112
7.3.1 核技巧 112
7.3.2 正定核 115
7.3.3 常用核函数 118
7.3.4 非线性支持向量分类机 120
7.4 序列最小最优化算法 121
7.4.1 两个变量二次规划的求解方法 122
7.4.2 变量的选择方法 124
7.4.3 SMO 算法 126
本章概要 127
继续阅读 129
习题 129
参考文献 129
第 8 章 Boosting 131
AdaBoost 算法 131
8.1.1 Boosting 的基本思路 131
AdaBoost 算法 132
AdaBoost 的例子 134
8.2 AdaBoost 算法的训练误差分析 135
8.3 AdaBoost 算法的解释 137
8.3.1 前向分步算法 137
8.3.2 前向分步算法与 AdaBoost 138
目录 XI
8.4 提升树 140
8.4.1 提升树模型 140
8.4.2 提升树算法 140
8.4.3 梯度提升 144
本章概要 145
继续阅读 146
习题 146
参考文献 146
第 9 章 EM 算法及其推广 148
9.1 EM 算法的引入 148
9.1.1 EM 算法 148
9.1.2 EM 算法的导出 151
9.1.3 EM 算法在无监督学习中的应用 153
9.2 EM 算法的收敛性 153
9.3 EM 算法在高斯混合模型学习中的应用 154
9.3.1 高斯混合模型 155
9.3.2 高斯混合模型参数估计的 EM 算法 155
9.4 EM 算法的推广 158
9.4.1 F 函数的极大-极大算法 158
9.4.2 GEM 算法 160
本章概要 161
继续阅读 162
习题 162
参考文献 162
第 10 章 隐马尔可夫模型 163
10.1 隐马尔可夫模型的基本概念 163
10.1.1 隐马尔可夫模型的定义 163
10.1.2 观测序列的生成过程 166
10.1.3 隐马尔可夫模型的 3 个基本问题 166
10.2 概率计算算法 166
10.2.1 直接计算法 166
10.2.2 前向算法 167
10.2.3 后向算法 169
10.2.4 一些概率与期望值的计算 170
10.3 学习算法 172
10.3.1 监督学习方法 172
10.3.2 Baum-Welch 算法 172
XII 机器学习方法
10.3.3 Baum-Welch 模型参数估计公式 174
10.4 预测算法 175
10.4.1 近似算法 175
10.4.2 维特比算法 176
本章概要 179
继续阅读 179
习题 180
参考文献 180
第 11 章 条件随机场 181
11.1 概率无向图模型 181
11.1.1 模型定义 181
11.1.2 概率无向图模型的因子分解 183
11.2 条件随机场的定义与形式 184
11.2.1 条件随机场的定义 184
11.2.2 条件随机场的参数化形式 185
11.2.3 条件随机场的简化形式 186
11.2.4 条件随机场的矩阵形式 187
11.3 条件随机场的概率计算问题 189
11.3.1 前向-后向算法 189
11.3.2 概率计算 189
11.3.3 期望值的计算 190
11.4 条件随机场的学习算法 191
11.4.1 改进的迭代尺度法 191
11.4.2 拟牛顿法 194
11.5 条件随机场的预测算法 195
本章概要 197
继续阅读 198
习题 198
参考文献 199
第 12 章 监督学习方法总结 200
草 2 蒲 元元血血督学学习习
第 13 章 无监督学习概论 207
13.1 无监督学习基本原理 207
13.2 基本问题 208
13.3 机器学习主要素 210
13.4 无监督学习方法 210
目录 XIII
本章概要 214
继续阅读 215
参考文献 215
第 14 章 聚类方法 216
14.1 聚类的基本概念 216
14.1.1 相似度或距离 216
14.1.2 类或簇 219
14.1.3 类与类之间的距离 220
14.2 层次聚类 220
14.3 k 均值聚类 222
14.3.1 模型 222
14.3.2 策略 223
14.3.3 算法 224
14.3.4 算法特性 225
本章概要 226
继续阅读 227
习题 227
参考文献 227
第 15 章 奇异值分解 229
15.1 奇异值分解的定义与性质 229
15.1.1 定义与定理 229
15.1.2 紧奇异值分解与截断奇异值分解 233
15.1.3 儿何解释 235
15.1.4 主要性质 237
15.2 奇异值分解的计算 238
15.3 奇异值分解与矩阵近似 241
15.3.1 弗罗贝尼乌斯范数 241
15.3.2 矩阵的最优近似 242
15.3.3 矩阵的外积展开式 245
本章概要 247
继续阅读 248
习题 248
参考文献 249
第 16 章 主成分分析 250
16.1 总体主成分分析 250
16.1.1 基本想法 250
XIV 机器学习方法
16.1.2 定义和导出 252
16.1.3 主要性质 253
16.1.4 主成分的个数 257
16.1.5 规范化变量的总体主成分 260
16.2 样本主成分分析 260
16.2.1 样本主成分的定义和性质 261
16.2.2 相关矩阵的特征值分解算法 263
16.2.3 数据矩阵的奇异值分解算法 265
本章概要 267
继续阅读 269
习题 269
参考文献 269
第 17 章 潜在语义分析 271
17.1 单词向量空间与话题向量空间 271
17.1.1 单词向量空间 271
17.1.2 话题向量空间 273
17.2 潜在语义分析算法 276
17.2.1 矩阵奇异值分解算法 276
17.2.2 例子 278
17.3 非负矩阵分解算法 279
17.3.1 非负矩阵分解 279
17.3.2 潜在语义分析模型 280
17.3.3 非负矩阵分解的形式化 280
17.3.4 算法 281
本章概要 283
继续阅读 284
习题 284
参考文献 285
第 18 章 概率潜在语义分析 286
18.1 概率潜在语义分析模型 286
18.1.1 基本想法 286
18.1.2 生成模型 287
18.1.3 共现模型 288
18.1.4 模型性质 289
18.2 概率潜在语义分析的算法 291
本章概要 293
继续阅读 294
目录 XV
习题 294
参考文献 295
第 19 章 马尔可夫链蒙特卡罗法 296
19.1 蒙特卡罗法 296
19.1.1 随机抽样 296
19.1.2 数学期望估计 297
19.1.3 积分计算 298
19.2 马尔可夫链 299
19.2.1 基本定义 299
19.2.2 离散状态马尔可夫链 300
19.2.3 连续状态马尔可夫链 305
19.2.4 马尔可夫链的性质 306
19.3 马尔可夫链蒙特卡罗法 310
19.3.1 基本想法 310
19.3.2 基本步骤 311
19.3.3 马尔可夫链蒙特卡罗法与统计学习 311
Metropolis-Hastings 算法 312
19.4.1 基本原理 312
Metropolis-Hastings 算法 315
单分量 Metropolis-Hastings 算法 315
19.5 吉布斯抽样 316
19.5.1 基本原理 316
19.5.2 吉布斯抽样算法 318
19.5.3 抽样计算 319
本章概要 320
继续阅读 321
习题 321
参考文献 322
第 20 章 潜在狄利克雷分配 324
20.1 狄利克雷分布 324
20.1.1 分布定义 324
20.1.2 共辄先验 327
20.2 潜在狄利克雷分自模型 328
20.2.1 基本想法 328
20.2.2 模型定义 329
20.2.3 概率图模型 331
20.2.4 随机变量序列的可交换性 332
XVI 机器学习方法
20.2.5 概率公式 332
20.3 LDA 的吉布斯抽样算法 333
20.3.1 基本想法 333
20.3.2 算法的主要部分 334
20.3.3 算法的后处理 336
20.3.4 算法 337
20.4 LDA 的变分 EM 算法 338
20.4.1 变分推理 338
20.4.2 变分 EM 算法 339
20.4.3 算法推导 340
20.4.4 算法总结 346
本章概要 346
继续阅读 348
习题 348
参考文献 348
第 21 章 PageRank 算法 349
PageRank 的定义 349
21.1.1 基本想法 349
21.1.2 有向图和随机游走模型 350
21.1.3 PageRank 的基本定义 352
21.1.4 PageRank 的一般定义 354
PageRank 的计算 355
21.2.1 迭代算法 355
21.2.2 幕法 357
21.2.3 代数算法 361
本章概要 362
继续阅读 363
习题 363
参考文献 364
第 22 章 无监督学习方法总结 365
22.1 无监督学习方法的关系和特点 365
22.1.1 各种方法之间的关系 365
22.1.2 无监督学习方法 366
22.1.3 基础机器学习方法 366
22.2 话题模型之间的关系和特点 367
参考文献 368
目录 XVII
草 3 蒲 深 反 学 习
第 23 章 前馈神经网络 371
23.1 前馈神经网络的模型 371
23.1.1 前馈神经网络定义 372
23.1.2 前馈神经网络的例子 381
23.1.3 前馈神经网络的表示能力 386
23.2 前馈神经网络的学习算法 389
23.2.1 前馈神经网络学习 389
23.2.2 前馈神经网络学习的优化算法 391
23.2.3 反向传播算法 393
23.2.4 在计算图上的实现 397
23.2.5 算法的实现技巧 401
23.3 前馈神经网络学习的正则化 406
23.3.1 深度学习中的正则化 406
23.3.2 早停法 406
23.3.3 暂返法 408
本章概要 410
继续阅读 413
习题 413
参考文献 414
第 24 章 卷积神经网络 415
24.1 卷积神经网络的模型 415
24.1.1 背景 415
24.1.2 卷积 416
24.1.3 汇聚 424
24.1.4 卷积神经网络 427
24.1.5 卷积神经网络性质 430
24.2 卷积神经网络的学习算法 432
24.2.1 卷积导数 432
24.2.2 反向传播算法 433
24.3 图像分类中的应用 436
24.3.1 AlexNet 436
24.3.2 残差网络 437
本章概要 441
继续阅读 443
习题 443
参考文献 445
XVIII 机器学习方法
第 25 章 循环神经网络 447
25.1 简单循环神经网络 447
25.1.1 模型 447
25.1.2 学习算法 450
25.2 常用循环神经网络 454
25.2.1 长短期记忆网络 454
25.2.2 门控循环单元网络 457
25.2.3 深度循环神经网络 458
25.2.4 双向循环神经网络 459
25.3 自然语言生成中的应用 460
25.3.1 词向量 460
25.3.2 语言模型与语言生成 463
本章概要 465
继续阅读 467
习题 467
参考文献 468
第 26 章 序列到序列模型 469
26.1 序列到序列基本模型 469
26.1.1 序列到序列学习 469
26.1.2 基本模型 471
RNN Search 模型 472
26.2.1 注意力 472
26.2.2 模型定义 474
26.2.3 模型特点 475
Transformer 模型 475
26.3.1 模型架构 476
26.3.2 模型特点 482
本章概要 483
继续阅读 486
习题 486
参考文献 486
第 27 章 预训练语言模型 488
27.1 GPT 模型 488
27.1.1 预训练语言模型 488
27.1.2 模型和学习 490
27.2 BERT 模型 493
27.2.1 去噪自动编码器 493
27.2.2 模型和学习 495
目录 XIX
27.2.3 模型特点 499
本章概要 500
继续阅读 502
习题 502
参考文献 502
第 28 章 生成对抗网络 504
28.1 GAN 基本模型 504
28.1.1 模型 504
28.1.2 学习算法 506
28.1.3 理论分析 507
28.2 图像生成中的应用 508
28.2.1 转置卷积 509
28.2.2 DCGAN 511
本章概要 513
继续阅读 514
习题 514
参考文献 515
第 29 章 深度学习方法总结 516
29.1 深度学习的模型 516
29.2 深度学习的方法 518
29.3 深度学习的优化算法 520
29.4 深度学习的优缺点 522
参考文献 523
附录 A 梯度下降法 524
附录 B 牛顿法和拟牛顿法 526
附录 C 拉格朗日对偶性 531
附录 D 矩阵的基本子空间 534
附录 E KL 散度的定义和狄利克雷分布的性质 537
附录 F 软最大化函数的偏导数和交叉烟损失函数的偏导数 539
索引 541
・ ・ ・ ・ ・ ・ (收起)