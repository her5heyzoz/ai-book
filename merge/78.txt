前言 .1
第一部分 生成式深度学习概述
第1 章 生成建模 11
1.1 什么是生成建模？ 11
1.1.1 生成建模与判别建模 13
1.1.2 机器学习的发展 . 14
1.1.3 生成建模的兴起 . 15
1.1.4 生成建模的框架 . 18
1.2 概率生成模型 21
1.2.1 你好，Wrodl ！ 24
1.2.2 你的第一个概率生成模型 . 25
1.2.3 朴素贝叶斯 28
1.2.4 你好，Wrodl ！续篇 . 31
1.3 生成建模的难题 33
表示学习 34
1.4 设置环境 37
1.5 小结 40
第2 章 深度学习 41
2.1 结构化与非结构化数据 41
2.2 深度神经网络 43
Keras 和TensorFlow 44
2.3 第一个深度神经网络 . 45
2.3.1 加载数据. 46
2.3.2 建立模型. 48
2.3.3 编译模型. 52
2.3.4 训练模型. 54
2.3.5 评估模型. 55
2.4 改进模型 58
2.4.1 卷积层 . 58
2.4.2 批标准化. 64
2.4.3 Dropout 层 . 66
2.4.4 结合所有层 68
2.5 小结 71
第3 章 变分自动编码器 73
3.1 画展 73
3.2 自动编码器 . 76
3.2.1 第一个自动编码器 . 77
3.2.2 编码器 . 78
3.2.3 解码器 . 80
3.2.4 连接编码器与解码器 82
3.2.5 分析自动编码器 . 84
3.3 变化后的画展 87
3.4 构建变分自动编码器 . 89
3.4.1 编码器 . 89
3.4.2 损失函数. 94
3.4.3 分析变分自动编码器 97
3.5 使用VAE 生成面部图像 98
3.5.1 训练VAE 99
3.5.2 分析VAE . 102
3.5.3 生成新面孔 . 103
3.5.4 隐空间的算术 104
3.5.5 面部变形 106
3.6 小结 . 107
第4 章 生成对抗网络 108
4.1 神秘兽 108
4.2 生成对抗网络简介 111
4.3 第一个生成对抗网络 112
4.3.1 判别器 113
4.3.2 生成器 115
4.3.3 训练GAN 119
4.4 GAN 面临的难题 125
4.4.1 损失震荡 125
4.4.2 模式收缩 126
4.4.3 不提供信息的损失函数 126
4.4.4 超参数 127
4.4.5 解决GAN 面临的难题 . 127
4.5 WGAN 127
4.5.1 Wasserstein 损失 128
4.5.2 利普希茨约束 130
4.5.3 权重裁剪 131
4.5.4 训练WGAN 132
4.5.5 分析WGAN 133
4.6 WGAN-GP 134
4.6.1 梯度惩罚损失 135
4.6.2 分析WGAN-GP 139
4.7 小结 . 140
第二部分 教机器绘画、写作、作曲和玩游戏
第5 章 绘画 145
5.1 苹果和橙子 146
5.2 CycleGAN 149
5.3 第一个CycleGAN 模型 . 151
5.3.1 简介 151
5.3.2 生成器（U-Net） 153
5.3.3 判别器 157
5.3.4 编译CycleGAN 158
5.3.5 训练CycleGAN 161
5.3.6 分析CycleGAN 162
5.4 创建一个模仿莫奈作品的CycleGAN . 164
5.4.1 生成器（ResNet） 165
5.4.2 分析CycleGAN 166
5.5 神经风格迁移 . 168
5.5.1 内容损失 169
5.5.2 风格损失 172
5.5.3 总方差损失 . 175
5.5.4 运行神经风格迁移 176
5.5.5 分析神经风格迁移模型 177
5.6 小结 . 178
第6 章 写作 179
6.1 坏家伙们的文学社 180
6.2 长短期记忆网络 181
6.3 第一个LSTM 网络 182
6.3.1 分词 183
6.3.2 建立数据集 . 185
6.3.3 LSTM 架构 . 187
6.3.4 嵌入层 187
6.3.5 LSTM 层 188
6.3.6 LSTM 元胞 . 190
6.4 生成新文本 192
6.5 RNN 扩展 . 196
6.5.1 堆叠式循环网络 196
6.5.2 门控制循环单元 198
6.5.3 双向元胞 200
6.6 编码器- 解码器模型 200
6.7 问答生成器 203
6.7.1 问答数据集 . 204
6.7.2 模型架构 205
6.7.3 推断 210
6.7.4 模型的结果 . 212
6.8 小结 . 214
第7 章 作曲 215
7.1 前提知识 216
音符 216
・ ・ ・ ・ ・ ・ (收起)