序言一
序言二
前　言
作者介绍
第1章　绪论/ 1
1.1　人工智能及其飞速发展/ 2
1.2　大规模、分布式机器学习/ 4
1.3　本书的安排/ 6
参考文献/ 7
第2章　机器学习基础/ 9
2.1　机器学习的基本概念/ 10
2.2　机器学习的基本流程/ 13
2.3　常用的损失函数/ 16
2.3.1　Hinge损失函数/ 16
2.3.2　指数损失函数/ 16
2.3.3　交叉熵损失函数/ 17
2.4　常用的机器学习模型/ 18
2.4.1　线性模型/ 18
2.4.2　核方法与支持向量机/ 18
2.4.3　决策树与Boosting/ 21
2.4.4　神经网络/ 23
2.5　常用的优化方法/ 32
2.6　机器学习理论/ 33
2.6.1　机器学习算法的泛化误差/ 34
2.6.2　泛化误差的分解/ 34
2.6.3　基于容度的估计误差的上界/ 35
2.7　总结/ 36
参考文献/ 36
第3章　分布式机器学习框架/ 41
3.1　大数据与大模型的挑战/ 42
3.2　分布式机器学习的基本流程/ 44
3.3　数据与模型划分模块/ 46
3.4　单机优化模块/ 48
3.5　通信模块/ 48
3.5.1　通信的内容/ 48
3.5.2　通信的拓扑结构/ 49
3.5.3　通信的步调/ 51
3.5.4　通信的频率/ 52
3.6　数据与模型聚合模块/ 53
3.7　分布式机器学习理论/ 54
3.8　分布式机器学习系统/ 55
3.9　总结/ 56
参考文献/ 57
第4章　单机优化之确定性算法/ 61
4.1　基本概述/ 62
4.1.1　机器学习的优化框架/ 62
4.1.2　优化算法的分类和发展历史/ 65
4.2　一阶确定性算法/ 67
4.2.1　梯度下降法/ 67
4.2.2　投影次梯度下降法/ 69
4.2.3　近端梯度下降法/ 70
4.2.4　Frank-Wolfe算法/ 71
4.2.5　Nesterov加速法/ 72
4.2.6　坐标下降法/ 75
4.3　二阶确定性算法/ 75
4.3.1　牛顿法/ 76
4.3.2　拟牛顿法/ 77
4.4　对偶方法/ 78
4.5　总结/ 81
参考文献/ 8
第5章　单机优化之随机算法/ 85
5.1　基本随机优化算法/ 86
5.1.1　随机梯度下降法/ 86
5.1.2　随机坐标下降法/ 88
5.1.3　随机拟牛顿法/ 91
5.1.4　随机对偶坐标上升法/ 93
5.1.5　小结/ 95
5.2　随机优化算法的改进/ 96
5.2.1　方差缩减方法/ 96
5.2.2　算法组合方法/ 100
5.3　非凸随机优化算法/ 101
5.3.1　Ada系列算法/ 102
5.3.2　非凸理论分析/ 104
5.3.3　逃离鞍点问题/ 106
5.3.4　等级优化算法/ 107
5.4　总结/ 109
参考文献/ 109
第6章　数据与模型并行/ 113
6.1　基本概述/ 114
6.2　计算并行模式/ 117
6.3　数据并行模式/ 119
6.3.1　数据样本划分/ 120
6.3.2　数据维度划分/ 123
6.4　模型并行模式/ 123
6.4.1　线性模型/ 123
6.4.2　神经网络/ 127
6.5　总结/ 133
参考文献/ 133
第7章　通信机制/ 135
7.1　基本概述/ 136
7.2　通信的内容/ 137
7.2.1　参数或参数的更新/ 137
7.2.2　计算的中间结果/ 137
7.2.3　讨论/ 138
7.3　通信的拓扑结构/ 139
7.3.1　基于迭代式MapReduce/AllReduce的通信拓扑/ 140
7.3.2　基于参数服务器的通信拓扑/ 142
7.3.3　基于数据流的通信拓扑/ 143
7.3.4　讨论/ 145
7.4　通信的步调/ 145
7.4.1　同步通信/ 146
7.4.2　异步通信/ 147
7.4.3　同步和异步的平衡/ 148
7.4.4　讨论/ 150
7.5　通信的频率/ 150
7.5.1　时域滤波/ 150
7.5.2　空域滤波/ 153
7.5.3　讨论/ 155
7.6　总结/ 156
参考文献/ 156
第8章　数据与模型聚合/ 159
8.1　基本概述/ 160
8.2　基于模型加和的聚合方法/ 160
8.2.1　基于全部模型加和的聚合/ 160
8.2.2　基于部分模型加和的聚合/ 162
8.3　基于模型集成的聚合方法/ 167
8.3.1　基于输出加和的聚合/ 168
8.3.2　基于投票的聚合/ 171
8.4　总结/ 174
参考文献/ 174
第9章　分布式机器学习算法/ 177
9.1　基本概述/ 178
9.2　同步算法/ 179
9.2.1　同步SGD方法/ 179
9.2.2　模型平均方法及其改进/ 182
9.2.3　ADMM算法/ 183
9.2.4　弹性平均SGD算法/ 185
9.2.5　讨论/ 186
9.3　异步算法/ 187
9.3.1　异步SGD/ 187
9.3.2　Hogwild!算法/ 189
9.3.3　Cyclades算法/ 190
9.3.4　带延迟处理的异步算法/ 192
9.3.5　异步方法的进一步加速/ 199
9.3.6　讨论/ 199
9.4　同步和异步的对比与融合/ 199
9.4.1　同步和异步算法的实验对比/ 199
9.4.2　同步和异步的融合/ 201
9.5　模型并行算法/ 203
9.5.1　DistBelief/ 203
9.5.2　AlexNet/ 204
9.6　总结/ 205
参考文献/ 205
第10章　分布式机器学习理论/ 209
10.1　基本概述/ 210
10.2　收敛性分析/ 210
10.2.1　优化目标和算法/ 211
10.2.2　数据和模型并行/ 213
10.2.3　同步和异步/ 215
10.3　加速比分析/ 217
10.3.1　从收敛速率到加速比/ 218
10.3.2　通信量的下界/ 219
10.4　泛化分析/ 221
10.4.1　优化的局限性/ 222
10.4.2　具有更好泛化能力的非凸优化算法/ 224
10.5　总结/ 226
参考文献/ 226
第11章　分布式机器学习系统/ 229
11.1　基本概述/ 230
11.2　基于IMR的分布式机器学习系统/ 231
11.2.1　IMR和Spark/ 231
11.2.2　Spark MLlib/ 234
11.3　基于参数服务器的分布式机器学习系统/ 236
11.3.1　参数服务器/ 236
11.3.2　Multiverso参数服务器/ 237
11.4　基于数据流的分布式机器学习系统/ 241
11.4.1　数据流/ 241
11.4.2　TensorFlow数据流系统/ 243
11.5　实战比较/ 248
11.6　总结/ 252
参考文献/ 252
第12章　结语/ 255
12.1　全书总结/ 256
12.2　未来展望/ 257
索引/ 260
・ ・ ・ ・ ・ ・ (收起)