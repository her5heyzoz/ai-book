第一部分　原理篇
第1章　机器学习与模型 2
1.1　模型 2
1.2　参数与训练 4
1.3　损失函数 9
1.4　计算图的训练 10
1.5　小结 12
第2章　计算图 13
2.1　什么是计算图 13
2.2　前向传播 14
2.3　函数优化与梯度下降法 18
2.4　链式法则与反向传播 29
2.5　在计算图上执行梯度下降法 36
2.6　节点类及其子类 36
2.7　用计算图搭建ADALINE并训练 44
2.8　小结 48
第3章　优化器 49
3.1　优化流程的抽象实现 49
3.2　BGD、SGD和MBGD 53
3.3　梯度下降优化器 58
3.4　朴素梯度下降法的局限 60
3.5　冲量优化器 61
3.6　AdaGrad优化器 62
3.7　RMSProp优化器 64
3.8　Adam优化器 65
3.9　小结 68
第二部分　模型篇
第4章　逻辑回归 70
4.1　对数损失函数 70
4.2　Logistic函数 73
4.3　二分类逻辑回归 75
4.4　多分类逻辑回归 78
4.5　交叉熵 81
4.6　实例：鸢尾花 85
4.7　小结 88
第5章　神经网络 90
5.1　神经元与激活函数 90
5.2　神经网络 95
5.3　多层全连接神经网络 99
5.4　多个全连接层的意义 101
5.5　实例：鸢尾花 108
5.6　实例：手写数字识别 110
5.7　小结 116
第6章　非全连接神经网络 117
6.1　带二次项的逻辑回归 117
6.2　因子分解机 124
6.3　Wide & Deep 132
6.4　DeepFM 137
6.5　实例：泰坦尼克号幸存者 141
6.6　小结 150
第7章　循环神经网络 151
7.1　RNN的结构 151
7.2　RNN的输出 152
7.3　实例：正弦波与方波 155
7.4　变长序列 159
7.5　实例：3D电磁发音仪单词识别 164
7.6　小结 167
第8章　卷积神经网络 168
8.1　蒙德里安与莫奈 168
8.2　滤波器 170
8.3　可训练的滤波器 176
8.4　卷积层 183
8.5　池化层 186
8.6　CNN的结构 189
8.7　实例：手写数字识别 190
8.8　小结 194
第三部分　工程篇
第9章　训练与评估 196
9.1　训练和Trainer训练器 196
9.2　评估和Metrics节点 202
9.3　混淆矩阵 204
9.4　正确率 204
9.5　查准率 206
9.6　查全率 206
9.7　ROC曲线和AUC 208
9.8　小结 211
第10章　模型保存、预测和服务 212
10.1　模型保存 213
10.2　模型加载和预测 216
10.3　模型服务 216
10.4　客户端 222
10.5　小结 223
第11章　分布式训练 224
11.1　分布式训练的原理 224
11.2　基于参数服务器的架构 230
11.3　Ring AllReduce原理 241
11.4　Ring AllReduce架构实现 248
11.5　分布式训练性能评测 257
11.6　小结 259
第12章　工业级深度学习框架 261
12.1　张量 262
12.2　计算加速 263
12.3　GPU 265
12.4　数据接口 266
12.5　模型并行 266
12.6　静态图和动态图 267
12.7　混合精度训练 268
12.8　图优化和编译优化 270
12.9　移动端和嵌入式端 270
12.10　小结 271
・ ・ ・ ・ ・ ・ (收起)