Contents 目　　录
前言
第一部分　PyTorch基础
第1章　Numpy基础2
1.1　生成Numpy数组3
1.1.1　从已有数据中创建数组3
1.1.2　利用random模块生成数组4
1.1.3　创建特定形状的多维数组5
1.1.4　利用arange、linspace函数生成数组6
1.2　获取元素7
1.3　Numpy的算术运算9
1.3.1　对应元素相乘9
1.3.2　点积运算10
1.4　数组变形11
1.4.1　更改数组的形状11
1.4.2　合并数组14
1.5　批量处理16
1.6　通用函数17
1.7　广播机制19
1.8　小结20
第2章　PyTorch基础21
2.1　为何选择PyTorch？21
2.2　安装配置22
2.2.1　安装CPU版PyTorch22
2.2.2　安装GPU版PyTorch24
2.3　Jupyter Notebook环境配置26
2.4　Numpy与Tensor28
2.4.1　Tensor概述28
2.4.2　创建Tensor28
2.4.3　修改Tensor形状30
2.4.4　索引操作31
2.4.5　广播机制32
2.4.6　逐元素操作32
2.4.7　归并操作33
2.4.8　比较操作34
2.4.9　矩阵操作35
2.4.10　PyTorch与Numpy比较35
2.5　Tensor与Autograd36
2.5.1　自动求导要点36
2.5.2　计算图37
2.5.3　标量反向传播38
2.5.4　非标量反向传播39
2.6　使用Numpy实现机器学习41
2.7　使用Tensor及Antograd实现机器学习44
2.8　使用TensorFlow架构46
2.9　小结48
第3章　PyTorch神经网络工具箱49
3.1　神经网络核心组件49
3.2　实现神经网络实例50
3.2.1　背景说明51
3.2.2　准备数据52
3.2.3　可视化源数据53
3.2.4　构建模型53
3.2.5　训练模型54
3.3　如何构建神经网络？56
3.3.1　构建网络层56
3.3.2　前向传播57
3.3.3　反向传播57
3.3.4　训练模型58
3.4　神经网络工具箱nn58
3.4.1　nn.Module58
3.4.2　nn.functional58
3.5　优化器59
3.6　动态修改学习率参数60
3.7　优化器比较60
3.8　小结62
第4章　PyTorch数据处理工具箱63
4.1　数据处理工具箱概述63
4.2　utils.data简介64
4.3　torchvision简介66
4.3.1　transforms67
4.3.2　ImageFolder67
4.4　可视化工具69
4.4.1　tensorboardX简介69
4.4.2　用tensorboardX可视化神经网络71
4.4.3　用tensorboardX可视化损失值72
4.4.4　用tensorboardX可视化特征图73
4.5　本章小结74
第二部分　深度学习基础
第5章　机器学习基础76
5.1　机器学习的基本任务76
5.1.1　监督学习77
5.1.2　无监督学习77
5.1.3　半监督学习78
5.1.4　强化学习78
5.2　机器学习一般流程78
5.2.1　明确目标79
5.2.2　收集数据79
5.2.3　数据探索与预处理79
5.2.4　选择模型及损失函数80
5.2.5　评估及优化模型81
5.3　过拟合与欠拟合81
5.3.1　权重正则化82
5.3.2　Dropout正则化83
5.3.3　批量正则化86
5.3.4　权重初始化88
5.4　选择合适激活函数89
5.5　选择合适的损失函数90
5.6　选择合适优化器92
5.6.1　传统梯度优化的不足93
5.6.2　动量算法94
5.6.3　AdaGrad算法96
5.6.4　RMSProp算法97
5.6.5　Adam算法98
5.7　GPU加速99
5.7.1　单GPU加速100
5.7.2　多GPU加速101
5.7.3　使用GPU注意事项104
5.8　本章小结104
第6章　视觉处理基础105
6.1　卷积神经网络简介105
6.2　卷积层107
6.2.1　卷积核108
6.2.2　步幅109
6.2.3　填充111
6.2.4　多通道上的卷积111
6.2.5　激活函数113
6.2.6　卷积函数113
6.2.7　转置卷积114
6.3　池化层115
6.3.1　局部池化116
6.3.2　全局池化117
6.4　现代经典网络119
6.4.1　LeNet-5模型119
6.4.2　AlexNet模型120
6.4.3　VGG模型121
6.4.4　GoogleNet模型122
6.4.5　ResNet模型123
6.4.6　胶囊网络简介124
6.5　PyTorch实现CIFAR-10多分类125
6.5.1　数据集说明125
6.5.2　加载数据125
6.5.3　构建网络127
6.5.4　训练模型128
6.5.5　测试模型129
6.5.6　采用全局平均池化130
6.5.7　像Keras一样显示各层参数131
6.6　模型集成提升性能133
6.6.1　使用模型134
6.6.2　集成方法134
6.6.3　集成效果135
6.7　使用现代经典模型提升性能136
6.8　本章小结137
第7章　自然语言处理基础138
7.1　循环神经网络基本结构138
7.2　前向传播与随时间反向传播140
7.3　循环神经网络变种143
7.3.1　LSTM144
7.3.2　GRU145
7.3.3　Bi-RNN146
7.4　循环神经网络的PyTorch实现146
7.4.1　RNN实现147
7.4.2　LSTM实现149
7.4.3　GRU实现151
7.5　文本数据处理152
7.6　词嵌入153
7.6.1　Word2Vec原理154
7.6.2　CBOW模型155
7.6.3　Skip-Gram模型155
7.7　PyTorch实现词性判别156
7.7.1　词性判别主要步骤156
7.7.2　数据预处理157
7.7.3　构建网络157
7.7.4　训练网络158
7.7.5　测试模型160
7.8　用LSTM预测股票行情160
7.8.1　 导入数据160
7.8.2　数据概览161
7.8.3　预处理数据162
7.8.4　定义模型163
7.8.5　训练模型163
7.8.6　测试模型164
7.9　循环神经网络应用场景165
7.10　小结166
第8章　生成式深度学习167
8.1　用变分自编码器生成图像167
8.1.1　自编码器168
8.1.2　变分自编码器168
8.1.3　用变分自编码器生成图像169
8.2　GAN简介173
8.2.1　GAN架构173
8.2.2　GAN的损失函数174
8.3　用GAN生成图像175
8.3.1　判别器175
8.3.2　生成器175
8.3.3　训练模型175
8.3.4　可视化结果177
8.4　VAE与GAN的优缺点178
8.5　ConditionGAN179
8.5.1　CGAN的架构179
8.5.2　CGAN生成器180
8.5.3　CGAN判别器180
8.5.4　CGAN损失函数181
8.5.5　CGAN可视化181
8.5.6　查看指定标签的数据182
8.5.7　可视化损失值182
8.6　DCGAN183
8.7　提升GAN训练效果的一些技巧184
8.8　小结185
第三部分　深度学习实践
第9章　人脸检测与识别188
9.1　人脸识别一般流程188
9.2　人脸检测189
9.2.1　目标检测189
9.2.2　人脸定位191
9.2.3　人脸对齐191
9.2.4　MTCNN算法192
9.3　特征提取193
9.4　人脸识别198
9.4.1　人脸识别主要原理198
9.4.2　人脸识别发展198
9.5　PyTorch实现人脸检测与识别199
9.5.1　验证检测代码199
9.5.2　检测图像200
9.5.3　检测后进行预处理200
9.5.4　查看经检测后的图像201
9.5.5　人脸识别202
9.6　小结202
第10章　迁移学习实例203
10.1　迁移学习简介203
10.2　特征提取204
10.2.1　PyTorch提供的预处理模块205
10.2.2　特征提取实例206
10.3　数据增强209
10.3.1　按比例缩放209
10.3.2　裁剪210
10.3.3　翻转210
10.3.4　改变颜色211
10.3.5　组合多种增强方法211
10.4　微调实例212
10.4.1　数据预处理212
10.4.2　加载预训练模型213
10.4.3　修改分类器213
10.4.4　选择损失函数及优化器213
10.4.5　训练及验证模型214
10.5　清除图像中的雾霾214
10.6　小结217
第11章　神经网络机器翻译实例218
11.1　Encoder-Decoder模型原理218
11.2　注意力框架220
11.3　PyTorch实现注意力Decoder224
11.3.1　构建Encoder224
11.3.2　构建简单Decoder225
11.3.3　构建注意力Decoder226
11.4　用注意力机制实现中英文互译227
11.4.1　导入需要的模块228
11.4.2　数据预处理228
11.4.3　构建模型231
11.4.4　训练模型234
11.4.5　随机采样，对模型进行测试235
11.4.6　可视化注意力236
11.5　小结237
第12章　实战生成式模型238
12.1　DeepDream模型238
12.1.1　Deep Dream原理238
12.1.2　DeepDream算法流程239
12.1.3　用PyTorch实现Deep Dream240
12.2　风格迁移243
12.2.1　内容损失244
12.2.2　风格损失245
12.2.3　用PyTorch实现神经网络风格迁移247
12.3　PyTorch实现图像修复252
12.3.1　网络结构252
12.3.2　损失函数252
12.3.3　图像修复实例253
12.4　PyTorch实现DiscoGAN255
12.4.1　DiscoGAN架构256
12.4.2　损失函数258
12.4.3　DiscoGAN实现258
12.4.4　用PyTorch实现从边框生成鞋子260
12.5　小结262
第13章　Caffe2模型迁移实例263
13.1　Caffe2简介263
13.2　Caffe如何升级到Caffe2264
13.3　PyTorch如何迁移到Caffe2265
13.4　小结268
第14章　AI新方向：对抗攻击269
14.1　对抗攻击简介269
14.1.1　白盒攻击与黑盒攻击270
14.1.2　无目标攻击与有目标攻击270
14.2　常见对抗样本生成方式271
14.2.1　快速梯度符号法271
14.2.2　快速梯度算法271
14.3　PyTorch实现对抗攻击272
14.3.1　实现无目标攻击272
14.3.2　实现有目标攻击274
14.4　对抗攻击和防御措施276
14.4.1　对抗攻击276
14.4.2　常见防御方法分类276
14.5　总结277
第15章　强化学习278
15.1　强化学习简介278
15.2　Q-Learning原理281
15.2.1　Q-Learning主要流程281
15.2.2　Q函数282
15.2.3　贪婪策略283
15.3　用PyTorch实现Q-Learning283
15.3.1　定义Q-Learing主函数283
15.3.2　执行Q-Learing284
15.4　SARSA算法285
15.4.1　SARSA算法主要步骤285
15.4.2　用PyTorch实现SARSA算法286
15.5　小结287
第16章　深度强化学习288
16.1　DQN算法原理288
16.1.1　Q-Learning方法的局限性289
16.1.2　用DL处理RL需要解决的问题289
16.1.3　用DQN解决方法289
16.1.4　定义损失函数290
16.1.5　DQN的经验回放机制290
16.1.6　目标网络290
16.1.7　网络模型291
16.1.8　DQN算法291
16.2　用PyTorch实现DQN算法292
16.3　小结295
附录A　PyTorch0.4版本变更296
附录B　AI在各行业的最新应用301
・ ・ ・ ・ ・ ・ (收起)