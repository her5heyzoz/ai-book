第1章　Python机器学习入门　　1
1.1 　梦之队：机器学习与Python　　1
1.2 　这本书将教给你什么（以及不会教什么）　　2
1.3 　遇到困难的时候怎么办　　3
1.4 　开始　　4
1.4.1 　NumPy、SciPy和Matplotlib简介　　4
1.4.2 　安装Python　　5
1.4.3 　使用NumPy和SciPy智能高效地处理数据　　5
1.4.4 　学习NumPy　　5
1.4.5 　学习SciPy　　9
1.5 　我们第一个（极小的）机器学习应用　　10
1.5.1 　读取数据　　10
1.5.2 　预处理和清洗数据　　11
1.5.3 　选择正确的模型和学习算法　　12
1.6 　小结　　20
第2章　如何对真实样本分类　　22
2.1 　Iris数据集　　22
2.1.1 　第一步是可视化　　23
2.1.2 　构建第一个分类模型　　24
2.2 　构建更复杂的分类器　　28
2.3 　更复杂的数据集和更复杂的分类器　　29
2.3.1 　从Seeds数据集中学习　　29
2.3.2 　特征和特征工程　　30
2.3.3 　最邻近分类　　30
2.4 　二分类和多分类　　33
2.5 　小结　　34
第3章　聚类：寻找相关的帖子　　35
3.1 　评估帖子的关联性　　35
3.1.1 　不应该怎样　　36
3.1.2 　应该怎样　　36
3.2 　预处理：用相近的公共词语个数来衡量相似性　　37
3.2.1 　将原始文本转化为词袋　　37
3.2.2 　统计词语　　38
3.2.3 　词语频次向量的归一化　　40
3.2.4 　删除不重要的词语　　41
3.2.5 　词干处理　　42
3.2.6 　停用词兴奋剂　　44
3.2.7 　我们的成果和目标　　45
3.3 　聚类　　46
3.3.1 　K均值　　46
3.3.2 　让测试数据评估我们的想法　　49
3.3.3 　对帖子聚类　　50
3.4 　解决我们最初的难题　　51
3.5 　调整参数　　54
3.6 　小结　　54
第4章　主题模型　　55
4.1 　潜在狄利克雷分配（LDA）　　55
4.2 　在主题空间比较相似度　　59
4.3 　选择主题个数　　64
4.4 　小结　　65
第5章　分类：检测劣质答案　　67
5.1 　路线图概述　　67
5.2 　学习如何区分出优秀的答案　　68
5.2.1 　调整样本　　68
5.2.2 　调整分类器　　68
5.3 　获取数据　　68
5.3.1 　将数据消减到可处理的程度　　69
5.3.2 　对属性进行预选择和处理　　70
5.3.3 　定义什么是优质答案　　71
5.4 　创建第一个分类器　　71
5.4.1 　从k邻近（kNN）算法开始　　71
5.4.2 　特征工程　　72
5.4.3 　训练分类器　　73
5.4.4 　评估分类器的性能　　74
5.4.5 　设计更多的特征　　74
5.5 　决定怎样提升效果　　77
5.5.1 　偏差?方差及其折中　　77
5.5.2 　解决高偏差　　78
5.5.3 　解决高方差　　78
5.5.4 　高偏差或低偏差　　78
5.6 　采用逻辑回归　　81
5.6.1 　一点数学和一个小例子　　81
5.6.2 　在帖子分类问题上应用逻辑回归　　83
5.7 　观察正确率的背后：准确率和召回率　　84
5.8 　为分类器瘦身　　87
5.9 　出货　　88
5.10 　小结　　88
第6章　分类II：情感分析　　89
6.1 　路线图概述　　89
6.2 　获取推特（Twitter）数据　　89
6.3 　朴素贝叶斯分类器介绍　　90
6.3.1 　了解贝叶斯定理　　90
6.3.2 　朴素　　91
6.3.3 　使用朴素贝叶斯进行分类　　92
6.3.4 　考虑未出现的词语和其他古怪情况　　94
6.3.5 　考虑算术下溢　　95
6.4 　创建第一个分类器并调优　　97
6.4.1 　先解决一个简单问题　　97
6.4.2 　使用所有的类　　99
6.4.3 　对分类器的参数进行调优　　101
6.5 　清洗推文　　104
6.6 　将词语类型考虑进去　　106
6.6.1 　确定词语的类型　　106
6.6.2 　用SentiWordNet成功地作弊　　108
6.6.3 　我们第一个估算器　　110
6.6.4 　把所有东西融合在一起　　111
6.7 　小结　　112
第7章　回归：推荐　　113
7.1 　用回归预测房价　　113
7.1.1 　多维回归　　116
7.1.2 　回归里的交叉验证　　116
7.2 　惩罚式回归　　117
7.2.1 　L1和L2惩罚　　117
7.2.2 　在Scikit-learn中使用Lasso或弹性网　　118
7.3 　P大于N的情形　　119
7.3.1 　基于文本的例子　　120
7.3.2 　巧妙地设置超参数（hyperparameter）　　121
7.3.3 　评分预测和推荐　　122
7.4 　小结　　126
第8章　回归：改进的推荐　　127
8.1 　改进的推荐　　127
8.1.1 　使用二值推荐矩阵　　127
8.1.2 　审视电影的近邻　　129
8.1.3 　组合多种方法　　130
8.2 　购物篮分析　　132
8.2.1 　获取有用的预测　　133
8.2.2 　分析超市购物篮　　134
8.2.3 　关联规则挖掘　　136
8.2.4 　更多购物篮分析的高级话题　　137
8.3 　小结　　138
第9章　分类III：音乐体裁分类　　139
9.1 　路线图概述　　139
9.2 　获取音乐数据　　139
9.3 　观察音乐　　140
9.4 　用FFT构建第一个分类器　　143
9.4.1 　增加实验敏捷性　　143
9.4.2 　训练分类器　　144
9.4.3 　在多分类问题中用混淆矩阵评估正确率　　144
9.4.4 　另一种方式评估分类器效果：受试者工作特征曲线（ROC）　　146
9.5 　用梅尔倒频谱系数（MFCC）提升分类效果　　148
9.6 　小结　　152
第10章　计算机视觉：模式识别　　154
10.1 　图像处理简介　　154
10.2 　读取和显示图像　　155
10.2.1 　图像处理基础　　156
10.2.2 　加入椒盐噪声　　161
10.2.3 　模式识别　　163
10.2.4 　计算图像特征　　163
10.2.5 　设计你自己的特征　　164
10.3 　在更难的数据集上分类　　166
10.4 　局部特征表示　　167
10.5 　小结　　170
第11章　降维　　171
11.1 　路线图　　171
11.2 　选择特征　　172
11.2.1 　用筛选器检测冗余特征　　172
11.2.2 　用封装器让模型选择特征　　178
11.3 　其他特征选择方法　　180
11.4 　特征抽取　　181
11.4.1 　主成分分析（PCA）　　181
11.4.2 　PCA的局限性以及LDA会有什么帮助　　183
11.5 　多维标度法（MDS）　　184
11.6 　小结　　187
第12章　大数据　　188
12.1 　了解大数据　　188
12.2 　用Jug程序包把你的处理流程分解成几个任务　　189
12.2.1 　关于任务　　189
12.2.2 　复用部分结果　　191
12.2.3 　幕后的工作原理　　192
12.2.4 　用Jug分析数据　　192
12.3 　使用亚马逊Web服务（AWS）　　194
12.3.1 　构建你的第一台机器　　195
12.3.2 　用starcluster自动创建集群　　199
12.4 　小结　　202
附录A 　更多机器学习知识　　203
A.1 　在线资源　　203
A.2 　参考书　　203
A.2.1 　问答网站　　203
A.2.2 　博客　　204
A.2.3 　数据资源　　205
A.2.4 　竞争日益加剧　　205
A.3 　还剩下什么　　205
A.4 　小结　　206
索引　　207
・ ・ ・ ・ ・ ・ (收起)