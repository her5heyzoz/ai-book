第一部分 人工智能基础
第  章 绪论 
. 什么是人工智能 
.. 类人行为：图灵测试方法 
.. 类人思考：认知建模方法 
.. 理性思考：“思维法则”方法 
.. 理性行为：理性智能体方法 
.. 益机 
. 人工智能的基础 
.. 哲学 
.. 数学 
.. 经济学 
.. 神经科学 
.. 心理学 
.. 计算机工程 
.. 控制理论与控制论 
.. 语言学 
. 人工智能的历史 
.. 人工智能的诞生（―） 
.. 早期热情高涨，期望无限（―） 
.. 一些现实（―） 
.. 专家系统（―） 
.. 神经网络的回归（―现在） 
.. 概率推理和机器学习（―现在） 
.. 大数据（―现在） 
.. 深度学习（―现在） 
. 目前的先进技术 
. 人工智能的风险和收益 
小结 
参考文献与历史注释 
第  章 智能体 
. 智能体和环境 
. 良好行为：理性的概念 
.. 性能度量 
.. 理性 
.. 全知、学习和自主 
. 环境的本质 
.. 指定任务环境 
.. 任务环境的属性 
. 智能体的结构 
.. 智能体程序 
.. 简单反射型智能体 
.. 基于模型的反射型智能体 
.. 基于目标的智能体 
.. 基于效用的智能体 
.. 学习型智能体 
.. 智能体程序的组件如何工作 
小结 
参考文献与历史注释 
第二部分 问题求解
第  章 通过搜索进行问题求解 
. 问题求解智能体 
.. 搜索问题和解 
.. 问题形式化 
. 问题示例 
.. 标准化问题 
.. 真实世界问题 
. 搜索算法 
.. 最佳优先搜索 
.. 搜索数据结构 
.. 冗余路径 
.. 问题求解性能评估 
. 无信息搜索策略 
.. 广度优先搜索 
.. Dijkstra 算法或一致代价搜索 
.. 深度优先搜索与内存问题 
.. 深度受限和迭代加深搜索 
.. 双向搜索 
.. 无信息搜索算法对比 
. 有信息（启发式）搜索策略 
.. 贪心最佳优先搜索 
.. A* 搜索 
.. 搜索等值线 
.. 满意搜索：不可容许的启发式
函数与加权 A* 搜索 
.. 内存受限搜索 
.. 双向启发式搜索 
. 启发式函数 
.. 启发式函数的准确性对性能的影响 
.. 从松弛问题出发生成启发式函数 
.. 从子问题出发生成启发式函数：模式数据库 
.. 使用地标生成启发式函数 
.. 学习以更好地搜索 
.. 从经验中学习启发式函数 
小结 
参考文献与历史注释 
第  章 复杂环境中的搜索 
. 局部搜索和最优化问题 
.. 爬山搜索 
.. 模拟退火 
.. 局部束搜索 
.. 进化算法 
. 连续空间中的局部搜索 
. 使用非确定性动作的搜索 
.. 不稳定的真空吸尘器世界 
.. 与或搜索树 
.. 反复尝试 
. 部分可观测环境中的搜索 
.. 无观测信息的搜索 
.. 部分可观测环境中的搜索 
.. 求解部分可观测问题 
.. 部分可观测环境中的智能体 
. 在线搜索智能体和未知环境 
.. 在线搜索问题 
.. 在线搜索智能体 
.. 在线局部搜索 
.. 在线搜索中的学习 
小结 
参考文献与历史注释 
第  章 对抗搜索和博弈 
. 博弈论 
. 博弈中的优化决策 
.. 极小化极大搜索算法 
.. 多人博弈中的最优决策 
.. α-β 剪枝 
.. 移动顺序 
. 启发式 α-β 树搜索 
.. 评价函数 
.. 截断搜索 
.. 前向剪枝 
.. 搜索和查表 
. 蒙特卡罗树搜索 
. 随机博弈 
. 部分可观测博弈 
.. 四国军棋：部分可观测的国际象棋 
.. 纸牌游戏 
. 博弈搜索算法的局限性 
小结 
参考文献与历史注释 
第  章 约束满足问题 
. 定义约束满足问题 
.. 问题示例：地图着色 
.. 问题示例：车间作业调度 
.. CSP 形式体系的变体 
. 约束传播：CSP 中的推断 
.. 节点一致性 
.. 弧一致性 
.. 路径一致性 
.. k 一致性 
.. 全局约束 
.. 数独 
. CSP 的回溯搜索 
.. 变量排序和值排序 
.. 交替进行搜索和推理 
.. 智能回溯：向后看 
.. 约束学习 
. CSP 的局部搜索 
. 问题的结构 
.. 割集调整 
.. 树分解 
.. 值对称 
小结 
参考文献与历史注释 
第三部分 知识、推理和规划
第  章 逻辑智能体 
. 基于知识的智能体 
. wumpus 世界 
. 逻辑 
. 命题逻辑：一种非常简单的逻辑 
.. 语法 
.. 语义 
.. 一个简单的知识库 
.. 一个简单的推断过程 
. 命题定理证明 
.. 推断与证明 
.. 通过归结证明 
.. 霍恩子句与确定子句 
.. 前向链接与反向链接 
. 高效命题模型检验 
.. 完备的回溯算法 
.. 局部搜索算法 
.. 随机 SAT 问题概览 
. 基于命题逻辑的智能体 
.. 世界的当前状态 
.. 混合智能体 
.. 逻辑状态估计 
.. 用命题推断进行规划 
小结 
参考文献与历史注释 
第  章 一阶逻辑 
. 回顾表示 
.. 思想的语言 
.. 结合形式语言和自然语言的优点 
. 一阶逻辑的语法和语义 
.. 一阶逻辑模型 
.. 符号与解释 
.. 项 
.. 原子语句 
.. 复合语句 
.. 量词 
.. 等词 
.. 数据库语义 
. 使用一阶逻辑 
.. 一阶逻辑的断言与查询 
.. 亲属关系论域 
.. 数、集合与列表 
.. wumpus 世界 
. 一阶逻辑中的知识工程 
.. 知识工程的过程 
.. 电子电路论域 
小结 
参考文献与历史注释 
第  章 一阶逻辑中的推断 
. 命题推断与一阶推断 
. 合一与一阶推断 
.. 合一 
.. 存储与检索 
. 前向链接 
.. 一阶确定子句 
.. 简单的前向链接算法 
.. 高效前向链接 
. 反向链接 
.. 反向链接算法 
.. 逻辑编程 
.. 冗余推断和无限循环 
.. Prolog 的数据库语义 
.. 约束逻辑编程 
. 归结 
.. 一阶逻辑的合取范式 
.. 归结推断规则 
.. 证明范例 
.. 归结的完备性 
.. 等词 
.. 归结策略 
小结 
参考文献与历史注释 
第  章 知识表示 
. 本体论工程 
. 类别与对象 
.. 物理组成 
.. 量度 
.. 对象：事物和物质 
. 事件 
.. 时间 
.. 流和对象 
. 精神对象和模态逻辑 
. 类别的推理系统 
.. 语义网络 
.. 描述逻辑 
. 用缺省信息推理 
.. 限定与缺省逻辑 
.. 真值维护系统 
小结 
参考文献与历史注释 
第  章 自动规划 
. 经典规划的定义 
.. 范例领域：航空货物运输 
.. 范例领域：备用轮胎问题 
.. 范例领域：积木世界 
. 经典规划的算法 
.. 规划的前向状态空间搜索 
.. 规划的反向状态空间搜索 
.. 使用布尔可满足性规划 
.. 其他经典规划方法 
. 规划的启发式方法 
.. 领域无关剪枝 
.. 规划中的状态抽象 
. 分层规划 
.. 高层动作 
.. 搜索基元解 
.. 搜索抽象解 
. 非确定性域的规划和行动 
.. 无传感器规划 
.. 应变规划 
.. 在线规划 
. 时间、调度和资源 
.. 时间约束和资源约束的表示 
.. 解决调度问题 
. 规划方法分析 
小结 
参考文献与历史注释 
第四部分 不确定知识和不确定推理
第  章 不确定性的量化 
. 不确定性下的动作 
.. 不确定性概述 
.. 不确定性与理性决策 
. 基本概率记号 
.. 概率是关于什么的 
.. 概率断言中的命题语言 
.. 概率公理及其合理性 
. 使用完全联合分布进行推断 
. 独立性 
. 贝叶斯法则及其应用 
.. 应用贝叶斯法则：简单实例 
.. 应用贝叶斯法则：合并证据 
. 朴素贝叶斯模型 
. 重游 wumpus 世界 
小结 
参考文献与历史注释 
第  章 概率推理 
. 不确定域的知识表示 
. 贝叶斯网络的语义 
.. 贝叶斯网络中的条件独立性关系 
.. 条件分布的高效表示 
.. 连续变量的贝叶斯网络 
.. 案例研究：汽车保险 
. 贝叶斯网络中的精确推断 
.. 通过枚举进行推断 
.. 变量消元算法 
.. 精确推断的复杂性 
.. 聚类算法 
. 贝叶斯网络中的近似推理 
.. 直接采样方法 
.. 通过马尔可夫链模拟进行推断 
.. 编译近似推断 
. 因果网络 
.. 表示动作：do 操作 
.. 后门准则 
小结 
参考文献与历史注释 
第  章 时间上的概率推理 
. 时间与不确定性 
.. 状态与观测 
.. 转移模型与传感器模型 
. 时序模型中的推断 
.. 滤波与预测 
.. 平滑 
.. 寻找最可能序列 
. 隐马尔可夫模型 
.. 简化矩阵算法 
.. 隐马尔可夫模型示例：定位 
. 卡尔曼滤波器 
.. 更新高斯分布 
.. 简单的一维示例 
.. 一般情况 
.. 卡尔曼滤波的适用范围 
. 动态贝叶斯网络 
.. 构建动态贝叶斯网络 
.. 动态贝叶斯网络中的精确推断 
.. 动态贝叶斯网络中的近似推断 
小结 
参考文献与历史注释 
第  章 概率编程 
. 关系概率模型 
.. 语法与语义 
.. 实例：评定玩家的技能等级 
.. 关系概率模型中的推断 
. 开宇宙概率模型 
.. 语义与语法 
.. 开宇宙概率模型的推断 
.. 示例 
. 追踪复杂世界 
.. 示例：多目标跟踪 
.. 示例：交通监控 
. 作为概率模型的程序 
.. 示例：文本阅读 
.. 语法与语义 
.. 推断结果 
.. 结合马尔可夫模型改进生成程序 
.. 生成程序的推断 
小结 
参考文献与历史注释 
第  章 做简单决策 
. 在不确定性下结合信念与愿望 
. 效用理论基础 
.. 理性偏好的约束 
.. 理性偏好导致效用 
. 效用函数 
.. 效用评估和效用尺度 
.. 金钱的效用 
.. 期望效用与决策后失望 
.. 人类判断与非理性 
. 多属性效用函数 
.. 占优 
.. 偏好结构与多属性效用 
. 决策网络 
.. 使用决策网络表示决策问题 
.. 评估决策网络 
. 信息价值 
.. 简单示例 
.. 完美信息的一般公式 
.. 价值信息的性质 
.. 信息收集智能体的实现 
.. 非短视信息收集 
.. 敏感性分析与健壮决策 
. 未知偏好 
.. 个人偏好的不确定性 
.. 顺从人类 
小结 
参考文献与历史注释 
第  章 做复杂决策 
. 序贯决策问题 
.. 时间上的效用 
.. 最优策略与状态效用 
.. 奖励规模 
.. 表示 MDP 
. MDP 的算法 
.. 价值迭代 
.. 策略迭代 
.. 线性规划 
.. MDP 的在线算法 
. 老虎机问题 
.. 计算基廷斯指数 
.. 伯努利老虎机 
.. 近似最优老虎机策略 
.. 不可索引变体 
. 部分可观测MDP 
. 求解POMDP 的算法 
.. POMDP的价值迭代 
.. POMDP的在线算法 
小结 
参考文献与历史注释 
第  章 多智能体决策 
. 多智能体环境的特性 
.. 单个决策者 
.. 多决策者 
.. 多智能体规划 
.. 多智能体规划：合作与协调 
. 非合作博弈论 
.. 单步博弈：正则形式博弈 
.. 社会福利 
.. 重复博弈 
.. 序贯博弈：扩展形式 
.. 不确定收益与辅助博弈 
. 合作博弈论 
.. 联盟结构与结果 
.. 合作博弈中的策略 
.. 合作博弈中的计算 
. 制定集体决策 
.. 在合同网中分配任务 
.. 通过拍卖分配稀缺资源 
.. 投票 
.. 议价 
小结 
参考文献与历史注释 
第五部分 机器学习
第  章 样例学习 
. 学习的形式 
. 监督学习 
. 决策树学习 
.. 决策树的表达能力 
.. 从样例中学习决策树 
.. 选择测试属性 
.. 泛化与过拟合 
.. 拓展决策树的适用范围 
. 模型选择与模型优化 
.. 模型选择 
.. 从错误率到损失函数 
.. 正则化 
.. 超参数调整 
. 学习理论 
. 线性回归与分类 
.. 单变量线性回归 
.. 梯度下降 
.. 多变量线性回归 
.. 带有硬阈值的线性分类器 
.. 基于逻辑斯谛回归的线性分类器 
. 非参数模型 
.. 最近邻模型 
.. 使用 k-d 树寻找最近邻 
.. 局部敏感哈希 
.. 非参数回归 
.. 支持向量机 
.. 核技巧 
. 集成学习 
.. 自助聚合法 
.. 随机森林法 
.. 堆叠法 
.. 自适应提升法 
.. 梯度提升法 
.. 在线学习 
. 开发机器学习系统 
.. 问题形式化 
.. 数据收集、评估和管理 
.. 模型选择与训练 
.. 信任、可解释性、可说明性 
.. 操作、监控和维护 
小结 
参考文献与历史注释 
第  章 概率模型学习 
. 统计学习 
. 完全数据学习 
.. 最大似然参数学习：离散模型 
.. 朴素贝叶斯模型 
.. 生成模型和判别模型 
.. 最大似然参数学习：连续模型 
.. 贝叶斯参数学习 
.. 贝叶斯线性回归 
.. 贝叶斯网络结构学习 
.. 非参数模型密度估计 
. 隐变量学习：EM 算法 
.. 无监督聚类：学习混合高斯 
.. 学习带隐变量的贝叶斯网络参数值 
.. 学习隐马尔可夫模型 
.. EM 算法的一般形式 
.. 学习带隐变量的贝叶斯网络结构 
小结 
参考文献与历史注释 
第  章 深度学习 
. 简单前馈网络 
.. 网络作为复杂函数 
.. 梯度与学习 
. 深度学习的计算图 
.. 输入编码 
.. 输出层与损失函数 
.. 隐藏层 
. 卷积网络 
.. 池化与下采样 
.. 卷积神经网络的张量运算 
.. 残差网络 
. 学习算法 
.. 计算图中的梯度计算 
.. 批量归一化 
. 泛化 
.. 选择正确的网络架构 
.. 神经架构搜索 
.. 权重衰减 
.. 暂退法 
. 循环神经网络 
.. 训练基本的循环神经网络 
.. 长短期记忆 RNN 
. 无监督学习与迁移学习 
.. 无监督学习 
.. 迁移学习和多任务学习 
. 应用 
.. 视觉 
.. 自然语言处理 
.. 强化学习 
小结 
参考文献与历史注释 
第  章 强化学习 
. 从奖励中学习 
. 被动强化学习 
.. 直接效用估计 
.. 自适应动态规划 
.. 时序差分学习 
. 主动强化学习 
.. 探索 
.. 安全探索 
.. 时序差分 Q 学习 
. 强化学习中的泛化 
.. 近似直接效用估计 
.. 近似时序差分学习 
.. 深度强化学习 
.. 奖励函数设计 
.. 分层强化学习 
. 策略搜索 
. 学徒学习与逆强化学习 
. 强化学习的应用 
.. 在电子游戏中的应用 
.. 在机器人控制中的应用 
小结 
参考文献与历史注释 
第六部分 沟通、感知和行动
第  章 自然语言处理 
. 语言模型 
.. 词袋模型 
.. n 元单词模型 
.. 其他 n 元模型 
.. n 元模型的平滑 
.. 单词表示 
.. 词性标注 
.. 语言模型的比较 
. 文法 
. 句法分析 
.. 依存分析 
.. 从样例中学习句法分析器 
. 扩展文法 
.. 语义解释 
.. 学习语义文法 
. 真实自然语言的复杂性 
. 自然语言任务 
小结 
参考文献与历史注释 
第  章 自然语言处理中的深度学习 
. 词嵌入 
. 自然语言处理中的循环神经网络 
.. 使用循环神经网络的语言模型 
.. 用循环神经网络进行分类 
.. 自然语言处理任务中的 LSTM模型 
. 序列到序列模型 
.. 注意力 
.. 解码 
. Transformer 架构 
.. 自注意力 
.. 从自注意力到 Transformer 
. 预训练和迁移学习 
.. 预训练词嵌入 
.. 预训练上下文表示 
.. 掩码语言模型 
. 最高水平（SOTA） 
小结 
参考文献与历史注释 
第  章 计算机视觉 
. 引言 
. 图像形成 
.. 无透镜成像：针孔照相机 
.. 透镜系统 
.. 缩放正交投影 
.. 光线与明暗 
.. 颜色 
. 简单图像特征 
.. 边缘 
.. 纹理 
.. 光流 
.. 自然图像分割 
. 图像分类 
.. 基于卷积神经网络的图像分类 
.. 卷积神经网络对图像分类问题
有效的原因 
. 物体检测 
. 三维世界 
.. 多个视图下的三维线索 
.. 双目立体视觉 
.. 移动摄像机给出的三维线索 
.. 单个视图的三维线索 
. 计算机视觉的应用 
.. 理解人类行为 
.. 匹配图片与文字 
.. 多视图重建 
.. 单视图中的几何 
.. 生成图片 
.. 利用视觉控制运动 
小结 
参考文献与历史注释 
第  章 机器人学 
. 机器人 
. 机器人硬件 
.. 机器人的硬件层面分类 
.. 感知世界 
.. 产生运动 
. 机器人学解决哪些问题 
. 机器人感知 
.. 定位与地图构建 
.. 其他感知类型 
.. 机器人感知中的监督学习与无监督学习 
. 规划与控制 
.. 构形空间 
.. 运动规划 
.. 轨迹跟踪控制 
.. 最优控制 
. 规划不确定的运动 
. 机器人学中的强化学习 
.. 利用模型 
.. 利用其他信息 
. 人类与机器人 
.. 协调 
.. 学习做人类期望的事情 
. 其他机器人框架 
.. 反应式控制器 
.. 包容架构 
. 应用领域 
小结 
参考文献与历史注释 
第七部分 总结
第  章 人工智能的哲学、伦理和安全性 
. 人工智能的极限 
.. 由非形式化得出的论据 
.. 由能力缺陷得出的论据 
.. 数学异议 
.. 衡量人工智能 
. 机器能真正地思考吗 
.. 中文房间 
.. 意识与感质 
. 人工智能的伦理 
.. 致命性自主武器 
.. 监控、安全与隐私 
.. 公平与偏见 
.. 信任与透明度 
.. 工作前景 
.. 机器人权利 
.. 人工智能安全性 
小结 
参考文献与历史注释 
第  章 人工智能的未来 
. 人工智能组件 
. 人工智能架构 
附录 A 数学背景知识 
附录 B 关于语言与算法的说明 
参考文献 Ⅰ artificial intelligence
 introduction
.what is al?
.the foundations of artificial intelligence
.the history of artificial intelligence
.the state of the art
.summary, bibliographical and historical notes, exercises
 intelligent agents
.agents and environments
.good behavior: the concept of rationality
.the nature of environments
.the structure of agents
.summary, bibliographical and historical notes, exercises
Ⅱ problem-solving
 solving problems by searching
.problem-solving agents
.example problems
.searching for solutions
.uninformed search strategies
.informed (heuristic) search strategies
.heuristic functions
.summary, bibliographical and historical notes, exercises
 beyond classical search
.local search algorithms and optimization problems
.local search in continuous spaces
.searching with nondeterministic actions
.searching with partial observations
.online search agents and unknown environments
.summary, bibliographical and historical notes, exercises
 adversarial search
.games
.optimal decisions in games
.alpha-beta pruning
.imperfect real-time decisions
.stochastic games
.partially observable games
.state-of-the-art game programs
.alternative approaches
.summary, bibliographical and historical notes, exercises
 constraint satisfaction problems
.defining constraint satisfaction problems
.constraint propagation: inference in csps
.backtracking search for csps
.local search for csps
.the structure of problems
.summary, bibliographical and historical notes, exercises
Ⅲ knowledge, reasoning, and planning
 logical agents
.knowledge-based agents
.the wumpus world
.logic
.propositional logic: a very simple logic
.propositional theorem proving
.effective propositional model checking
.agents based on propositional logic
.summary, bibliographical and historical notes, exercises
 first-order logic
.representation revisited
.syntax and semantics of first-order logic
.using first-order logic
.knowledge engineering in first-order logic
.summary, bibliographical and historical notes, exercises
 inference in first-order logic
.propositional vs. first-order inference
.unification and lifting
.forward chaining
.backward chaining
.resolution
.summary, bibliographical and historical notes, exercises
 classical planning
. definition of classical planning
. algorithms for planning as state-space search
. planning graphs
. other classical planning approaches
. analysis of planning approaches
. summary, bibliographical and historical notes, exercises
 planning and acting in the real world
. time, schedules, and resources
. hierarchical planning
. planning and acting in nondeterministic domains
. multiagent planning
. summary, bibliographical and historical notes, exercises
 knowledge representation
. ontological engineering
. categories and objects
. events
. mental events and mental objects
. reasoning systems for categories
. reasoning with default information
. the intemet shopping world
. summary, bibliographical and historical notes, exercises
Ⅳ uncertain knowledge and reasoning
 quantifying uncertainty
. acting under uncertainty
. basic probability notation
. inference using full joint distributions
. independence
. bayes' rule and its use
. the wumpus world revisited
. summary, bibliographical and historical notes, exercises
 probabilistic reasoning
. representing knowledge in an uncertain domain
. the semantics of bayesian networks
. efficient representation of conditional distributions
. exact inference in bayesian networks
. approximate inference in bayesian networks
. relational and first-order probability models
. other approaches to uncertain reasoning
. summary, bibliographical and historical notes, exercises
 probabilistic reasoning over time
. time and uncertainty
. inference in temporal models
. hidden markov models
. kalman filters
. dynamic bayesian networks
. keeping track of many objects
. summary, bibliographical and historical notes, exercises
 making simple decisions
. combining beliefs and desires under uncertainty
. the basis of utility theory
. utility functions
. multiattribute utility functions
. decision networks
. the value of information
. decision-theoretic expert systems
. summary, bibliographical and historical notes, exercises
 making complex decisions
. sequential decision problems
. value iteration
. policy iteration
. partially observable mdps
. decisions with multiple agents: game theory
. mechanism design
. summary, bibliographical and historical notes, exercises
V learning
 learning from examples
. forms of learning
. supervised learning
. leaming decision trees
. evaluating and choosing the best hypothesis
. the theory of learning
. regression and classification with linear models
. artificial neural networks
. nonparametric models
. support vector machines
. ensemble learning
. practical machine learning
. summary, bibliographical and historical notes, exercises
 knowledge in learning
. a logical formulation of learning
. knowledge in learning
. explanation-based learning
. learning using relevance information
. inductive logic programming
. summary, bibliographical and historical notes, exercis
 learning probabilistic models
. statistical learning
. learning with complete data
. learning with hidden variables: the em algorithm.
. summary, bibliographical and historical notes, exercis
 reinforcement learning
. l introduction
. passive reinforcement learning
. active reinforcement learning
. generalization in reinforcement learning
. policy search
. applications of reinforcement learning
. summary, bibliographical and historical notes, exercis
VI communicating, perceiving, and acting
 natural language processing
. language models
. text classification
. information retrieval
. information extraction
. summary, bibliographical and historical notes, exercis
 natural language for communication
. phrase structure grammars
. syntactic analysis (parsing)
. augmented grammars and semantic interpretation
. machine translation
. speech recognition
. summary, bibliographical and historical notes, exercis
 perception
. image formation
. early image-processing operations
. object recognition by appearance
. reconstructing the d world
. object recognition from structural information
. using vision
. summary, bibliographical and historical notes, exercises
 robotics
. introduction
. robot hardware
. robotic perception
. planning to move
. planning uncertain movements
. moving
. robotic software architectures
. application domains
. summary, bibliographical and historical notes, exercises
VII conclusions
 philosophical foundations
. weak ai: can machines act intelligently?
. strong ai: can machines really think?
. the ethics and risks of developing artificial intelligence
. summary, bibliographical and historical notes, exercises
 al: the present and future
. agent components
. agent architectures
. are we going in the right direction?
. what if ai does succeed?
a mathematical background
a. complexity analysis and o notation
a. vectors, matrices, and linear algebra
a. probability distributions
b notes on languages and algorithms
b.defining languages with backus-naur form (bnf)
b.describing algorithms with pseudocode
b.online help
bibliography
index
・ ・ ・ ・ ・ ・ (收起)第章 AIGC为何引发关注
.　《太空歌剧院》带来的冲击和影响　
.　“生成”所引发的创意性工作革新　
.　内容生成方式进入新阶段　
.　AIGC在绘画领域率先破圈　
.　典型的AIGC模型　
海外模型　
国内模型　
第章 模型即服务时代的到来
.　模型即服务的历史进程　
早期人工智能在曲折中探索　
深度学习引发关注　
.　典型的深度学习网络　
生成对抗网络　
Transformer　
.　大公司探索之路　
DeepMind　
OpenAI　
.　基础模型普及的关键节点　
基础模型的能力与服务　
曾经热议的云，今后的基础模型　
基础模型的通用性　
.　人工智能的未来何在　
人工智能逐步接近人类的思考模式　
未来人工智能的发展特点　
第章 ChatGPT引发的潮流与思考
.　ChatGPT会成为人工智能的拐点吗　
引发全球关注的ChatGPT　
ChatGPT潜在的应用领域　
.　ChatGPT能力大揭秘　
.　ChatGPT是OpenAI对大模型的坚定实践　
.　ChatGPT的局限性及其引发的思考　
技术创新性与工程创新性　
知识局限性　
盈利与成本之间的平衡　
应用落地所面临的困境　
法律合规与应用抵制　
网络安全风险　
能耗挑战　
.　ChatGPT引发的思考　
如何看待人类创新与机器创新　
ChatGPT在哪些方面值得我们学习　
.?GPT-未来已来，奇点时刻该如何面对　
多模态　
提示工程的价值　
安全隐忧　
第章 大模型驱动的人工智能绘画“创作”
.　AI绘画的先驱――AARON　
.　人工智能绘画的原理　
神经网络是如何模仿人类思考的　
如何让神经网络画一幅画　
.　人工智能学习如何画一只猫　
教会你的神经网络认识“猫咪”　
人工智能真的画出了猫咪　
.　DALL-E的初次尝试与突破　
.　人工智能绘画的技术创新点　
CLIP实现跨模态创新，打造图文匹配　
用Diffusion加速AIGC落地普及　
Diffusion模型为AIGC写下的注脚　
Stable Diffusion岂止于开源　
AIGC进一步降低模型的使用门槛　
.　使AIGC绘画技术成熟的重要因素　
提示词的重要性　
算力资源的关键支撑　
第章 人类的创新能力会被AIGC替代吗
.　艺术创作会被AIGC取代吗　
用户的猎奇与创作者的抵触　
AIGC不会取代艺术创作工作　
使用AIGC，需要具备什么能力　
AIGC是直接消费品还是工具　
.　创作者如何通过AIGC获得更大的收益　
如何将AIGC应用于创作　
创意工作者的收益探索　
未来人工智能创作艺术的个层次　
.　AIGC――你的“达・芬奇”　
内容输出的“平民化”　
大众与艺术家“直连”　
实时互动和精准化构建的“即时满足”　
社区与共创的“想象力”　
基于生成全新内容的平台　
.　抓住AIGC的机遇　
AIGC时代，做“短信”还是“微信”　
AIGC的发展仍无法脱离技术周期　
第章 开源成就行业发展的未来
.　开源让我们站在巨人的肩膀上　
.　开源成为引爆AIGC的导火索　
.　大模型的开源之路　
第章 AIGC与商业化
.　AIGC商业化的个阶段　
感知冲击――尝鲜阶段　
认知领悟――协助阶段　
新生态链――原创阶段　
.　AI领域的企业发展　
平台型企业　
应用型企业　
现有产品的智能化　
.　当下典型的AIGC变现手段　
按照计算量收费　
按照输出图像数量收费　
软件按月付费　
模型训练费　
.　AIGC商业模式的困境　
AIGC Inside的商业化并不容易　
难以建立技术壁垒　
探索自主的大模型及应用　
第章 AIGC的典型应用
.　文字创作　
主要特点　
典型应用　
.　音频生成　
主要特点　
典型应用　
.　视频生成　
主要特点　
典型应用　
.　D模型生成　
主要特点　
典型应用　
.　编写代码　
主要特点　
典型应用　
.　游戏创作开发　
主要特点　
典型应用　
.　绘画产品　
典型绘画产品的AIGC应用　
AIGC绘画与NFT结合　
.　建筑设计　
将AIGC融入建筑设计　
用AIGC实现装修设计　
.　其他应用　
DIY设计　
儿童创意实现　
内容营销　
诊疗与心灵慰藉　
第章 AIGC的不足与挑战
.　技术与产业方面的不足与挑战　
细节仍需打磨　
成本问题　
输出结果不一致　
大模型到大应用的挑战　
通用性较差　
.　在确权方面面临的挑战　
AIGC作品的著作权归属　
著作权争议的潜在解决方案　
法律监管出现争议　
企业态度不统一　
伦理与安全风险　
第章 业界和学界的专家洞察
.　AIGC可扩展潜力巨大，可能掀起新一波创新创业浪潮　
从AIGC到AIGS，“服务规模化的个性化”时代到来　
从科技圈体验到全民使用，AI首次成功破圈　
OpenAI已经成功探索出AI领域科技创新落地的新模式　
中国需要自主大模型，也有可能探索出自己的创新　
.　AIGC火热的背后，需要深度思考治理难题　
破解“克林格里奇困境”，要靠更敏捷的治理思路　
加强对弱势群体的保护，平台应该做好“守门人”　
AIGC内容知识产权还没有定论，但业界已有基本共识　
探索人工智能领域“数据合作”新范式　
.　AIGC火热背后的业界冷思考：中国AI行业的未来发展，需要有自己的思路　
ChatGPT的流畅对话来源于预训练大模型　
“AI幻觉”仍是阻碍产业发展的难题　
大规模预训练技术仍处于早期探索阶段，人工智能公司还需耐心打磨　
在AIGC技术浪潮中，一些行业将迎来全新挑战　
中国AI行业的未来发展，需要有自己的思考和思路　
・ ・ ・ ・ ・ ・ (收起)第 章　从数学建模到人工智能 
.　数学建模　
..　数学建模与人工智能　
..　数学建模中的常见问题　
.　人工智能下的数学　
..　统计量　
..　矩阵概念及运算　
..　概率论与数理统计　
..　高等数学――导数、微分、不定积分、定积分　
第　章 Python快速入门　
.　安装Python　
..　Python安装步骤　
..　IDE的选择　
.　Python基本操作　
..　第 一个小程序　
..　注释与格式化输出　
..　列表、元组、字典　
..　条件语句与循环语句　
..　break、continue、pass　
.　Python高级操作　
..　lambda　
..　map　
..　filter　
第章　Python科学计算库NumPy　
.　NumPy简介与安装　
..　NumPy简介　
..　NumPy安装　
.　基本操作　
..　初识NumPy　
..　NumPy数组类型　
..　NumPy创建数组　
..　索引与切片　
..　矩阵合并与分割　
..　矩阵运算与线性代数　
..　NumPy的广播机制　
..　NumPy统计函数　
..　NumPy排序、搜索　
..　NumPy数据的保存　
第章　常用科学计算模块快速入门　
.　Pandas科学计算库　
..　初识Pandas　
..　Pandas基本操作　
.　Matplotlib可视化图库　
..　初识Matplotlib　
..　Matplotlib基本操作　
..　Matplotlib绘图案例　
.　SciPy科学计算库　
..　初识SciPy　
..　SciPy基本操作　
..　SciPy图像处理案例　
第章　Python网络爬虫　
.　爬虫基础　
..　初识爬虫　
..　网络爬虫的算法　
.　爬虫入门实战　
..　调用API　
..　爬虫实战　
.　爬虫进阶―高效率爬虫　
..　多进程　
..　多线程　
..　协程　
..　小结　
第章　Python数据存储　
.　关系型数据库MySQL　
..　初识MySQL　
..　Python操作MySQL　
.　NoSQL之MongoDB　
..　初识NoSQL　
..　Python操作MongoDB　
.　本章小结　
..　数据库基本理论　
..　数据库结合　
..　结束语　
第章　Python数据分析　
.　数据获取　
..　从键盘获取数据　
..　文件的读取与写入　
..　Pandas读写操作　
.　数据分析案例　
..　普查数据统计分析案例　
..　小结　
第章　自然语言处理　
.　Jieba分词基础　
..　Jieba中文分词　
..　Jieba分词的种模式　
..　标注词性与添加定义词　
.　关键词提取　
..　TF-IDF关键词提取　
..　TextRank关键词提取　
.　wordvec介绍　
..　wordvec基础原理简介　
..　wordvec训练模型　
..　基于gensim的wordvec实战　
第章　从回归分析到算法基础　
.　回归分析简介　
..　“回归”一词的来源　
..　回归与相关　
..　回归模型的划分与应用　
.　线性回归分析实战　
..　线性回归的建立与求解　
..　Python求解回归模型案例　
..　检验、预测与控制　
第　章 从K-Means聚类看算法调参　
.　K-Means基本概述　
..　K-Means简介　
..　目标函数　
..　算法流程　
..　算法优缺点分析　
.　K-Means实战　
第　章 从决策树看算法升级　
.　决策树基本简介　
.　经典算法介绍　
..　信息熵　
..　信息增益　
..　信息增益率
..　基尼系数　
..　小结　
.　决策树实战　
..　决策树回归　
..　决策树的分类　
第　章 从朴素贝叶斯看算法多变　
.　朴素贝叶斯简介　
..　认识朴素贝叶斯　
..　朴素贝叶斯分类的工作过程　
..　朴素贝叶斯算法的优缺点　
.　种朴素贝叶斯实战　
第　章 从推荐系统看算法场景　
.　推荐系统简介　
..　推荐系统的发展　
..　协同过滤　
.　基于文本的推荐　
..　标签与知识图谱推荐案例　
..　小结　
第　章 从TensorFlow开启深度学习之旅　
.　初识TensorFlow　
..　什么是TensorFlow　
..　安装TensorFlow　
..　TensorFlow基本概念与原理　
.　TensorFlow数据结构　
..　阶　
..　形状　
..　数据类型　
.　生成数据十二法　
..　生成Tensor　
..　生成序列　
..　生成随机数　
.　TensorFlow实战　
参考文献　
・ ・ ・ ・ ・ ・ (收起)目 录

第章 人工智能初印象 
. 什么是人工智能？ 
.. 定义AI 
.. 理解数据是智能算法的核心 
.. 把算法看作“菜谱” 
. 人工智能简史 
. 问题类型与问题解决范式 
. 人工智能概念的直观印象 
. 人工智能算法的用途 
.. 农业：植物种植优化 
.. 银行业：欺诈检测 
.. 网络安全：攻击检测与处理 
.. 医疗：智能诊断 
.. 物流：路径规划与优化 
.. 通信：网络优化 
.. 游戏：主体创造 
.. 艺术：创造杰出作品 
. 本章小结 
第章 搜索算法基础 
. 什么是规划与搜索？ 
. 计算成本：需要智能算法的原因 
. 适合用搜索算法的问题 
. 表示状态：创建一个表示问题空间与解的框架 
.. 图：表示搜索问题与解 
.. 用具体的数据结构表示图 
.. 树：表示搜索结果的具体结构 
. 无知搜索：盲目地找寻解 
. 广度优先搜索：先看广度，再看深度 
. 深度优先搜索：先看深度，再看广度 
. 盲目搜索算法的用例 
. 可选：关于图的类别 
. 可选：其他表示图的方法 
.. 关联矩阵 
.. 邻接表 
. 本章小结 
第章 智能搜索 
. 定义启发式方法：设计有根据的猜测 
. 知情搜索：在指导下寻求解决方案 
.. A*搜索 
.. 知情搜索算法的用例 
. 对抗性搜索：在不断变化的环境中寻找解决方案 
.. 一个简单的对抗性问题 
.. 最小-最大搜索：模拟行动并选择最好的未来 
.. 启发式 
.. 阿尔法-贝塔剪枝：仅探索合理的路径 
.. 对抗搜索算法的典型案例 
. 本章小结 
第章 进化算法 
. 什么是进化？ 
. 适合用进化算法的问题 
. 遗传算法的生命周期 
. 对解空间进行编码 
. 创建解决方案种群 
. 衡量种群中个体的适应度 
. 根据适应度得分筛选亲本 
. 由亲本繁殖个体 
.. 单点交叉：从每个亲本继承一部分 
.. 两点交叉：从每个亲本继承多个部分 
.. 均匀交叉：从每个亲本继承多个部分 
.. 二进制编码的位串突变 
.. 二进制编码的翻转位突变 
. 繁衍下一代 
.. 探索与挖掘 
.. 停止条件 
. 遗传算法的参数配置 
. 进化算法的用例 
. 本章小结 
第章 进化算法(高级篇) 
. 进化算法的生命周期 
. 其他筛选策略 
.. 排序筛选法：均分赛场 
.. 联赛筛选法：分组对抗 
.. 精英筛选法：只选最好的 
. 实值编码：处理真实数值 
.. 实值编码的核心概念 
.. 算术交叉：数学化繁殖 
.. 边界突变 
.. 算术突变 
. 顺序编码：处理序列 
.. 适应度函数的重要性 
.. 顺序编码的核心概念 
.. 顺序突变：适用于顺序编码 
. 树编码：处理层次结构 
.. 树编码的核心概念 
.. 树交叉：继承树的分支 
.. 节点突变：更改节点的值 
. 常见进化算法 
.. 遗传编程 
.. 进化编程 
. 进化算法术语表 
. 进化算法的其他用例 
. 本章小结 
第章 群体智能：蚁群优化 
. 什么是群体智能？ 
. 适合用蚁群优化算法的问题 
. 状态表达：如何表达蚂蚁和路径？ 
. 蚁群优化算法的生命周期 
.. 初始化信息素印迹 
.. 建立蚂蚁种群 
.. 为蚂蚁选择下一个访问项目 
.. 更新信息素印迹 
.. 更新最佳解决方案 
.. 确定终止条件 
. 蚁群优化算法的用例 
. 本章小结 
第章 群体智能：粒子群优化 
. 什么是粒子群优化？ 
. 优化问题：略偏技术性的观点 
. 适合用粒子群优化算法的问题 
. 状态表达：粒子是什么样的？ 
. 粒子群优化的生命周期 
.. 初始化粒子群 
.. 计算粒子的适应度 
.. 更新粒子的位置 
.. 确定终止条件 
. 粒子群优化算法的用例 
. 本章小结 
第章 机器学习 
. 什么是机器学习？ 
. 适合用机器学习的问题 
.. 监督学习 
.. 非监督学习 
.. 强化学习 
. 机器学习的工作流程 
.. 收集和理解数据：掌握数据背景 
.. 准备数据：清洗和整理 
.. 训练模型：用线性回归预测 
.. 测试模型：验证模型精度 
.. 提高准确性 
. 分类问题：决策树 
.. 分类问题：非此即彼 
.. 决策树的基础知识 
.. 训练决策树 
.. 用决策树对实例进行分类 
. 其他常见的机器学习算法 
. 机器学习算法的用例 
. 本章小结 
第章 人工神经网络 
. 什么是人工神经网络？ 
. 感知器：表征神经元 
. 定义人工神经网络 
. 前向传播：使用训练好的人工神经网络 
. 反向传播：训练人工神经网络 
. 激活函数一览 
. 设计人工神经网络 
. 人工神经网络的类型和用例 
.. 卷积神经网络 
.. 递归神经网络 
.. 生成对抗网络 
. 本章小结 
第章 基于Q-learning的强化学习 
. 什么是强化学习？ 
. 适合用强化学习的问题 
. 强化学习的生命周期 
.. 模拟与数据：环境重现 
.. 使用Q-learning模拟训练 
.. 模拟并测试Q表 
.. 衡量训练的性能 
.. 无模型和基于模型的学习 
. 强化学习的深度学习方法 
. 强化学习的用例 
.. 机器人技术 
.. 推荐引擎 
.. 金融贸易 
.. 电子游戏 
. 本章小结 
・ ・ ・ ・ ・ ・ (收起)第一部分引言
第　章人工智能概述　
.　引言　
..　人工智能的定义　
..　思维是什么？智能是什么？　
.　图灵测试　
..　图灵测试的定义　
..　图灵测试的争议和批评　
.　强人工智能与弱人工智能　
.　启发法　
..　长方体的对角线：解决一个相对简单但相关的
问题　
..　水壶问题：向后倒推　
.　识别适用人工智能来求解的问题　
.　应用和方法　
..　搜索算法和拼图　
..　二人博弈　
..　自动推理　
..　产生式规则和专家系统　
..　细胞自动机　
..　神经计算　
..　遗传算法　
..　知识表示　
..　不确定性推理　
.　人工智能的早期历史　
.　人工智能的近期历史到现在　
..　博弈　
..　专家系统　
..　神经计算　
..　进化计算　
..　自然语言处理　
..　生物信息学　
.　新千年人工智能的发展　
.　本章小结　
第二部分　基础知识
第　章盲目搜索　
.　简介：智能系统中的搜索　
.　状态空间图　
.　生成与测试范式　
..　回溯　
..　贪婪算法　
..　旅行销售员问题　
.　盲目搜索算法　
..　深度优先搜索　
..　广度优先搜索　
.　盲目搜索算法的实现和比较　
..　实现深度优先搜索　
..　实现广度优先搜索　
..　问题求解性能的测量指标　
..　DFS和BFS的比较　
.　本章小结　
第章　知情搜索　
.　引言　
.　启发法　
.　知情搜索（第一部分）――找到任何解　
..　爬山法　
..　最陡爬坡法　
.　最佳优先搜索　
.　集束搜索　
.　搜索算法的其他指标　
.　知情搜索（第二部分）――找到最佳解　
..　分支定界法　
..　使用低估值的分支定界法　
..　采用动态规划的分支定界法　
..　A*搜索　
.　知情搜索（第三部分）―高级搜索算法　
..　约束满足搜索　
..　与或树　
..　双向搜索　
.　本章小结　
第章　博弈中的搜索　
.　引言　
.　博弈树和极小化极大评估　
..　启发式评估　
..　博弈树的极小化极大评估　
.　具有α-剪枝的极小化极大算法　
.　极小化极大算法的变体和改进　
..　负极大值算法　
..　渐进深化法　
..　启发式续篇和地平线效应　
.　概率游戏和预期极小化极大值算法　
.　博弈理论　
迭代的囚徒困境　
.　本章小结　
第章　人工智能中的逻辑　
.　引言　
.　逻辑和表示　
.　命题逻辑　
..　命题逻辑―基础　
..　命题逻辑中的论证　
..　证明命题逻辑论证有效的第二种方法　
.　谓词逻辑――简要介绍　
..　谓词逻辑中的合一　
..　谓词逻辑中的反演　
..　将谓词表达式转换为子句形式　
.　其他一些逻辑　
..　二阶逻辑　
..　非单调逻辑　
..　模糊逻辑　
..　模态逻辑　
.　本章小结　
第章　知识表示　
.　引言　
.　图形草图和人类视窗　
.　图和哥尼斯堡桥问题　
.　搜索树　
.　表示方法的选择　
.　产生式系统　
.　面向对象　
.　框架法　
.　脚本和概念依赖系统　
.　语义网络　
.　关联　
.　新近的方法　
..　概念地图　
..　概念图　
..　Baecker的工作　
.　智能体：智能或其他　
..　智能体的一些历史　
..　当代智能体　
..　语义网　
..　IBM眼中的未来世界　
..　作者的观点　
.　本章小结　
第章　产生式系统　
.　引言　
.　背景　
.　基本示例　
.　CARBUYER系统　
.　产生式系统和推导方法　
..　冲突消解　
..　正向链接　
..　反向链接　
.　产生式系统和细胞自动机　
.　随机过程与马尔可夫链　
.　本章小结　
第三部分　基于知识的系统
第章　人工智能中的不确定性　
.　引言　
.　模糊集　
.　模糊逻辑　
.　模糊推理　
.　概率理论和不确定性　
.　本章小结　
第章　专家系统　
.　引言　
.　背景　
.　专家系统的特点　
.　知识工程　
.　知识获取　
.　经典的专家系统　
..　DENDRAL　
..　MYCIN　
..　EMYCIN　
..　PROSPECTOR　
..　模糊知识和贝叶斯规则　
.　提高效率的方法　
..　守护规则　
..　Rete算法　
.　基于案例的推理　
.　更多最新的专家系统　
..　改善就业匹配系统　
..　振动故障诊断的专家系统　
..　自动牙科识别　
..　更多采用案例推理的专家系统　
.　本章小结　
第　章机器学习第一部分　
.　引言　
.　机器学习：简要概述　
.　机器学习系统中反馈的作用　
.　归纳学习　
.　利用决策树进行学习　
.　适用于决策树的问题　
.　熵　
.　使用ID构建决策树　
.　其余问题　
.　本章小结　
第　章机器学习第二部分：神经网络　
.　引言　
.　人工神经网络的研究　
.　麦卡洛克-皮茨网络　
.　感知器学习规则　
.　增量规则　
.　反向传播　
.　实现关注点　
..　模式分析　
..　训练方法　
.　离散型霍普菲尔德网络　
.　应用领域　
.　本章小结　
第　章受到自然启发的搜索　
.　引言　
.　模拟退火　
.　遗传算法　
.　遗传规划　
.　禁忌搜索　
.　蚂蚁聚居地优化　
.　本章小结　
第四部分　高级专题
第　章自然语言处理　
.　引言　
.　概述：语言的问题和可能性　
.　自然语言处理的历史　
..　基础期（世纪年代和年代）　
..　符号与随机方法（―）　
..　种范式（―）　
..　经验主义和有限状态模型（―）　
..　大融合（―）　
..　机器学习的兴起（―）　
.　句法和形式语法　
..　语法类型　
..　句法解析：CYK算法　
.　语义分析和扩展语法　
..　转换语法　
..　系统语法　
..　格语法　
..　语义语法　
..　Schank系统　
.　NLP中的统计方法　
..　统计解析　
..　机器翻译（回顾）和IBM的Candide系统　
..　词义消歧　
.　统计NLP的概率模型　
..　隐马尔可夫模型　
..　维特比算法　
.　统计NLP语言数据集　
..　宾夕法尼亚州树库项目　
..　WordNet　
..　NLP中的隐喻模型　
.　应用：信息提取和问答系统　
..　问答系统　
..　信息提取　
.　现在和未来的研究（基于CHARNIAK的工作）　
.　语音理解　
.　语音理解技术的应用　
.　本章小结　
第　章自动规划　
.　引言　
.　规划问题　
..　规划术语　
..　规划应用示例　
.　一段简短的历史和一个著名的问题　
.　规划方法　
..　规划即搜索　
..　部分有序规划　
..　分级规划　
..　基于案例的规划　
..　规划方法集锦　
.　早期规划系统　
..　STRIPS　
..　NOAH　
..　NONLIN　
.　更多现代规划系统　
..　O-PLAN　
..　Graphplan　
..　规划系统集锦　
..　学习系统的规划方法　
..　SCIBox自动规划器　
.　本章小结　
第五部分　现在和未来
第　章机器人技术　
.　引言　
.　历史：服务人类、仿效人类、增强人类和替代人类　
..　早期机械机器人　
..　电影与文学中的机器人　
..　世纪早期的机器人　
.　技术问题　
..　机器人的组件　
..　运动　
..　点机器人的路径规划　
..　移动机器人运动学　
.　应用：世纪的机器人　
.　本章小结　
第　章高级计算机博弈　
.　引言　
.　跳棋：从塞缪尔到舍弗尔　
..　在跳棋博弈中用于机器学习的启发式方法　
..　填鸭式学习与概括　
..　签名表评估和棋谱学习　
..　含有奇诺克程序的世界跳棋锦标赛　
..　彻底解决跳棋游戏　
.　国际象棋：人工智能的“果蝇”　
..　计算机国际象棋的历史背景　
..　编程方法　
..　超越地平线效应　
..　DeepThought和DeepBlue与特级大师的比赛（―年）　
.　计算机国际象棋对人工智能的贡献　
..　在机器中的搜索　
..　在搜索方面，人与机器的对比　
..　启发式、知识和问题求解　
..　蛮力：知识vs.搜索；表现vs.能力　
..　残局数据库和并行计算　
..　本书第一作者的贡献　
.　其他博弈　
..　奥赛罗　
..　西洋双陆棋　
..　桥牌　
..　扑克　
.　围棋：人工智能的“新果蝇”？　
.　本章小结　
第　章大事记　
.　引言　
.　提纲挈领――概述　
.　普罗米修斯归来　
.　提纲挈领――介绍人工智能的成果　
.　IBM的沃森-危险边缘挑战赛　
.　世纪的人工智能　
.　本章小结　
附录A　CLIPS示例：专家系统外壳　
附录B　用于隐马尔可夫链的维特比算法的实现（由HarunIftikhar提供）　
附录C　对计算机国际象棋的贡献：令人惊叹的WalterShawnBrowne　
附录D　应用程序和数据　
附录E　部分练习的答案　
・ ・ ・ ・ ・ ・ (收起)第章 绪论
第章 数学基础
. 导数
. 概率论基础
. 矩阵基础
习题
第章 搜索
引言
. 搜索问题的定义
. 搜索算法基础
. 盲目搜索
. 启发式搜索
. 局部搜索
. 对抗搜索
本章总结
历史回顾
习题
第章 机器学习
引言
. 监督学习的概念
. 数据集与损失函数
. 泛化
. 过拟合与欠拟合
. 创建数据集
. 无监督学习与半监督学习
本章总结
历史回顾
习题
参考文献
第章 线性回归
引言
. 线性回归
. 优化方法
. 二分类问题
. 多分类问题
. 岭回归
. 套索回归
. 支持向量机算法
本章总结
习题
第章 决策树模型
引言
. 决策树的例子
. 决策树的定义
. 决策树的训练算法
本章总结
历史回顾
习题
参考文献
第章 集成学习
引言
. 集成学习
. 随机森林
. 梯度提升
本章总结
历史回顾
习题
参考文献
第章 神经网络初步
引言
. 深度线性网络
. 非线性神经网络
. 反向传播计算导数
. 优化器
. 权值初始化
. 权值衰减
. 权值共享与卷积
. 循环神经网络
本章总结
历史回顾
习题
第章 计算机视觉
引言
. 什么是计算机视觉
. 图像的形成
. 线性滤波器
. 边缘检测
. 立体视觉
. 卷积神经网络
. 物体检测
. 语义分割
本章总结
历史回顾
习题
参考文献
第章 自然语言处理
引言
. 语言模型
. 向量语义
. 基于神经网络的语言模型处理
. 基于神经网络的机器翻译
. 语言模型预训练
本章总结
历史回顾
习题
第章 马尔可夫决策过程与强化学习
引言
. 马尔可夫链
. 马尔可夫决策过程
. 马尔可夫决策过程的求解算法及分析
. 强化学习
本章总结
历史回顾
参考文献
习题
附录A 数学基础
A. 导数
A. 概率
A. 矩阵
・ ・ ・ ・ ・ ・ (收起)第 章 人工智能与数学基础..........
. 什么是人工智能............................ 
. 人工智能的发展 ............................ 
. 人工智能的应用 ............................ 
. 学习人工智能需要哪些知识 ............. 
. 为什么要学习数学 ......................... 
. 本书包括的数学知识 ...................... 
第  篇
基础篇................................................................. 
第  章 高等数学基础 ................. 
. 函数.......................................... 
. 极限..........................................
. 无穷小与无穷大...........................
. 连续性与导数..............................
. 偏导数...................................... 
. 方向导数................................... 
. 梯度......................................... 
. 综合实例―梯度下降法求函数的最小值.......................................
. 高手点拨................................... 
. 习题....................................... 
第  章 微积分..............................
. 微积分的基本思想 ....................... 
. 微积分的解释..............................
. 定积分...................................... 
. 定积分的性质............................. 
. 牛顿―莱布尼茨公式.................... 
. 综合实例―Python 中常用的定积分求解方法................................... 
. 高手点拨....................................
. 习题 ........................................ 
第  章 泰勒公式与拉格朗日乘子法..............................
. 泰勒公式出发点.......................... 
. 一点一世界................................ 
. 阶数和阶乘的作用....................... 
. 麦克劳林展开式的应用..................
. 拉格朗日乘子法.......................... 
. 求解拉格朗日乘子法.................... 
. 综合实例―编程模拟实现 sinx 的n 阶泰勒多项式并验证结果.................. 
. 高手点拨 ................................... 
. 习题 ......................................... 
第 篇
核心篇............................................................... 
第  章 将研究对象形式化―线性代数基础 ..........................
. 向量..........................................
. 矩阵......................................... 
. 矩阵和向量的创建....................... 
. 特殊的矩阵................................ 
. 矩阵基本操作..............................
. 转置矩阵和逆矩阵....................... 
. 行列式..................................... 
. 矩阵的秩..................................
. 内积与正交...............................
. 综合实例―线性代数在实际问题中的应用 ....................................... 
. 高手点拨 ................................ 
. 习题......................................
第  章 从数据中提取重要信息―特征值与矩阵分解..........
. 特征值与特征向量 .....................
. 特征空间..................................
. 特征值分解...............................
. SVD 解决的问题.......................
. 奇异值分解（SVD）..................
. 综合实例 ―利用 SVD 对图像进行压缩 .......................................
. 综合实例 ―利用 SVD 推荐商品 .......................................
. 高手点拨..................................
. 习题 .......................................
第  章 描述统计规律 ―概率论基础................................
. 随机事件及其概率 ......................
. 条件概率.................................. 
. 独立性.....................................
. 随机变量..................................
. 二维随机变量............................
. 边缘分布..................................
. 综合实例―概率的应用.............
. 高手点拨.................................. 
. 习题........................................
第  章 描述统计规律 ―随机变量与概率估计........................
. 随机变量的数字特征 ..................
. 大数定律和中心极限定理.............
. 数理统计基本概念......................
. 最大似然估计........................... 
. 最大后验估计........................... 
. 综合实例 ―贝叶斯用户满意度预测 ...................................... 
. 综合实例 ―最大似然法求解模型参数 .......................................
. 高手点拨 ................................ 
. 习题 ....................................... 
第  篇
提高篇............................................................. 
第  章 随机变量的几种分布...... 
. 正态分布 ................................ 
. 二项分布................................. 
. 泊松分布................................. 
. 均匀分布..................................
. 卡方分布................................. 
. Beta 分布 .............................. 
. 综合实例―估算棒球运动员的击中率 ...................................... 
. 高手点拨 ................................ 
. 习题 ...................................... 
第  章 数据的空间变换―核函数变换............................. 
. 相关知识简介 ......................... 
. 核函数的引入 ......................... 
. 核函数实例............................ 
. 常用核函数.............................
. 核函数的选择......................... 
. SVM 原理 ............................ 
. 非线性 SVM 与核函数的引入.... 
. 综合实例―利用 SVM 构建分类
问题......................................
. 高手点拨................................
. 习题 ................................... 
第  章 熵与激活函数 .............. 
. 熵和信息熵............................ 
. 激活函数 ............................... 
. 综合案例―分类算法中信息熵的应用...................................... 
. 高手点拨 ................................
. 习题 ..................................... 
第 篇
应用篇............................................................. 
第  章 假设检验 ..................... 
. 假设检验的基本概念................. 
. Z 检验 ...................................
. t 检验 ................................... 
. 卡方检验............................... 
. 假设检验中的两类错误 ..............
. 综合实例 ―体检数据中的假设检验问题..................................... 
. 综合实例 ―种族对求职是否有影响..................................... 
. 高手点拨............................... 
. 习题..................................... 
 章 相关分析...................... 
. 相关分析概述.......................... 
. 皮尔森相关系数....................... 
. 相关系数的计算与假设检验........ 
. 斯皮尔曼等级相关.................... 
. 肯德尔系数............................. 
. 质量相关分析.......................... 
. 品质相关分析.......................... 
. 偏相关与复相关....................... 
. 综合实例―相关系数计算........ 
. 高手点拨.............................. 
. 习题..................................... 
第  章 回归分析......................
. 回归分析概述...........................
. 回归方程推导及应用..................
. 回归直线拟合优度.....................
. 线性回归的模型检验..................
. 利用回归直线进行估计和预测......
. 多元与曲线回归问题..................
. Python 工具包....................... 
. 综合实例―个人医疗保费预测任务...................................... 
. 高手点拨................................ 
. 习题..................................... 
第  章 方差分析......................
. 方差分析概述.......................... 
. 方差的比较............................. 
. 方差分析.................................
. 综合实例―连锁餐饮用户评级分析...................................... 
. 高手点拨................................ 
. 习题...................................... 
第  章 聚类分析......................
. 聚类分析概述.......................... 
. 层次聚类................................ 
. K-Means 聚类...................... 
. DBSCAN 聚类....................... 
. 综合实例―聚类分析.............. 
. 高手点拨.................................
. 习题.......................................
第  章 贝叶斯分析....................
. 贝叶斯分析概述........................
. MCMC 概述.......................... 
. MCMC 采样 ......................... 
. Gibbs 采样........................... 
. 综合实例―利用 PyMC 实现随机模拟样本分布......................... 
. 高手点拨............................... 
. 习题..................................... 
・ ・ ・ ・ ・ ・ (收起)出版者的话
专家指导委员会
译者序
序
第版序
致谢
第章 基于知识的智能系统概述
. 智能机器概述
. 人工智能发展历史
. 小结
复习题
参考文献
第章 基于规则的专家系统
. 知识概述
. 规则是一种知识表达技术
. 专家系统研发团队中的主要参与者
. 基于规则的专家系统的结构
. 专家系统的基本特征
. 前向链接和后向链接推理技术
. 实例
. 冲突的解决方案
. 基于规则的专家系统的优缺点
. 小结
复习题
参考文献
第章 基于规则的专家系统的不确定管理
. 不确定性简介
. 基本概率论
. 贝叶斯推理
. FORECAST：贝叶斯证据累积
. 贝叶斯方法的偏差
. 确定因子理论和证据推理
. FORECAST：确定因子的应用
. 贝叶斯推理和确定因子的比较
. 小结
复习题
参考文献
第章 模糊专家系统
. 概述
. 模糊集
. 语言变量和模糊限制语
. 模糊集的操作
. 模糊规则
. 模糊推理
. 建立模糊专家系统
. 小结
复习题
参考文献
参考书目
第章 基于框架的专家系统
. 框架简介
. 作为知识表达技术的框架
. 基于框架系统中的继承
. 方法和守护程序
. 框架和规则的交互
. 基于框架的专家系统实例：Buy Smart
. 小结
复习题
参考文献
参考书目
第章 人工神经网络
. 人脑工作机制简介
. 作为简单计算元素的神经元
. 感知器
. 多层神经网络
. 多层神经网络的加速学习
. Hopfield神经网络
. 双向相关记忆
. 自组织神经网络
. 小结
复习题
参考文献
第章 进化计算
. 进化是智能的吗
. 模拟自然进化
. 遗传算法
. 遗传算法如何工作
. 实例：用遗传算法来维护计划
. 进化策略
. 遗传编程
. 小结
复习题
参考文献
参考书目
第章 混合智能系统
. 概述
. 神经专家系统
. 神经模糊系统
. ANFIS：自适应性神经模糊推理系统
. 进化神经网络
. 模糊进化系统
. 小结
复习题
参考文献
第章 知识工程和数据挖掘
. 知识工程简介
. 专家系统可以解决的问题
. 模糊专家系统可以解决的问题
. 神经网络可以解决的问题
. 遗传算法可以解决的问题
. 混合智能系统可以解决的问题
. 数据挖掘和知识发现
. 小结
复习题
参考文献
术语表
附录 人工智能工具和厂商
・ ・ ・ ・ ・ ・ (收起)推荐序 情感机器离我们有多远
李德毅
中国人工智能学会理事长
中国工程院院士
引言 人类思维与人工智能的未来
第一部分 情感，另一种人类思维方式
 坠入爱河
我们的每一种主要的“情感状态”都是因为激活了一些资源,同时关闭了另外一些资源――大脑的运行方式由此改变了。如果每次这种改变都会激活更多其他资源,那么最终将导致资源的大规模“级联”。
“爱”的手提箱
精神奥秘之海
情绪与情感
本能机，让婴儿情感更好捉摸
云认知型思维
成人精神活动的大层级
情感“瀑布”
思维维度的多样性
 依恋与目标
人类的一些目标是天生的本能, 是由我们的基因决定的; 另一些目标则是通过“尝试和错误”学习，来实现已有目标的次级目标；而高层次目标, 则是由一种特殊的机器体系形成的。这种特殊的机器体系是指我们对身为依恋对象的父母、朋友或亲人的价值观的继承, 这些价值观积极地响应了我们的需要, 在我们体内产生了“自我意识”情感。
沙子游戏 ：从叉子到勺子
依恋与目标
印刻者
依恋性学习模式
学习、快乐和信用赋能
价值体系的塑造
幼儿和动物的依恋
谁是我们的印刻者
自律，构建目标一致的自我模型
公众印刻
 从疼痛到煎熬
任何疼痛都会激活“摆脱疼痛”这一目标, 而这个目标的实现将有助于目标本身的消失。然而, 如果疼痛强烈而又持久, 就会激发其他大脑资源, 进而压制其他目标。如果这种情况级联式地爆发下去, 那么大脑
的大部分区域都会被痛苦占据 。可见，在处于某种精神状态中时, 我们也就失去了“选择的自由”。
疼痛之中
煎熬，大脑失去自由选择权
苦难机器
致命性的痛苦
心智“批评家”：纠正性警告、外显抑制和内隐束缚
弗洛伊德的思维“三明治”
控制我们的情绪和性情
情感利用
第二部分 洞悉思维本质，创建情感机器的大维度
 意识
“意识”是一个“手提箱”式词汇, 它被我们用来表示许多不同的精神活动。而这些精神活动并没有单一的原因或起源, 当然, 这也正是为何人们发现很难“理解意识是什么”的原因所在。心灵的每个阶段都
是一个同时存在多种可能性的剧场，而意识则将这些可能性相互比较, 通过注意力的强化和抑制作用, 选择一些可能性、抑制其他可能性。
什么是意识
打开意识的手提箱
A 脑、B 脑和C 脑
对意识的高估
如何开启意识
主观体验，心理学中的无解难题
自我模型与自我意识
笛卡儿剧场
不间断的意识流
 精神活动层级
我们的大脑是如何产生如此多新事物和新想法的? 资源可以分为  种不同的层级――本能反应、后天反应、沉思、反思、自我反思、自我意识，以对想法和思维机制进行衡量。每一个层级模式都建立在下一个
层级模式的基础之上, 最上层的模式表现的是人们的最高理想和个人目标。
本能反应
后天反应
沉思
反思
自我反思
自我意识
想象
想象场景
预测机器
 常识
我们所做的许多常识性事情和常识性推理，要比吸引更多关注、获得令人敬仰的专业技能复杂得多。你所“看到”的并不完全来自视觉, 还来自这些视觉引发的其他知识。常识性知识的主体, 即人类需要在文明
世界中相处下去会涉及的许多问题, 如我们所说的常识性问题, 目标是什么以及它们是如何实现的，我们平常是如何通过类比来推理, 以及我们如何猜测哪一项知识等，可能与我们的决策方式相关联。
什么是常识
常识性知识和推理
意图和目标
差异的“幻想”世界
在不确定性中，作出最优决策
相似推理
正面经验和负面经验的博弈
 思维
我们几乎从未认识到常识性思考所创造的奇迹。人人都有不同的思维方式。在众多的兴趣爱好当中, 是什么选择了我们下一步将要思考的内容？每一种兴趣又会持续多久? 批评家又是如何选择所使用思维方式
的？事实上，工作被隐藏在“脑后”, 仍在继续运行。
是什么选择了我们思考的主题
批评家-选择器模型，思维跳跃之源
情感化思维
人类的大思维方式
 大批评家，选择最合适的思维方式
先有情感，还是先有行为
庞加莱无意识过程的 大阶段
认知语境下的批评家选择
人类心理学的核心问题
 智能
每个物种的个体智力都会从愚笨逐渐发展到优秀, 即使最高级的人类思维也本应从这个过程发展而来。我们可以通过多种视角来观察事物，我们拥有快速进行视角转换的方法、拥有高效学习的特殊方式、拥有获
得相关知识的有效方式并可以不断扩大思维方式的范围、拥有表征事物的多种方式。正是这种多样性造就了人类思维的多功能。
预估距离
平行类比
高效率学习的奥秘
信用赋能
创造力和天才
记忆与表征结构
表征等级
 自我
是什么让人类变得独一无二? 任何其他动物都无法像人类这样拥有各种各样的人格。其中一些性格是与生俱来的, 而另一些性格则来自个人经验, 但在每一种情况中, 我们都具有各异
的特征。每当想尝试理解自己时, 我们都可能需要采取多种角度来看待自己。
多样的“自我”
人格特质
“自我”观念的魅力
为什么我们喜欢快乐
情感描述难题
发现感觉中独特的“质”
人类思维的组织方式
复杂的尊严
人类智能的大时间跨度
致 谢
注 释
译者后记
・ ・ ・ ・ ・ ・ (收起)第  章 引言 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 本书面向的读者 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 深度学习的历史趋势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 神经网络的众多名称和命运变迁 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 与日俱增的数据量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 与日俱增的模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 与日俱增的精度、复杂度和对现实世界的冲击 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  部分 应用数学与机器学习基础
第  章 线性代数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 标量、向量、矩阵和张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 矩阵和向量相乘. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 单位矩阵和逆矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 线性相关和生成子空间 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 范数. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 特殊类型的矩阵和向量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 特征分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 奇异值分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Moore-Penrose 伪逆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 迹运算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 行列式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实例：主成分分析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 概率与信息论. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 为什么要使用概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 离散型变量和概率质量函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 连续型变量和概率密度函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 边缘概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 条件概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 条件概率的链式法则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 独立性和条件独立性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 期望、方差和协方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 常用概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Bernoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Multinoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高斯分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 指数分布和 Laplace 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Dirac 分布和经验分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 分布的混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 常用函数的有用性质. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 贝叶斯规则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 连续型变量的技术细节 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 信息论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 数值计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 上溢和下溢 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 病态条件 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于梯度的优化方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 梯度之上：Jacobian 和 Hessian 矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 约束优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实例：线性最小二乘 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 机器学习基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 任务 T . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 性能度量 P . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 经验 E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 示例：线性回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 容量、过拟合和欠拟合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 没有免费午餐定理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 超参数和验证集. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 交叉验证 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 估计、偏差和方差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 点估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 偏差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 方差和标准差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 权衡偏差和方差以最小化均方误差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 一致性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 最大似然估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 条件对数似然和均方误差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 最大似然的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 贝叶斯统计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最大后验 (MAP) 估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 监督学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 概率监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 支持向量机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他简单的监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 无监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 主成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. k-均值聚类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 构建机器学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 促使深度学习发展的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 维数灾难 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 局部不变性和平滑正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 流形学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  部分 深度网络：现代实践
第  章 深度前馈网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实例：学习 XOR. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于梯度的学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 代价函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 输出单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 隐藏单元. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 整流线性单元及其扩展 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. logistic sigmoid 与双曲正切函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他隐藏单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 架构设计. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 万能近似性质和深度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 其他架构上的考虑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 反向传播和其他的微分算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 微积分中的链式法则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 递归地使用链式法则来实现反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 全连接 MLP 中的反向传播计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 符号到符号的导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 一般化的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 实例：用于 MLP 训练的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 复杂化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 深度学习界以外的微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高阶微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 历史小记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 深度学习中的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 参数范数惩罚 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. L 参数正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. L 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 作为约束的范数惩罚. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 正则化和欠约束问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 噪声鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 向输出目标注入噪声. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 半监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 提前终止. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 参数绑定和参数共享. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 稀疏表示. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. Bagging 和其他集成方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 对抗训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 切面距离、正切传播和流形正切分类器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度模型中的优化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 学习和纯优化有什么不同 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 经验风险最小化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 代理损失函数和提前终止 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 批量算法和小批量算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 神经网络优化中的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 病态 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 局部极小值 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高原、鞍点和其他平坦区域 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 悬崖和梯度爆炸 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 长期依赖 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 非精确梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 局部和全局结构间的弱对应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 优化的理论限制 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基本算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 动量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Nesterov 动量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 参数初始化策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 自适应学习率算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. AdaGrad . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. RMSProp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 选择正确的优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 二阶近似方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 牛顿法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 共轭梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. BFGS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 优化策略和元算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 批标准化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 坐标下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Polyak 平均 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 设计有助于优化的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 延拓法和课程学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 卷积网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积运算. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 动机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 池化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积与池化作为一种无限强的先验 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基本卷积函数的变体. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 结构化输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 数据类型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 高效的卷积算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 随机或无监督的特征. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 卷积网络的神经科学基础 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积网络与深度学习的历史 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 序列建模：循环和递归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 展开计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 导师驱动过程和输出循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 计算循环神经网络的梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 作为有向图模型的循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于上下文的 RNN 序列建模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 双向 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于编码 - 解码的序列到序列架构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 深度循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 递归神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 长期依赖的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 回声状态网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 渗漏单元和其他多时间尺度的策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 时间维度的跳跃连接. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 渗漏单元和一系列不同时间尺度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 删除连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 长短期记忆和其他门控 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他门控 RNN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 优化长期依赖. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 截断梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 引导信息流的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 外显记忆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 实践方法论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 性能度量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 默认的基准模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 决定是否收集更多数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 选择超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 手动调整超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 自动超参数优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 网格搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 随机搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于模型的超参数优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 调试策略. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 示例：多位数字识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 大规模深度学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 快速的 CPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. GPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 大规模的分布式实现. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 模型压缩 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 动态结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 深度网络的专用硬件实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 计算机视觉 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 语音识别. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 自然语言处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. n-gram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高维输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 结合 n-gram 和神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 神经机器翻译 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 其他应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 推荐系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 知识表示、推理和回答 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  部分 深度学习研究
第  章 线性因子模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 概率 PCA 和因子分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 独立成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 慢特征分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 稀疏编码. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. PCA 的流形解释 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 欠完备自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 正则自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 稀疏自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 去噪自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 惩罚导数作为正则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 表示能力、层的大小和深度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 随机编码器和解码器. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 去噪自编码器详解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 得分估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 使用自编码器学习流形 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 收缩自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 预测稀疏分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 自编码器的应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 表示学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 贪心逐层无监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 何时以及为何无监督预训练有效有效 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 迁移学习和领域自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 半监督解释因果关系. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 分布式表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 得益于深度的指数增益 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 提供发现潜在原因的线索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度学习中的结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 非结构化建模的挑战. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 使用图描述模型结构. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 有向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于能量的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 分离和 d-分离 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 在有向模型和无向模型中转换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 因子图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 从图模型中采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 结构化建模的优势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 学习依赖关系 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 推断和近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 结构化概率模型的深度学习方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 实例：受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 采样和蒙特卡罗方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 为什么需要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 蒙特卡罗采样的基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 重要采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 马尔可夫链蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Gibbs 采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 不同的峰值之间的混合挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 不同峰值之间通过回火来混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 深度也许会有助于混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 直面配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 对数似然梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 随机最大似然和对比散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 伪似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 得分匹配和比率匹配. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 去噪得分匹配 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 估计配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 退火重要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 桥式采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 把推断视作优化问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 期望最大化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 最大后验推断和稀疏编码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 变分推断和变分学习. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 离散型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 变分法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 连续型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学习和推断之间的相互作用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 学成近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 醒眠算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学成推断的其他形式. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 深度生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 条件分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练受限玻尔兹曼机. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 深度信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 有趣的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. DBM 均匀场推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. DBM 的参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 逐层预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 联合训练深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实值数据上的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Gaussian-Bernoulli RBM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 条件协方差的无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 用于结构化或序列输出的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 其他玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 通过随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 通过离散随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 有向生成网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. sigmoid 信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 可微生成器网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 变分自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 生成式对抗网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 生成矩匹配网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 卷积生成网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 线性自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 神经自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. NADE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 从自编码器采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 与任意去噪自编码器相关的马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 夹合与条件采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 回退训练过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 生成随机网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 判别性 GSN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 其他生成方案. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 评估生成模型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 结论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
参考文献. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
索引 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
・ ・ ・ ・ ・ ・ (收起)译者序　　xiii
前言　　xv
第章　Python入门　　
. Python是什么　　
. Python的安装　　
..　Python版本　　
..　使用的外部库　　
..　Anaconda发行版　　
. Python解释器　　
..　算术计算　　
..　数据类型　　
..　变量　　
..　列表　　
..　字典　　
..　布尔型　　
..　if 语句　　
..　for 语句　　
..　函数　　
. Python脚本文件　　
..　保存为文件　　
..　类　　
. NumPy　　
..　导入NumPy　　
..　生成NumPy数组　　
..　NumPy 的算术运算　　
..　NumPy的N维数组　　
..　广播　　
..　访问元素　　
. Matplotlib　　
..　绘制简单图形　　
..　pyplot 的功能　　
..　显示图像　　
. 小结　　
第章　感知机　　
. 感知机是什么　　
. 简单逻辑电路　　
..　与门　　
..　与非门和或门　　
. 感知机的实现　　
..　简单的实现　　
..　导入权重和偏置　　
..　使用权重和偏置的实现　　
. 感知机的局限性　　
..　异或门　　
..　线性和非线性　　
. 多层感知机　　
..　已有门电路的组合　　
..　异或门的实现　　
. 从与非门到计算机　　
. 小结　　
第章　神经网络　　
. 从感知机到神经网络　　
..　神经网络的例子　　
..　复习感知机　　
..　激活函数登场　　
. 激活函数　　
..　sigmoid 函数　　
..　阶跃函数的实现　　
..　阶跃函数的图形　　
..　sigmoid 函数的实现　　
..　sigmoid 函数和阶跃函数的比较　　
..　非线性函数　　
..　ReLU函数　　
. 多维数组的运算　　
..　多维数组　　
..　矩阵乘法　　
..　神经网络的内积　　
.　　 层神经网络的实现　　
..　符号确认　　
..　各层间信号传递的实现　　
..　代码实现小结　　
. 输出层的设计　　
..　恒等函数和softmax 函数　　
..　实现softmax 函数时的注意事项　　
..　softmax 函数的特征　　
..　输出层的神经元数量　　
. 手写数字识别　　
..　MNIST数据集　　
..　神经网络的推理处理　　
..　批处理　　
. 小结　　
第章　神经网络的学习　　
. 从数据中学习　　
..　数据驱动　　
..　训练数据和测试数据　　
. 损失函数　　
..　均方误差　　
..　交叉熵误差　　
..　mini-batch 学习　　
..　mini-batch 版交叉熵误差的实现　　
..　为何要设定损失函数　　
. 数值微分　　
..　导数　　
..　数值微分的例子　　
..　偏导数　　
. 梯度　　
..　梯度法　　
..　神经网络的梯度　　
. 学习算法的实现　　
..　 层神经网络的类　　
..　mini-batch 的实现　　
..　基于测试数据的评价　　
. 小结　　
第章　误差反向传播法　　
. 计算图　　
..　用计算图求解　　
..　局部计算　　
..　为何用计算图解题　　
. 链式法则　　
..　计算图的反向传播　　
..　什么是链式法则　　
..　链式法则和计算图　　
. 反向传播　　
..　加法节点的反向传播　　
..　乘法节点的反向传播　　
..　苹果的例子　　
. 简单层的实现　　
..　乘法层的实现　　
..　加法层的实现　　
. 激活函数层的实现　　
..　ReLU层　　
..　Sigmoid 层　　
. AffineSoftmax层的实现　　
..　Affine层　　
..　批版本的Affine层　　
..　Softmax-with-Loss 层　　
. 误差反向传播法的实现　　
..　神经网络学习的全貌图　　
..　对应误差反向传播法的神经网络的实现　　
..　误差反向传播法的梯度确认　　
..　使用误差反向传播法的学习　　
. 小结　　
第章　与学习相关的技巧　　
. 参数的更新　　
..　探险家的故事　　
..　SGD　　
..　SGD的缺点　　
..　Momentum　　
..　AdaGrad　　
..　Adam　　
..　使用哪种更新方法呢　　
..　基于MNIST数据集的更新方法的比较　　
. 权重的初始值　　
..　可以将权重初始值设为 吗　　
..　隐藏层的激活值的分布　　
..　ReLU的权重初始值　　
..　基于MNIST数据集的权重初始值的比较　　
. Batch Normalization　　
..　Batch Normalization 的算法　　
..　Batch Normalization 的评估　　
. 正则化　　
..　过拟合　　
..　权值衰减　　
..　Dropout　　
. 超参数的验证　　
..　验证数据　　
..　超参数的最优化　　
..　超参数最优化的实现　　
. 小结　　
第章　卷积神经网络　　
. 整体结构　　
. 卷积层　　
..　全连接层存在的问题　　
..　卷积运算　　
..　填充　　
..　步幅　　
..　 维数据的卷积运算　　
..　结合方块思考　　
..　批处理　　
. 池化层　　
. 卷积层和池化层的实现　　
..　 维数组　　
..　基于imcol 的展开　　
..　卷积层的实现　　
..　池化层的实现　　
. CNN的实现　　
. CNN的可视化　　
..　第 层权重的可视化　　
..　基于分层结构的信息提取　　
. 具有代表性的CNN　　
..　LeNet　　
..　AlexNet　　
. 小结　　
第章　深度学习　　
. 加深网络　　
..　向更深的网络出发　　
..　进一步提高识别精度　　
..　加深层的动机　　
. 深度学习的小历史　　
..　ImageNet　　
..　VGG　　
..　GoogLeNet　　
..　ResNet　　
. 深度学习的高速化　　
..　需要努力解决的问题　　
..　基于GPU的高速化　　
..　分布式学习　　
..　运算精度的位数缩减　　
. 深度学习的应用案例　　
..　物体检测　　
..　图像分割　　
..　图像标题的生成　　
. 深度学习的未来　　
..　图像风格变换　　
..　图像的生成　　
..　自动驾驶　　
..　Deep Q-Network（强化学习）　　
. 小结　　
附录A　Softmax-with-Loss 层的计算图　　
A. 正向传播　　
A. 反向传播　　
A. 小结　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
前言
译者简介
学习环境配置
资源与支持
主要符号表
第 章　引言　
.　日常生活中的机器学习　
.　机器学习中的关键组件　
..　数据　
..　模型　
..　目标函数　
..　优化算法　
.　各种机器学习问题　
..　监督学习　
..　无监督学习　
..　与环境互动　
..　强化学习　
.　起源　
.　深度学习的发展　
.　深度学习的成功案例　
.　特点　
第 章　预备知识　
.　数据操作　
..　入门　
..　运算符　
..　广播机制　
..　索引和切片　
..　节省内存　
..　转换为其他Python对象　
.　数据预处理　
..　读取数据集　
..　处理缺失值　
..　转换为张量格式　
.　线性代数　
..　标量　
..　向量　
..　矩阵　
..　张量　
..　张量算法的基本性质　
..　降维　
..　点积　
..　矩阵-向量积　
..　矩阵-矩阵乘法　
..　范数　
..　关于线性代数的更多信息　
.　微积分　
..　导数和微分　
..　偏导数　
..　梯度　
..　链式法则　
.　自动微分　
..　一个简单的例子　
..　非标量变量的反向传播　
..　分离计算　
..　Python控制流的梯度计算　
.　概率　
..　基本概率论　
..　处理多个随机变量　
..　期望和方差　
.　查阅文档　
..　查找模块中的所有函数和类　
..　查找特定函数和类的用法　
第章　线性神经网络　
.　线性回归　
..　线性回归的基本元素　
..　向量化加速　
..　正态分布与平方损失　
..　从线性回归到深度网络　
.　线性回归的从零开始实现　
..　生成数据集　
..　读取数据集　
..　初始化模型参数　
..　定义模型　
..　定义损失函数　
..　定义优化算法　
..　训练　
.　线性回归的简洁实现　
..　生成数据集　
..　读取数据集　
..　定义模型　
..　初始化模型参数　
..　定义损失函数　
..　定义优化算法　
..　训练　
.　softmax回归　
..　分类问题　
..　网络架构　
..　全连接层的参数开销　
..　softmax运算　
..　小批量样本的向量化　
..　损失函数　
..　信息论基础　
..　模型预测和评估　
.　图像分类数据集　
..　读取数据集　
..　读取小批量　
..　整合所有组件　
.　softmax回归的从零开始实现　
..　初始化模型参数　
..　定义softmax操作　
..　定义模型　
..　定义损失函数　
..　分类精度　
..　训练　
..　预测　
.　softmax回归的简洁实现　
..　初始化模型参数　
..　重新审视softmax的实现　
..　优化算法　
..　训练　
第章　多层感知机　
.　多层感知机　
..　隐藏层　
..　激活函数　
.　多层感知机的从零开始实现　
..　初始化模型参数　
..　激活函数　
..　模型　
..　损失函数　
..　训练　
.　多层感知机的简洁实现　
模型　
.　模型选择、欠拟合和过拟合　
..　训练误差和泛化误差　
..　模型选择　
..　欠拟合还是过拟合　
..　多项式回归　
.　权重衰减　
..　范数与权重衰减　
..　高维线性回归　
..　从零开始实现　
..　简洁实现　
.　暂退法　
..　重新审视过拟合　
..　扰动的稳健性　
..　实践中的暂退法　
..　从零开始实现　
..　简洁实现　
.　前向传播、反向传播和计算图　
..　前向传播　
..　前向传播计算图　
..　反向传播　
..　训练神经网络　
.　数值稳定性和模型初始化　
..　梯度消失和梯度爆炸　
..　参数初始化　
.　环境和分布偏移　
..　分布偏移的类型　
..　分布偏移示例　
..　分布偏移纠正　
..　学习问题的分类法　
..　机器学习中的公平、责任和透明度　
.　实战Kaggle比赛：预测房价　
..　下载和缓存数据集　
..　Kaggle　
..　访问和读取数据集　
..　数据预处理　
..　训练　
..　K折交叉验证　
..　模型选择　
..　提交Kaggle预测　
第章　深度学习计算　
.　层和块　
..　自定义块　
..　顺序块　
..　在前向传播函数中执行代码　
..　效率　
.　参数管理　
..　参数访问　
..　参数初始化　
..　参数绑定　
.　延后初始化　
实例化网络　
.　自定义层　
..　不带参数的层　
..　带参数的层　
.　读写文件　
..　加载和保存张量　
..　加载和保存模型参数　
.　GPU　
..　计算设备　
..　张量与GPU　
..　神经网络与GPU　
第章　卷积神经网络　
.　从全连接层到卷积　
..　不变性　
..　多层感知机的限制　
..　卷积　
..　“沃尔多在哪里”回顾　
.　图像卷积　
..　互相关运算　
..　卷积层　
..　图像中目标的边缘检测　
..　学习卷积核　
..　互相关和卷积　
..　特征映射和感受野　
.　填充和步幅　
..　填充　
..　步幅　
.　多输入多输出通道　
..　多输入通道　
..　多输出通道　
..　×卷积层　
.　汇聚层　
..　最大汇聚和平均汇聚　
..　填充和步幅　
..　多个通道　
.　卷积神经网络（LeNet）　
..　LeNet　
..　模型训练　
第章　现代卷积神经网络　
.　深度卷积神经网络（AlexNet）　
..　学习表征　
..　AlexNet　
..　读取数据集　
..　训练AlexNet　
.　使用块的网络（VGG）　
..　VGG块　
..　VGG网络　
..　训练模型　
.　网络中的网络（NiN）　
..　NiN块　
..　NiN模型　
..　训练模型　
.　含并行连接的网络（GoogLeNet）　
..　Inception块　
..　GoogLeNet模型　
..　训练模型　
.　批量规范化　
..　训练深层网络　
..　批量规范化层　
..　从零实现　
..　使用批量规范化层的 LeNet　
..　简明实现　
..　争议　
.　残差网络（ResNet）　
..　函数类　
..　残差块　
..　ResNet模型　
..　训练模型　
.　稠密连接网络（DenseNet）　
..　从ResNet到DenseNet　
..　稠密块体　
..　过渡层　
..　DenseNet模型　
..　训练模型　
第章　循环神经网络　
.　序列模型　
..　统计工具　
..　训练　
..　预测　
.　文本预处理　
..　读取数据集　
..　词元化　
..　词表　
..　整合所有功能　
.　语言模型和数据集　
..　学习语言模型　
..　马尔可夫模型与n元语法　
..　自然语言统计　
..　读取长序列数据　
.　循环神经网络　
..　无隐状态的神经网络　
..　有隐状态的循环神经网络　
..　基于循环神经网络的字符级语言模型　
..　困惑度　
.　循环神经网络的从零开始实现　
..　独热编码　
..　初始化模型参数　
..　循环神经网络模型　
..　预测　
..　梯度截断　
..　训练　
.　循环神经网络的简洁实现　
..　定义模型　
..　训练与预测　
.　通过时间反向传播　
..　循环神经网络的梯度分析　
..　通过时间反向传播的细节　
第章　现代循环神经网络　
.　门控循环单元（GRU）　
..　门控隐状态　
..　从零开始实现　
..　简洁实现　
.　长短期记忆网络（LSTM）　
..　门控记忆元　
..　从零开始实现　
..　简洁实现　
.　深度循环神经网络　
..　函数依赖关系　
..　简洁实现　
..　训练与预测　
.　双向循环神经网络　
..　隐马尔可夫模型中的动态规划　
..　双向模型　
..　双向循环神经网络的错误应用　
.　机器翻译与数据集　
..　下载和预处理数据集　
..　词元化　
..　词表　
..　加载数据集　
..　训练模型　
.　编码器-解码器架构　
..　编码器　
..　解码器　
..　合并编码器和解码器　
.　序列到序列学习（seqseq）　
..　编码器　
..　解码器　
..　损失函数　
..　训练　
..　预测　
..　预测序列的评估　
.　束搜索　
..　贪心搜索　
..　穷举搜索　
..　束搜索　
第 章　注意力机制　
.　注意力提示　
..　生物学中的注意力提示　
..　查询、键和值　
..　注意力的可视化　
.　注意力汇聚：Nadaraya-Watson 核回归　
..　生成数据集　
..　平均汇聚　
..　非参数注意力汇聚　
..　带参数注意力汇聚　
.　注意力评分函数　
..　掩蔽softmax操作　
..　加性注意力　
..　缩放点积注意力　
.　Bahdanau 注意力　
..　模型　
..　定义注意力解码器　
..　训练　
.　多头注意力　
..　模型　
..　实现　
.　自注意力和位置编码　
..　自注意力　
..　比较卷积神经网络、循环神经网络和自注意力　
..　位置编码　
.　Transformer　
..　模型　
..　基于位置的前馈网络　
..　残差连接和层规范化　
..　编码器　
..　解码器　
..　训练　
第 章　优化算法　
.　优化和深度学习　
..　优化的目标　
..　深度学习中的优化挑战　
.　凸性　
..　定义　
..　性质　
..　约束　
.　梯度下降　
..　一维梯度下降　
..　多元梯度下降　
..　自适应方法　
.　随机梯度下降　
..　随机梯度更新　
..　动态学习率　
..　凸目标的收敛性分析　
..　随机梯度和有限样本　
.　小批量随机梯度下降　
..　向量化和缓存　
..　小批量　
..　读取数据集　
..　从零开始实现　
..　简洁实现　
.　动量法　
..　基础　
..　实际实验　
..　理论分析　
.　AdaGrad算法　
..　稀疏特征和学习率　
..　预处理　
..　算法　
..　从零开始实现　
..　简洁实现　
.　RMSProp算法　
..　算法　
..　从零开始实现　
..　简洁实现　
.　Adadelta算法　
..　算法　
..　实现　
.　Adam算法　
..　算法　
..　实现　
..　Yogi　
.　学习率调度器　
..　一个简单的问题　
..　学习率调度器　
..　策略　
第 章　计算性能　
.　编译器和解释器　
..　符号式编程　
..　混合式编程　
..　Sequential的混合式编程　
.　异步计算　
通过后端异步处理　
.　自动并行　
..　基于GPU的并行计算　
..　并行计算与通信　
.　硬件　
..　计算机　
..　内存　
..　存储器　
..　CPU　
..　GPU和其他加速卡　
..　网络和总线　
..　更多延迟　
.　多GPU训练　
..　问题拆分　
..　数据并行性　
..　简单网络　
..　数据同步　
..　数据分发　
..　训练　
.　多GPU的简洁实现　
..　简单网络　
..　网络初始化　
..　训练　
.　参数服务器　
..　数据并行训练　
..　环同步（ring
synchronization）　
..　多机训练　
..　键-值存储　
第 章　计算机视觉　
.　图像增广　
..　常用的图像增广方法　
..　使用图像增广进行训练　
.　微调　
..　步骤　
..　热狗识别　
.　目标检测和边界框　
边界框　
.　锚框　
..　生成多个锚框　
..　交并比（IoU）　
..　在训练数据中标注锚框　
..　使用非极大值抑制预测
边界框　
.　多尺度目标检测　
..　多尺度锚框　
..　多尺度检测　
.　目标检测数据集　
..　下载数据集　
..　读取数据集　
..　演示　
.　单发多框检测（SSD）　
..　模型　
..　训练模型　
..　预测目标　
.　区域卷积神经网络（R-CNN）系列　
..　R-CNN　
..　Fast R-CNN　
..　Faster R-CNN　
..　Mask R-CNN　
.　语义分割和数据集　
..　图像分割和实例分割　
..　Pascal VOC 语义分割数据集　
.　转置卷积　
..　基本操作　
..　填充、步幅和多通道　
..　与矩阵变换的联系　
.　全卷积网络　
..　构建模型　
..　初始化转置卷积层　
..　读取数据集　
..　训练　
..　预测　
.　风格迁移　
..　方法　
..　阅读内容和风格图像　
..　预处理和后处理　
..　提取图像特征　
..　定义损失函数　
..　初始化合成图像　
..　训练模型　
.　实战 Kaggle竞赛：图像分类（CIFAR-）　
..　获取并组织数据集　
..　图像增广 　
..　读取数据集　
..　定义模型　
..　定义训练函数　
..　训练和验证模型　
..　在Kaggle上对测试集进行分类并提交结果　
.　实战Kaggle竞赛：狗的品种识别（ImageNet Dogs）　
..　获取和整理数据集　
..　图像增广　
..　读取数据集　
..　微调预训练模型　
..　定义训练函数　
..　训练和验证模型　
..　对测试集分类并在Kaggle提交结果　
第 章　自然语言处理：预训练　
.　词嵌入（wordvec）　
..　为何独热向量是一个糟糕的选择　
..　自监督的wordvec　
..　跳元模型　
..　连续词袋模型　
.　近似训练　
..　负采样　
..　层序softmax　
.　用于预训练词嵌入的数据集　
..　读取数据集　
..　下采样　
..　中心词和上下文词的提取　
..　负采样　
..　小批量加载训练实例　
..　整合代码　
.　预训练wordvec　
..　跳元模型　
..　训练　
..　应用词嵌入　
.　全局向量的词嵌入（GloVe）　
..　带全局语料库统计的跳元模型　
..　GloVe模型　
..　从共现概率比值理解GloVe模型　
.　子词嵌入　
..　fastText模型　
..　字节对编码　
.　词的相似度和类比任务　
..　加载预训练词向量　
..　应用预训练词向量　
.　来自Transformer的双向编码器表示（BERT）　
..　从上下文无关到上下文敏感　
..　从特定于任务到不可知任务　
..　BERT：将ELMo与GPT结合起来　
..　输入表示　
..　预训练任务　
..　整合代码　
.　用于预训练BERT的数据集　
..　为预训练任务定义辅助函数　
..　将文本转换为预训练数据集　
.　预训练BERT　
..　预训练BERT　
..　用BERT表示文本　
第 章　自然语言处理：应用　
.　情感分析及数据集　
..　读取数据集　
..　预处理数据集　
..　创建数据迭代器　
..　整合代码　
.　情感分析：使用循环神经网络　
..　使用循环神经网络表示单个文本　
..　加载预训练的词向量　
..　训练和评估模型　
.　情感分析：使用卷积神经网络　
..　一维卷积　
..　最大时间汇聚层　
..　textCNN模型　
.　自然语言推断与数据集　
..　自然语言推断　
..　斯坦福自然语言推断（SNLI）数据集　
.　自然语言推断：使用注意力　
..　模型　
..　训练和评估模型　
.　针对序列级和词元级应用微调BERT　
..　单文本分类　
..　文本对分类或回归　
..　文本标注　
..　问答　
.　自然语言推断：微调BERT　
..　加载预训练的BERT　
..　微调BERT的数据集　
..　微调BERT　
附录A　深度学习工具　
A.　使用Jupyter记事本　
A..　在本地编辑和运行代码　
A..　高级选项　
A.　使用Amazon SageMaker　
A..　注册　
A..　创建SageMaker实例　
A..　运行和停止实例　
A..　更新Notebook　
A.　使用Amazon EC实例　
A..　创建和运行EC实例　
A..　安装CUDA　
A..　安装库以运行代码　
A..　远程运行Jupyter记事本　
A..　关闭未使用的实例　
A.　选择服务器和GPU　
A..　选择服务器　
A..　选择GPU　
A.　为本书做贡献　
A..　提交微小更改　
A..　大量文本或代码修改　
A..　提交主要更改　
参考文献　
・ ・ ・ ・ ・ ・ (收起)第章　什么是深度学习 
.　人工智能、机器学习和深度学习 
..　人工智能 
..　机器学习 
..　从数据中学习规则与表示 
..　深度学习之“深度” 
..　用三张图理解深度学习的工作原理 
..　深度学习已取得的进展 
..　不要相信短期炒作 
..　人工智能的未来 
.　深度学习之前：机器学习简史 
..　概率建模 
..　早期神经网络 
..　核方法 
..　决策树、随机森林和梯度提升机 
..　回到神经网络 
..　深度学习有何不同 
..　机器学习现状 
.　为什么要用深度学习，为什么是现在 
..　硬件 
..　数据 
..　算法 
..　新一轮投资热潮 
..　深度学习的普及 
..　这种趋势会持续下去吗 
第章　神经网络的数学基础 
.　初识神经网络 
.　神经网络的数据表示 
..　标量（阶张量） 
..　向量（阶张量） 
..　矩阵（阶张量） 
..　阶张量与更高阶的张量 
..　关键属性 
..　在NumPy中操作张量 
..　数据批量的概念 
..　现实世界中的数据张量实例 
..　向量数据 
..　时间序列数据或序列数据 
..　图像数据 
..　视频数据 
.　神经网络的“齿轮”：张量运算 
..　逐元素运算 
..　广播 
..　张量积 
..　张量变形 
..　张量运算的几何解释 
..　深度学习的几何解释 
.　神经网络的“引擎”：基于梯度的优化 
..　什么是导数 
..　张量运算的导数：梯度 
..　随机梯度下降 
..　链式求导：反向传播算法 
.　回顾第一个例子 
..　用TensorFlow 从头开始重新实现第一个例子 
..　完成一次训练步骤 
..　完整的训练循环 
..　评估模型 
.　本章总结 
第章　Keras 和TensorFlow 入门 
.　TensorFlow 简介 
.　Keras 简介 
.　Keras 和TensorFlow 简史 
.　建立深度学习工作区 
..　Jupyter笔记本：运行深度学习实验的首选方法 
..　使用Colaboratory 
.　TensorFlow入门 
..　常数张量和变量 
..　张量运算：用TensorFlow进行数学运算 
..　重温GradientTape API 
..　一个端到端的例子：用TensorFlow编写线性分类器 
.　神经网络剖析：了解核心Keras API 
..　层：深度学习的基础模块 
..　从层到模型 
..　编译步骤：配置学习过程 
..　选择损失函数 
..　理解fit()方法 
..　监控验证数据上的损失和指标 
..　推断：在训练后使用模型 
.　本章总结 
第章　神经网络入门：分类与回归 
.　影评分类：二分类问题示例 
..　IMDB 数据集 
..　准备数据 
..　构建模型 
..　验证你的方法 
..　利用训练好的模型对新数据进行预测 
..　进一步实验 
..　小结 
.　新闻分类：多分类问题示例 
..　路透社数据集 
..　准备数据 
..　构建模型 
..　验证你的方法 
..　对新数据进行预测 
..　处理标签和损失的另一种方法 
..　拥有足够大的中间层的重要性 
..　进一步实验 
..　小结 
.　预测房价：标量回归问题示例 
..　波士顿房价数据集 
..　准备数据 
..　构建模型 
..　利用K折交叉验证来验证你的方法 
..　对新数据进行预测 
..　小结 
.　本章总结 
第章　机器学习基础 
.　泛化：机器学习的目标 
..　欠拟合与过拟合 
..　深度学习泛化的本质 
.　评估机器学习模型 
..　训练集、验证集和测试集 
..　超越基于常识的基准 
..　模型评估的注意事项 
.　改进模型拟合 
..　调节关键的梯度下降参数 
..　利用更好的架构预设 
..　提高模型容量 
.　提高泛化能力 
..　数据集管理 
..　特征工程 
..　提前终止 
..　模型正则化 
.　本章总结 
第章　机器学习的通用工作流程 
.　定义任务 
..　定义问题 
..　收集数据集 
..　理解数据 
..　选择衡量成功的指标 
.　开发模型 
..　准备数据 
..　选择评估方法 
..　超越基准 
..　扩大模型规模：开发一个过拟合的模型 
..　模型正则化与调节超参数 
.　部署模型 
..　向利益相关者解释你的工作并设定预期 
..　部署推断模型 
..　监控模型在真实环境中的性能 
..　维护模型 
.　本章总结 
第章　深入Keras 
.　Keras 工作流程 
.　构建Keras 模型的不同方法 
..　序贯模型 
..　函数式API 
..　模型子类化 
..　混合使用不同的组件 
..　用正确的工具完成工作 
.　使用内置的训练循环和评估循环 
..　编写自定义指标 
..　使用回调函数 
..　编写自定义回调函数 
..　利用TensorBoard进行监控和可视化 
.　编写自定义的训练循环和评估循环 
..　训练与推断 
..　指标的低阶用法 
..　完整的训练循环和评估循环 
..　利用tf.function加快运行速度 
..　在fit()中使用自定义训练循环 
.　本章总结 
第章　计算机视觉深度学习入门 
.　卷积神经网络入门 
..　卷积运算 
..　最大汇聚运算 
.　在小型数据集上从头开始训练一个卷积神经网络 
..　深度学习对数据量很小的问题的适用性 
..　下载数据 
..　构建模型 . 
..　数据预处理 
..　使用数据增强 
.　使用预训练模型 
..　使用预训练模型做特征提取 
..　微调预训练模型 
.　本章总结 
第章　计算机视觉深度学习进阶 
.　三项基本的计算机视觉任务 
.　图像分割示例 
.　现代卷积神经网络架构模式 
..　模块化、层次结构和复用 
..　残差连接 
..　批量规范化 
..　深度可分离卷积 
..　综合示例：一个类似Xception的迷你模型 
.　解释卷积神经网络学到的内容 
..　中间激活值的可视化 
..　卷积神经网络滤波器的可视化 
..　类激活热力图的可视化 
.　本章总结 
第章　深度学习处理时间序列 
.　不同类型的时间序列任务 
.　温度预测示例 
..　准备数据 
..　基于常识、不使用机器学习的基准 
..　基本的机器学习模型 
..　一维卷积模型 
..　第一个RNN 基准 
.　理解RNN 
.　RNN 的高级用法 
..　利用循环dropout 降低过拟合 
..　循环层堆叠 
..　使用双向RNN 
..　进一步实验 
.　本章总结 
第章　深度学习处理文本 
.　自然语言处理概述 
.　准备文本数据 
..　文本标准化 
..　文本拆分（词元化） 
..　建立词表索引 
..　使用TextVectorization层 
.　表示单词组的两种方法：集合和序列 
..　准备IMDB 影评数据 
..　将单词作为集合处理：词袋方法 
..　将单词作为序列处理：序列模型方法 
.　Transformer架构 
..　理解自注意力 
..　多头注意力 
..　Transformer编码器 
..　何时使用序列模型而不是词袋模型 
.　超越文本分类：序列到序列学习 
..　机器翻译示例 
..　RNN 的序列到序列学习 
..　使用Transformer 进行序列到序列学习 
.　本章总结 
第章　生成式深度学习 
.　文本生成 
..　生成式深度学习用于序列生成的简史 
..　如何生成序列数据 
..　采样策略的重要性 
..　用Keras 实现文本生成 
..　带有可变温度采样的文本生成回调函数 
..　小结 
.　DeepDream 
..　用Keras 实现DeepDream 
..　小结 
.　　神经风格迁移 
..　内容损失 
..　风格损失 
..　用Keras 实现神经风格迁移 
..　小结 
.　用变分自编码器生成图像 
..　从图像潜在空间中采样 
..　图像编辑的概念向量 
..　变分自编码器 
..　用Keras 实现变分自编码器 
..　小结 
.　生成式对抗网络入门 
..　简要实现流程 
..　诸多技巧 
..　CelebA 数据集 
..　判别器 
..　生成器 
..　对抗网络 
..　小结 
.　本章总结 
第章　适合现实世界的最佳实践 
.　将模型性能发挥到极致 
..　超参数优化 
..　模型集成 
.　加速模型训练 
..　使用混合精度加快GPU上的训练速度 
..　多GPU训练 
..　TPU训练 
.　本章总结 
第章　总结 
.　重点概念回顾 
..　人工智能的多种方法 
..　深度学习在机器学习领域中的特殊之处 
..　如何看待深度学习 
..　关键的推动技术 
..　机器学习的通用工作流程 
..　关键网络架构 
..　可能性空间 
.　深度学习的局限性 
..　将机器学习模型拟人化的风险 
..　自动机与智能体 
..　局部泛化与极端泛化 
..　智能的目的 
..　逐步提高泛化能力 
.　如何实现更加通用的人工智能 
..　设定正确目标的重要性：捷径法则 
..　新目标 
.　实现智能：缺失的内容 
..　智能是对抽象类比的敏感性 
..　两种抽象 
..　深度学习所缺失的那一半 
.　深度学习的未来 
..　模型即程序 
..　将深度学习与程序合成融合 
..　终身学习和模块化子程序复用 
..　长期愿景 
.　了解快速发展的领域的最新进展 
..　在Kaggle 上练习解决现实世界的问题 
..　在arXiv上了解最新进展 
..　探索Keras 生态系统 
.　结束语 
・ ・ ・ ・ ・ ・ (收起)第一部分　深度学习基础
第章　什么是深度学习　　
.　人工智能、机器学习与深度学习　　
..　人工智能　　
..　机器学习　　
..　从数据中学习表示　　
..　深度学习之“深度”　　
..　用三张图理解深度学习的工作原理　　
..　深度学习已经取得的进展　　
..　不要相信短期炒作　　
..　人工智能的未来　　
.　深度学习之前：机器学习简史　　
..　概率建模　　
..　早期神经网络　　
..　核方法　　
..　决策树、随机森林与梯度提升机　　
..　回到神经网络　　
..　深度学习有何不同　　
..　机器学习现状　　
.　为什么是深度学习，为什么是现在　　
..　硬件　　
..　数据　　
..　算法　　
..　新的投资热潮　　
..　深度学习的大众化　　
..　这种趋势会持续吗　　
第章　神经网络的数学基础　　
.　初识神经网络　　
.　神经网络的数据表示　　
..　标量（D张量）　　
..　向量（D张量）　　
..　矩阵（D张量）　　
..　D张量与更高维张量　　
..　关键属性　　
..　在Numpy中操作张量　　
..　数据批量的概念　　
..　现实世界中的数据张量　　
..　向量数据　　
..　时间序列数据或序列数据　　
..　图像数据　　
..　视频数据　　
.　神经网络的“齿轮”：张量运算　　
..　逐元素运算　　
..　广播　　
..　张量点积　　
..　张量变形　　
..　张量运算的几何解释　　
..　深度学习的几何解释　　
.　神经网络的“引擎”：基于梯度的优化　　
..　什么是导数　　
..　张量运算的导数：梯度　　
..　随机梯度下降　　
..　链式求导：反向传播算法　　
.　回顾第一个例子　　
本章小结　　
第章　神经网络入门　　
.　神经网络剖析　　
..　层：深度学习的基础组件　　
..　模型：层构成的网络　　
..　损失函数与优化器：配置学习过程的关键　　
.　Keras简介　　
..　Keras、TensorFlow、Theano 和CNTK　　
..　使用Keras 开发：概述　　
.　建立深度学习工作站　　
..　Jupyter笔记本：运行深度学习实验的首选方法　　
..　运行Keras：两种选择　　
..　在云端运行深度学习任务：优点和缺点　　
..　深度学习的最佳GPU　　
.　电影评论分类：二分类问题　　
..　IMDB 数据集　　
..　准备数据　　
..　构建网络　　
..　验证你的方法　　
..　使用训练好的网络在新数据上生成预测结果　　
..　进一步的实验　　
..　小结　　
.　新闻分类：多分类问题　　
..　路透社数据集　　
..　准备数据　　
..　构建网络　　
..　验证你的方法　　
..　在新数据上生成预测结果　　
..　处理标签和损失的另一种方法　　
..　中间层维度足够大的重要性　　
..　进一步的实验　　
..　小结　　
.　预测房价：回归问题　　
..　波士顿房价数据集　　
..　准备数据　　
..　构建网络　　
..　利用K折验证来验证你的方法　　
..　小结　　
本章小结　　
第章　机器学习基础　　
.　机器学习的四个分支　　
..　监督学习　　
..　无监督学习　　
..　自监督学习　　
..　强化学习　　
.　评估机器学习模型　　
..　训练集、验证集和测试集　　
..　评估模型的注意事项　　
.　数据预处理、特征工程和特征学习　　
..　神经网络的数据预处理　　
..　特征工程　　
.　过拟合与欠拟合　　
..　减小网络大小　　
..　添加权重正则化　　
..　添加dropout正则化　　
.　机器学习的通用工作流程　　
..　定义问题，收集数据集　　
..　选择衡量成功的指标　　
..　确定评估方法　　
..　准备数据　　
..　开发比基准更好的模型　　
..　扩大模型规模：开发过拟合的模型　　
..　模型正则化与调节超参数　　
本章小结　　
第二部分　深度学习实践
第章　深度学习用于计算机视觉　　
.　卷积神经网络简介　　
..　卷积运算　　
..　最大池化运算　　
.　在小型数据集上从头开始训练一个卷积神经网络　　
..　深度学习与小数据问题的相关性　　
..　下载数据　　
..　构建网络　　
..　数据预处理　　
..　使用数据增强　　
.　使用预训练的卷积神经网络　　
..　特征提取　　
..　微调模型　　
..　小结　　
.　卷积神经网络的可视化　　
..　可视化中间激活　　
..　可视化卷积神经网络的过滤器　　
..　可视化类激活的热力图　　
本章小结　　
第章　深度学习用于文本和序列　　
.　处理文本数据　　
..　单词和字符的one-hot编码　　
..　使用词嵌入　　
..　整合在一起：从原始文本到词嵌入　　
..　小结　　
.　理解循环神经网络　　
..　Keras中的循环层　　
..　理解LSTM层和GRU层　　
..　Keras中一个LSTM的具体例子　　
..　小结　　
.　循环神经网络的高级用法　　
..　温度预测问题　　
..　准备数据　　
..　一种基于常识的、非机器学习的基准方法　　
..　一种基本的机器学习方法　　
..　第一个循环网络基准　　
..　使用循环dropout来降低过拟合　　
..　循环层堆叠　　
..　使用双向RNN　　
..　更多尝试　　
..　小结　　
.　用卷积神经网络处理序列　　
..　理解序列数据的一维卷积　　
..　序列数据的一维池化　　
..　实现一维卷积神经网络　　
..　结合CNN和RNN来处理长序列　　
..　小结　　
本章总结　　
第章　高级的深度学习最佳实践　　
.　不用Sequential模型的解决方案：Keras 函数式API　　
..　函数式API简介　　
..　多输入模型　　
..　多输出模型　　
..　层组成的有向无环图　　
..　共享层权重　　
..　将模型作为层　　
..　小结　　
.　使用Keras回调函数和TensorBoard来检查并监控深度学习模型　　
..　训练过程中将回调函数作用于模型　　
..　TensorBoard简介：TensorFlow的可视化框架　　
..　小结　　
.　让模型性能发挥到极致　　
..　高级架构模式　　
..　超参数优化　　
..　模型集成　　
..　小结　　
本章总结　　
第章　生成式深度学习　　
.　使用LSTM生成文本　　
..　生成式循环网络简史　　
..　如何生成序列数据　　
..　采样策略的重要性　　
..　实现字符级的LSTM文本生成　　
..　小结　　
.　DeepDream　　
..　用Keras实现DeepDream　　
..　小结　　
.　神经风格迁移　　
..　内容损失　　
..　风格损失　　
..　用Keras实现神经风格迁移　　
..　小结　　
.　用变分自编码器生成图像　　
..　从图像的潜在空间中采样　　
..　图像编辑的概念向量　　
..　变分自编码器　　
..　小结　　
.　生成式对抗网络简介　　
..　GAN 的简要实现流程　　
..　大量技巧　　
..　生成器　　
..　判别器　　
..　对抗网络　　
..　如何训练DCGAN　　
..　小结　　
本章总结　　
第章　总结　　
.　重点内容回顾　　
..　人工智能的各种方法　　
..　深度学习在机器学习领域中的特殊之处　　
..　如何看待深度学习　　
..　关键的推动技术　　
..　机器学习的通用工作流程　　
..　关键网络架构　　
..　可能性空间　　
.　深度学习的局限性　　
..　将机器学习模型拟人化的风险　　
..　局部泛化与极端泛化　　
..　小结　　
.　深度学习的未来　　
..　模型即程序　　
..　超越反向传播和可微层　　
..　自动化机器学习　　
..　终身学习与模块化子程序复用　　
..　长期愿景　　
.　了解一个快速发展领域的最新进展　　
..　使用Kaggle练习解决现实世界的问题　　
..　在arXiv阅读最新进展　　
..　探索Keras生态系统　　
.　结束语　　
附录A　在Ubuntu上安装Keras及其依赖　　
附录B　在EC GPU实例上运行Jupyter笔记本　　
・ ・ ・ ・ ・ ・ (收起)序
前言
常用符号表
第一部分 机器学习基础
第章 绪论
.人工智能...............................
..人工智能的发展历史....................
..人工智能的流派.......................
.机器学习...............................
.表示学习...............................
..局部表示和分布式表示...................
..表示学习...........................
.深度学习...............................
..端到端学习..........................
.神经网络...............................
..人脑神经网络........................
..人工神经网络........................
..神经网络的发展历史....................
.本书的知识体系...........................
.常用的深度学习框架.........................
.总结和深入阅读...........................
第章 机器学习概述
.基本概念...............................
.机器学习的三个基本要素......................
..模型..............................
..学习准则...........................
..优化算法...........................
.机器学习的简单示例――线性回归.................
..参数学习...........................
.偏差-方差分解............................
.机器学习算法的类型.........................
.数据的特征表示...........................
..传统的特征学习.......................
..深度学习方法........................
.评价指标...............................
.理论和定理..............................
..PAC学习理论........................
..没有免费午餐定理......................
..奥卡姆剃刀原理.......................
..丑小鸭定理..........................
..归纳偏置...........................
.总结和深入阅读...........................
第章 线性模型
.线性判别函数和决策边界......................
..二分类............................
..多分类............................
.Logistic回归.............................
..参数学习...........................
.Softmax回归.............................
..参数学习...........................
.感知器.................................
..参数学习...........................
..感知器的收敛性.......................
..参数平均感知器.......................
..扩展到多分类........................
.支持向量机..............................
..参数学习...........................
..核函数............................
..软间隔............................
.损失函数对比.............................
.总结和深入阅读...........................
第二部分 基础模型
第章 前馈神经网络
.神经元.................................
..Sigmoid型函数.......................
..ReLU函数..........................
..Swish函数..........................
..GELU函数..........................
..Maxout单元.........................
.网络结构...............................
..前馈网络...........................
..记忆网络...........................
..图网络............................
.前馈神经网络.............................
..通用近似定理........................
..应用到机器学习.......................
..参数学习...........................
.反向传播算法.............................
.自动梯度计算.............................
..数值微分...........................
..符号微分...........................
..自动微分...........................
.优化问题...............................
..非凸优化问题........................
..梯度消失问题........................
.总结和深入阅读...........................
第章 卷积神经网络
.卷积..................................
..卷积的定义..........................
..互相关............................
..卷积的变种..........................
..卷积的数学性质.......................
.卷积神经网络.............................
..用卷积来代替全连接....................
..卷积层............................
..汇聚层............................
..卷积网络的整体结构....................
.参数学习...............................
..卷积神经网络的反向传播算法...............
.几种典型的卷积神经网络......................
..LeNet-............................
..AlexNet...........................
..Inception网络........................
..残差网络...........................
.其他卷积方式.............................
..转置卷积...........................
..空洞卷积...........................
.总结和深入阅读...........................
第章 循环神经网络
.给网络增加记忆能力.........................
..延时神经网络........................
..有外部输入的非线性自回归模型..............
..循环神经网络........................
.简单循环网络.............................
..循环神经网络的计算能力..................
.应用到机器学习...........................
..序列到类别模式.......................
..同步的序列到序列模式...................
..异步的序列到序列模式...................
.参数学习...............................
..随时间反向传播算法....................
..实时循环学习算法......................
.长程依赖问题.............................
..改进方案...........................
.基于门控的循环神经网络......................
..长短期记忆网络.......................
..LSTM网络的各种变体...................
..门控循环单元网络......................
.深层循环神经网络..........................
..堆叠循环神经网络......................
..双向循环神经网络......................
.扩展到图结构.............................
..递归神经网络........................
..图神经网络..........................
.总结和深入阅读...........................
第章 网络优化与正则化
.网络优化...............................
..网络结构多样性.......................
..高维变量的非凸优化....................
..神经网络优化的改善方法..................
.优化算法...............................
..小批量梯度下降.......................
..批量大小选择........................
..学习率调整..........................
..梯度估计修正........................
..优化算法小结........................
.参数初始化..............................
..基于固定方差的参数初始化.................
..基于方差缩放的参数初始化.................
..正交初始化..........................
.数据预处理..............................
.逐层归一化..............................
..批量归一化..........................
..层归一化...........................
..权重归一化..........................
..局部响应归一化.......................
.超参数优化..............................
..网格搜索...........................
..随机搜索...........................
..贝叶斯优化..........................
..动态资源分配........................
..神经架构搜索........................
.网络正则化..............................
..?和?正则化........................
..权重衰减...........................
..提前停止...........................
..丢弃法............................
..数据增强...........................
..标签平滑...........................
.总结和深入阅读...........................
第章 注意力机制与外部记忆
.认知神经学中的注意力.......................
.注意力机制..............................
..注意力机制的变体......................
.自注意力模型.............................
.人脑中的记忆.............................
.记忆增强神经网络..........................
..端到端记忆网络.......................
..神经图灵机..........................
.基于神经动力学的联想记忆.....................
..Hopfiel网络........................
..使用联想记忆增加网络容量.................
.总结和深入阅读...........................
第章 无监督学习
.无监督特征学习...........................
..主成分分析..........................
..稀疏编码...........................
..自编码器...........................
..稀疏自编码器........................
..堆叠自编码器........................
..降噪自编码器........................
.概率密度估计.............................
..参数密度估计........................
..非参数密度估计.......................
.总结和深入阅读...........................
第章 模型独立的学习方式
.集成学习...............................
..AdaBoost算法........................
.自训练和协同训练..........................
..自训练............................
..协同训练...........................
.多任务学习..............................
.迁移学习...............................
..归纳迁移学习........................
..转导迁移学习........................
.终身学习...............................
.元学习.................................
..基于优化器的元学习....................
..模型无关的元学习......................
.总结和深入阅读...........................
第三部分 进阶模型
第章 概率图模型
.模型表示...............................
..有向图模型..........................
..常见的有向图模型......................
..无向图模型..........................
..无向图模型的概率分解...................
..常见的无向图模型......................
..有向图和无向图之间的转换.................
.学习..................................
..不含隐变量的参数估计...................
..含隐变量的参数估计....................
.推断..................................
..精确推断...........................
..近似推断...........................
.变分推断...............................
.基于采样法的近似推断.......................
..采样法............................
..拒绝采样...........................
..重要性采样..........................
..马尔可夫链蒙特卡罗方法..................
.总结和深入阅读...........................
第章 深度信念网络
.玻尔兹曼机..............................
..生成模型...........................
..能量最小化与模拟退火...................
..参数学习...........................
.受限玻尔兹曼机...........................
..生成模型...........................
..参数学习...........................
..受限玻尔兹曼机的类型...................
.深度信念网络.............................
..生成模型...........................
..参数学习...........................
.总结和深入阅读...........................
第章 深度生成模型
.概率生成模型.............................
..密度估计...........................
..生成样本...........................
..应用于监督学习.......................
.变分自编码器.............................
..含隐变量的生成模型....................
..推断网络...........................
..生成网络...........................
..模型汇总...........................
..再参数化...........................
..训练..............................
.生成对抗网络.............................
..显式密度模型和隐式密度模型...............
..网络分解...........................
..训练..............................
..一个生成对抗网络的具体实现：DCGAN..........
..模型分析...........................
..改进模型...........................
.总结和深入阅读...........................
第章 深度强化学习
.强化学习问题.............................
..典型例子...........................
..强化学习定义........................
..马尔可夫决策过程......................
..强化学习的目标函数....................
..值函数............................
..深度强化学习........................
.基于值函数的学习方法.......................
..动态规划算法........................
..蒙特卡罗方法........................
..时序差分学习方法......................
..深度Q网络..........................
.基于策略函数的学习方法......................
..REINFORCE算法......................
..带基准线的REINFORCE算法...............
.演员-评论员算法...........................
.总结和深入阅读...........................
第章 序列生成模型
.序列概率模型.............................
..序列生成...........................
.N元统计模型.............................
.深度序列模型.............................
..模型结构...........................
..参数学习...........................
.评价方法...............................
..困惑度............................
..BLEU算法..........................
..ROUGE算法.........................
.序列生成模型中的学习问题.....................
..曝光偏差问题........................
..训练目标不一致问题....................
..计算效率问题........................
.序列到序列模型...........................
..基于循环神经网络的序列到序列模型...........
..基于注意力的序列到序列模型...............
..基于自注意力的序列到序列模型..............
.总结和深入阅读...........................
附录数学基础 
附录A 线性代数 
附录B 微积分 
附录C 数学优化 
附录D 概率论 
附录E 信息论 
索引 
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
前言
如何使用本书
资源与支持
主要符号表
第 章　深度学习简介… ………………… 
.　起源…………………………………………… 
.　发展…………………………………………… 
.　成功案例……………………………………… 
.　特点………………………………………… 
小结…………………………………………… 
练习…………………………………………… 
第 章　预备知识… ……………………… 
.　获取和运行本书的代码……………………… 
..　获取代码并安装运行环境 … ……… 
..　更新代码和运行环境 … …………… 
..　使用GPU版的MXNet … ………… 
小结……………………………………………
练习……………………………………………
.　数据操作… ……………………………… 
..　创建NDArray ………………………
..　运算 …………………………………
..　广播机制 ……………………………
..　索引 …………………………………
..　运算的内存开销 ……………………
..　NDArray和NumPy相互变换………
小结……………………………………………
练习……………………………………………
.　自动求梯度… …………………………… 
..　简单例子 … …………………………
..　训练模式和预测模式 …………… 
..　对Python控制流求梯度 … …… 
小结……………………………………………
练习……………………………………………
.　查阅文档… ……………………………… 
..　查找模块里的所有函数和类 … ……
..　查找特定函数和类的使用 ……… 
..　在MXNet网站上查阅 …………… 
小结………………………………………… 
练习………………………………………… 
第 章　深度学习基础… ……………… 
.　线性回归…………………………………… 
..　线性回归的基本要素 … ………… 
..　线性回归的表示方法 … ………… 
小结………………………………………… 
练习………………………………………… 
.　线性回归的从零开始实现… …………… 
..　生成数据集 … …………………… 
..　读取数据集 ……………………… 
..　初始化模型参数 ………………… 
..　定义模型 ………………………… 
..　定义损失函数 …………………… 
..　定义优化算法 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　线性回归的简洁实现… ………………… 
..　生成数据集 … …………………… 
..　读取数据集 ……………………… 
..　定义模型 ………………………… 
..　初始化模型参数 ………………… 
..　定义损失函数 …………………… 
..　定义优化算法 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　softmax回归… ………………………… 
..　分类问题 … ……………………… 
..　softmax回归模型… …………… 
..　单样本分类的矢量计算表达式…… 
..　小批量样本分类的矢量计算表达式 …………………………… 
..　交叉熵损失函数 ……………………
..　模型预测及评价 ………………… 
小结………………………………………… 
练习………………………………………… 
.　图像分类数据集（Fashion-MNIST）… ……………… 
..　获取数据集 … …………………… 
..　读取小批量 ……………………… 
小结………………………………………… 
练习………………………………………… 
.　softmax回归的从零开始实现… ……… 
..　读取数据集 … …………………… 
..　初始化模型参数 ………………… 
..　实现softmax运算 … …………… 
..　定义模型 ………………………… 
..　定义损失函数 …………………… 
..　计算分类准确率 ………………… 
..　训练模型 ………………………… 
..　预测… …………………………… 
小结………………………………………… 
练习………………………………………… 
.　softmax回归的简洁实现… …………… 
..　读取数据集 … …………………… 
..　定义和初始化模型 ……………… 
..　softmax和交叉熵损失函数 … … 
..　定义优化算法 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　多层感知机… …………………………… 
..　隐藏层 … ……………………………
..　激活函数 ………………………… 
..　多层感知机 ……………………… 
小结………………………………………… 
练习………………………………………… 
.　多层感知机的从零开始实现… ………… 
..　读取数据集 … …………………… 
..　定义模型参数 …………………… 
..　定义激活函数 …………………… 
..　定义模型 ………………………… 
..　定义损失函数 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　多层感知机的简洁实现………………… 
..　定义模型 ………………………… 
..　训练模型 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　模型选择、欠拟合和过拟合… ………… 
..　训练误差和泛化误差 …………… 
..　模型选择 ………………………… 
..　欠拟合和过拟合 ………………… 
..　多项式函数拟合实验 ……………
小结………………………………………… 
练习………………………………………… 
.　权重衰减………………………………… 
..　方法 ……………………………… 
..　高维线性回归实验 … ………… 
..　从零开始实现 … ……………… 
..　简洁实现 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　丢弃法…………………………………… 
..　方法 ……………………………… 
..　从零开始实现 … …………………
..　简洁实现 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　正向传播、反向传播和计算图………… 
..　正向传播 ……………………… 
..　正向传播的计算图 … ………… 
..　反向传播 … …………………… 
..　训练深度学习模型 … ………… 
小结………………………………………… 
练习………………………………………… 
.　数值稳定性和模型初始化……………… 
..　衰减和爆炸 ……………………… 
..　随机初始化模型参数 … ……… 
小结………………………………………… 
练习………………………………………… 
.　实战Kaggle比赛：房价预测… ……… 
..　Kaggle比赛 … ………………… 
..　读取数据集 … ………………… 
..　预处理数据集 … …………………
..　训练模型 … …………………… 
..　k 折交叉验证 …………………… 
..　模型选择 … …………………… 
..　预测并在Kaggle提交结果… … 
小结………………………………………… 
练习………………………………………… 
第 章　深度学习计算… ……………… 
.　模型构造………………………………… 
..　继承Block类来构造模型 … …… 
..　Sequential类继承自Block类…………………………… 
..　构造复杂的模型… ……………… 
小结………………………………………… 
练习………………………………………… 
.　模型参数的访问、初始化和共享… …… 
..　访问模型参数 … ………………… 
..　初始化模型参数 ………………… 
..　自定义初始化方法 ……………… 
..　共享模型参数 …………………… 
小结………………………………………… 
练习………………………………………… 
.　模型参数的延后初始化… ……………… 
..　延后初始化 … …………………… 
..　避免延后初始化 ………………… 
小结………………………………………… 
练习………………………………………… 
.　自定义层… ……………………………… 
..　不含模型参数的自定义层 … …… 
..　含模型参数的自定义层 ………… 
小结………………………………………… 
练习………………………………………… 
.　读取和存储… …………………………… 
..　读写NDArray… ………………… 
..　读写Gluon模型的参数… ……… 
小结………………………………………… 
练习………………………………………… 
.　GPU计算………………………………… 
..　计算设备 … ……………………… 
..　NDArray的GPU计算…………… 
..　Gluon的GPU计算 ……………… 
小结………………………………………… 
练习………………………………………… 
第 章　卷积神经网络… ……………… 
.　二维卷积层………………………………… 
..　二维互相关运算 … ……………… 
..　二维卷积层 … …………………… 
..　图像中物体边缘检测 … ………… 
..　通过数据学习核数组 … ………… 
..　互相关运算和卷积运算 … ……… 
..　特征图和感受野… ……………… 
小结………………………………………… 
练习………………………………………… 
.　填充和步幅… …………………………… 
..　填充 … …………………………… 
..　步幅 ……………………………… 
小结………………………………………… 
练习………………………………………… 
.　多输入通道和多输出通道… …………… 
..　多输入通道 … …………………… 
..　多输出通道… …………………… 
..　×卷积层 ……………………… 
小结………………………………………… 
练习………………………………………… 
.　池化层… ………………………………… 
..　二维最大池化层和平均池化层 … ………………………… 
..　填充和步幅 ……………………… 
..　多通道 …………………………… 
小结………………………………………… 
练习………………………………………… 
.　卷积神经网络（LeNet）… …………… 
..　LeNet模型 … …………………… 
..　训练模型… ……………………… 
小结………………………………………… 
练习………………………………………… 
.　深度卷积神经网络（AlexNet）… …… 
..　学习特征表示 … ………………… 
..　AlexNet… ……………………… 
..　读取数据集 ……………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　使用重复元素的网络（VGG）………… 
..　VGG块 …………………………… 
..　VGG网络 … …………………… 
..　训练模型… ……………………… 
小结………………………………………… 
练习………………………………………… 
.　网络中的网络（NiN）… ……………… 
..　NiN块 … ………………………… 
..　NiN模型 … ……………………… 
..　训练模型… ……………………… 
小结………………………………………… 
练习………………………………………… 
.　含并行连结的网络（GoogLeNet）…… 
..　Inception块 ……………………… 
..　GoogLeNet模型 … …………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　批量归一化……………………………… 
..　批量归一化层 ………………… 
..　从零开始实现 … ……………… 
..　使用批量归一化层的LeNet … … 
..　简洁实现 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　残差网络（ResNet） ……………… 
..　残差块 …………………………… 
..　ResNet模型… ………………… 
..　训练模型………………………… 
小结………………………………………… 
练习………………………………………… 
.　稠密连接网络（DenseNet）………… 
..　稠密块 …………………………… 
..　过渡层 … ……………………… 
..　DenseNet模型 ………………… 
..　训练模型 … …………………… 
小结………………………………………… 
练习………………………………………… 
第 章　循环神经网络… ……………… 
.　语言模型………………………………… 
..　语言模型的计算 … ……………… 
..　n 元语法 … ……………………… 
小结………………………………………… 
练习………………………………………… 
.　循环神经网络… ………………………… 
..　不含隐藏状态的神经网络 … …… 
..　含隐藏状态的循环神经网络… … 
..　应用：基于字符级循环神经网络的语言模型 … ……………………… 
小结………………………………………… 
练习………………………………………… 
.　语言模型数据集（歌词）…… 
..　读取数据集 … …………………… 
..　建立字符索引 …………………… 
..　时序数据的采样 ………………… 
小结………………………………………… 
练习………………………………………… 
.　循环神经网络的从零开始实现… ……… 
..　one-hot向量 … ………………… 
..　初始化模型参数 ………………… 
..　定义模型 ………………………… 
..　定义预测函数 …………………… 
..　裁剪梯度 ………………………… 
..　困惑度 …………………………… 
..　定义模型训练函数 ……………… 
..　训练模型并创作歌词 …………… 
小结………………………………………… 
练习………………………………………… 
.　循环神经网络的简洁实现… …………… 
..　定义模型 … ……………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　通过时间反向传播… …………………… 
..　定义模型 … ……………………… 
..　模型计算图 ……………………… 
..　方法 ……………………………… 
小结………………………………………… 
练习………………………………………… 
.　门控循环单元（GRU）………………… 
..　门控循环单元 … ………………… 
..　读取数据集 ……………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　长短期记忆（LSTM）… ……………… 
..　长短期记忆 … …………………… 
..　读取数据集 ……………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　深度循环神经网络… …………………… 
小结………………………………………… 
练习………………………………………… 
.　双向循环神经网络……………………… 
小结………………………………………… 
练习………………………………………… 
第 章　优化算法… …………………… 
.　优化与深度学习…………………………… 
..　优化与深度学习的关系 … ……… 
..　优化在深度学习中的挑战 … …… 
小结………………………………………… 
练习………………………………………… 
.　梯度下降和随机梯度下降… …………… 
..　一维梯度下降 … ………………… 
..　学习率 …………………………… 
..　多维梯度下降 …………………… 
..　随机梯度下降 …………………… 
小结………………………………………… 
练习………………………………………… 
.　小批量随机梯度下降… ………………… 
..　读取数据集 … …………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　动量法… …………………………………
..　梯度下降的问题 … ……………… 
..　动量法 …………………………… 
・・　目　　录
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　AdaGrad算法……………………………
..　算法 … …………………………… 
..　特点 ……………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　RMSProp算法… ………………………
..　算法 … …………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　AdaDelta算法… ……………………… 
..　算法… …………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　Adam算法… …………………………… 
..　算法 … …………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
第 章　计算性能… …………………… 
.　命令式和符号式混合编程… …………… 
..　混合式编程取两者之长 … ……… 
..　使用HybridSequential类构造模型 … …………………………… 
..　使用HybridBlock类构造模型… …………………………… 
小结………………………………………… 
练习………………………………………… 
.　异步计算… ………………………………
..　MXNet中的异步计算 …………… 
..　用同步函数让前端等待计算结果 … …………………………… 
..　使用异步计算提升计算性能 …… 
..　异步计算对内存的影响 ………… 
小结………………………………………… 
练习………………………………………… 
.　自动并行计算… …………………………
..　CPU和GPU的并行计算 … …… 
..　计算和通信的并行计算 ………… 
小结………………………………………… 
练习………………………………………… 
.　多GPU计算……………………………… 
..　数据并行 … ……………………… 
..　定义模型 ………………………… 
..　多GPU之间同步数据 … ……… 
..　单个小批量上的多GPU训练 … …………………………… 
..　定义训练函数 …………………… 
..　多GPU训练实验 … …………… 
小结………………………………………… 
练习………………………………………… 
.　多GPU计算的简洁实现………………… 
..　多GPU上初始化模型参数……… 
..　多GPU训练模型 … …………… 
小结………………………………………… 
练习………………………………………… 
第 章　计算机视觉… ………………… 
.　图像增广…………………………………
..　常用的图像增广方法 … ………… 
..　使用图像增广训练模型 … ……… 
小结………………………………………… 
练习………………………………………… 
.　微调… ……………………………………
热狗识别 … ……………………………… 
小结………………………………………… 
练习………………………………………… 
目　　录　・・
.　目标检测和边界框… ……………………
边界框 … ………………………………… 
小结………………………………………… 
练习………………………………………… 
.　锚框… …………………………………… 
..　生成多个锚框… ………………… 
..　交并比 …………………………… 
..　标注训练集的锚框 ……………… 
..　输出预测边界框… ……………… 
小结………………………………………… 
练习………………………………………… 
.　多尺度目标检测… ………………………
小结………………………………………… 
练习………………………………………… 
.　目标检测数据集（皮卡丘）… …………
..　获取数据集 … …………………… 
..　读取数据集… …………………… 
..　图示数据 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　单发多框检测（SSD）… ……………… 
..　定义模型… ……………………… 
..　训练模型 ………………………… 
..　预测目标 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　区域卷积神经网络（R-CNN）系列……
..　R-CNN … ……………………… 
..　Fast R-CNN …………………… 
..　Faster R-CNN ………………… 
..　Mask R-CNN … ……………… 
小结………………………………………… 
练习………………………………………… 
.　语义分割和数据集… ……………………
..　图像分割和实例分割 … ………… 
..　Pascal VOC语义分割数据集 … ………………………… 
小结………………………………………… 
练习………………………………………… 
.　全卷积网络（FCN）… ………………
..　转置卷积层 …………………… 
..　构造模型 … …………………… 
..　初始化转置卷积层……………… 
..　读取数据集 … ………………… 
..　训练模型………………………… 
..　预测像素类别…………………… 
小结………………………………………… 
练习………………………………………… 
.　样式迁移… ………………………………
..　方法 ……………………………… 
..　读取内容图像和样式图像……… 
..　预处理和后处理图像 ………… 
..　抽取特征 ……………………… 
..　定义损失函数 ………………… 
..　创建和初始化合成图像 ……… 
..　训练模型………………………… 
小结………………………………………… 
练习………………………………………… 
.　实战Kaggle比赛：图像
分类（CIFAR-）……………………
..　获取和整理数据集 ……………… 
..　图像增广 … …………………… 
..　读取数据集 … ………………… 
..　定义模型………………………… 
..　定义训练函数 … ……………… 
..　训练模型 … …………………… 
..　对测试集分类并在Kaggle
提交结果 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　实战Kaggle比赛：狗的品种
识别（ImageNet Dogs）…………… 
..　获取和整理数据集 …………… 
..　图像增广 … …………………… 
..　读取数据集 … ………………… 
..　定义模型 … …………………… 
..　定义训练函数 … ……………… 
..　训练模型 … …………………… 
・・　目　　录
..　对测试集分类并在Kaggle提交结果 … …………………… 
小结………………………………………… 
练习………………………………………… 
第 章　自然语言处理………………… 
.　词嵌入（wordvec）………………… 
..　为何不采用one-hot向量… …… 
..　跳字模型 ………………………… 
..　连续词袋模型 …………………… 
小结………………………………………… 
练习………………………………………… 
.　近似训练…………………………………
..　负采样 …………………………… 
..　层序softmax …………………… 
小结………………………………………… 
练习………………………………………… 
.　wordvec的实现………………………
..　预处理数据集 …………………… 
..　负采样 … ……………………… 
..　读取数据集 … ………………… 
..　跳字模型 … …………………… 
..　训练模型 … …………………… 
..　应用词嵌入模型 … …………… 
小结………………………………………… 
练习………………………………………… 
.　子词嵌入（fastText）… ……………
小结………………………………………… 
练习………………………………………… 
.　全局向量的词嵌入（GloVe）…………
..　GloVe模型 …………………… 
..　从条件概率比值理解GloVe模型……………………… 
小结………………………………………… 
练习………………………………………… 
.　求近义词和类比词………………………
..　使用预训练的词向量 ………… 
..　应用预训练词向量 … ………… 
小结………………………………………… 
练习………………………………………… 
.　文本情感分类：使用循环神经网络…… 
..　文本情感分类数据集 ………… 
..　使用循环神经网络的模型……… 
小结………………………………………… 
练习………………………………………… 
.　文本情感分类：使用卷积神经网络（textCNN）… …………………
..　一维卷积层 … ………………… 
..　时序最大池化层 … …………… 
..　读取和预处理IMDb数据集 … ……………………… 
..　textCNN模型 … ……………… 
小结………………………………………… 
练习………………………………………… 
.　编码器-解码器（seqseq）…………
..　编码器 ………………………… 
..　解码器 … ……………………… 
..　训练模型………………………… 
小结………………………………………… 
练习………………………………………… 
.　 束搜索… ………………………………
..　贪婪搜索 … …………………… 
..　穷举搜索 ……………………… 
..　束搜索 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　注意力机制… …………………………
..　计算背景变量 … ……………… 
..　更新隐藏状态 … ……………… 
..　发展… ………………………… 
小结………………………………………… 
练习………………………………………… 
.　机器翻译… …………………………… 
..　读取和预处理数据集… ……… 
..　含注意力机制的编码器-解码器 … …………… 
..　训练模型 ……………………… 
..　预测不定长的序列… ………… 
..　评价翻译结果 ………………… 
小结………………………………………… 
练习………………………………………… 
附录A　数学基础… …………………… 
附录B　使用 Jupyter 记事本… ……… 
附录C　使用 AWS 运行代码…………… 
附录D　GPU 购买指南………………… 
附录E　如何为本书做贡献… ………… 
附录F　dlzh 包索引…………………… 
附录G　中英文术语对照表… ………… 
参考文献………………………………… 
索引……………………………………… 
・ ・ ・ ・ ・ ・ (收起)前言
第阶段 自动微分 
步骤 作为“箱子”的变量 
. 什么是变量 
. 实现Variable类 
. （补充）NumPy的多维数组 
步骤 创建变量的函数 
. 什么是函数 
. Function类的实现 
. 使用Function类 
步骤 函数的连续调用 
. Exp函数的实现 
. 函数的连续调用 
步骤 数值微分 
. 什么是导数 
. 数值微分的实现 
. 复合函数的导数 
. 数值微分存在的问题 
步骤 反向传播的理论知识 
. 链式法则 
. 反向传播的推导 
. 用计算图表示 
步骤 手动进行反向传播 
. Variable类的功能扩展 
. Function类的功能扩展 
. Square类和Exp类的功能扩展 
. 反向传播的实现 
步骤 反向传播的自动化 
. 为反向传播的自动化创造条件 
. 尝试反向传播 
. 增加backward方法 
步骤 从递归到循环 
. 现在的Variable类 
. 使用循环实现 
. 代码验证 
步骤 让函数更易用 
. 作为Python函数使用 
. 简化backward方法 
. 只支持ndarray 
步骤 测试 
. Python的单元测试 
. square函数反向传播的测试 
. 通过梯度检验来自动测试 
. 测试小结 
第阶段 用自然的代码表达 
步骤 可变长参数（正向传播篇) 
. 修改Function类 
. Add类的实现 
步骤 可变长参数（改进篇) 
. 第项改进：使函数更容易使用 
. 第项改进：使函数更容易实现 
. add函数的实现 
步骤 可变长参数（反向传播篇) 
. 支持可变长参数的Add类的反向传播 
. 修改Variable类 
. Square类的实现 
步骤 重复使用同一个变量 
. 问题的原因 
. 解决方案 
. 重置导数 
步骤 复杂的计算图（理论篇）
. 反向传播的正确顺序 
. 当前的DeZero 
. 函数的优先级 
步骤 复杂的计算图（实现篇）
. 增加“辈分”变量 
. 按照“辈分”顺序取出元素 
. Variable类的backward 
. 代码验证 
步骤 内存管理和循环引用 
. 内存管理 
. 引用计数方式的内存管理 
. 循环引用 
. weakref模块 
. 代码验证 
步骤 减少内存使用量的模式 
. 不保留不必要的导数 
. 回顾Function类 
. 使用Confifig类进行切换 
. 模式的切换 
. 使用with语句切换 
步骤 让变量更易用 
. 命名变量 
. 实例变量ndarray 
. len函数和print函数 
步骤 运算符重载（）
. Mul类的实现 
. 运算符重载 
步骤 运算符重载（）
. 与ndarray一起使用 
. 与flfloat和int一起使用 
. 问题：左项为flfloat或int的情况 
. 问题：左项为ndarray实例的情况 
步骤 运算符重载（）
. 负数 
. 减法 
. 除法 
. 幂运算 
步骤 打包 
. 文件结构 
. 将代码移到核心类 
. 运算符重载 
. 实际的_ _init_ _.py文件 
. 导入dezero 
步骤 复杂函数的求导 
. Sphere函数 
. matyas函数 
. GoldsteinPrice函数 
第阶段 实现高阶导数 
步骤 计算图的可视化（） 
. 安装Graphviz 
. 使用DOT语言描述图形 
. 指定节点属性 
. 连接节点 
步骤 计算图的可视化（）
. 可视化代码的使用示例 
. 从计算图转换为DOT语言 
. 从DOT语言转换为图像 
. 代码验证 
步骤 泰勒展开的导数 
. sin函数的实现 
. 泰勒展开的理论知识 
. 泰勒展开的实现 
. 计算图的可视化 
步骤 函数优化 
. Rosenbrock函数 
. 求导 
. 梯度下降法的实现 
步骤 使用牛顿法进行优化（手动计算）
. 使用牛顿法进行优化的理论知识 
. 使用牛顿法实现优化 
步骤 高阶导数（准备篇） 
. 确认工作：Variable实例变量 
. 确认工作：Function类 
. 确认工作：Variable类的反向传播 
步骤 高阶导数（理论篇） 
. 在反向传播时进行的计算 
. 创建反向传播的计算图的方法 
步骤 高阶导数（实现篇） 
. 新的DeZero 
. 函数类的反向传播 
. 实现更有效的反向传播（增加模式控制代码）
. 修改_ _init_ _.py 
步骤 使用牛顿法进行优化（自动计算） 
. 求二阶导数 
. 使用牛顿法进行优化 
步骤 sin函数的高阶导数 
. sin函数的实现 
. cos函数的实现 
. sin函数的高阶导数 
步骤 高阶导数的计算图 
. tanh函数的导数 
. tanh函数的实现 
. 高阶导数的计算图可视化 
步骤 DeZero的其他用途 
. double backprop的用途 
. 深度学习研究中的应用示例 
第阶段 创建神经网络 
步骤 处理张量 
. 对各元素进行计算 
. 使用张量时的反向传播 
. 使用张量时的反向传播（补充内容）
步骤 改变形状的函数 
. reshape函数的实现 
. 从Variable对象调用reshape 
. 矩阵的转置 
. 实际的transpose函数（补充内容）
步骤 求和的函数 
. sum函数的反向传播 
. sum函数的实现 
. axis和keepdims 
步骤 进行广播的函数 
. broadcast_to函数和sum_to函数 
. DeZero的broadcast_to函数和sum_to函数 
. 支持广播 
步骤 矩阵的乘积 
. 向量的内积和矩阵的乘积 
. 检查矩阵的形状 
. 矩阵乘积的反向传播 
步骤 线性回归 
. 玩具数据集 
. 线性回归的理论知识 
. 线性回归的实现 
. DeZero的mean_squared_error函数（补充内容） 
步骤 神经网络 
. DeZero中的linear函数 
. 非线性数据集 
. 激活函数和神经网络 
. 神经网络的实现 
步骤 汇总参数的层 
. Parameter类的实现 
. Layer类的实现 
. Linear类的实现 
. 使用Layer实现神经网络 
步骤 汇总层的层 
. 扩展Layer类 
. Model类 
. 使用Model来解决问题 
. MLP类 
步骤 通过Optimizer更新参数 
. Optimizer类 
. SGD类的实现 
. 使用SGD类来解决问题 
. SGD以外的优化方法 
步骤 softmax函数和交叉熵误差 
. 用于切片操作的函数 
. softmax函数 
. 交叉熵误差 
步骤 多分类 
. 螺旋数据集 
. 用于训练的代码 
步骤 Dataset类和预处理 
. Dataset类的实现 
. 大型数据集的情况 
. 数据的连接 
. 用于训练的代码 
. 数据集的预处理 
步骤 用于取出小批量数据的DataLoader 
. 什么是迭代器 
. 使用DataLoader 
. accuracy函数的实现 
. 螺旋数据集的训练代码 
步骤 MINST的训练 
. MNIST数据集 
. 训练MNIST 
. 改进模型 
第阶段 DeZero高级挑战 
步骤 支持GPU 
. CuPy的安装和使用方法 
. cuda模块 
. 向Variable / Layer / DataLoader类添加代码 
. 函数的相应修改 
. 在GPU上训练MNIST 
步骤 模型的保存和加载 
. NumPy的save函数和load函数 
. Layer类参数的扁平化 
. Layer类的save函数和load函数 
步骤 Dropout和测试模式 
. 什么是Dropout 
. Inverted Dropout 
. 增加测试模式 
. Dropout的实现 
步骤 CNN的机制（） 
. CNN的网络结构 
. 卷积运算 
. 填充 
. 步幅 
. 输出大小的计算方法 
步骤 CNN的机制（）
. 三阶张量 
. 结合方块进行思考 
. 小批量处理 
. 池化层 
步骤 convd函数和pooling函数 
. 使用imcol展开 
. convd函数的实现 
. Convd层的实现 
. pooling函数的实现 
步骤 具有代表性的CNN（VGG）
. VGG的实现 
. 已训练的权重数据 
. 使用已训练的VGG 
步骤 使用RNN处理时间序列数据 
. RNN层的实现 
. RNN模型的实现 
. 切断连接的方法 
. 正弦波的预测 
步骤 LSTM与数据加载器 
. 用于时间序列数据的数据加载器 
. LSTM层的实现 
附录A inplace运算（步骤的补充内容）
A. 问题确认 
A. 关于复制和覆盖 
A. DeZero的反向传播 
附录B 实现get_item函数（步骤的补充内容）
附录C 在Google Colaboratory上运行 
后 记 
参考文献 
・ ・ ・ ・ ・ ・ (收起)推 荐 序 面对科技拐点，我们的判断与选择
中文版序 人工智能会放大认知能力
前 言 深度学习与智能的本质
第一部分 智能的新构想
 机器学习的崛起
汽车新生态：无人驾驶将全面走入人们生活
自然语言翻译：从语言到句子的飞跃
语音识别：实时跨文化交流不再遥远
AI医疗：医学诊断将更加准确
金融科技：利用数据和算法获取最佳回报
深度法律：效率的提高与费用的降低
德州扑克：当机器智能学会了虚张声势
AlphaGo奇迹：神经科学与人工智能的协同
弗林效应：深度学习让人类更加智能
新教育体系：每个人都需要终身学习
正面影响：新兴技术不是生存威胁
回到未来：当人类智能遇到人工智能
 人工智能的重生
看似简单的视觉识别
计算机视觉的进步
早期人工智能发展缓慢
从神经网络到人工智能
 神经网络的黎明
深度学习的起点
从样本中学习
利用感知器区分性别
被低估的神经网络
 大脑式的计算
网络模型能够模仿智能行为
神经网络先驱者
乔治・布尔与机器学习
利用神经科学理解大脑
大脑如何处理问题
计算神经科学的兴起
 洞察视觉系统
人眼是如何看到东西的
大脑皮层中的视觉
突触的可塑性
通过阴影脑补立体全貌
视觉区域的层级结构
认知神经科学的诞生
第二部分 深度学习的演进
 语音识别的突破
在嘈杂中找到你的声音
将独立分量分析应用于大脑
什么在操控我们的言行
 霍普菲尔德网络和玻尔兹曼机
约翰・霍普菲尔德的伟大之处
内容可寻址存储器
局部最小值与全局最小值
玻尔兹曼机
赫布理论
学习识别镜像对称
学习识别手写数字
无监督学习和皮层发育
 反向传播算法
算法的优化
语音合成的突破
神经网络的重生
理解真正的深度学习
神经网络的局限性
 卷积学习
机器学习的稳步发展
卷积网络的渐进式改进
当深度学习遇到视觉层级结构
有工作记忆的神经网络
生成式对抗网络
应对现实社会的复杂性
 奖励学习
机器如何学会下棋
大脑的奖励机制
用“感知-行动”框架提高绩效
学习如何翱翔
学习如何歌唱
人工智能的可塑性
更多需要被解决的问题
 火爆的NIPS
为什么NIPS如此受欢迎
谁拥有最多数据，谁就是赢家
为未来做准备
第三部分 人类，智能与未来
 智能时代
世纪的生活
未来的身份认证
社交机器人的崛起
机器已经会识别人类面部表情
新技术改变教育方式
成为更好的学习者
训练你的大脑
智能商业
 算法驱动
用算法把复杂问题简单化
理解、分析复杂系统
大脑的逻辑深度
尝试所有可能的策略
 芯片崛起
神经形态芯片
视网膜芯片
神经形态工程
摩尔定律的终结
 信息科学
用字节丈量世界
用数学思维解决通信难题
预测是如何产生的
深度理解大脑
大脑的操作系统
生物学与计算科学
人工智能能拥有媲美人类大脑的操作系统
 生命与意识
视觉意识
视觉感知的过程
视觉感知的时机
视觉感知的部位
视觉搜索的机理
创造意识比理解意识更容易
 进化的力量
大自然比我们聪明
认知科学的兴起
不能把语言问题只留给语言学家
难预测的行为规律
神经网络的寒冬
从深度学习到通用人工智能
 深度智能
遗传密码
每个物种都有智能
进化的起源
人类终将解决智能难题
・ ・ ・ ・ ・ ・ (收起)第 部分　PyTorch核心
第　章 深度学习和PyTorch库简介　
．　深度学习革命　
．　PyTorch深度学习　
．　为什么用PyTorch　
．　PyTorch如何支持深度学习概述　
．　硬件和软件要求　
．　练习题　
．　本章小结　
第　章 预训练网络　
．　一个识别图像主体的预训练网络　
．．　获取一个预先训练好的网络用于图像识别　
．．　AlexNet　
．．　ResNet　
．．　准备运行　
．．　运行模型　
．　一个足以以假乱真的预训练模型　
．．　GAN游戏　
．．　CycleGAN　
．．　一个把马变成斑马的网络　
．　一个描述场景的预训练网络　
．　Torch Hub　
．　总结　
．　练习题　
．　本章小结　
第章　从张量开始　
．　实际数据转为浮点数　
．　张量：多维数组　
．．　从Python列表到PyTorch张量　
．．　构造第 个张量　
．．　张量的本质　
．　索引张量　
．　命名张量　
．　张量的元素类型　
．．　使用dtype指定数字类型　
．．　适合任何场合的dtype　
．．　管理张量的dtype属性　
．　张量的API　
．　张量的存储视图　
．．　索引存储区　
．．　修改存储值：就地操作　
．　张量元数据：大小、偏移量和步长　
．．　另一个张量的存储视图　
．．　无复制转置　
．．　高维转置　
．．　连续张量　
．　将张量存储到GPU　
．　NumPy互操作性　
．　广义张量也是张量　
．　序列化张量　
．　总结　
．　练习题　
．　本章小结　
第章　使用张量表征真实数据　
．　处理图像　
．．　添加颜色通道　
．．　加载图像文件　
．．　改变布局　
．．　正规化数据　
．　三维图像：体数据　
．　表示表格数据　
．．　使用真实的数据集　
．．　加载葡萄酒数据张量　
．．　表示分数　
．．　独热编码　
．．　何时分类　
．．　寻找阈值　
．　处理时间序列　
．．　增加时间维度　
．．　按时间段调整数据　
．．　准备训练　
．　表示文本　
．．　将文本转化为数字　
．．　独热编码字符　
．．　独热编码整个词　
．．　文本嵌入　
．．　作为蓝图的文本嵌入　
．　总结　
．　练习题　
．　本章小结　
第章　学习的机制　
．　永恒的建模经验　
．　学习就是参数估计　
．．　一个热点问题　
．．　收集一些数据　
．．　可视化数据　
．．　选择线性模型首试　
．　减少损失是我们想要的　
．　沿着梯度下降　
．．　减小损失　
．．　进行分析　
．．　迭代以适应模型　
．．　归一化输入　
．．　再次可视化数据　
．　PyTorch自动求导：反向传播的一切　
．．　自动计算梯度　
．．　优化器　
．．　训练、验证和过拟合　
．．　自动求导更新及关闭　
．　总结　
．　练习题　
．　本章小结　
第章　使用神经网络拟合数据　
．　人工神经网络　
．．　组成一个多层网络　
．．　理解误差函数　
．．　我们需要的只是激活函数　
．．　更多激活函数　
．．　选择最佳激活函数　
．．　学习对于神经网络意味着什么　
．　PyTorch nn模块　
．．　使用__call__()而不是forward()　
．．　回到线性模型　
．　最终完成一个神经网络　
．．　替换线性模型　
．．　检查参数　
．．　与线性模型对比　
．　总结　
．　练习题　
．　本章小结　
第章　区分鸟和飞机：从图像学习　
．　微小图像数据集　
．．　下载CIFAR-　
．．　Dataset类　
．．　Dataset变换　
．．　数据归一化　
．　区分鸟和飞机　
．．　构建数据集　
．．　一个全连接模型　
．．　分类器的输出　
．．　用概率表示输出　
．．　分类的损失　
．．　训练分类器　
．．　全连接网络的局限　
．　总结　
．　练习题　
．　本章小结　
第章　使用卷积进行泛化　
．　卷积介绍　
．　卷积实战　
．．　填充边界　
．．　用卷积检测特征　
．．　使用深度和池化技术进一步研究　
．．　为我们的网络整合一切　
．　子类化nn．Module　
．．　将我们的网络作为一个nn．Module　
．．　PyTorch如何跟踪参数和子模块　
．．　函数式API　
．　训练我们的convnet　
．．　测量精度　
．．　保存并加载我们的模型　
．．　在GPU上训练　
．　模型设计　
．．　增加内存容量：宽度　
．．　帮助我们的模型收敛和泛化：正则化　
．．　深入学习更复杂的结构：深度　
．．　本节设计的比较　
．．　已经过时了　
．　总结　
．　练习题　
．　本章小结　
第　部分 从现实世界的图像中学习：肺癌的早期检测
第章　使用PyTorch来检测癌症　
．　用例简介　
．　为一个大型项目做准备　
．　到底什么是CT扫描　
．　项目：肺癌的端到端检测仪　
．．　为什么我们不把数据扔给神经网络直到它起作用呢　
．．　什么是结节　
．．　我们的数据来源：LUNA大挑战赛　
．．　下载LUNA数据集　
．　总结　
．　本章小结　
第　章 将数据源组合成统一的数据集　
．　原始CT数据文件　
．　解析LUNA的标注 数据　
．．　训练集和验证集　
．．　统一标注和候选 数据　
．　加载单个CT扫描　
．　使用病人坐标系定位结节　
．．　病人坐标系　
．．　CT扫描形状和体素大小　
．．　毫米和体素地址之间的转换　
．．　从CT扫描中取出一个结节　
．　一个简单的数据集实现　
．．　使用getCtRawCandidate()函数缓存候选数组　
．．　在LunaDataset．__init__()中构造我们的数据集　
．．　分隔训练集和验证集　
．．　呈现数据　
．　总结　
．　练习题　
．　本章小结　
第　章 训练分类模型以检测可疑肿瘤　
．　一个基本的模型和训练循环　
．　应用程序的主入口点　
．　预训练和初始化　
．．　初始化模型和优化器　
．．　数据加载器的维护和供给　
．　我们的首次神经网络设计　
．．　核心卷积　
．．　完整模型　
．　训练和验证模型　
．．　computeBatchLoss()函数　
．．　类似的验证循环　
．　输出性能指标　
．　运行训练脚本　
．．　训练所需的数据　
．．　插曲：enumerateWithEstimate()函数　
．　评估模型：得到．%的正确率是否意味着我们完成了任务　
．　用TensorBoard绘制训练指标　
．．　运行TensorBoard　
．．　增加TensorBoard对指标记录函数的支持　
．　为什么模型不学习检测结节　
．　总结　
．　练习题　
．　本章小结　
第　章 通过指标和数据增强来提升训练　
．　高级改进计划　
．　好狗与坏狗：假阳性与假阴性　
．　用图表表示阳性与阴性　
．．　召回率是Roxie的强项　
．．　精度是Preston的强项　
．．　在logMetrics()中实现精度和召回率　
．．　我们的终极性能指标：F分数　
．．　我们的模型在新指标下表现如何　
．　理想的数据集是什么样的　
．．　使数据看起来更理想化　
．．　使用平衡的LunaDataset与之前的数据集运行情况对比　
．．　认识过拟合　
．　重新审视过拟合的问题　
．　通过数据增强防止过拟合　
．．　具体的数据增强技术　
．．　看看数据增强带来的改进　
．　总结　
．　练习题　
．　本章小结　
第　章 利用分割法寻找可疑结节　
．　向我们的项目添加第 个模型　
．　各种类型的分割　
．　语义分割：逐像素分类　
．　更新分割模型　
．　更新数据集以进行分割　
．．　U-Net有非常具体的对输入大小的要求　
．．　U-Net对三维和二维数据的权衡　
．．　构建真实、有效的数据集　
．．　实现LunadSegmentationDataset　
．．　构建训练和验证数据　
．．　实现TrainingLunadSegmentationDataset　
．．　在GPU上增强数据　
．　更新用于分割的训练脚本　
．．　初始化分割和增强模型　
．．　使用Adam优化器　
．．　骰子损失　
．．　将图像导入TensorBoard　
．．　更新指标日志　
．．　保存模型　
．　结果　
．　总结　
．　练习题　
．　本章小结　
第　章 端到端的结节分析及下一步的方向　
．　接近终点线　
．　验证集的独立性　
．　连接CT分割和候选结节分类　
．．　分割　
．．　将体素分组为候选结节　
．．　我们发现结节了吗？分类以减少假阳性　
．　定量验证　
．　预测恶性肿瘤　
．．　获取恶性肿瘤信息　
．．　曲线基线下的区域：按直径分类　
．．　重用预先存在的权重：微调　
．．　TensorBoard中的输出　
．　在诊断时所见的内容　
．　接下来呢？其他灵感和数据的来源　
．．　防止过拟合：更好的正则化　
．．　精细化训练数据　
．．　竞赛结果及研究论文　
．　总结　
．　练习题　
．　本章小结　
第部分　部署
第　章 部署到生产环境　
．　PyTorch模型的服务　
．．　支持Flask服务的模型　
．．　我们想从部署中得到的东西　
．．　批处理请求　
．　导出模型　
．．　PyTorch与ONNX的互操作性　
．．　PyTorch自己的导出：跟踪　
．．　具有跟踪模型的服务器　
．　与PyTorch JIT编译器交互　
．．　超越经典Python/PyTorch的期望是什么　
．．　PyTorch作为接口和后端的双重特性　
．．　TorchScript　
．．　为可追溯的差异编写脚本　
．　LibTorch：C++中的PyTorch　
．．　从C++中运行JITed模型　
．．　从C++ API开始　
．　部署到移动设备　
．　新兴技术：PyTorch
模型的企业服务　
．　总结　
．　练习题　
．　本章小结　
・ ・ ・ ・ ・ ・ (收起)第章 互联网的增长引擎――推荐系统
. 为什么推荐系统是互联网的增长引擎
.. 推荐系统的作用和意义
.. 推荐系统与YouTube的观看时长增长
.. 推荐系统与电商网站的收入增长
. 推荐系统的架构
.. 推荐系统的逻辑框架
.. 推荐系统的技术架构
.. 推荐系统的数据部分
.. 推荐系统的模型部分
.. 深度学习对推荐系统的革命性贡献
.. 把握整体，补充细节
. 本书的整体结构
第章 前深度学习时代――推荐系统的进化之路
. 传统推荐模型的演化关系图
. 协同过滤――经典的推荐算法
.. 什么是协同过滤
.. 用户相似度计算
.. 终结果的排序
.. ItemCF
.. UserCF与ItemCF的应用场景
.. 协同过滤的下一步发展
. 矩阵分解算法――协同过滤的进化
.. 矩阵分解算法的原理
.. 矩阵分解的求解过程
.. 消除用户和物品打分的偏差
.. 矩阵分解的优点和局限性
. 逻辑回归――融合多种特征的推荐模型
.. 基于逻辑回归模型的推荐流程
.. 逻辑回归模型的数学形式
.. 逻辑回归模型的训练方法
.. 逻辑回归模型的优势
.. 逻辑回归模型的局限性
. 从FM到FFM――自动特征交叉的解决方案
.. POLY模型――特征交叉的开始
.. FM模型――隐向量特征交叉
.. FFM模型――引入特征域的概念
.. 从POLY到FFM的模型演化过程
. GBDT+LR――特征工程模型化的开端
.. GBDT+LR组合模型的结构
.. GBDT进行特征转换的过程
.. GBDT+LR 组合模型开启的特征工程新趋势
. LS-PLM――阿里巴巴曾经的主流推荐模型
.. LS-PLM 模型的主要结构
.. LS-PLM模型的优点
.. 从深度学习的角度重新审视LS-PLM模型
. 总结――深度学习推荐系统的前夜
第章 浪潮之巅――深度学习在推荐系统中的应用
. 深度学习推荐模型的演化关系图
. AutoRec――单隐层神经网络推荐模型
.. AutoRec模型的基本原理
.. AutoRec模型的结构
.. 基于AutoRec模型的推荐过程
.. AutoRec模型的特点和局限性
. Deep Crossing模型――经典的深度学习架构
.. Deep Crossing模型的应用场景
.. Deep Crossing模型的网络结构
.. Deep Crossing模型对特征交叉方法的革命
. NeuralCF模型――CF与深度学习的结合
.. 从深度学习的视角重新审视矩阵分解模型
.. NeuralCF模型的结构
.. NeuralCF模型的优势和局限性
. PNN模型――加强特征交叉能力
.. PNN模型的网络架构
.. Product层的多种特征交叉方式
.. PNN模型的优势和局限性
. Wide&Deep 模型――记忆能力和泛化能力的综合
.. 模型的记忆能力与泛化能力
.. Wide&Deep模型的结构
.. Wide&Deep模型的进化――Deep&Cross模型
.. Wide&Deep模型的影响力
. FM与深度学习模型的结合
.. FNN――用FM的隐向量完成Embedding层初始化
.. DeepFM――用FM代替Wide部分
.. NFM――FM的神经网络化尝试
.. 基于FM的深度学习模型的优点和局限性
. 注意力机制在推荐模型中的应用
.. AFM――引入注意力机制的FM
.. DIN――引入注意力机制的深度学习网络
.. 注意力机制对推荐系统的启发
. DIEN――序列模型与推荐系统的结合
.. DIEN的“进化”动机
.. DIEN模型的架构
.. 兴趣抽取层的结构
.. 兴趣进化层的结构
.. 序列模型对推荐系统的启发
. 强化学习与推荐系统的结合
.. 深度强化学习推荐系统框架
.. 深度强化学习推荐模型
.. DRN的学习过程
.. DRN的在线学习方法――竞争梯度下降算法
.. 强化学习对推荐系统的启发
. 总结――推荐系统的深度学习时代
第章 Embedding技术在推荐系统中的应用
. 什么是Embedding
.. 词向量的例子
.. Embedding 技术在其他领域的扩展
.. Embedding 技术对于深度学习推荐系统的重要性
. Wordvec――经典的Embedding方法
.. 什么是Wordvec
.. Wordvec模型的训练过程
.. Wordvec的“负采样”训练方法
.. Wordvec对Embedding技术的奠基性意义
. Itemvec――Wordvec 在推荐系统领域的推广
.. Itemvec的基本原理
.. “广义”的Itemvec
.. Itemvec方法的特点和局限性
. Graph Embedding――引入更多结构信息的图嵌入技术
.. DeepWalk――基础的Graph Embedding方法
.. Nodevec――同质性和结构性的权衡
.. EGES――阿里巴巴的综合性Graph Embedding方法
. Embedding与深度学习推荐系统的结合
.. 深度学习网络中的Embedding层
.. Embedding的预训练方法
.. Embedding作为推荐系统召回层的方法
. 局部敏感哈希――让Embedding插上翅膀的快速搜索方法
.. “快速”Embedding近邻搜索
.. 局部敏感哈希的基本原理
.. 局部敏感哈希多桶策略
. 总结――深度学习推荐系统的核心操作
第章 多角度审视推荐系统
. 推荐系统的特征工程
.. 构建推荐系统特征工程的原则
.. 推荐系统中的常用特征
.. 常用的特征处理方法
.. 特征工程与业务理解
. 推荐系统召回层的主要策略
.. 召回层和排序层的功能特点
.. 多路召回策略
.. 基于Embedding的召回方法
. 推荐系统的实时性
.. 为什么说推荐系统的实时性是重要的
.. 推荐系统“特征”的实时性
.. 推荐系统“模型”的实时性
.. 用“木桶理论”看待推荐系统的迭代升级
. 如何合理设定推荐系统中的优化目标
.. YouTube以观看时长为优化目标的合理性
.. 模型优化和应用场景的统一性
.. 优化目标是和其他团队的接口性工作
. 推荐系统中比模型结构更重要的是什么
.. 有解决推荐问题的“银弹”吗
.. Netflix对用户行为的观察
.. 观察用户行为，在模型中加入有价值的用户信息
.. DIN模型的改进动机
.. 算法工程师不能只是一个“炼金术士”
. 冷启动的解决办法
.. 基于规则的冷启动过程
.. 丰富冷启动过程中可获得的用户和物品特征
.. 利用主动学习、迁移学习和“探索与利用”机制
.. “巧妇难为无米之炊”的困境
. 探索与利用
.. 传统的探索与利用方法
.. 个性化的探索与利用方法
.. 基于模型的探索与利用方法
.. “探索与利用”机制在推荐系统中的应用
第章 深度学习推荐系统的工程实现
. 推荐系统的数据流
.. 批处理大数据架构
.. 流计算大数据架构
.. Lambda架构
.. Kappa架构
.. 大数据平台与推荐系统的整合
. 推荐模型离线训练之Spark MLlib
.. Spark的分布式计算原理
.. Spark MLlib的模型并行训练原理
.. Spark MLlib并行训练的局限性
. 推荐模型离线训练之Parameter Server
.. Parameter Server的分布式训练原理
.. 一致性与并行效率之间的取舍
.. 多server节点的协同和效率问题
.. Parameter Server技术要点总结
. 推荐模型离线训练之TensorFlow
.. TensorFlow的基本原理
.. TensorFlow基于任务关系图的并行训练过程
.. TensorFlow的单机训练与分布式训练模式
.. TensorFlow技术要点总结
. 深度学习推荐模型的上线部署
.. 预存推荐结果或Embedding结果
.. 自研模型线上服务平台
.. 预训练Embedding+轻量级线上模型
.. 利用PMML转换并部署模型
.. TensorFlow Serving
.. 灵活选择模型服务方法
. 工程与理论之间的权衡
.. 工程师职责的本质
.. Redis容量和模型上线方式之间的权衡
.. 研发周期限制和技术选型的权衡
.. 硬件平台环境和模型结构间的权衡
.. 处理好整体和局部的关系
第章 推荐系统的评估
. 离线评估方法与基本评价指标
.. 离线评估的主要方法
.. 离线评估的指标
. 直接评估推荐序列的离线指标
.. P-R曲线
.. ROC曲线
.. 平均精度均值
.. 合理选择评估指标
. 更接近线上环境的离线评估方法――Replay
.. 模型评估的逻辑闭环
.. 动态离线评估方法
.. Netflix的Replay评估方法实践
. A/B测试与线上评估指标
.. 什么是A/B测试
.. A/B测试的“分桶”原则
.. 线上A/B测试的评估指标
. 快速线上评估方法――Interleaving
.. 传统A/B测试存在的统计学问题
.. Interleaving方法的实现
.. Interleaving方法与传统A/B测试的灵敏度比较
.. Interleaving方法指标与A/B测试指标的相关性
.. Interleaving方法的优点与缺点
. 推荐系统的评估体系
第章 深度学习推荐系统的前沿实践
. Facebook的深度学习推荐系统
.. 推荐系统应用场景
.. 以GBDT+LR组合模型为基础的CTR预估模型
.. 实时数据流架构
.. 降采样和模型校正
.. Facebook GBDT+LR组合模型的工程实践
.. Facebook的深度学习模型DLRM
.. DLRM模型并行训练方法
.. DLRM模型的效果
.. Facebook深度学习推荐系统总结
. Airbnb基于Embedding的实时搜索推荐系统
.. 推荐系统应用场景
.. 基于短期兴趣的房源Embedding方法
.. 基于长期兴趣的用户Embedding和房源Embedding
.. Airbnb搜索词的Embedding
.. Airbnb的实时搜索排序模型及其特征工程
.. Airbnb实时搜索推荐系统总结
. YouTube深度学习视频推荐系统
.. 推荐系统应用场景
.. YouTube推荐系统架构
.. 候选集生成模型
.. 候选集生成模型独特的线上服务方法
.. 排序模型
.. 训练和测试样本的处理
.. 如何处理用户对新视频的偏好
.. YouTube深度学习视频推荐系统总结
. 阿里巴巴深度学习推荐系统的进化
.. 推荐系统应用场景
.. 阿里巴巴的推荐模型体系
.. 阿里巴巴深度学习推荐模型的进化过程
.. 模型服务模块的技术架构
.. 阿里巴巴推荐技术架构总结
第章 构建属于你的推荐系统知识框架
. 推荐系统的整体知识架构图
. 推荐模型发展的时间线
. 如何成为一名优秀的推荐工程师
.. 推荐工程师的项能力
.. 能力的深度和广度
.. 推荐工程师的能力总结
后记
・ ・ ・ ・ ・ ・ (收起)第 章绪论
. 简介
. 图深度学习的动机
. 本书内容
. 本书读者定位
. 图特征学习的简要发展史
.. 图特征选择
.. 图表示学习
. 小结
. 扩展阅读
第 篇基础理论
第 章图论基础
. 简介
. 图的表示
. 图的性质
.. 度
.. 连通度
.. 中心性
. 谱图论
.. 拉普拉斯矩阵
.. 拉普拉斯矩阵的特征值和特征向量
. 图信号处理
. 复杂图
.. 异质图
.. 二分图
.. 多维图
.. 符号图
.. 超图
.. 动态图
. 图的计算任务
.. 侧重于节点的任务
.. 侧重于图的任务
. 小结
. 扩展阅读
第 章深度学习基础
. 简介
. 深度前馈神经网络
.. 网络结构
.. 激活函数
.. 输出层和损失函数
. 卷积神经网络
.. 卷积操作和卷积层
.. 实际操作中的卷积层
.. 非线性激活层
.. 池化层
.. 卷积神经网络总体框架
. 循环神经网络
.. 传统循环神经网络的网络结构
.. 长短期记忆网络
.. 门控循环单元
. 自编码器
.. 欠完备自编码器
.. 正则化自编码器
. 深度神经网络的训练
.. 梯度下降
.. 反向传播
.. 预防过拟合
. 小结
. 扩展阅读
第 篇模型方法
第 章图嵌入
. 简介
. 简单图的图嵌入
.. 保留节点共现
.. 保留结构角色
.. 保留节点状态
.. 保留社区结构
. 复杂图的图嵌入
.. 异质图嵌入
.. 二分图嵌入
.. 多维图嵌入
.. 符号图嵌入
.. 超图嵌入
.. 动态图嵌入
. 小结
. 扩展阅读
第 章图神经网络
. 简介
. 图神经网络基本框架
.. 侧重于节点的任务的图神经网络框架
.. 侧重于图的任务的图神经网络框架
. 图滤波器
.. 基于谱的图滤波器
.. 基于空间的图滤波器
. 图池化
.. 平面图池化
.. 层次图池化
. 图卷积神经网络的参数学习
.. 节点分类中的参数学习
.. 图分类中的参数学习
. 小结
. 扩展阅读
第 章图神经网络的健壮性
. 简介
. 图对抗攻击
.. 图对抗攻击的分类
.. 白盒攻击
.. 灰盒攻击
.. 黑盒攻击
. 图对抗防御
.. 图对抗训练
.. 图净化
.. 图注意力机制
.. 图结构学习
. 小结
. 扩展阅读
第 章可扩展图神经网络
. 简介
. 逐点采样法
. 逐层采样法
. 子图采样法
. 小结
. 扩展阅读
第 章复杂图神经网络
. 简介
. 异质图神经网络
. 二分图神经网络
. 多维图神经网络
. 符号图神经网络
. 超图神经网络
. 动态图神经网络
. 小结
. 扩展阅读
第 章图上的其他深度模型
. 简介
. 图上的自编码器
. 图上的循环神经网络
. 图上的变分自编码器
.. 用于节点表示学习的变分自编码器
.. 用于图生成的变分自编码器
.. 编码器：推论模型
.. 解码器: 生成模型
.. 重建的损失函数
. 图上的生成对抗网络
.. 用于节点表示学习的生成对抗网络
.. 用于图生成的生成对抗网络
. 小结
. 扩展阅读
第 篇实际应用
第 章自然语言处理中的图神经网络
. 简介
. 语义角色标注
. 神经机器翻译
. 关系抽取
. 问答系统
.. 多跳问答任务
.. Entity-GCN 
. 图到序列学习
. 知识图谱中的图神经网络
.. 知识图谱中的图滤波
.. 知识图谱到简单图的转换
.. 知识图谱补全
. 小结
. 扩展阅读
第 章计算机视觉中的图神经网络
. 简介
. 视觉问答
.. 图像表示为图
.. 图像和问题表示为图
. 基于骨架的动作识别
. 图像分类
.. 零样本图像分类
.. 少样本图像分类
.. 多标签图像分类
. 点云学习
. 小结
. 扩展阅读
第 章数据挖掘中的图神经网络
. 简介
. 万维网数据挖掘
.. 社交网络分析
.. 推荐系统
. 城市数据挖掘
.. 交通预测
.. 空气质量预测
. 网络安全数据挖掘
.. 恶意账户检测
.. 虚假新闻检测
. 小结
. 扩展阅读
第 章生物化学和医疗健康中的
图神经网络
. 简介
. 药物开发与发现
.. 分子表示学习
.. 蛋白质相互作用界面预测
.. 药物C靶标结合亲和力预测
. 药物相似性整合
. 复方药物副作用预测
. 疾病预测
. 小结
. 扩展阅读
第 篇前沿进展
第 章图神经网络的高级方法
. 简介
. 深层图神经网络
.. Jumping Knowledge 
.. DropEdge 
.. PairNorm 
. 通过自监督学习探索未标记数据
.. 侧重于节点的任务
.. 侧重于图的任务
. 图神经网络的表达能力
.. WL 测试
.. 表达能力
. 小结
. 扩展阅读
第 章图神经网络的高级应用
. 简介
. 图的组合优化
. 学习程序表示
. 物理学中相互作用的动力系统推断
. 小结
. 扩展阅读
参考文献
索引
・ ・ ・ ・ ・ ・ (收起)Contents 目　　录
前言
第一部分　PyTorch基础
第章　Numpy基础
.　生成Numpy数组
..　从已有数据中创建数组
..　利用random模块生成数组
..　创建特定形状的多维数组
..　利用arange、linspace函数生成数组
.　获取元素
.　Numpy的算术运算
..　对应元素相乘
..　点积运算
.　数组变形
..　更改数组的形状
..　合并数组
.　批量处理
.　通用函数
.　广播机制
.　小结
第章　PyTorch基础
.　为何选择PyTorch？
.　安装配置
..　安装CPU版PyTorch
..　安装GPU版PyTorch
.　Jupyter Notebook环境配置
.　Numpy与Tensor
..　Tensor概述
..　创建Tensor
..　修改Tensor形状
..　索引操作
..　广播机制
..　逐元素操作
..　归并操作
..　比较操作
..　矩阵操作
..　PyTorch与Numpy比较
.　Tensor与Autograd
..　自动求导要点
..　计算图
..　标量反向传播
..　非标量反向传播
.　使用Numpy实现机器学习
.　使用Tensor及Antograd实现机器学习
.　使用TensorFlow架构
.　小结
第章　PyTorch神经网络工具箱
.　神经网络核心组件
.　实现神经网络实例
..　背景说明
..　准备数据
..　可视化源数据
..　构建模型
..　训练模型
.　如何构建神经网络？
..　构建网络层
..　前向传播
..　反向传播
..　训练模型
.　神经网络工具箱nn
..　nn.Module
..　nn.functional
.　优化器
.　动态修改学习率参数
.　优化器比较
.　小结
第章　PyTorch数据处理工具箱
.　数据处理工具箱概述
.　utils.data简介
.　torchvision简介
..　transforms
..　ImageFolder
.　可视化工具
..　tensorboardX简介
..　用tensorboardX可视化神经网络
..　用tensorboardX可视化损失值
..　用tensorboardX可视化特征图
.　本章小结
第二部分　深度学习基础
第章　机器学习基础
.　机器学习的基本任务
..　监督学习
..　无监督学习
..　半监督学习
..　强化学习
.　机器学习一般流程
..　明确目标
..　收集数据
..　数据探索与预处理
..　选择模型及损失函数
..　评估及优化模型
.　过拟合与欠拟合
..　权重正则化
..　Dropout正则化
..　批量正则化
..　权重初始化
.　选择合适激活函数
.　选择合适的损失函数
.　选择合适优化器
..　传统梯度优化的不足
..　动量算法
..　AdaGrad算法
..　RMSProp算法
..　Adam算法
.　GPU加速
..　单GPU加速
..　多GPU加速
..　使用GPU注意事项
.　本章小结
第章　视觉处理基础
.　卷积神经网络简介
.　卷积层
..　卷积核
..　步幅
..　填充
..　多通道上的卷积
..　激活函数
..　卷积函数
..　转置卷积
.　池化层
..　局部池化
..　全局池化
.　现代经典网络
..　LeNet-模型
..　AlexNet模型
..　VGG模型
..　GoogleNet模型
..　ResNet模型
..　胶囊网络简介
.　PyTorch实现CIFAR-多分类
..　数据集说明
..　加载数据
..　构建网络
..　训练模型
..　测试模型
..　采用全局平均池化
..　像Keras一样显示各层参数
.　模型集成提升性能
..　使用模型
..　集成方法
..　集成效果
.　使用现代经典模型提升性能
.　本章小结
第章　自然语言处理基础
.　循环神经网络基本结构
.　前向传播与随时间反向传播
.　循环神经网络变种
..　LSTM
..　GRU
..　Bi-RNN
.　循环神经网络的PyTorch实现
..　RNN实现
..　LSTM实现
..　GRU实现
.　文本数据处理
.　词嵌入
..　WordVec原理
..　CBOW模型
..　Skip-Gram模型
.　PyTorch实现词性判别
..　词性判别主要步骤
..　数据预处理
..　构建网络
..　训练网络
..　测试模型
.　用LSTM预测股票行情
..　 导入数据
..　数据概览
..　预处理数据
..　定义模型
..　训练模型
..　测试模型
.　循环神经网络应用场景
.　小结
第章　生成式深度学习
.　用变分自编码器生成图像
..　自编码器
..　变分自编码器
..　用变分自编码器生成图像
.　GAN简介
..　GAN架构
..　GAN的损失函数
.　用GAN生成图像
..　判别器
..　生成器
..　训练模型
..　可视化结果
.　VAE与GAN的优缺点
.　ConditionGAN
..　CGAN的架构
..　CGAN生成器
..　CGAN判别器
..　CGAN损失函数
..　CGAN可视化
..　查看指定标签的数据
..　可视化损失值
.　DCGAN
.　提升GAN训练效果的一些技巧
.　小结
第三部分　深度学习实践
第章　人脸检测与识别
.　人脸识别一般流程
.　人脸检测
..　目标检测
..　人脸定位
..　人脸对齐
..　MTCNN算法
.　特征提取
.　人脸识别
..　人脸识别主要原理
..　人脸识别发展
.　PyTorch实现人脸检测与识别
..　验证检测代码
..　检测图像
..　检测后进行预处理
..　查看经检测后的图像
..　人脸识别
.　小结
第章　迁移学习实例
.　迁移学习简介
.　特征提取
..　PyTorch提供的预处理模块
..　特征提取实例
.　数据增强
..　按比例缩放
..　裁剪
..　翻转
..　改变颜色
..　组合多种增强方法
.　微调实例
..　数据预处理
..　加载预训练模型
..　修改分类器
..　选择损失函数及优化器
..　训练及验证模型
.　清除图像中的雾霾
.　小结
第章　神经网络机器翻译实例
.　Encoder-Decoder模型原理
.　注意力框架
.　PyTorch实现注意力Decoder
..　构建Encoder
..　构建简单Decoder
..　构建注意力Decoder
.　用注意力机制实现中英文互译
..　导入需要的模块
..　数据预处理
..　构建模型
..　训练模型
..　随机采样，对模型进行测试
..　可视化注意力
.　小结
第章　实战生成式模型
.　DeepDream模型
..　Deep Dream原理
..　DeepDream算法流程
..　用PyTorch实现Deep Dream
.　风格迁移
..　内容损失
..　风格损失
..　用PyTorch实现神经网络风格迁移
.　PyTorch实现图像修复
..　网络结构
..　损失函数
..　图像修复实例
.　PyTorch实现DiscoGAN
..　DiscoGAN架构
..　损失函数
..　DiscoGAN实现
..　用PyTorch实现从边框生成鞋子
.　小结
第章　Caffe模型迁移实例
.　Caffe简介
.　Caffe如何升级到Caffe
.　PyTorch如何迁移到Caffe
.　小结
第章　AI新方向：对抗攻击
.　对抗攻击简介
..　白盒攻击与黑盒攻击
..　无目标攻击与有目标攻击
.　常见对抗样本生成方式
..　快速梯度符号法
..　快速梯度算法
.　PyTorch实现对抗攻击
..　实现无目标攻击
..　实现有目标攻击
.　对抗攻击和防御措施
..　对抗攻击
..　常见防御方法分类
.　总结
第章　强化学习
.　强化学习简介
.　Q-Learning原理
..　Q-Learning主要流程
..　Q函数
..　贪婪策略
.　用PyTorch实现Q-Learning
..　定义Q-Learing主函数
..　执行Q-Learing
.　SARSA算法
..　SARSA算法主要步骤
..　用PyTorch实现SARSA算法
.　小结
第章　深度强化学习
.　DQN算法原理
..　Q-Learning方法的局限性
..　用DL处理RL需要解决的问题
..　用DQN解决方法
..　定义损失函数
..　DQN的经验回放机制
..　目标网络
..　网络模型
..　DQN算法
.　用PyTorch实现DQN算法
.　小结
附录A　PyTorch.版本变更
附录B　AI在各行业的最新应用
・ ・ ・ ・ ・ ・ (收起)目录

第章 深度学习简介：为什么应该学习深度学习 
.　欢迎阅读《深度学习图解》 
.　为什么要学习深度学习 
.　这很难学吗? 
.　为什么要阅读本书 
.　准备工作 
.　你可能需要掌握一部分Python知识 
.　本章小结 
第章 基本概念：机器该如何学习？ 
.　什么是深度学习? 
.　什么是机器学习？ 
.　监督机器学习 
.　无监督机器学习 
.　参数学习和非参数学习 
.　监督参数学习 
.　无监督参数学习 
.　非参数学习 
.　本章小结 
第章 神经网络预测导论：前向传播 
.　什么是预测 
.　能够进行预测的简单神经网络 
.　什么是神经网络? 
.　这个神经网络做了什么? 
.　使用多个输入进行预测 
.　多个输入：这个神经网络做了什么? 
.　多个输入：完整的可运行代码 
.　预测多个输出 
.　使用多个输入和输出进行预测 
.　多输入多输出神经网络的工作原理 
.　用预测结果进一步预测 
.　NumPy快速入门 
.　本章小结 
第章 神经网络学习导论：梯度下降 
.　预测、比较和学习 
.　什么是比较 
.　学习 
.　比较：你的神经网络是否做出了好的预测？ 
.　为什么需要测量误差？ 
.　最简单的神经学习形式是什么？ 
.　冷热学习 
.　冷热学习的特点 
.　基于误差调节权重 
.　梯度下降的一次迭代 
.　学习就是减少误差 
.　回顾学习的步骤 
.　权重增量到底是什么? 
.　狭隘的观点 
.　插着小棍的盒子 
.　导数：两种方式 
.　你真正需要知道的 
.　你不需要知道的 
.　如何使用导数来学习 
.　看起来熟悉吗? 
.　破坏梯度下降 
.　过度修正的可视化 
.　发散 
.　引入α 
.　在代码中实现α 
.　记忆背诵 
第章 通用梯度下降：一次学习多个权重 
.　多输入梯度下降学习 
.　多输入梯度下降详解 
.　回顾学习的步骤 
.　单项权重冻结：它有什么作用? 
.　具有多个输出的梯度下降学习 
.　具有多个输入和输出的梯度下降 
.　这些权重学到了什么? 
.　权重可视化 
.　点积(加权和)可视化 
.　本章小结 
第章 建立你的第一个深度神经网络：反向传播 
.　交通信号灯问题 
.　准备数据 
.　矩阵和矩阵关系 
.　使用Python创建矩阵 
.　建立神经网络 
.　学习整个数据集 
.　完全、批量和随机梯度下降 
.　神经网络对相关性的学习 
.　向上与向下的压力 
.　边界情况：过拟合 
.　边界情况：压力冲突 
.　学习间接相关性 
.　创建关联 
.　堆叠神经网络：回顾 
.　反向传播：远程错误归因 
.　反向传播：为什么有效? 
.　线性与非线性 
.　为什么神经网络仍然不起作用 
.　选择性相关的秘密 
.　快速冲刺 
.　你的第一个深度神经网络 
.　反向传播的代码 
.　反向传播的一次迭代 
.　整合代码 
.　为什么深度网络这么重要? 
第章 如何描绘神经网络：在脑海里，在白纸上 
.　到了简化的时候了 
.　关联抽象 
.　旧的可视化方法过于复杂 
.　简化版可视化 
.　进一步简化 
.　观察神经网络是如何进行预测的 
.　用字母而不是图片来进行可视化 
.　连接变量 
.　信息整合 
.　可视化工具的重要性 
第章 学习信号，忽略噪声：正则化和批处理介绍 
.　用在MNIST上的三层网络 
.　好吧，这很简单 
.　记忆与泛化 
.　神经网络中的过拟合 
.　过拟合从何而来 
.　最简单的正则化：提前停止 
.　行业标准正则化：dropout 
.　为什么dropout有效：整合是有效的 
.　dropout的代码 
.　在MNIST数据集上对dropout进行测试 
.　批量梯度下降 
.　本章小结 
第章 概率和非线性建模：激活函数 
.　什么是激活函数? 
.　标准隐藏层激活函数 
.　标准输出层激活函数 
.　核心问题：输入具有
相似性 
.　计算softmax 
.　激活函数使用说明 
.　将增量与斜率相乘 
.　将输出转换为斜率(导数) 
.　升级MNIST网络 
第章 卷积神经网络概论：关于边与角的神经学习 
.　在多个位置复用权重 
.　卷积层 
.　基于NumPy的简单实现 
.　本章小结 
第章 能够理解自然语言的神经网络：国王-男人+女人=？ 
.　理解语言究竟是指什么? 
.　自然语言处理(NLP) 
.　监督NLP学习 
.　IMDB电影评论数据集 
.　在输入数据中提取单词相关性 
.　对影评进行预测 
.　引入嵌入层 
.　解释输出 
.　神经网络结构 
.　单词嵌入表达的对比 
.　神经元是什么意思? 
.　完形填空 
.　损失函数的意义 
.　国王-男人+女人~=女王 
.　单词类比 
.　本章小结 
第章 像莎士比亚一样写作的神经网络：变长数据的递归层 
.　任意长度的挑战 
.　做比较真的重要吗？ 
.　平均词向量的神奇力量 
.　信息是如何存储在这些向量嵌入中的？ 
.　神经网络是如何使用嵌入的？ 
.　词袋向量的局限 
.　用单位向量求词嵌入之和 
.　不改变任何东西的矩阵 
.　学习转移矩阵 
.　学习创建有用的句子向量 
.　Python下的前向传播 
.　如何反向传播？ 
.　让我们训练它！ 
.　进行设置 
.　任意长度的前向传播 
.　任意长度的反向传播 
.　任意长度的权重更新 
.　运行代码，并分析输出 
.　本章小结 
第章 介绍自动优化：搭建深度学习框架 
.　深度学习框架是什么？ 
.　张量介绍 
.　自动梯度计算(autograd)介绍 
.　快速检查 
.　多次使用的张量 
.　升级autograd以支持多次使用的张量 
.　加法的反向传播如何工作？ 
.　增加取负值操作的支持 
.　添加更多函数的支持 
.　使用autograd训练神经网络 
.　增加自动优化 
.　添加神经元层类型的支持 
.　包含神经元层的神经元层 
.　损失函数层 
.　如何学习一个框架 
.　非线性层 
.　嵌入层 
.　将下标操作添加到
autograd 
.　再看嵌入层 
.　交叉熵层 
.　递归神经网络层 
.　本章小结 
第章 像莎士比亚一样写作：长短期记忆网络 
.　字符语言建模 
.　截断式反向传播的必要性 
.　截断式反向传播 
.　输出样例 
.　梯度消失与梯度激增 
.　RNN反向传播的小例子 
.　长短期记忆(LSTM)元胞 
.　关于LSTM门限的直观理解 
.　长短期记忆层 
.　升级字符语言模型 
.　训练LSTM字符语言模型 
.　调优LSTM字符语言模型 
.　本章小结 
第章 在看不见的数据上做深度学习：联邦学习导论 
.　深度学习的隐私问题 
.　联邦学习 
.　学习检测垃圾邮件 
.　让我们把它联邦化 
.　深入联邦学习 
.　安全聚合 
.　同态加密 
.　同态加密联邦学习 
.　本章小结 
第章 往哪里去：简要指引 
・ ・ ・ ・ ・ ・ (收起)第　一部分 基础知识
第　章 走近深度学习：机器学习入门　
．　什么是机器学习　
．．　机器学习与AI的关系　
．．　机器学习能做什么，不能做什么　
．　机器学习示例　
．．　在软件应用中使用机器学习　
．．　监督学习　
．．　无监督学习　
．．　强化学习　
．　深度学习　
．　阅读本书能学到什么　
．　小结　
第　章 围棋与机器学习　
．　为什么选择游戏　
．　围棋快速入门　
．．　了解棋盘　
．．　落子与吃子　
．．　终盘与胜负计算　
．．　理解劫争　
．．　让子　
．　更多学习资源　
．　我们可以教会计算机什么　
．．　如何开局　
．．　搜索游戏状态　
．．　减少需要考虑的动作数量　
．．　评估游戏状态　
．　如何评估围棋AI的能力　
．．　传统围棋评级　
．．　对围棋AI进行基准测试　
．　小结　
第章　实现第 一个围棋机器人　
．　在Python中表达围棋游戏　
．．　实现围棋棋盘　
．．　在围棋中跟踪相连的棋组：棋链　
．．　在棋盘上落子和提子　
．　跟踪游戏状态并检查非法动作　
．．　自吃　
．．　劫争　
．　终盘　
．　创建自己的第 一个机器人：理论上最弱的围棋AI　
．　使用Zobrist哈希加速棋局　
．　人机对弈　
．　小结　
第二部分　机器学习和游戏AI
第章　使用树搜索下棋　
．　游戏分类　
．　利用极小化极大搜索预测对手　
．　井字棋推演：一个极小化极大算法的示例　
．　通过剪枝算法缩减搜索空间　
．．　通过棋局评估减少搜索深度　
．．　利用α-β剪枝缩减搜索宽度　
．　使用蒙特卡洛树搜索评估游戏状态　
．．　在Python中实现蒙特卡洛树搜索　
．．　如何选择继续探索的分支　
．．　将蒙特卡洛树搜索应用于围棋　
．　小结　
第章　神经网络入门　
．　一个简单的用例：手写数字分类　
．．　MNIST手写数字数据集　
．．　MNIST数据的预处理　
．　神经网络基础　
．．　将对率回归描述为简单的神经网络　
．．　具有多个输出维度的神经网络　
．　前馈网络　
．　我们的预测有多好？损失函数及优化　
．．　什么是损失函数　
．．　均方误差　
．．　在损失函数中找极小值　
．．　使用梯度下降法找极小值　
．．　损失函数的随机梯度下降算法　
．．　通过网络反向传播梯度　
．　在Python中逐步训练神经网络　
．．　Python中的神经网络层　
．．　神经网络中的激活层　
．．　在Python中实现稠密层　
．．　Python顺序神经网络　
．．　将网络集成到手写数字分类应用中　
．　小结　
第章　为围棋数据设计神经网络　
．　为神经网络编码围棋棋局　
．　生成树搜索游戏用作网络训练数据　
．　使用Keras深度学习库　
．．　了解Keras的设计原理　
．．　安装Keras深度学习库　
．．　热身运动：在Keras中运行一个熟悉的示例　
．．　使用Keras中的前馈神经网络进行动作预测　
．　使用卷积网络分析空间　
．．　卷积的直观解释　
．．　用Keras构建卷积神经网络　
．．　用池化层缩减空间　
．　预测围棋动作概率　
．．　在最后一层使用softmax激活函数　
．．　分类问题的交叉熵损失函数　
．　使用丢弃和线性整流单元构建更深的网络　
．．　通过丢弃神经元对网络进行正则化　
．．　线性整流单元激活函数　
．　构建更强大的围棋动作预测网络　
．　小结　
第章　从数据中学习：构建深度学习机器人　
．　导入围棋棋谱　
．．　SGF文件格式　
．．　从KGS下载围棋棋谱并复盘　
．　为深度学习准备围棋数据　
．．　从SGF棋谱中复盘围棋棋局　
．．　构建围棋数据处理器　
．．　构建可以高效地加载数据的围棋数据生成器　
．．　并行围棋数据处理和生成器　
．　基于真实棋局数据训练深度学习模型　
．　构建更逼真的围棋数据编码器　
．　使用自适应梯度进行高效的训练　
．．　在SGD中采用衰减和动量　
．．　使用Adagrad优化神经网络　
．．　使用Adadelta优化自适应梯度　
．　运行自己的实验并评估性能　
．．　测试架构与超参数的指南　
．．　评估训练与测试数据的性能指标　
．　小结　
第章　实地部署围棋机器人　
．　用深度神经网络创建动作预测代理　
．　为围棋机器人提供Web前端　
．　在云端训练与部署围棋机器人　
．　与其他机器人对话：围棋文本协议　
．　在本地与其他机器人对弈　
．．　机器人应该何时跳过回合或认输　
．．　让机器人与其他围棋程序进行对弈　
．　将围棋机器人部署到在线围棋服务器　
．　小结　
第章　通过实践学习：强化学习　
．　强化学习周期　
．　经验包括哪些内容　
．　建立一个有学习能力的代理　
．．　从某个概率分布中进行抽样　
．．　剪裁概率分布　
．．　初始化一个代理实例　
．．　在磁盘上加载并保存代理　
．．　实现动作选择　
．　自我对弈：计算机程序进行实践训练的方式　
．．　经验数据的表示　
．．　模拟棋局　
．　小结　
第　章 基于策略梯度的强化学习　
．　如何在随机棋局中识别更佳的决策　
．　使用梯度下降法修改神经网络的策略　
．　使用自我对弈进行训练的几个小技巧　
．．　评估学习的进展　
．．　衡量强度的细微差别　
．．　SGD优化器的微调　
．　小结　
第　章 基于价值评估方法的强化学习　
．　使用Q学习进行游戏　
．　在Keras中实现Q学习　
．．　在Keras中构建双输入网络　
．．　用Keras实现ε贪婪策略　
．．　训练一个行动-价值函数　
．　小结　
第　章 基于演员-评价方法的强化学习　
．　优势能够告诉我们哪些决策更加重要　
．．　什么是优势　
．．　在自我对弈过程中计算优势值　
．　为演员-评价学习设计神经网络　
．　用演员-评价代理下棋　
．　用经验数据训练一个演员-评价代理　
．　小结　
第三部分　一加一大于二
第　章 AlphaGo：全部集结　
．　为AlphaGo训练深度神经网络　
．．　AlphaGo的网络架构　
．．　AlphaGo棋盘编码器　
．．　训练AlphaGo风格的策略网络　
．　用策略网络启动自我对弈　
．　从自我对弈数据衍生出一个价值网络　
．　用策略网络和价值网络做出更好的搜索　
．．　用神经网络改进蒙特卡洛推演　
．．　用合并价值函数进行树搜索　
．．　实现AlphaGo的搜索算法　
．　训练自己的AlphaGo可能遇到的实践问题　
．　小结　
第　章 AlphaGo Zero：将强化学习集成到树搜索中　
．　为树搜索构建一个神经网络　
．　使用神经网络来指导树搜索　
．．　沿搜索树下行　
．．　扩展搜索树　
．．　选择一个动作　
．　训练　
．　用狄利克雷噪声改进探索　
．　处理超深度神经网络的相关最新技术　
．．　批量归一化　
．．　残差网络　
．　探索额外资源　
．　结语　
．　小结　
附录A　数学基础　
附录B　反向传播算法　
附录C　围棋程序与围棋服务器　
附录D　用AWS来训练和部署围棋程序与围棋服务器　
附录E　将机器人发布到OGS　
・ ・ ・ ・ ・ ・ (收起)第章 深度学习简介 
. 人工智能、机器学习与深度学习 
. 深度学习的发展历程 
. 深度学习的应用 
.. 计算机视觉 
.. 语音识别 
.. 自然语言处理 
.. 人机博弈 
. 深度学习工具介绍和对比 
小结 
第章 TensorFlow环境搭建 
. TensorFlow的主要依赖包 
.. Protocol Buffer 
.. Bazel 
. TensorFlow安装 
.. 使用Docker安装 
.. 使用pip安装 
.. 从源代码编译安装 
. TensorFlow测试样例 
小结 
第章 TensorFlow入门 
. TensorFlow计算模型――计算图 
.. 计算图的概念 
.. 计算图的使用 
. TensorFlow数据模型――张量 
.. 张量的概念 
.. 张量的使用 
. TensorFlow运行模型――会话 
. TensorFlow实现神经网络 
.. TensorFlow游乐场及神经网络简介 
.. 前向传播算法简介 
.. 神经网络参数与TensorFlow变量 
.. 通过TensorFlow训练神经网络模型 
.. 完整神经网络样例程序 
小结 
第章 深层神经网络 
. 深度学习与深层神经网络 
.. 线性模型的局限性 
.. 激活函数实现去线性化 
.. 多层网络解决异或运算 
. 损失函数定义 
.. 经典损失函数 
.. 自定义损失函数 
. 神经网络优化算法 
. 神经网络进一步优化 
.. 学习率的设置 
.. 过拟合问题 
.. 滑动平均模型 
小结 
第章 MNIST数字识别问题 
. MNIST数据处理 
. 神经网络模型训练及不同模型结果对比 
.. TensorFlow训练神经网络 
.. 使用验证数据集判断模型效果 
.. 不同模型效果比较 
. 变量管理 
. TensorFlow模型持久化 
.. 持久化代码实现 
.. 持久化原理及数据格式 
. TensorFlow最佳实践样例程序 
小结 
第章 图像识别与卷积神经网络 
. 图像识别问题简介及经典数据集 
. 卷积神经网络简介 
. 卷积神经网络常用结构 
.. 卷积层 
.. 池化层 
. 经典卷积网络模型 
.. LeNet-模型 
.. Inception-v模型 
. 卷积神经网络迁移学习 
.. 迁移学习介绍 
.. TensorFlow实现迁移学习 
小结 
第章 图像数据处理 
. TFRecord输入数据格式 
.. TFRecord格式介绍 
.. TFRecord样例程序 
. 图像数据处理 
.. TensorFlow图像处理函数 
.. 图像预处理完整样例 
. 多线程输入数据处理框架 
.. 队列与多线程 
.. 输入文件队列 
.. 组合训练数据（batching） 
.. 输入数据处理框架 
小结 
第章 循环神经网络 
. 循环神经网络简介 
. 长短时记忆网络（LTSM）结构 
. 循环神经网络的变种 
.. 双向循环神经网络和深层循环神经网络 
.. 循环神经网络的dropout 
. 循环神经网络样例应用 
.. 自然语言建模 
.. 时间序列预测 
小结 
第章 TensorBoard可视化 
. TensorBoard简介 
. TensorFlow计算图可视化 
.. 命名空间与TensorBoard图上节点 
.. 节点信息 
. 监控指标可视化 
小结 
第章 TensorFlow计算加速 
. TensorFlow使用GPU 
. 深度学习训练并行模式 
. 多GPU并行 
. 分布式TensorFlow 
.. 分布式TensorFlow原理 
.. 分布式TensorFlow模型训练 
.. 使用Caicloud运行分布式TensorFlow 
小结 
・ ・ ・ ・ ・ ・ (收起)前言 .
第一部分 生成式深度学习概述
第 章 生成建模 
. 什么是生成建模？ 
.. 生成建模与判别建模 
.. 机器学习的发展 . 
.. 生成建模的兴起 . 
.. 生成建模的框架 . 
. 概率生成模型 
.. 你好，Wrodl ！ 
.. 你的第一个概率生成模型 . 
.. 朴素贝叶斯 
.. 你好，Wrodl ！续篇 . 
. 生成建模的难题 
表示学习 
. 设置环境 
. 小结 
第 章 深度学习 
. 结构化与非结构化数据 
. 深度神经网络 
Keras 和TensorFlow 
. 第一个深度神经网络 . 
.. 加载数据. 
.. 建立模型. 
.. 编译模型. 
.. 训练模型. 
.. 评估模型. 
. 改进模型 
.. 卷积层 . 
.. 批标准化. 
.. Dropout 层 . 
.. 结合所有层 
. 小结 
第 章 变分自动编码器 
. 画展 
. 自动编码器 . 
.. 第一个自动编码器 . 
.. 编码器 . 
.. 解码器 . 
.. 连接编码器与解码器 
.. 分析自动编码器 . 
. 变化后的画展 
. 构建变分自动编码器 . 
.. 编码器 . 
.. 损失函数. 
.. 分析变分自动编码器 
. 使用VAE 生成面部图像 
.. 训练VAE 
.. 分析VAE . 
.. 生成新面孔 . 
.. 隐空间的算术 
.. 面部变形 
. 小结 . 
第 章 生成对抗网络 
. 神秘兽 
. 生成对抗网络简介 
. 第一个生成对抗网络 
.. 判别器 
.. 生成器 
.. 训练GAN 
. GAN 面临的难题 
.. 损失震荡 
.. 模式收缩 
.. 不提供信息的损失函数 
.. 超参数 
.. 解决GAN 面临的难题 . 
. WGAN 
.. Wasserstein 损失 
.. 利普希茨约束 
.. 权重裁剪 
.. 训练WGAN 
.. 分析WGAN 
. WGAN-GP 
.. 梯度惩罚损失 
.. 分析WGAN-GP 
. 小结 . 
第二部分 教机器绘画、写作、作曲和玩游戏
第 章 绘画 
. 苹果和橙子 
. CycleGAN 
. 第一个CycleGAN 模型 . 
.. 简介 
.. 生成器（U-Net） 
.. 判别器 
.. 编译CycleGAN 
.. 训练CycleGAN 
.. 分析CycleGAN 
. 创建一个模仿莫奈作品的CycleGAN . 
.. 生成器（ResNet） 
.. 分析CycleGAN 
. 神经风格迁移 . 
.. 内容损失 
.. 风格损失 
.. 总方差损失 . 
.. 运行神经风格迁移 
.. 分析神经风格迁移模型 
. 小结 . 
第 章 写作 
. 坏家伙们的文学社 
. 长短期记忆网络 
. 第一个LSTM 网络 
.. 分词 
.. 建立数据集 . 
.. LSTM 架构 . 
.. 嵌入层 
.. LSTM 层 
.. LSTM 元胞 . 
. 生成新文本 
. RNN 扩展 . 
.. 堆叠式循环网络 
.. 门控制循环单元 
.. 双向元胞 
. 编码器- 解码器模型 
. 问答生成器 
.. 问答数据集 . 
.. 模型架构 
.. 推断 
.. 模型的结果 . 
. 小结 . 
第 章 作曲 
. 前提知识 
音符 
・ ・ ・ ・ ・ ・ (收起)第章 深度学习简介
. 人工智能、机器学习与深度学习
. 深度学习的发展历程
. 深度学习的应用
.. 计算机视觉
.. 语音识别
.. 自然语言处理
.. 人机博弈
. 深度学习工具介绍和对比
小结
第章 TensorFlow环境搭建
. TensorFlow的主要依赖包
.. Protocol Buffer
.. Bazel
. TensorFlow安装
.. 使用Docker安装
.. 使用pip安装
.. 从源代码编译安装
. TensorFlow测试样例
小结
第章 TensorFlow入门
. TensorFlow计算模型――计算图
.. 计算图的概念
.. 计算图的使用
. TensorFlow数据模型――张量
.. 张量的概念
.. 张量的使用
. TensorFlow运行模型――会话
. TensorFlow实现神经网络
.. TensorFlow游乐场及神经网络简介
.. 前向传播算法简介
.. 神经网络参数与TensorFlow变量
.. 通过TensorFlow训练神经网络模型
.. 完整神经网络样例程序
小结
第章 深层神经网络
. 深度学习与深层神经网络
.. 线性模型的局限性
.. 激活函数实现去线性化
.. 多层网络解决异或运算
. 损失函数定义
.. 经典损失函数
.. 自定义损失函数
. 神经网络优化算法
. 神经网络进一步优化
.. 学习率的设置
.. 过拟合问题
.. 滑动平均模型
小结
第章 MNIST数字识别问题
. MNIST数据处理
. 神经网络模型训练及不同模型结果对比
.. TensorFlow训练神经网络
.. 使用验证数据集判断模型效果
.. 不同模型效果比较
. 变量管理
. TensorFlow模型持久化
.. 持久化代码实现
.. 持久化原理及数据格式
. TensorFlow最佳实践样例程序
小结
第章 图像识别与卷积神经网络
. 图像识别问题简介及经典数据集
. 卷积神经网络简介
. 卷积神经网络常用结构
.. 卷积层
.. 池化层
. 经典卷积网络模型
.. LeNet-模型
.. Inception-v模型
. 卷积神经网络迁移学习
.. 迁移学习介绍
.. TensorFlow实现迁移学习
小结
第章 图像数据处理
. TFRecord输入数据格式
.. TFRecord格式介绍
.. TFRecord样例程序
. 图像数据处理
.. TensorFlow图像处理函数
.. 图像预处理完整样例
. 多线程输入数据处理框架
.. 队列与多线程
.. 输入文件队列
.. 组合训练数据（batching）
.. 输入数据处理框架
. 数据集（Dataset）
.. 数据集的基本使用方法
.. 数据集的高层操作
小结
第章 循环神经网络
. 循环神经网络简介
. 长短时记忆网络（LSTM）结构
. 循环神经网络的变种
.. 双向循环神经网络和深层循环神经网络
.. 循环神经网络的dropout
. 循环神经网络样例应用
小结
第章 自然语言处理
. 语言模型的背景知识
.. 语言模型简介
.. 语言模型的评价方法
. 神经语言模型
.. PTB数据集的预处理
.. PTB数据的batching方法
.. 基于循环神经网络的神经语言模型
. 神经网络机器翻译
.. 机器翻译背景与SeqSeq模型介绍
.. 机器翻译文本数据的预处理
.. SeqSeq模型的代码实现
.. 注意力机制
小结
第章 TensorFlow高层封装
. TensorFlow高层封装总览
. Keras介绍
.. Keras基本用法
.. Keras高级用法
. Estimator介绍
.. Estimator基本用法
.. Estimator自定义模型
.. 使用数据集（Dataset）作为Estimator输入
小结
第章 TensorBoard可视化
. TensorBoard简介
. TensorFlow计算图可视化
.. 命名空间与TensorBoard图上节点
.. 节点信息
. 监控指标可视化
. 高维向量可视化
小结
第章 TensorFlow计算加速
. TensorFlow使用GPU
. 深度学习训练并行模式
. 多GPU并行
. 分布式TensorFlow
.. 分布式TensorFlow原理
.. 分布式TensorFlow模型训练
小结
・ ・ ・ ・ ・ ・ (收起)第一部分　原理篇
第章　机器学习与模型 
.　模型 
.　参数与训练 
.　损失函数 
.　计算图的训练 
.　小结 
第章　计算图 
.　什么是计算图 
.　前向传播 
.　函数优化与梯度下降法 
.　链式法则与反向传播 
.　在计算图上执行梯度下降法 
.　节点类及其子类 
.　用计算图搭建ADALINE并训练 
.　小结 
第章　优化器 
.　优化流程的抽象实现 
.　BGD、SGD和MBGD 
.　梯度下降优化器 
.　朴素梯度下降法的局限 
.　冲量优化器 
.　AdaGrad优化器 
.　RMSProp优化器 
.　Adam优化器 
.　小结 
第二部分　模型篇
第章　逻辑回归 
.　对数损失函数 
.　Logistic函数 
.　二分类逻辑回归 
.　多分类逻辑回归 
.　交叉熵 
.　实例：鸢尾花 
.　小结 
第章　神经网络 
.　神经元与激活函数 
.　神经网络 
.　多层全连接神经网络 
.　多个全连接层的意义 
.　实例：鸢尾花 
.　实例：手写数字识别 
.　小结 
第章　非全连接神经网络 
.　带二次项的逻辑回归 
.　因子分解机 
.　Wide & Deep 
.　DeepFM 
.　实例：泰坦尼克号幸存者 
.　小结 
第章　循环神经网络 
.　RNN的结构 
.　RNN的输出 
.　实例：正弦波与方波 
.　变长序列 
.　实例：D电磁发音仪单词识别 
.　小结 
第章　卷积神经网络 
.　蒙德里安与莫奈 
.　滤波器 
.　可训练的滤波器 
.　卷积层 
.　池化层 
.　CNN的结构 
.　实例：手写数字识别 
.　小结 
第三部分　工程篇
第章　训练与评估 
.　训练和Trainer训练器 
.　评估和Metrics节点 
.　混淆矩阵 
.　正确率 
.　查准率 
.　查全率 
.　ROC曲线和AUC 
.　小结 
第章　模型保存、预测和服务 
.　模型保存 
.　模型加载和预测 
.　模型服务 
.　客户端 
.　小结 
第章　分布式训练 
.　分布式训练的原理 
.　基于参数服务器的架构 
.　Ring AllReduce原理 
.　Ring AllReduce架构实现 
.　分布式训练性能评测 
.　小结 
第章　工业级深度学习框架 
.　张量 
.　计算加速 
.　GPU 
.　数据接口 
.　模型并行 
.　静态图和动态图 
.　混合精度训练 
.　图优化和编译优化 
.　移动端和嵌入式端 
.　小结 
・ ・ ・ ・ ・ ・ (收起)第 章　PyTorch与深度学习 
．　人工智能　
．　机器学习　
．　深度学习　
．．　深度学习的应用　
．．　深度学习的浮夸宣传　
．．　深度学习发展史　
．．　为何是现在　
．．　硬件可用性　
．．　数据和算法　
．．　深度学习框架　
．　小结　
第　章 神经网络的构成　
．　安装PyTorch　
．　实现第 一个神经网络　
．．　准备数据　
．．　为神经网络创建数据　
．．　加载数据　
．　小结　
第章　深入了解神经网络　
．　详解神经网络的组成部分　
．．　层―神经网络的基本组成　
．．　非线性激活函数　
．．　PyTorch中的非线性激活函数　
．．　使用深度学习进行图像分类　
．　小结　
第章　机器学习基础　
．　三类机器学习问题　
．．　有监督学习　
．．　无监督学习　
．．　强化学习　
．　机器学习术语　
．　评估机器学习模型　
．　数据预处理与特征工程　
．．　向量化　
．．　值归一化　
．．　处理缺失值　
．．　特征工程　
．　过拟合与欠拟合　
．．　获取更多数据　
．．　缩小网络规模　
．．　应用权重正则化　
．．　应用dropout　
．．　欠拟合　
．　机器学习项目的工作流　
．．　问题定义与数据集创建　
．．　成功的衡量标准　
．．　评估协议　
．．　准备数据　
．．　模型基线　
．．　大到过拟合的模型　
．．　应用正则化　
．．　学习率选择策略　
．　小结　
第章　深度学习之计算机视觉　
．　神经网络简介　
．　从零开始构建CNN模型　
．．　Convd　
．．　池化　
．．　非线性激活―ReLU　
．．　视图　
．．　训练模型　
．．　狗猫分类问题―从零开始构建CNN　
．．　利用迁移学习对狗猫分类　
．　创建和探索VGG模型　
．．　冻结层　
．．　微调VGG模型　
．．　训练VGG模型　
．　计算预卷积特征　
．　理解CNN模型如何学习　
．　CNN层的可视化权重　
．　小结　
第章　序列数据和文本的深度学习　
．　使用文本数据　
．．　分词　
．．　向量化　
．　通过构建情感分类器训练词向量　
．．　下载IMDB数据并对文本分词　
．．　构建词表　
．．　生成向量的批数据　
．．　使用词向量创建网络模型　
．．　训练模型　
．　使用预训练的词向量　
．．　下载词向量　
．．　在模型中加载词向量　
．．　冻结embedding层权重　
．　递归神经网络（RNN）　
．　LSTM　
．．　长期依赖　
．．　LSTM网络　
．　基于序列数据的卷积网络　
．　小结　
第章　生成网络　
．　神经风格迁移　
．．　加载数据　
．．　创建VGG模型　
．．　内容损失　
．．　风格损失　
．．　提取损失　
．．　为网络层创建损失函数　
．．　创建优化器　
．．　训练　
．　生成对抗网络（GAN）　
．　深度卷机生成对抗网络　
．．　定义生成网络　
．．　定义判别网络　
．．　定义损失函数和优化器　
．．　训练判别网络　
．．　训练生成网络　
．．　训练整个网络　
．．　检验生成的图片　
．　语言建模　
．．　准备数据　
．．　生成批数据　
．．　定义基于LSTM的模型　
．．　定义训练和评估函数　
．．　训练模型　
．　小结　
第章　现代网络架构　
．　现代网络架构　
．．　ResNet　
．．　Inception　
．　稠密连接卷积网络（DenseNet）　
．．　DenseBlock　
．．　DenseLayer　
．　模型集成　
．．　创建模型　
．．　提取图片特征　
．．　创建自定义数据集和数据加载器　
．．　创建集成模型　
．．　训练和验证模型　
．　encoder-decoder架构　
．．　编码器　
．．　解码器　
．　小结　
第章　未来走向　
．　未来走向　
．　回顾　
．　有趣的创意应用　
．．　对象检测　
．．　图像分割　
．．　PyTorch中的OpenNMT　
．．　Allen NLP　
．．　fast．ai―神经网络不再神秘　
．．　Open Neural Network Exchange　
．　如何跟上前沿　
．　小结　
・ ・ ・ ・ ・ ・ (收起)第章　深度学习入门　　
.　机器学习简介　　
..　监督学习　　
..　无监督学习　　
..　强化学习　　
.　深度学习定义　　
..　人脑的工作机制　　
..　深度学习历史　　
..　应用领域　　
.　神经网络　　
..　生物神经元　　
..　人工神经元　　
.　人工神经网络的学习方式　　
..　反向传播算法　　
..　权重优化　　
..　随机梯度下降法　　
.　神经网络架构　　
..　多层感知器　　
..　DNN架构　　
..　卷积神经网络　　
..　受限玻尔兹曼机　　
.　自编码器　　
.　循环神经网络　　
.　几种深度学习框架对比　　
.　小结　　
第章　TensorFlow初探　　
.　总览　　
..　TensorFlow .x版本特性　　
..　使用上的改进　　
..　TensorFlow安装与入门　　
.　在Linux上安装TensorFlow　　
.　为TensorFlow启用NVIDIA GPU　　
..　第步：安装NVIDIA CUDA　　
..　　第步：安装NVIDIA cuDNN v.+　　
..　　第步：确定GPU卡的CUDA计算能力为.+　　
..　第步：安装libcupti-dev库　　
..　　第步：安装Python
（或Python ）　　
..　第步：安装并升级PIP
（或PIP）　　
..　第步：安装TensorFlow　　
.　如何安装TensorFlow　　
..　直接使用pip安装　　
..　使用virtualenv安装　　
..　从源代码安装　　
.　在Windows上安装TensorFlow　　
..　在虚拟机上安装TensorFlow　　
..　直接安装到Windows　　
.　测试安装是否成功　　
.　计算图　　
.　为何采用计算图　　
.　编程模型　　
.　数据模型　　
..　阶　　
..　形状　　
..　数据类型　　
..　变量　　
..　取回　　
..　注入　　
.　TensorBoard　　
.　实现一个单输入神经元　　
.　单输入神经元源代码　　
.　迁移到TensorFlow .x版本　　
..　如何用脚本升级　　
..　局限　　
..　手动升级代码　　
..　变量　　
..　汇总函数　　
..　简化的数学操作　　
..　其他事项　　
.　小结　　
第章　用TensorFlow构建前馈
神经网络　　
.　前馈神经网络介绍　　
..　前馈和反向传播　　
..　权重和偏差　　
..　传递函数　　
.　手写数字分类　　
.　探究MNIST数据集　　
.　softmax分类器　　
.　TensorFlow模型的保存和还原　　
..　保存模型　　
..　还原模型　　
..　softmax源代码　　
..　softmax启动器源代码　　
.　实现一个五层神经网络　　
..　可视化　　
..　五层神经网络源代码　　
.　ReLU分类器　　
.　可视化　　
.　dropout优化　　
.　可视化　　
.　小结　　
第章　TensorFlow与卷积神经网络　　
.　CNN简介　　
.　CNN架构　　
.　构建你的第一个CNN　　
.　CNN表情识别　　
..　表情分类器源代码　　
..　使用自己的图像测试模型　　
..　源代码　　
.　小结　　
第章　优化TensorFlow自编码器　　
.　自编码器简介　　
.　实现一个自编码器　　
.　增强自编码器的鲁棒性　　
.　构建去噪自编码器　　
.　卷积自编码器　　
..　编码器　　
..　解码器　　
..　卷积自编码器源代码　　
.　小结　　
第章　循环神经网络　　
.　RNN的基本概念　　
.　RNN的工作机制　　
.　RNN的展开　　
.　梯度消失问题　　
.　LSTM网络　　
.　RNN图像分类器　　
.　双向RNN　　
.　文本预测　　
..　数据集　　
..　困惑度　　
..　PTB模型　　
..　运行例程　　
.　小结　　
第章　GPU计算　　
.　GPGPU计算　　
.　GPGPU的历史　　
.　CUDA架构　　
.　GPU编程模型　　
.　TensorFlow中GPU的设置　　
.　TensorFlow的GPU管理　　
.　GPU内存管理　　
.　在多GPU系统上分配单个GPU　　
.　使用多个GPU　　
.　小结　　
第章　TensorFlow高级编程　　
.　Keras简介　　
.　构建深度学习模型　　
.　影评的情感分类　　
.　添加一个卷积层　　
.　Pretty Tensor　　
.　数字分类器　　
.　TFLearn　　
.　泰坦尼克号幸存者预测器　　
.　小结　　
第章　TensorFlow高级多媒体编程　　
.　多媒体分析简介　　
.　基于深度学习的大型对象检测　　
..　瓶颈层　　
..　使用重训练的模型　　
.　加速线性代数　　
..　TensorFlow的核心优势　　
..　加速线性代数的准时编译　　
.　TensorFlow和Keras　　
..　Keras简介　　
..　拥有Keras的好处　　
..　视频问答系统　　
.　Android上的深度学习　　
..　TensorFlow演示程序　　
..　Android入门　　
.　小结　　
第章　强化学习　　
.　强化学习基本概念　　
.　Q-learning算法　　
.　OpenAI Gym框架简介　　
.　FrozenLake-v实现问题　　
.　使用TensorFlow实现Q-learning　　
.　小结　　
・ ・ ・ ・ ・ ・ (收起)上篇 初见
第天 什么是深度学习 
. 星星之火，可以燎原 
. 师夷长技 
.. 谷歌与微软 
.. Facebook、亚马逊与NVIDIA 
. 中国崛起 
.. BAT在路上 
.. 星光闪耀 
.. 企业热是风向标 
. 练习题 
第天 深度学习的过往 
. 传统机器学习的局限性 
. 从表示学习到深度学习 
. 监督学习 
. 反向传播算法 
. 卷积神经网络 
. 深度学习反思 
. 练习题 
. 参考资料 
第天 深度学习工具汇总 
. Caffe 
. Torch & OverFeat 
. MxNet 
. TensorFlow 
. Theano 
. CNTK 
. 练习题 
. 参考资料 
第天 准备Caffe环境 
. Mac OS环境准备 
. Ubuntu环境准备 
. RHEL/Fedora/CentOS环境准备 
. Windows环境准备 
. 常见问题 
. 练习题 
. 参考资料 
第天 Caffe依赖包解析 
. ProtoBuffer 
. Boost 
. GFLAGS 
. GLOG 
. BLAS 
. HDF 
. OpenCV 
. LMDB和LEVELDB 
. Snappy 
. 小结 
. 练习题 
. 参考资料 
第天 运行手写体数字识别例程 
. MNIST数据集 
.. 下载MNIST数据集 
.. MNIST数据格式描述 
.. 转换格式 
. LeNet-模型 
.. LeNet-模型描述 
.. 训练超参数 
.. 训练日志 
.. 用训练好的模型对数据进行预测 
.. Windows下训练模型 
. 回顾 
. 练习题 
. 参考资料 
篇尾语 
中篇 热恋
第天 Caffe代码梳理 
. Caffe目录结构 
. 如何有效阅读Caffe源码 
. Caffe支持哪些深度学习特性 
.. 卷积层 
.. 全连接层 
.. 激活函数 
. 小结 
. 练习题 
. 参考资料 
第天 Caffe数据结构 
. Blob 
.. Blob基本用法 
.. 数据结构描述 
.. Blob是怎样炼成的 
. Layer 
.. 数据结构描述 
.. Layer是怎样建成的 
. Net 
.. Net基本用法 
.. 数据结构描述 
.. Net是怎样绘成的 
. 机制和策略 
. 练习题 
. 参考资料 
第天 Caffe I/O模块 
. 数据读取层 
.. 数据结构描述 
.. 数据读取层实现 
. 数据变换器 
.. 数据结构描述 
.. 数据变换器的实现 
. 练习题 
第天 Caffe模型 
. prototxt表示 
. 内存中的表示 
. 磁盘上的表示 
. Caffe Model Zoo 
. 练习题 
. 参考资料 
第天 Caffe前向传播计算 
. 前向传播的特点 
. 前向传播的实现 
.. DAG构造过程 
.. Net Forward实现 
. 练习题 
第天 Caffe反向传播计算 
. 反向传播的特点 
. 损失函数 
.. 算法描述 
.. 参数描述 
.. 源码分析 
. 反向传播的实现 
. 练习题 
第天 Caffe最优化求解过程 
. 求解器是什么 
. 求解器是如何实现的 
.. 算法描述 
.. 数据结构描述 
.. CNN训练过程 
.. CNN预测过程 
.. Solver的快照和恢复功能 
. 练习题 
第天 Caffe实用工具 
. 训练和预测 
. 特征提取 
. 转换图像格式 
. 计算图像均值 
. 自己编写工具 
. 练习题 
篇尾语 
下篇 升华
第天 Caffe计算加速 
. Caffe计时功能 
. Caffe GPU加速模式 
.. GPU是什么 
.. CUDA是什么 
.. GPU、CUDA和深度学习 
.. Caffe GPU环境准备 
.. 切换到Caffe GPU加速模式 
. Caffe cuDNN加速模式 
.. 获取cuDNN 
.. 切换到Caffe cuDNN加速模式 
.. Caffe不同硬件配置性能 
. 练习题 
. 参考资料 
第天 Caffe可视化方法 
. 数据可视化 
.. MNIST数据可视化 
.. CIFAR数据可视化 
.. ImageNet数据可视化 
. 模型可视化 
.. 网络结构可视化 
.. 网络权值可视化 
. 特征图可视化 
. 学习曲线 
. 小结 
. 练习题 
. 参考资料 
第天 Caffe迁移和部署 
. 从开发测试到生产部署 
. 使用Docker 
.. Docker基本概念 
.. Docker安装 
.. Docker入门 
.. Docker使用进阶 
. 练习题 
. 参考资料 
第天 关于ILSVRC不得不说的一些事儿 
. ImageNet数据集 
. ILSVRC比赛项目 
.. 图像分类（CLS） 
.. 目标定位（LOC） 
.. 目标检测（DET） 
.. 视频目标检测（VID） 
.. 场景分类 
. Caffe ILSVRC实践 
. 练习题 
. 参考资料 
第天 放之四海而皆准 
. 图像分类 
.. 问题描述 
.. 应用案例--商品分类 
. 图像中的字符识别 
.. 问题描述 
.. 应用案例--身份证实名认证 
. 目标检测 
.. 问题描述 
.. 最佳实践--运行R-CNN例程 
. 人脸识别 
.. 问题描述 
.. 最佳实践--使用Face++ SDK实现人脸检测 
. 自然语言处理 
.. 问题描述 
.. 最佳实践--NLP-Caffe 
. 艺术风格 
.. 问题描述 
.. 最佳实践--style-transfer 
. 小结 
. 练习题 
. 参考资料 
第天 继往开来的领路人 
. Caffe Traps and Pitfalls 
.. 不支持任意数据类型 
.. 不够灵活的高级接口 
.. 繁杂的依赖包 
.. 堪忧的卷积层实现 
.. 架构之殇 
.. 应用场景局限性 
. 最佳实践--Caffe 
. 练习题 
. 参考资料 
第天 新生 
. 三人行，必有我师 
. 路漫漫其修远兮，吾将上下而求索 
篇尾语 
结束语 
附录A 其他深度学习工具
・ ・ ・ ・ ・ ・ (收起)第  章 深度学习介绍 
. 人工智能 
. 数据挖掘、机器学习与深度学习
.. 数据挖掘 
.. 机器学习 
.. 深度学习 
. 学习资源与建议 
第  章 深度学习框架 
. 深度学习框架介绍 . 
. PyTorch 介绍. 
.. 什么是 PyTorch. 
.. 为何要使用 PyTorch 
. 配置 PyTorch 深度学习环境 
.. 操作系统的选择. 
.. Python 开发环境的安装 
.. PyTorch 的安装. 
第  章 多层全连接神经网络 
. 热身：PyTorch 基础 
.. Tensor（张量）. 
.. Variable（变量）
.. Dataset（数据集）
.. nn.Module（模组） 
.. torch.optim（优化） 
.. 模型的保存和加载 
. 线性模型 
.. 问题介绍 
.. 一维线性回归
.. 多维线性回归
.. 一维线性回归的代码实现. 
.. 多项式回归 
. 分类问题 
.. 问题介绍 
.. Logistic 起源 
.. Logistic 分布 
.. 二分类的 Logistic 回归 
.. 模型的参数估计. 
.. Logistic 回归的代码实现
. 简单的多层全连接前向网络 . 
.. 模拟神经元 
.. 单层神经网络的分类器 
.. 激活函数 
.. 神经网络的结构. 
.. 模型的表示能力与容量 
. 深度学习的基石：反向传播算法
.. 链式法则 
.. 反向传播算法
.. Sigmoid 函数举例
. 各种优化算法的变式
.. 梯度下降法 
.. 梯度下降法的变式 
. 处理数据和训练模型的技巧 . 
.. 数据预处理 
.. 权重初始化 
.. 防止过拟合 
. 多层全连接神经网络实现 MNIST 手写数字分类 
.. 简单的三层全连接神经网络
.. 添加激活函数
.. 添加批标准化
.. 训练网络 
第  章 卷积神经网络 
. 主要任务及起源 
. 卷积神经网络的原理和结构 . 
.. 卷积层
.. 池化层
.. 全连接层 
.. 卷积神经网络的基本形式. 
. PyTorch 卷积模块 . 
.. 卷积层
.. 池化层
.. 提取层结构 
.. 如何提取参数及自定义初始化 
. 卷积神经网络案例分析. 
.. LeNet. 
.. AlexNet
.. VGGNet 
.. GoogLeNet . 
.. ResNet
. 再实现 MNIST 手写数字分类 . 
. 图像增强的方法 
. 实现 cifar 分类 
第  章 循环神经网络 
. 循环神经网络
.. 问题介绍 
.. 循环神经网络的基本结构. 
.. 存在的问题 
. 循环神经网络的变式：LSTM 与 GRU 
.. LSTM. 
.. GRU. 
.. 收敛性问题 
. 循环神经网络的 PyTorch 实现 
.. PyTorch 的循环网络模块
.. 实例介绍 
. 自然语言处理的应用
.. 词嵌入
.. 词嵌入的 PyTorch 实现 
.. N Gram 模型 
.. 单词预测的 PyTorch 实现
.. 词性判断 
.. 词性判断的 PyTorch 实现
. 循环神经网络的更多应用
.. Many to one 
.. Many to Many（shorter）
.. Seqseq
.. CNN+RNN . 
第  章 生成对抗网络 
. 生成模型 
.. 自动编码器 
.. 变分自动编码器. 
. 生成对抗网络
.. 何为生成对抗网络 
.. 生成对抗网络的数学原理. 
. Improving GAN
.. Wasserstein GAN. 
.. Improving WGAN
. 应用介绍 
.. Conditional GAN. 
.. Cycle GAN . 
第  章 深度学习实战 
. 实例一――猫狗大战：运用预训练卷积神经网络进行特征提取与预测 . 
.. 背景介绍 
.. 原理分析 
.. 代码实现 
.. 总结. 
. 实例二――Deep Dream：探索卷积神经网络眼中的世界
.. 原理介绍 
.. 预备知识：backward . 
.. 代码实现 
.. 总结. 
. 实例三――Neural-Style：使用 PyTorch 进行风格迁移
.. 背景介绍 
.. 原理分析 
.. 代码实现 
.. 总结. 
. 实例四――Seqseq：通过 RNN 实现简单的 Neural Machine Translation . 
.. 背景介绍 
.. 原理分析 
.. 代码实现 
.. 总结. 
・ ・ ・ ・ ・ ・ (收起)第章　深度学习介绍　　
.　开始深度学习之旅　　
..　深度前馈网络　　
..　各种学习算法　　
.　深度学习的相关术语　　
.　深度学习――一场人工智能革命　　
.　深度学习网络的分类　　
..　深度生成或无监督模型　　
..　深度判别模型　　
.　小结　　
第章　大规模数据的分布式深度学习　　
.　海量数据的深度学习　　
.　大数据深度学习面临的挑战　　
..　海量数据带来的挑战（第一个V）　　
..　数据多样性带来的挑战（第二个V）　　
..　数据快速处理带来的挑战（第三个V）　　
..　数据真实性带来的挑战（第四个V）　　
.　分布式深度学习和Hadoop　　
..　Map-Reduce　　
..　迭代Map-Reduce　　
..　YARN　　
..　分布式深度学习设计的重要特征　　
.　深度学习的开源分布式框架Deeplearningj　　
..　Deeplearningj的主要特性　　
..　Deeplearningj功能总结　　
.　在Hadoop YARN上配置Deeplearningj　　
..　熟悉Deeplearningj　　
..　为进行分布式深度学习集成Hadoop YARN和Spark　　
..　Spark在Hadoop YARN上的内存分配规则　　
.　小结　　
第章　卷积神经网络　　
.　卷积是什么　　
.　卷积神经网络的背景　　
.　卷积神经网络的基本层　　
..　卷积神经网络深度的重要性　　
..　卷积层　　
..　为卷积层选择超参数　　
..　ReLU层　　
..　池化层　　
..　全连接层　　
.　分布式深度卷积神经网络　　
..　最受欢迎的深度神经网络及其配置　　
..　训练时间――深度神经网络面临的主要挑战　　
..　将Hadoop应用于深度卷积神经网络　　
.　使用Deeplearningj构建卷积层　　
..　加载数据　　
..　模型配置　　
..　训练与评估　　
.　小结　　
第章　循环神经网络　　
.　循环网络与众不同的原因　　
.　循环神经网络　　
..　展开循环计算　　
..　循环神经网络的记忆　　
..　架构　　
.　随时间反向传播　　
.　长短期记忆　　
..　随时间深度反向传播的问题　　
..　长短期记忆　　
.　双向循环神经网络　　
..　循环神经网络的不足　　
..　解决方案　　
.　分布式深度循环神经网络　　
.　用Deeplearningj训练循环神经网络　　
.　小结　　
第章　受限玻尔兹曼机　　
.　基于能量的模型　　
.　玻尔兹曼机　　
..　玻尔兹曼机如何学习　　
..　玻尔兹曼机的不足　　
.　受限玻尔兹曼机　　
..　基础架构　　
..　受限玻尔兹曼机的工作原理　　
.　卷积受限玻尔兹曼机　　
.　深度信念网络　　
.　分布式深度信念网络　　
..　受限玻尔兹曼机的分布式训练　　
..　深度信念网络的分布式训练　　
.　用Deeplearningj实现受限玻尔兹曼机和深度信念网络　　
..　受限玻尔兹曼机　　
..　深度信念网络　　
.　小结　　
第章　自动编码器　　
.　自动编码器　　
.　稀疏自动编码器　　
..　稀疏编码　　
..　稀疏自动编码器　　
.　深度自动编码器　　
..　训练深度自动编码器　　
..　使用Deeplearningj实现深度自动编码器　　
.　降噪自动编码器　　
..　降噪自动编码器的架构　　
..　堆叠式降噪自动编码器　　
..　使用Deeplearningj实现堆叠式降噪自动编码器　　
.　自动编码器的应用　　
.　小结　　
第章　用Hadoop玩转深度学习　　
.　Hadoop中的分布式视频解码　　
.　使用Hadoop进行大规模图像处理　　
.　使用Hadoop进行自然语言处理　　
..　Web爬虫　　
..　自然语言处理的关键词提取和模块　　
..　从页面评估相关关键词　　
.　小结　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)第 章绪论.
. 知识图谱简介
. 深度学习的优势和挑战
. 深度学习+ 知识图谱= .
.. 知识的表示学习
.. 知识的自动获取
.. 知识的计算应用
. 本书结构
. 本章总结
第一篇世界知识图谱
第 章世界知识的表示学习
. 章节引言
. 相关工作
.. 知识表示学习经典模型
.. 平移模型及其拓展模型
. 基于复杂关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系路径建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
vi j 知识图谱与深度学习
. 基于属性关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体描述信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合层次类型信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体图像信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的自动获取
. 章节引言
. 相关工作
.. 有监督的关系抽取模型
.. 远程监督的关系抽取模型.
. 基于选择性注意力机制的关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系层次注意力机制的关系抽取
.. 算法模型.
目录j vii
.. 实验分析.
.. 小结
. 基于选择性注意力机制的多语言关系抽取.
.. 算法模型.
.. 实验分析.
.. 小结
. 引入对抗训练的多语言关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于知识图谱与文本互注意力机制的知识获取.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的计算应用
. 章节引言
. 细粒度实体分类
.. 算法模型.
.. 实验分析.
.. 小结
. 实体对齐
.. 算法模型.
.. 实验分析.
.. 小结
. 融入知识的信息检索.
.. 算法模型.
.. 实验分析.
.. 小结
viii j 知识图谱与深度学习
. 本章总结
第二篇语言知识图谱
第 章语言知识的表示学习
. 章节引言
. 相关工作
.. 词表示学习
.. 词义消歧.
. 义原的表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于义原的词表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的自动获取
. 章节引言
. 相关工作
.. 知识图谱及其构建
.. 子词和字级NLP 
.. 词表示学习及跨语言的词表示学习
. 基于协同过滤和矩阵分解的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 融入中文字信息的义原预测
.. 算法模型.
目录j ix
.. 实验分析.
.. 小结
. 跨语言词汇的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的计算应用
. 章节引言
. 义原驱动的词典扩展.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 义原驱动的神经语言模型.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章总结与展望
. 本书总结
. 未来展望
.. 更全面的知识类型
.. 更复杂的知识结构
.. 更有效的知识获取
.. 更强大的知识指导
x j 知识图谱与深度学习
.. 更精深的知识推理
. 结束语
相关开源资源
参考文献
后记.
・ ・ ・ ・ ・ ・ (收起)第 章绪论.
. 知识图谱简介
. 深度学习的优势和挑战
. 深度学习+ 知识图谱= .
.. 知识的表示学习
.. 知识的自动获取
.. 知识的计算应用
. 本书结构
. 本章总结
第一篇世界知识图谱
第 章世界知识的表示学习
. 章节引言
. 相关工作
.. 知识表示学习经典模型
.. 平移模型及其拓展模型
. 基于复杂关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系路径建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
vi j 知识图谱与深度学习
. 基于属性关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体描述信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合层次类型信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体图像信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的自动获取
. 章节引言
. 相关工作
.. 有监督的关系抽取模型
.. 远程监督的关系抽取模型.
. 基于选择性注意力机制的关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系层次注意力机制的关系抽取
.. 算法模型.
目录j vii
.. 实验分析.
.. 小结
. 基于选择性注意力机制的多语言关系抽取.
.. 算法模型.
.. 实验分析.
.. 小结
. 引入对抗训练的多语言关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于知识图谱与文本互注意力机制的知识获取.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的计算应用
. 章节引言
. 细粒度实体分类
.. 算法模型.
.. 实验分析.
.. 小结
. 实体对齐
.. 算法模型.
.. 实验分析.
.. 小结
. 融入知识的信息检索.
.. 算法模型.
.. 实验分析.
.. 小结
viii j 知识图谱与深度学习
. 本章总结
第二篇语言知识图谱
第 章语言知识的表示学习
. 章节引言
. 相关工作
.. 词表示学习
.. 词义消歧.
. 义原的表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于义原的词表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的自动获取
. 章节引言
. 相关工作
.. 知识图谱及其构建
.. 子词和字级NLP 
.. 词表示学习及跨语言的词表示学习
. 基于协同过滤和矩阵分解的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 融入中文字信息的义原预测
.. 算法模型.
目录j ix
.. 实验分析.
.. 小结
. 跨语言词汇的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的计算应用
. 章节引言
. 义原驱动的词典扩展.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 义原驱动的神经语言模型.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章总结与展望
. 本书总结
. 未来展望
.. 更全面的知识类型
.. 更复杂的知识结构
.. 更有效的知识获取
.. 更强大的知识指导
x j 知识图谱与深度学习
.. 更精深的知识推理
. 结束语
相关开源资源
参考文献
后记.
・ ・ ・ ・ ・ ・ (收起)第 章什么是推荐系统
. 推荐系统的概念.
.. 推荐系统的基本概念
.. 深度学习与推荐系统
第 章深度神经网络.
. 什么是深度学习.
.. 深度学习的三次兴起
.. 深度学习的优势
. 神经网络基础
.. 神经元
.. 神经网络.
.. 反向传播.
.. 优化算法.
. 卷积网络基础
.. 卷积层
.. 池化层
.. 常见的网络结构
. 循环网络基础
.. 时序反向传播算法
.. 长短时记忆网络
. 生成对抗基础
.. 对抗博弈.
.. 理论推导.
.. 常见的生成对抗网络
iv j 推荐系统与深度学习
第 章TensorFlow 平台
. 什么是TensorFlow 
. TensorFlow 安装指南.
.. Windows 环境安装.
.. Linux 环境安装.
. TensorFlow 基础.
.. 数据流图.
.. 会话
.. 图可视化.
.. 变量
.. 占位符
.. 优化器
.. 一个简单的例子
. 其他深度学习平台
第 章推荐系统的基础算法
. 基于内容的推荐算法.
.. 基于内容的推荐算法基本流程
.. 基于内容推荐的特征提取.
. 基于协同的推荐算法.
.. 基于物品的协同算法
.. 基于用户的协同算法
.. 基于用户协同和基于物品协同的区别
.. 基于矩阵分解的推荐方法.
.. 基于稀疏自编码的推荐方法.
. 基于社交网络的推荐算法
.. 基于用户的推荐在社交网络中的应用
.. nodevec 技术在社交网络推荐中的应用
. 推荐系统的冷启动问题
.. 如何解决推荐系统冷启动问题
.. 深度学习技术在物品冷启动上的应用
目录j v
第 章混合推荐系统
. 什么是混合推荐系统.
.. 混合推荐系统的意义
.. 混合推荐系统的算法分类.
. 推荐系统特征处理方法
.. 特征处理方法
.. 特征选择方法
. 常见的预测模型
.. 基于逻辑回归的模型
.. 基于支持向量机的模型.
.. 基于梯度提升树的模型.
. 排序学习
.. 基于排序的指标来优化.
.. LR 算法的三种情形.
第 章基于深度学习的推荐模型
. 基于DNN 的推荐算法
. 基于DeepFM 的推荐算法
. 基于矩阵分解和图像特征的推荐算法
. 基于循环网络的推荐算法.
. 基于生成对抗网络的推荐算法.
.. IRGAN 的代码实现.
第 章推荐系统架构设计.
. 推荐系统基本模型
. 推荐系统常见架构
.. 基于离线训练的推荐系统架构设计
.. 面向深度学习的推荐系统架构设计
.. 基于在线训练的推荐系统架构设计
.. 面向内容的推荐系统架构设计
. 推荐系统常用组件
.. 数据上报常用组件
vi j 推荐系统与深度学习
.. 离线存储常用组件
.. 离线计算常用组件
.. 在线存储常用组件
.. 模型服务常用组件
.. 实时计算常用组件
. 推荐系统常见问题
.. 实时性.
.. 多样性.
.. 曝光打击和不良内容过滤.
.. 评估测试.
后记.
图. 淘宝猜你喜欢栏目
图. 百度指数.
图. 歌曲词嵌入模型空间向量.
图. 神经网络的三次兴起
图. 不同层数的神经网络拟合分界面的能力.
图. 不同层数的神经网络表示能力
图. 神经网络的基本结构
图. 感知器算法
图. 三层全连接神经网络
图. 动量对比.
图. 卷积运算.
图. 池化层
图. LeNet 卷积结构.
图. Alex-Net 卷积结构
图. RNN 
图. LSTM 在t 时刻的内部结构
图. GAN 网络
图. TensorFlow 安装截图
图. TensorBoard 计算
图. 腾讯视频APP 推荐页面.
图. 截取自当当网.
图. 截取自QQ 音乐APP.
图. 用户购买物品记录
图. 同时被购买次数矩阵C 
图. 相似度计算结果 
图. 相似度计算结果 
viii j 推荐系统与深度学习
图. 相似度计算结果 
图. 截取自当当网.
图. 物品的倒排索引
图. 用户评分矩阵.
图. Sigma 值
图. NewData 值
图. Mydata 值
图. 自编码神经网络模型
图. 稀疏自编码第一个网络.
图. 稀疏自编码第二个网络.
图. 稀疏自编码第三个网络.
图. 将三个网络组合起来
图. 社交网络关系图示例
图. 融入用户关系和物品关系
图. 社交网络关系图示例
图. 社交网络关系图示例
图. CBOW 和Skip-Gram 示例.
图. Skip-Gram 网络结构
图. CBOW 网络结构
图. word analogy 示例
图. 某网站登录页面
图. QQ 互联开放注册平台 
图. QQ 互联开放注册平台 
图. QQ 互联应用管理页面 
图. QQ 互联应用管理页面 
图. QQ 互联QQ 登录功能获取
图. QQ 音乐APP 中的偏好选择
图. (a) 为每部电影被打分的分布，(b) 为每个用户打分的分布
图. (a) 为每部电影平均分分布，(b) 为每个用户平均分分布.
图. 基于专家数据的CF 与基于用户数据CF 比较.
图目录j ix
图. 音乐频谱示例
图.  个流派的频谱图示例
图. CNN 音频分类结构.
图. CNN+LSTM 组合音频分类模型.
图. 分类预测结果的混淆矩阵
图. 模型倒数第二层 维向量降维可视化
图. 微软how-old.net 
图. SCUT-FBP 数据集示例图
图. 脸部截取后的数据集示例图.
图. CNN 层数过多，误差反而较大
图. 残差网络的基本结构
图. 残差网络完整结构.
图. NetFlix 的实时推荐系统的架构图
图. 整体式混合推荐系统
图. 并行式混合推荐系统
图. 流水线式混合推荐系统.
图. MDLP 特征离散化
图. ChiMerge 特征离散化.
图. 层次化时间按序列特征.
图. Learn to rank 的局限
图. Wide & Deep 模型结构
图. 推荐系统的召回和排序两个阶段
图. 召回模型结构.
图. 序列信息
图. 排序模型结构.
图. 不同NN 的效果
图. DeepFM 模型结构(网络左边为FM 层，右边为DNN 层).
图. FM 一阶部分
图. FM 二阶部分
图. FM/DNN/DeepFM 的比较
x j 推荐系统与深度学习
图. 电影静止帧图片举例
图. Alex-Net 卷积网络.
图. 左图：时间无关的推荐系统。右图：时间相关的推荐系统
图. 基于循环神经网络的推荐系统
图. 判别器
图. 生成器
图. IRGAN 说明
图. 监督学习基本模型.
图. 基于离线训练的推荐系统架构设计
图. 数据上报模块.
图. 离线训练模块.
图. 推荐系统中的存储分层.
图. 在线预测的几个阶段
图. 推荐系统通用性设计
图. 面向深度学习的推荐系统架构设计
图. 利用深度学习进行特征提取
图. 参数服务器架构
图. 基于在线训练的推荐系统架构设计
图. 在线学习之实时特征处理
图. 面向内容的推荐系统架构设计
图. 用于推荐的内容池.
图. Apache Kafka 逻辑架构.
表. 用户A 和B 的评分矩阵.
表. 电影内容特征二进制表示
表. 人脸魅力值打分不同模型的MAE 比较
表. 人脸魅力值打分不同模型的MAE 比较

表. Keras 预训练好的图像分类模型
・ ・ ・ ・ ・ ・ (收起) 概述
. 智能问答：让机器更好地服务于人 
. 问答系统类型介绍 
.. 基于事实的问答系统 
.. 基于常见问题集的问答系统 
.. 开放域的问答系统 
. 使用本书附带的源码程序 
.. 安装依赖软件 
.. 下载源码 
.. 执行示例程序 
.. 联系我们 
. 全书结构 
 机器学习基础
. 线性代数 
.. 标量、向量、矩阵和张量 
.. 矩阵运算 
.. 特殊类型的矩阵 
.. 线性相关 
.. 范数 
. 概率论基础 
.. 随机变量 
.. 期望和方差 
.. 伯努利分布 
.. 二项分布 
.. 泊松分布 
.. 正态分布 
.. 条件概率、联合概率和全概率 
.. 先验概率与后验概率 
.. 边缘概率 
.. 贝叶斯公式 
.. 最大似然估计算法 
.. 线性回归模型 
.. 逻辑斯蒂回归模型 
. 信息论基础 
.. 熵 
.. 联合熵和条件熵 
.. 相对熵与互信息 
.. 信道和信道容量 
.. 最大熵模型 
.. 信息论与机器学习 
. 统计学习 
.. 输入空间、特征空间与输出空间 
.. 向量表示 
.. 数据集 
.. 从概率到函数 
.. 统计学习三要素 
. 隐马尔可夫模型 
.. 随机过程和马尔可夫链 
.. 隐马尔可夫模型的定义 
.. 三个基本假设及适用场景 
.. 概率计算问题之直接计算 
.. 概率计算问题之前向算法 
.. 概率计算问题之后向算法 
.. 预测问题之维特比算法 
.. 学习问题之Baum-Welch 算法 
. 条件随机场模型 
.. 超越HMM 
.. 项目实践 
. 总结 
 自然语言处理基础
. 中文自动分词 
.. 有向无环图 
.. 最大匹配算法 
.. 算法评测 
.. 由字构词的方法 
. 词性标注 
.. 词性标注规范 
.. 隐马尔可夫模型词性标注 
. 命名实体识别 
. 上下文无关文法 
.. 原理介绍 
.. 算法浅析 
. 依存关系分析 
.. 算法浅析 
.. 项目实践 
.. 小结 
. 信息检索系统 
.. 什么是信息检索系统 
.. 衡量信息检索系统的关键指标 
.. 理解非结构化数据 
.. 倒排索引 
.. 处理查询 
.. 项目实践 
.. Elasticsearch 
.. 小结 
. 问答语料 
.. WikiQA 
.. 中文版保险行业语料库InsuranceQA 
. 总结 
 深度学习初步
. 深度学习简史 
.. 感知机 
.. 寒冬和复苏 
.. 走出实验室 
.. 寒冬再临 
.. 走向大规模实际应用 
. 基本架构 
.. 神经元 
.. 输入层、隐藏层和输出层 
.. 标准符号 
. 神经网络是如何学习的 
.. 梯度下降 
.. 反向传播理论 
.. 神经网络全连接层的实现 
.. 使用简单神经网络实现问答任务 
. 调整神经网络超参数 
.. 超参数 
.. 参考建议 
. 卷积神经网络与池化 
.. 简介 
.. 卷积层的前向传播 
.. 池化层的前向传播 
.. 卷积层的实现 
.. 池化层的实现 
.. 使用卷积神经网络实现问答任务 
. 循环神经网络及其变种 
.. 简介 
.. 循环神经网络 
.. 长短期记忆单元和门控循环单元 
.. 循环神经网络的实现 
.. 使用循环神经网络实现问答任务 
. 简易神经网络工具包 
 词向量实现及应用
. 语言模型 
.. 评测 
.. ARPA 格式介绍 
.. 项目实践 
. One-hot 表示法 
. 词袋模型 
. NNLM 和RNNLM 
. wordvec 
.. C-BOW 的原理 
.. Skip-gram 的原理 
.. 计算效率优化 
.. 项目实践 
. GloVe 
.. GloVe 的原理 
.. GloVe 与wordvec 的区别和联系 
.. 项目实践 
. fastText 
.. fastText 的原理 
.. fastText 与wordvec 的区别和联系 
.. 项目实践 
. 中文近义词工具包 
.. 安装 
.. 接口 
. 总结 
 社区问答中的QA 匹配
. 社区问答任务简介 
. 孪生网络模型 
. QACNN 模型 
.. 模型构建 
.. 实验结果 
. Decomposable Attention 模型 
.. 模型介绍 
.. 模型构建 
. 多比较方式的比较C集成模型 
.. 模型介绍 
.. 模型构建 
. BiMPM 模型 
.. 模型介绍 
.. 模型构建 
 机器阅读理解
. 完型填空型机器阅读理解任务 
.. CNN/Daily Mail 数据集 
.. Children’s Book Test（CBT）数据集 
.. GA Reader 模型 
.. SA Reader 模型 
.. AoA Reader 模型 
. 答案抽取型机器阅读理解任务 
.. SQuAD 数据集 
.. MS MARCO 数据集 
.. TriviaQA 数据集 
.. DuReader 数据集 
.. BiDAF 模型 
.. R-Net 模型 
.. S-Net 模型 
. 答案选择型机器阅读理解任务 
. 展望 
参考文献
・ ・ ・ ・ ・ ・ (收起)第  章引言 
．　本书面向的读者　
．　深度学习的历史趋势　
．．　神经网络的众多名称和命运变迁　
．．　与日俱增的数据量　
．．　与日俱增的模型规模　
．．　与日俱增的精度、复杂度和对现实世界的冲击　
第　 部分应用数学与机器学习基础
第　 章线性代数　
．　标量、向量、矩阵和张量　
．　矩阵和向量相乘　
．　单位矩阵和逆矩阵　
．　线性相关和生成子空间　
．　范数　
．　特殊类型的矩阵和向量　
．　特征分解　
．　奇异值分解　
．　Moore-Penrose 伪逆　
．　迹运算　
．　行列式　
．　实例：主成分分析　
第　章概率与信息论　
．　为什么要使用概率　
．　随机变量　
．　概率分布　
．．　离散型变量和概率质量函数　
．．　连续型变量和概率密度函数　
．　边缘概率　
．　条件概率　
．　条件概率的链式法则　
．　独立性和条件独立性　
．　期望、方差和协方差　
．　常用概率分布　
．．　Bernoulli 分布　
．．　Multinoulli 分布　
．．　高斯分布　
．．　指数分布和Laplace 分布　
．．　Dirac 分布和经验分布　
．．　分布的混合　
．　常用函数的有用性质　
．　贝叶斯规则　
．　连续型变量的技术细节　
．　信息论　
．　结构化概率模型　
第　章数值计算　
．　上溢和下溢　
．　病态条件　
．　基于梯度的优化方法　
．　约束优化　
．　实例：线性最小二乘　
第　章机器学习基础　
．　学习算法　
．．　任务T　
．．　性能度量P　
．．　经验E　
．．　示例：线性回归　
．　容量、过拟合和欠拟合　
．．　没有免费午餐定理　
．．　正则化　
．　超参数和验证集　
．　估计、偏差和方差　
．．　点估计　
．．　偏差　
．．　方差和标准差　
．．　权衡偏差和方差以最小化均方误差　
．．　一致性　
．　最大似然估计　
．．　条件对数似然和均方误差　
．．　最大似然的性质　
．　贝叶斯统计　
．　监督学习算法　
．．　概率监督学习　
．．　支持向量机　
．．　其他简单的监督学习算法　
．　无监督学习算法　
．．　主成分分析　
．．　k- 均值聚类　
．　随机梯度下降　
．　构建机器学习算法　
．　促使深度学习发展的挑战　
．．　维数灾难　
．．　局部不变性和平滑正则化　
．．　流形学习　
第　 部分深度网络：现代实践
第　章深度前馈网络　
．　实例：学习XOR　
．　基于梯度的学习　
．．　代价函数　
．．　输出单元　
．　隐藏单元　
．．　整流线性单元及其扩展　
．．　logistic sigmoid 与双曲正切函数　
．．　其他隐藏单元　
．　架构设计　
．．　万能近似性质和深度　
．．　其他架构上的考虑　
．　反向传播和其他的微分算法　
．．　计算图　
．．　微积分中的链式法则　
．．　递归地使用链式法则来实现反向传播　
．．　全连接MLP 中的反向传播计算　
．．　符号到符号的导数　
．．　一般化的反向传播　
．．　实例：用于MLP 训练的反向传播　
．．　复杂化　
．．　深度学习界以外的微分　
．．　高阶微分　
．　历史小记　
第　章深度学习中的正则化　
．　参数范数惩罚　
．．　L 参数正则化　
．．　L 正则化　
．　作为约束的范数惩罚　
．　正则化和欠约束问题　
．　数据集增强　
．　噪声鲁棒性　
．　半监督学习　
．　多任务学习　
．　提前终止　
．　参数绑定和参数共享　
．　稀疏表示　
．　Bagging 和其他集成方法　
．　Dropout　
．　对抗训练　
．　切面距离、正切传播和流形正切分类器　
第　章深度模型中的优化　
．　学习和纯优化有什么不同　
．．　经验风险最小化　
．．　代理损失函数和提前终止　
．．　批量算法和小批量算法　
．　神经网络优化中的挑战　
．．　病态　
．．　局部极小值　
．．　高原、鞍点和其他平坦区域　
．．　悬崖和梯度爆炸　
．．　长期依赖　
．．　非精确梯度　
．．　局部和全局结构间的弱对应　
．．　优化的理论限制　
．　基本算法　
．．　随机梯度下降　
．．　动量　
．．　Nesterov 动量　
．　参数初始化策略　
．　自适应学习率算法　
．．　AdaGrad　
．．　RMSProp　
．．　Adam　
．．　选择正确的优化算法　
．　二阶近似方法　
．．　牛顿法　
．．　共轭梯度　
．．　BFGS　
．　优化策略和元算法　
．．　批标准化　
．．　坐标下降　
．．　Polyak 平均　
．．　监督预训练　
．．　设计有助于优化的模型　
．．　延拓法和课程学习　
第　章卷积网络　
．　卷积运算　
．　动机　
．　池化　
．　卷积与池化作为一种无限强的先验　
．　基本卷积函数的变体　
．　结构化输出　
．　数据类型　
．　高效的卷积算法　
．　随机或无监督的特征　
．　卷积网络的神经科学基础　
．　卷积网络与深度学习的历史　
第　 章序列建模：循环和递归网络　
．　展开计算图　
．　循环神经网络　
．．　导师驱动过程和输出循环网络　
．．　计算循环神经网络的梯度　
．．　作为有向图模型的循环网络　
．．　基于上下文的RNN 序列建模　
．　双向RNN　
．　基于编码{解码的序列到序列架构　
．　深度循环网络　
．　递归神经网络　
．　长期依赖的挑战　
．　回声状态网络　
．　渗漏单元和其他多时间尺度的策略　
．．　时间维度的跳跃连接　
．．　渗漏单元和一系列不同时间尺度　
．．　删除连接　
．　长短期记忆和其他门控RNN　
．．　LSTM　
．．　其他门控RNN　
．　优化长期依赖　
．．　截断梯度　
．．　引导信息流的正则化　
．　外显记忆　
第　 章实践方法论　
．　性能度量　
．　默认的基准模型　
．　决定是否收集更多数据　
．　选择超参数　
．．　手动调整超参数　
．．　自动超参数优化算法　
．．　网格搜索　
．．　随机搜索　
．．　基于模型的超参数优化　
．　调试策略　
．　示例：多位数字识别　
第　 章应用　
．　大规模深度学习　
．．　快速的CPU 实现　
．．　GPU 实现　
．．　大规模的分布式实现　
．．　模型压缩　
．．　动态结构　
．．　深度网络的专用硬件实现　
．　计算机视觉　
．．　预处理　
．．　数据集增强　
．　语音识别　
．　自然语言处理　
．．　n-gram　
．．　神经语言模型　
．．　高维输出　
．．　结合n-gram 和神经语言模型　
．．　神经机器翻译　
．．　历史展望　
．　其他应用　
．．　推荐系统　
．．　知识表示、推理和回答　
第　部分深度学习研究
第　 章线性因子模型　
．　概率PCA 和因子分析　
．　独立成分分析　
．　慢特征分析　
．　稀疏编码　
．　PCA 的流形解释　
第　 章自编码器　
．　欠完备自编码器　
．　正则自编码器　
．．　稀疏自编码器　
．．　去噪自编码器　
．．　惩罚导数作为正则　
．　表示能力、层的大小和深度　
．　随机编码器和解码器　
．　去噪自编码器详解　
．．　得分估计　
．．　历史展望　
．　使用自编码器学习流形　
．　收缩自编码器　
．　预测稀疏分解　
．　自编码器的应用　
第　 章表示学习　
．　贪心逐层无监督预训练　
．　迁移学习和领域自适应　
．　半监督解释因果关系　
．　分布式表示　
．　得益于深度的指数增益　
．　提供发现潜在原因的线索　
第　 章深度学习中的结构化概率模型　
．　非结构化建模的挑战　
．　使用图描述模型结构　
．．　有向模型　
．．　无向模型　
．．　配分函数　
．．　基于能量的模型　
．．　分离和d-分离　
．．　在有向模型和无向模型中转换　
．．　因子图　
．　从图模型中采样　
．　结构化建模的优势　
．　学习依赖关系　
．　推断和近似推断　
．　结构化概率模型的深度学习方法 第  章蒙特卡罗方法　
．　采样和蒙特卡罗方法　
．．　为什么需要采样　
．．　蒙特卡罗采样的基础　
．　重要采样　
．　马尔可夫链蒙特卡罗方法　
．　Gibbs 采样　
．　不同的峰值之间的混合挑战　
．．　不同峰值之间通过回火来混合　
．．　深度也许会有助于混合　
第　 章直面配分函数　
．　对数似然梯度　
．　随机最大似然和对比散度　
．　伪似然　
．　得分匹配和比率匹配　
．　去噪得分匹配　
．　噪声对比估计　
．　估计配分函数　
．．　退火重要采样　
．．　桥式采样　
第　 章近似推断　
．　把推断视作优化问题　
．　期望最大化　
．　最大后验推断和稀疏编码　
．　变分推断和变分学习　
．．　离散型潜变量　
．．　变分法　
．．　连续型潜变量　
．．　学习和推断之间的相互作用　
．　学成近似推断　
．．　醒眠算法　
．．　学成推断的其他形式　
第　 章深度生成模型　
．　玻尔兹曼机　
．　受限玻尔兹曼机　
．．　条件分布　
．．　训练受限玻尔兹曼机　
．　深度信念网络　
．　深度玻尔兹曼机　
．．　有趣的性质　
．．　DBM 均匀场推断　
．．　DBM 的参数学习　
．．　逐层预训练　
．．　联合训练深度玻尔兹曼机　
．　实值数据上的玻尔兹曼机　
．．　Gaussian-Bernoulli RBM　
．．　条件协方差的无向模型　
．　卷积玻尔兹曼机　
．　用于结构化或序列输出的玻尔兹曼机　
．　其他玻尔兹曼机　
．　通过随机操作的反向传播　
．　有向生成网络　
．．　sigmoid 信念网络　
．．　可微生成器网络　
．．　变分自编码器　
．．　生成式对抗网络　
．．　生成矩匹配网络　
．．　卷积生成网络　
．．　自回归网络　
．．　线性自回归网络　
．．　神经自回归网络　
．．　NADE　
．　从自编码器采样　
．．　与任意去噪自编码器相关的马尔可夫链 ．　
．．　夹合与条件采样　
．．　回退训练过程　
．　生成随机网络　
．　其他生成方案　
．　评估生成模型　
．　结论　
参考文献　
索引　
・ ・ ・ ・ ・ ・ (收起)目 录
第章 深度学习的发展介绍 
. 如何阅读本书 
. 深度学习沉浮史 
.. 模拟生物大脑的疯狂远古时代 
.. 联结主义近代 
.. 百花齐放，层次结构主导，模型巨大的当代 
. Python简易教程 
.. Anaconda搭建 
.. IPython Notebook使用 
.. Python基本用法 
.. NumPy 
.. Matplotlib 
. 参考文献 
第章 机器学习快速入门 
. 学习算法 
.. 学习任务 
.. 性能度量 
.. 学习经验 
. 代价函数 
.. 均方误差函数 
.. 极大似然估计 
. 梯度下降法 
.. 批量梯度下降法 
.. 随机梯度下降法 
. 过拟合与欠拟合 
.. 没免费午餐理论 
.. 正则化 
. 超参数与验证集 
. Softmax编码实战 
.. 编码说明 
.. 熟练使用CIFAR- 数据集 
.. 显式循环计算损失函数及其梯度 
.. 向量化表达式计算损失函数及其梯度 
.. 最小批量梯度下降算法训练Softmax分类器 
.. 使用验证数据选择超参数 
. 参考代码 
. 参考文献 
第章 前馈神经网络 
. 神经元 
.. Sigmoid神经元 
.. Tanh神经元 
.. ReLU神经元 
. 前馈神经网络 
.. 输出层单元 
.. 隐藏层单元 
.. 网络结构设计 
. BP算法 
. 深度学习编码实战上 
.. 实现仿射传播 
.. 实现ReLU传播 
.. 组合单层神经元 
.. 实现浅层神经网络 
.. 实现深层全连接网络 
. 参考代码 
. 参考文献 
第章 深度学习正则化 
. 参数范数惩罚 
.. L参数正则化 
.. L正则化 
. 参数绑定与参数共享 
. 噪声注入与数据扩充 
. 稀疏表征 
. 早停 
. Dropout 
.. 个体与集成 
.. Dropout 
. 深度学习编码实战中 
.. Dropout传播 
.. 组合Dropout传播层 
.. Dropout神经网络 
.. 解耦训练器trainer 
.. 解耦更新器updater 
.. 正则化实验 
. 参考代码 
. 参考文献 
第章 深度学习优化 
. 神经网络优化困难 
.. 局部最优 
.. 鞍点 
.. 梯度悬崖 
.. 梯度消失或梯度爆炸 
.. 梯度不精确 
.. 优化理论的局限性 
. 随机梯度下降 
. 动量学习法 
. AdaGrad和RMSProp 
. Adam 
. 参数初始化策略 
. 批量归一化 
.. BN算法详解 
.. BN传播详解 
. 深度学习编码实战下 
.. Momentum 
.. RMSProp 
.. Adam 
.. 更新规则比较 
.. BN前向传播 
.. BN反向传播 
.. 使用BN的全连接网络 
.. BN算法与权重标准差比较 
. 参考代码 
. 参考文献 
第章 卷积神经网络 
. 卷积操作 
. 卷积的意义 
.. 稀疏连接 
.. 参数共享 
. 池化操作 
. 设计卷积神经网络 
.. 跨步卷积 
.. 零填充 
.. 非共享卷积 
.. 平铺卷积 
. 卷积网络编码练习 
.. 卷积前向传播 
.. 卷积反向传播 
.. 最大池化前向传播 
.. 最大池化反向传播 
.. 向量化执行 
.. 组合完整卷积层 
.. 浅层卷积网络 
.. 空间批量归一化 
. 参考代码 
. 参考文献 
第章 循环神经网络 
. 循环神经网络 
.. 循环神经元展开 
.. 循环网络训练 
. 循环神经网络设计 
.. 双向循环网络结构 
.. 编码-解码网络结构 
.. 深度循环网络结构 
. 门控循环神经网络 
.. LSTM 
.. 门控循环单元 
. RNN编程练习 
.. RNN单步传播 
.. RNN时序传播 
.. 词嵌入 
.. RNN输出层 
.. 时序Softmax损失 
.. RNN图片说明任务 
. LSTM编程练习 
.. LSTM单步传播 
.. LSTM时序传播 
.. LSTM实现图片说明任务 
. 参考代码 
.. RNN参考代码 
.. LSTM参考代码 
. 参考文献 
第章 TensorFlow快速入门 
. TensorFlow介绍 
. TensorFlow .安装指南 
.. 双版本切换Anaconda 
.. 安装CUDA . 
.. 安装cuDNN 
.. 安装TensorFlow 
.. 验证安装 
. TensorFlow基础 
.. Tensor 
.. TensorFlow核心API教程 
.. tf.train API 
.. tf.contrib.learn 
. TensorFlow构造CNN 
.. 构建Softmax模型 
.. 使用TensorFlow训练模型 
.. 使用TensorFlow评估模型 
.. 使用TensorFlow构建卷积神经网络 
. TensorBoard快速入门 
.. TensorBoard可视化学习 
.. 计算图可视化 
・ ・ ・ ・ ・ ・ (收起)译者序 iv
序 vii
前言 ix
术语缩写 xxii
符号 xxvii
第  章 简介 
. 自动语音识别：更好的沟通之桥 . . . . . . . . . . . . . . . . . . . . . . . 
.. 人类之间的交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 人机交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 语音识别系统的基本结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 全书结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 第一部分：传统声学模型 . . . . . . . . . . . . . . . . . . . . . . 
.. 第二部分：深度神经网络 . . . . . . . . . . . . . . . . . . . . . . 
.. 第三部分：语音识别中的 DNN-HMM 混合系统 . . . . . . . . . . 
.. 第四部分：深度神经网络中的表征学习 . . . . . . . . . . . . . . 
.. 第五部分：高级的深度模型 . . . . . . . . . . . . . . . . . . . . . 
第一部分 传统声学模型 
第  章 混合高斯模型 
. 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 高斯分布和混合高斯随机变量 . . . . . . . . . . . . . . . . . . . . . . . . 
. 参数估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 采用混合高斯分布对语音特征建模 . . . . . . . . . . . . . . . . . . . . . 
第  章 隐马尔可夫模型及其变体 
. 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 序列与模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 隐马尔可夫模型的性质 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 隐马尔可夫模型的仿真 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 隐马尔可夫模型似然度的计算 . . . . . . . . . . . . . . . . . . . . 
.. 计算似然度的高效算法 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 前向与后向递归式的证明 . . . . . . . . . . . . . . . . . . . . . . 
. 期望最大化算法及其在学习 HMM 参数中的应用 . . . . . . . . . . . . . 
.. 期望最大化算法介绍 . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 使用 EM 算法来学习 HMM 参数――Baum-Welch 算法 . . . . . . 
. 用于解码 HMM 状态序列的维特比算法 . . . . . . . . . . . . . . . . . . . 
.. 动态规划和维特比算法 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 用于解码 HMM 状态的动态规划算法 . . . . . . . . . . . . . . . . 
. 隐马尔可夫模型和生成语音识别模型的变体 . . . . . . . . . . . . . . . . 
.. 用于语音识别的 GMM-HMM 模型 . . . . . . . . . . . . . . . . . 
.. 基于轨迹和隐藏动态模型的语音建模和识别 . . . . . . . . . . . . 
.. 使用生成模型 HMM 及其变体解决语音识别问题 . . . . . . . . . 
第二部分 深度神经网络 
第  章 深度神经网络 
. 深度神经网络框架 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 使用误差反向传播来进行参数训练 . . . . . . . . . . . . . . . . . . . . . 
.. 训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实际应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 模型初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 权重衰减 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 丢弃法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 批量块大小的选择 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 取样随机化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 惯性系数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学习率和停止准则 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 网络结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 可复现性与可重启性 . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 高级模型初始化技术 
. 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 受限玻尔兹曼机的属性 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 受限玻尔兹曼机参数学习 . . . . . . . . . . . . . . . . . . . . . . 
. 深度置信网络预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 降噪自动编码器预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 鉴别性预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 混合预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 采用丢弃法的预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第三部分 语音识别中的深度神经网络C隐马尔可夫混合模型 
第  章 深度神经网络C隐马尔可夫模型混合系统 
. DNN-HMM 混合系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 用 CD-DNN-HMM 解码 . . . . . . . . . . . . . . . . . . . . . . . . 
.. CD-DNN-HMM 训练过程 . . . . . . . . . . . . . . . . . . . . . . . 
.. 上下文窗口的影响 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. CD-DNN-HMM 的关键模块及分析 . . . . . . . . . . . . . . . . . . . . . 
.. 进行比较和分析的数据集和实验 . . . . . . . . . . . . . . . . . . 
.. 对单音素或者三音素的状态进行建模 . . . . . . . . . . . . . . . . 
.. 越深越好 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 利用相邻的语音帧 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练数据的标注质量的影响 . . . . . . . . . . . . . . . . . . . . . 
.. 调整转移概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于 KL 距离的隐马尔可夫模型 . . . . . . . . . . . . . . . . . . . . . . . 
第  章 训练和解码的加速 
. 训练加速 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 使用多 GPU 流水线反向传播 . . . . . . . . . . . . . . . . . . . . 
.. 异步随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 增广拉格朗日算法及乘子方向交替算法 . . . . . . . . . . . . . . 
.. 减小模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 加速解码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 并行计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 稀疏网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 低秩近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 用大尺寸 DNN 训练小尺寸 DNN . . . . . . . . . . . . . . . . . . 
.. 多帧 DNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度神经网络序列鉴别性训练 
. 序列鉴别性训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最大相互信息 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 增强型 MMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最小音素错误/状态级最小贝叶斯风险 . . . . . . . . . . . . . . . 
.. 统一的公式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 具体实现中的考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 词图产生 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 词图补偿 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 帧平滑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学习率调整 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练准则选择 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 将概率密度估计问题转换为二分类设计问题 . . . . . . . . . . . . 
.. 拓展到未归一化的模型 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 在深度学习网络训练中应用噪声对比估计算法 . . . . . . . . . . 
第四部分 深度神经网络中的特征表示学习 
第  章 深度神经网络中的特征表示学习 
. 特征和分类器的联合学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 特征层级 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 使用随意输入特征的灵活性 . . . . . . . . . . . . . . . . . . . . . . . . . 
. 特征的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对说话人变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对环境变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 
. 对环境的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对噪声的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对语速变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 
. 缺乏严重信号失真情况下的推广能力 . . . . . . . . . . . . . . . . . . . . 
第  章 深度神经网络和混合高斯模型的融合 
. 在 GMM-HMM 系统中使用由 DNN 衍生的特征 . . . . . . . . . . . . . . 
.. 使用 Tandem 和瓶颈特征的 GMM-HMM 模型 . . . . . . . . . . . 
.. DNN-HMM 混合系统与采用深度特征的 GMM-HMM 系统的比较 
. 识别结果融合技术 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 识别错误票选降低技术（ ROVER） . . . . . . . . . . . . . . . . . 
.. 分段条件随机场（ SCARF） . . . . . . . . . . . . . . . . . . . . . 
.. 最小贝叶斯风险词图融合 . . . . . . . . . . . . . . . . . . . . . . 
. 帧级别的声学分数融合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 多流语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度神经网络的自适应技术 
. 深度神经网络中的自适应问题 . . . . . . . . . . . . . . . . . . . . . . . . 
. 线性变换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 线性输入网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 线性输出网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 线性隐层网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 保守训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. L  正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. KL 距离正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 减少每个说话人的模型开销 . . . . . . . . . . . . . . . . . . . . . 
. 子空间方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 通过主成分分析构建子空间 . . . . . . . . . . . . . . . . . . . . . 
.. 噪声感知、说话人感知及设备感知训练 . . . . . . . . . . . . . . 
.. 张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. DNN 说话人自适应的效果 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于 KL 距离的正则化方法 . . . . . . . . . . . . . . . . . . . . . 
.. 说话人感知训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第五部分 先进的深度学习模型 
第  章 深度神经网络中的表征共享和迁移 
. 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 多语言和跨语言语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于 Tandem 或瓶颈特征的跨语言语音识别 . . . . . . . . . . . . 
.. 共享隐层的多语言深度神经网络 . . . . . . . . . . . . . . . . . . 
.. 跨语言模型迁移 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 语音识别中深度神经网络的多目标学习 . . . . . . . . . . . . . . . . . . . 
.. 使用多任务学习的鲁棒语音识别 . . . . . . . . . . . . . . . . . . 
.. 使用多任务学习改善音素识别 . . . . . . . . . . . . . . . . . . . . 
.. 同时识别音素和字素（ graphemes） . . . . . . . . . . . . . . . . . 
. 使用视听信息的鲁棒语音识别 . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 循环神经网络及相关模型 
. 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基本循环神经网络中的状态-空间公式 . . . . . . . . . . . . . . . . . . . . 
. 沿时反向传播学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最小化目标函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 误差项的递归计算 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 循环神经网络权重的更新 . . . . . . . . . . . . . . . . . . . . . . 
. 一种用于学习循环神经网络的原始对偶技术 . . . . . . . . . . . . . . . . 
.. 循环神经网络学习的难点 . . . . . . . . . . . . . . . . . . . . . . 
.. 回声状态（ Echo-State）性质及其充分条件 . . . . . . . . . . . . . 
.. 将循环神经网络的学习转化为带约束的优化问题 . . . . . . . . . 
.. 一种用于学习 RNN 的原始对偶方法 . . . . . . . . . . . . . . . . 
. 结合长短时记忆单元（ LSTM）的循环神经网络 . . . . . . . . . . . . . . 
.. 动机与应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 长短时记忆单元的神经元架构 . . . . . . . . . . . . . . . . . . . . 
.. LSTM-RNN 的训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 循环神经网络的对比分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 信息流方向的对比：自上而下还是自下而上 . . . . . . . . . . . . 
.. 信息表征的对比：集中式还是分布式 . . . . . . . . . . . . . . . . 
.. 解释能力的对比：隐含层推断还是端到端学习 . . . . . . . . . . 
.. 参数化方式的对比：吝啬参数集合还是大规模参数矩阵 . . . . . 
.. 模型学习方法的对比：变分推理还是梯度下降 . . . . . . . . . . 
.. 识别正确率的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 讨论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 计算型网络 
. 计算型网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 前向计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 模型训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 典型的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 无操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 含一个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 
.. 含两个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 
.. 用来计算统计量的计算节点类型 . . . . . . . . . . . . . . . . . . 
. 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 循环连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 只在循环中一个接一个地处理样本 . . . . . . . . . . . . . . . . . 
.. 同时处理多个句子 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 创建任意的循环神经网络 . . . . . . . . . . . . . . . . . . . . . . 
第  章 总结及未来研究方向 
. 路线图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 语音识别中的深度神经网络启蒙 . . . . . . . . . . . . . . . . . . 
.. 深度神经网络训练和解码加速 . . . . . . . . . . . . . . . . . . . . 
.. 序列鉴别性训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 特征处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 循环神经网络和长短时记忆神经网络 . . . . . . . . . . . . . . . . 
.. 其他深度模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 技术前沿和未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 技术前沿简析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
参考文献 
・ ・ ・ ・ ・ ・ (收起)目录
前言
第章　工具与技术
. 神经网络的类型
. 数据获取
. 数据预处理
第章　摆脱困境
. 确定我们遇到的问题
. 解决运行过程中的错误
. 检查中间结果
. 为最后一层选择正确的激活函数
. 正则化和Dropout
. 网络结构、批尺寸和学习率
第章　使用词嵌入计算文本相似性
. 使用预训练的词嵌入发现词的相似性
. Wordvec数学特性
. 可视化词嵌入
. 在词嵌入中发现实体类
. 计算类内部的语义距离
. 在地图上可视化国家数据
第章　基于维基百科外部链接构建推荐系统
. 收集数据
. 训练电影嵌入
. 构建电影推荐系统
. 预测简单的电影属性
第章　按照示例文本的风格生成文本
. 获取公开领域书籍文本
. 生成类似莎士比亚的文本
. 使用RNN编写代码
. 控制输出温度
. 可视化循环神经网络的活跃程度
第章　问题匹配
. 从Stack Exchange网站获取数据
. 使用Pandas探索数据
. 使用Keras对文本进行特征化
. 构建问答模型
. 用Pandas训练模型
. 检查相似性
第章　推荐表情符号
. 构建一个简单的情感分类器
. 检验一个简单的分类器
. 使用卷积网络进行情感分析
. 收集Twitter数据
. 一个简单的表情符号预测器
. Dropout和多层窗口
. 构建单词级模型
. 构建你自己的嵌入
. 使用循环神经网络进行分类
. 可视化一致性/不一致性
. 组合模型
第章　Sequence-to-Sequence映射
. 训练一个简单的Sequence-to-Sequence模型
. 从文本中提取对话
. 处理开放词汇表
. 训练seqseq 聊天机器人
第章　复用预训练的图像识别网络
. 加载预训练网络
. 图像预处理
. 推测图像内容
. 使用Flickr API收集一组带标签的图像
. 构建一个分辨猫狗的分类器
. 改进搜索结果
. 复训图像识别网络
第章　构建反向图像搜索服务
. 从维基百科中获取图像
. 向N维空间投影图像
. 在高维空间中寻找最近邻
. 探索嵌入中的局部邻域
第章　检测多幅图像
. 使用预训练的分类器检测多个图像
. 使用Faster RCNN进行目标检测
. 在自己的图像上运行Faster RCNN
第章　图像风格
. 可视化卷积神经网络激活值
. 尺度和缩放
. 可视化神经网络所见
. 捕捉图像风格
. 改进损失函数以提升图像相干性
. 将风格迁移至不同图像
. 风格内插
第章　用自编码器生成图像
. 从Google Quick Draw中导入绘图
. 为图像创建自编码器
. 可视化自编码器结果
. 从正确的分布中采样图像
. 可视化变分自编码器空间
. 条件变分编码器
第章　使用深度网络生成图标
. 获得训练用的图标
. 将图标转换为张量表示
. 使用变分自编码器生成图标
. 使用数据扩充提升自编码器的性能
. 构建生成式对抗网络
. 训练生成式对抗网络
. 显示GAN生成的图标
. 将图标编码成绘图指令
. 训练RNN绘制图标
. 使用RNN生成图标
第章　音乐与深度学习
. 为音乐分类器创建训练数据集
. 训练音乐风格检测器
. 对混淆情况进行可视化
. 为已有的音乐编制索引
. 设置Spotify API
. 从Spotify中收集播放列表和歌曲
. 训练音乐推荐系统
. 使用Wordvec模型推荐歌曲
第章　生产化部署机器学习系统
. 使用scikit-learn最近邻计算嵌入
. 使用Postgres存储嵌入
. 填充和查询Postgres存储的嵌入
. 在Postgres中存储高维模型
. 使用Python编写微服务
. 使用微服务部署Keras模型
. 从Web框架中调用微服务
. Tensorflow seqseq模型
. 在浏览器中执行深度学习模型
. 使用TensorFlow服务执行Keras模型
. 在iOS中使用Keras模型
・ ・ ・ ・ ・ ・ (收起)第章 绪论 
. 引言 
. 本书内容 
.. 图像分类 
.. 动作识别 
.. 时序动作定位 
.. 视频 Embedding 
. 本章小结 
第章 经典网络结构回顾 
. 经典图像分类网络 
.. LetNet- 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. Inception V/V 
.. ResNet 
.. preResNet 
.. WRN 
.. 随机深度网络 
.. DenseNet 
.. ResNeXt 
.. SENet 
.. MobileNet 
.. MobileNet V/V 
.. ShuffleNet 
.. ShuffleNet V 
. RNN、LSTM和GRU 
.. RNN 
.. 梯度爆炸与梯度消失 
.. LSTM 
.. GRU 
. 本章小结 
第章 基于D卷积的动作识别 
. 平均汇合 
. NetVLAD和NeXtVLAD 
.. VLAD 
.. NetVLAD 
.. NeXtVLAD 
.. NetFV和其他策略 
. 利用RNN融合各帧特征 
.. D卷积 + RNN的基本结构 
.. 对RNN结构进行改造 
. 利用D卷积融合各帧特征 
.. 什么是D卷积 
.. ECO 
. 双流法 
.. 什么是光流 
.. 双流法的基本网络结构 
.. 双流法的网络结构优化 
. 时序稀疏采样 
.. TSN 
.. TSN的实现 
.. ActionVLAD 
.. StNet 
.. TRN 
. 利用iDT轨迹 
.. DT和iDT 
.. TDD 
. 本章小结 
第章 基于D卷积的动作识别 
. D卷积基础网络结构 
.. CD 
.. ResD/D ResNet 
.. LTC 
. ID 
.. 类动作识别网络 
.. D卷积扩展为D卷积 
.. 类网络对比 
. D卷积的低秩近似 
.. 低秩近似的基本原理 
.. FSTCN 
.. PD 
.. R(+)D 
.. SD 
. TSM 
. D卷积 + RNN 
. ARTNet 
. Non-Local 
.. Non-Local 操作 
.. Non-Local 动作识别网络 
. SlowFast 
.. Slow分支和Fast分支 
.. 网络结构设计 
. D卷积神经网络超参数设计 
.. 多网格训练 
.. XD 
. 本章小结 
第章 时序动作定位 
. 基于滑动窗的算法 
.. S-CNN 
.. TURN 
.. CBR 
. 基于候选时序区间的算法 
.. Faster R-CNN 回顾 
.. R-CD 
.. TAL-Net 
. 自底向上的时序动作定位算法 
.. BSN 
.. TSA-Net 
.. BMN 
. 对时序结构信息建模的算法 
.. TAG 候选时序区间生成算法 
.. SSN 网络结构 
. 逐帧预测的算法 
.. CDC层 
.. CDC 网络结构 
. 单阶段算法 
.. SSAD 
.. SS-TAD 
.. GTAN 
. 本章小结 
第章 视频Embedding 
. 基于视频内容的无监督 Embedding 
.. 编码-解码网络 
.. 视频序列验证 
.. 视频和音频信息 
.. 视频和文本信息 
. WordVec 
.. CBOW和Skip-Gram 
.. 分层 Softmax 
.. 负采样 
. ItemVec 
.. ItemVec 基本形式 
.. ItemVec的改进 
. 基于图的随机游走 
.. DeepWalk 
.. NodeVec 
. 结合一二阶相似度 
.. LINE 
.. SDNE 
. 基于图的邻居结点 
.. GCN 
.. GraphSAGE 
.. GAT 
. 基于多种信息学习视频Embedding 
.. 召回模型 
.. 训练 
. 本章小结 
附录A 视频处理常用工具 
A. FFmpeg 
A. OpenCV 
A. Decord 
A. Lintel 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第 部分深度学习基础篇
 概述
. 人工智能 
.. 人工智能的分类 
.. 人工智能发展史 
. 机器学习 
.. 机器学习的由来 
.. 机器学习发展史 
.. 机器学习方法分类 
.. 机器学习中的基本概念 
. 神经网络 
.. 神经网络发展史 
参考文献 
 神经网络
. 在神经科学中对生物神经元的研究 
.. 神经元激活机制 
.. 神经元的特点 
. 神经元模型 
.. 线性神经元 
.. 线性阈值神经元 
.. Sigmoid 神经元 
.. Tanh 神经元 
.. ReLU 
.. Maxout 
.. Softmax 
.. 小结 
. 感知机 
.. 感知机的提出 
.. 感知机的困境 
. DNN 
.. 输入层、输出层及隐层 
.. 目标函数的选取 
.. 前向传播 
.. 后向传播 
.. 参数更新 
.. 神经网络的训练步骤 
参考文献 
 初始化模型
. 受限玻尔兹曼机 
.. 能量模型 
.. 带隐藏单元的能量模型 
.. 受限玻尔兹曼机基本原理 
.. 二值RBM 
.. 对比散度 
. 自动编码器 
.. 稀疏自动编码器 
.. 降噪自动编码器 
.. 栈式自动编码器 
. 深度信念网络 
参考文献 
 卷积神经网络
. 卷积算子 
. 卷积的特征 
. 卷积网络典型结构 
.. 基本网络结构 
.. 构成卷积神经网络的层 
.. 网络结构模式 
. 卷积网络的层 
.. 卷积层 
.. 池化层 
参考文献 
 循环神经网络
. 循环神经网络简介 
. RNN、LSTM 和GRU 
. 双向RNN 
. RNN 语言模型的简单实现 
参考文献 
 深度学习优化算法
. SGD 
. Momentum 
. NAG 
. Adagrad 
. RMSProp 
. Adadelta 
. Adam 
. AdaMax 
. Nadam 
. 关于优化算法的使用 
参考文献 
 深度学习训练技巧
. 数据预处理 
. 权重初始化 
. 正则化 
.. 提前终止 
.. 数据增强 
.. L/L 参数正则化 
.. 集成 
.. Dropout 
参考文献 
 深度学习框架
. Theano 
.. Theano 
.. 安装 
.. 计算图 
. Torch 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. PyTorch 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. Caffe 
.. 概述 
.. 安装 
.. 核心组件 
.. 小试牛刀 
. TensorFlow 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. MXNet 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. Keras 
.. 概述 
.. 安装 
.. 模块介绍 
.. 小试牛刀 
参考文献 
第 部分计算机视觉篇
 计算机视觉背景
. 传统计算机视觉 
. 基于深度学习的计算机视觉 
. 参考文献 
 图像分类模型
. LeNet- 
. AlexNet 
. VGGNet 
.. 网络结构 
.. 配置 
.. 讨论 
.. 几组实验 
. GoogLeNet 
.. NIN 
.. GoogLeNet 的动机 
.. 网络结构细节 
.. 训练方法 
.. 后续改进版本 
. ResNet 
.. 基本思想 
.. 网络结构 
. DenseNet 
. DPN 
参考文献 
 目标检测
. 相关研究 
.. 选择性搜索 
.. OverFeat 
. 基于区域提名的方法 
.. R-CNN 
.. SPP-net 
.. Fast R-CNN 
.. Faster R-CNN 
.. R-FCN 
. 端到端的方法 
.. YOLO 
.. SSD 
. 小结 
参考文献 
 语义分割
. 全卷积网络 
.. FCN 
.. DeconvNet 
.. SegNet 
.. DilatedConvNet 
. CRF/MRF 的使用 
.. DeepLab 
.. CRFasRNN 
.. DPN 
. 实例分割 
.. Mask R-CNN 
参考文献 
 图像检索的深度哈希编码
. 传统哈希编码方法 
. CNNH 
. DSH 
. 小结 
参考文献 
第 部分语音识别篇
 传统语音识别基础
. 语音识别简介 
. HMM 简介 
.. HMM 是特殊的混合模型 
.. 转移概率矩阵 
.. 发射概率 
.. Baum-Welch 算法 
.. 后验概率 
.. 前向-后向算法 
. HMM 梯度求解 
.. 梯度算法 
.. 梯度算法 
.. 梯度求解的重要性 
. 孤立词识别 
.. 特征提取 
.. 孤立词建模 
.. GMM-HMM 
. 连续语音识别 
. Viterbi 解码 
. 三音素状态聚类 
. 判别式训练 
参考文献 
 基于WFST 的语音解码
. 有限状态机 
. WFST 及半环定义 
.. WFST 
.. 半环（Semiring） 
. 自动机操作 
.. 自动机基本操作 
.. 转换器基本操作 
.. 优化操作 
. 基于WFST 的语音识别系统 
.. 声学模型WFST 
.. 三音素WFST 
.. 发音字典WFST 
.. 语言模型WFST 
.. WFST 组合和优化 
.. 组合和优化实验 
.. WFST 解码 
参考文献 
 深度语音识别
. CD-DNN-HMM 
. TDNN 
. CTC 
. EESEN 
. Deep Speech 
. Chain 
参考文献 
 CTC 解码
. 序列标注 
. 序列标注任务的解决办法 
.. 序列分类 
.. 分割分类 
.. 时序分类 
. 隐马模型 
. CTC 基本定义 
. CTC 前向算法 
. CTC 后向算法 
. CTC 目标函数 
. CTC 解码基本原理 
.. 最大概率路径解码 
.. 前缀搜索解码 
.. 约束解码 
参考文献 
第 部分自然语言处理篇
 自然语言处理简介
. NLP 的难点 
. NLP 的研究范围 
 词性标注
. 传统词性标注模型 
. 基于神经网络的词性标注模型 
. 基于Bi-LSTM 的神经网络词性标注模型 
参考文献 
 依存句法分析
. 背景 
. SyntaxNet 技术要点 
.. Transition-based 系统 
.. “模板化” 技术 
.. Beam Search 
参考文献 
 wordvec 
. 背景 
.. 词向量 
.. 统计语言模型 
.. 神经网络语言模型 
.. Log-linear 模型 
.. Log-bilinear 模型 
.. 层次化Log-bilinear 模型 
. CBOW 模型 
. Skip-gram 模型 
. Hierarchical Softmax 与Negative Sampling 
. fastText 
. GloVe 
. 小结 
参考文献 
 神经网络机器翻译
. 机器翻译简介 
. 神经网络机器翻译基本模型 
. 基于Attention 的神经网络机器翻译 
. 谷歌机器翻译系统GNMT 
. 基于卷积的机器翻译 
. 小结 
参考文献 
第 部分深度学习研究篇
 Batch Normalization 
. 前向与后向传播 
.. 前向传播 
.. 后向传播 
. 有效性分析 
.. 内部协移 
.. 梯度流 
. 使用与优化方法 
. 小结 
参考文献 
 Attention 
. 从简单RNN 到RNN + Attention 
. Soft Attention 与Hard Attention 
. Attention 的应用 
. 小结 
参考文献 
 多任务学习
. 背景 
. 什么是多任务学习 
. 多任务分类与其他分类概念的关系 
.. 二分类 
.. 多分类 
.. 多标签分类 
.. 相关关系 
. 多任务学习如何发挥作用 
.. 提高泛化能力的潜在原因 
.. 多任务学习机制 
.. 后向传播多任务学习如何发现任务是相关的 
. 多任务学习被广泛应用 
.. 使用未来预测现在 
.. 多种表示和度量 
.. 时间序列预测 
.. 使用不可操作特征 
.. 使用额外任务来聚焦 
.. 有序迁移 
.. 多个任务自然地出现 
.. 将输入变成输出 
. 多任务深度学习应用 
.. 脸部特征点检测 
.. DeepID 
.. Fast R-CNN 
.. 旋转人脸网络 
.. 实例感知语义分割的MNC 
. 小结 
参考文献 
 模型压缩
. 模型压缩的必要性 
. 较浅的网络 
. 剪枝 
. 参数共享 
. 紧凑网络 
. 二值网络 
. 小结 
参考文献 
 增强学习
. 什么是增强学习 
. 增强学习的数学表达形式 
.. MDP 
.. 策略函数 
.. 奖励与回报 
.. 价值函数 
.. 贝尔曼方程 
.. 最优策略性质 
. 用动态规划法求解增强学习问题 
.. Agent 的目标 
.. 策略评估 
.. 策略改进 
.. 策略迭代 
.. 策略迭代的例子 
.. 价值迭代 
.. 价值迭代的例子 
.. 策略函数和价值函数的关系 
. 无模型算法 
.. 蒙特卡罗法 
.. 时序差分法 
.. Q-Learning 
. Q-Learning 的例子 
. AlphaGo 原理剖析 
.. 围棋与机器博弈 
.. Alpha-Beta 树 
.. MCTS 
.. UCT 
.. AlphaGo 的训练策略 
.. AlphaGo 的招式搜索算法 
.. 围棋的对称性 
. AlphaGo Zero 
参考文献 
 GAN 
. 生成模型 
. 生成对抗模型的概念 
. GAN 实战 
. InfoGAN――探寻隐变量的内涵 
. Image-Image Translation 
. WGAN（Wasserstein GAN） 
.. GAN 目标函数的弱点 
.. Wasserstein 度量的优势 
.. WGAN 的目标函数 
参考文献 
A 本书涉及的开源资源列表 
・ ・ ・ ・ ・ ・ (收起) 深度学习简介
. 人工智能、机器学习和深度学习 
.. 引言 
.. 人工智能、机器学习和深度学习三者的关系 
. 神经网络 
.. 感知器 
.. 激活函数 
.. 损失函数 
.. 梯度下降和随机梯度下降 
.. 反向传播算法简述 
.. 其他神经网络 
. 学习方法建议 
.. 网络资源 
.. TensorFlow 官方深度学习教程 
.. 开源社区 
. TensorLayer 
.. 深度学习框架概况 
.. TensorLayer 概括 
.. 实验环境配置 
 多层感知器
. McCulloch-Pitts 神经元模型 
.. 人工神经网络到底能干什么？到底在干什么 
.. 什么是激活函数？什么是偏值 
. 感知器 
.. 什么是线性分类器 
.. 线性分类器有什么优缺点 
.. 感知器实例和异或问题（XOR 问题） 
. 多层感知器 
. 实现手写数字分类 
. 过拟合 
.. 什么是过拟合 
.. Dropout 
.. 批规范化 
.. L、L 和其他正则化方法 
.. Lp 正则化的图形化解释 
. 再实现手写数字分类 
.. 数据迭代器 
.. 通过all_drop 启动与关闭Dropout 
.. 通过参数共享实现训练测试切换 
 自编码器
. 稀疏性 
. 稀疏自编码器 
. 实现手写数字特征提取 
. 降噪自编码器 
. 再实现手写数字特征提取 
. 堆栈式自编码器及其实现 
 卷积神经网络
. 卷积原理 
.. 卷积操作 
.. 张量 
.. 卷积层 
.. 池化层 
.. 全连接层 
. 经典任务 
.. 图像分类 
.. 目标检测 
.. 语义分割 
.. 实例分割 
. 经典卷积网络 
.. LeNet 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. ResNet 
. 实现手写数字分类 
. 数据增强与规范化 
.. 数据增强 
.. 批规范化 
.. 局部响应归一化 
. 实现CIFAR 分类 
.. 方法：tl.prepro 做数据增强 
.. 方法：TFRecord 做数据增强 
. 反卷积神经网络 
 词的向量表达
. 目的与原理 
. WordVec 
.. 简介 
.. Continuous Bag-Of-Words（CBOW）模型 
.. Skip Gram（SG）模型 
.. Hierarchical Softmax 
.. Negative Sampling 
. 实现WordVec 
.. 简介 
.. 实现 
. 重载预训练矩阵 
 递归神经网络
. 为什么需要它 
. 不同的RNNs 
.. 简单递归网络 
.. 回音网络 
. 长短期记忆 
.. LSTM 概括 
.. LSTM 详解 
.. LSTM 变种 
. 实现生成句子 
.. 模型简介 
.. 数据迭代 
.. 损失函数和更新公式 
.. 生成句子及Top K 采样 
.. 接下来还可以做什么 
 深度增强学习
. 增强学习 
.. 概述 
.. 基于价值的增强学习 
.. 基于策略的增强学习 
.. 基于模型的增强学习 
. 深度增强学习 
.. 深度Q 学习 
.. 深度策略网络 
. 更多参考资料 
.. 书籍 
.. 在线课程 
 生成对抗网络
. 何为生成对抗网络 
. 深度卷积对抗生成网络 
. 实现人脸生成 
. 还能做什么 
 高级实现技巧
. 与其他框架对接 
.. 无参数层 
.. 有参数层 
. 自定义层 
.. 无参数层 
.. 有参数层 
. 建立词汇表 
. 补零与序列长度 
. 动态递归神经网络 
. 实用小技巧 
.. 屏蔽显示 
.. 参数名字前缀 
.. 获取特定参数 
.. 获取特定层输出 
 实例一：使用预训练卷积网络
. 高维特征表达 
. VGG 网络 
. 连接TF-Slim 
 实例二：图像语义分割及其医学图像应用
. 图像语义分割概述 
.. 传统图像分割算法简介 
.. 损失函数与评估指标 
. 医学图像分割概述 
. 全卷积神经网络和U-Net 网络结构 
. 医学图像应用：实现脑部肿瘤分割 
.. 数据与数据增强 
.. U-Net 网络 
.. 损失函数 
.. 开始训练 
 实例三：由文本生成图像
. 条件生成对抗网络之GAN-CLS 
. 实现句子生成花朵图片 
 实例四：超高分辨率复原
. 什么是超高分辨率复原 
. 网络结构 
. 联合损失函数 
. 训练网络 
. 使用测试 
 实例五：文本反垃圾
. 任务场景 
. 网络结构 
. 词的向量表示 
. Dynamic RNN 分类器 
. 训练网络 
.. 训练词向量 
.. 文本的表示 
.. 训练分类器 
.. 模型导出 
. TensorFlow Serving 部署 
. 客户端调用 
. 其他常用方法 
中英对照表及其缩写
参考文献
・ ・ ・ ・ ・ ・ (收起)目　　录
第　章 深度学习简介　
．　深度学习与人工智能　
．　深度学习的历史渊源　
．．　从感知机到人工神经网络　
．．　深度学习时代　
．．　巨头之间的角逐　
．　深度学习的影响因素　
．．　大数据　
．．　深度网络架构　
．．　GPU　
．　深度学习为什么如此成功　
．．　特征学习（representation learning）　
．．　迁移学习（transfer learning）　
．　小结　
参考文献　
第　章 PyTorch简介　
．　PyTorch安装　
．　初识PyTorch　
．．　与Python的完美融合　
．．　张量计算　
．．　动态计算图　
．　PyTorch实例：预测房价　
．．　准备数据　
．．　模型设计　
．．　训练　
．．　预测　
．．　术语汇总　
．　小结　
第章　单车预测器：你的第 一个
神经网络　
．　共享单车的烦恼　
．　单车预测器．　
．．　神经网络简介　
．．　人工神经元　
．．　两个隐含层神经元　
．．　训练与运行　
．．　失败的神经预测器　
．．　过拟合　
．　单车预测器．　
．．　数据的预处理过程　
．．　构建神经网络　
．．　测试神经网络　
．　剖析神经网络Neu　
．　小结　
．　Q&A　
第章　机器也懂感情――中文情绪
分类器　
．　神经网络分类器　
．．　如何用神经网络做分类　
．．　分类问题的损失函数　
．　词袋模型分类器　
．．　词袋模型简介　
．．　搭建简单文本分类器　
．　程序实现　
．．　数据获取　
．．　数据处理　
．．　文本数据向量化　
．．　划分数据集　
．．　建立神经网络　
．　运行结果　
．　剖析神经网络　
．　小结　
．　Q&A　
第章　手写数字识别器――认识卷积
神经网络　
．　什么是卷积神经网络　
．．　手写数字识别任务的CNN
网络及运算过程　
．．　卷积运算操作　
．．　池化操作　
．．　立体卷积核　
．．　超参数与参数　
．．　其他说明　
．　手写数字识别器　
．．　数据准备　
．．　构建网络　
．．　运行模型　
．．　测试模型　
．　剖析卷积神经网络　
．．　第 一层卷积核与特征图　
．．　第二层卷积核与特征图　
．．　卷积神经网络的健壮性试验　
．　小结　
．　Q&A　
．　扩展阅读　
第章　手写数字加法机――迁移学习　
．　什么是迁移学习　
．．　迁移学习的由来　
．．　迁移学习的分类　
．．　迁移学习的意义　
．．　如何用神经网络实现迁移
学习　
．　应用案例：迁移学习如何抗击贫困　
．．　背景介绍　
．．　方法探寻　
．．　迁移学习方法　
．　蚂蚁还是蜜蜂：迁移大型卷积神经
网络　
．．　任务描述与初步尝试　
．．　ResNet与模型迁移　
．．　代码实现　
．．　结果分析　
．．　更多的模型与数据　
．　手写数字加法机　
．．　网络架构　
．．　代码实现　
．．　训练与测试　
．．　结果　
．．　大规模实验　
．　小结　
．　实践项目：迁移与效率　
第章　你自己的Prisma――图像
风格迁移　
．　什么是风格迁移　
．．　什么是风格　
．．　风格迁移的涵义　
．　风格迁移技术发展简史　
．．　神经网络之前的风格迁移　
．．　特定风格的实现　
．　神经网络风格迁移　
．．　神经网络风格迁移的优势　
．．　神经网络风格迁移的基本
思想　
．．　卷积神经网络的选取　
．．　内容损失　
．．　风格损失　
．．　风格损失原理分析　
．．　损失函数与优化　
．　神经网络风格迁移实战　
．．　准备工作　
．．　建立风格迁移网络　
．．　风格迁移训练　
．　小结　
．　扩展阅读　
第章　人工智能造假术――图像生成
与对抗学习　
．　反卷积与图像生成　
．．　CNN回顾　
．．　反卷积操作　
．．　反池化过程　
．．　反卷积与分数步伐　
．．　输出图像尺寸公式　
．．　批正则化技术　
．　图像生成实验――最小均方误差
模型　
．．　模型思路　
．．　代码实现　
．．　运行结果　
．　图像生成实验――生成器-识别器
模型　
．．　生成器-识别器模型的实现　
．．　对抗样本　
．　图像生成实验――生成对抗网络
GAN　
．．　GAN的总体架构　
．．　程序实现　
．．　结果展示　
．　小结　
．　Q&A　
．　扩展阅读　
第章　词汇的星空――神经语言模型
与WordVec　
．　词向量技术介绍　
．．　初识词向量　
．．　传统编码方式　
．　NPLM：神经概率语言模型　
．．　NPLM的基本思想　
．．　NPLM的运作过程详解　
．．　读取NPLM中的词向量　
．．　NPLM的编码实现　
．．　运行结果　
．．　NPLM的总结与局限　
．　WordVec　
．．　CBOW模型和Skip-gram模型的结构　
．．　层级软最大　
．．　负采样　
．．　总结及分析　
．　WordVec的应用　
．．　在自己的语料库上训练WordVec词向量　
．．　调用现成的词向量　
．．　女人-男人＝皇后-国王　
．．　使用向量的空间位置进行词对词翻译　
．．　WordVec小结　
．　小结　
．　Q&A　
第　章 LSTM作曲机――序列生成
模型　
．　序列生成问题　
．　RNN与LSTM　
．．　RNN　
．．　LSTM　
．　简单序列的学习问题　
．．　RNN的序列学习　
．．　LSTM的序列学习　
．　LSTM作曲机　
．．　MIDI文件　
．．　数据准备　
．．　模型结构　
．．　代码实现　
．　小结　
．　Q&A　
．　扩展阅读　
・ ・ ・ ・ ・ ・ (收起)第章　编程和数学基础 
.　Python快速入门 
..　快速安装Python 
..　Python基础 
..　Python中的常见运算 
..　Python控制语句 
..　Python常用容器类型 
..　Python常用函数 
..　类和对象 
..　Matplotlib入门 
.　张量库NumPy 
..　什么是张量 
..　创建ndarray对象 
..　ndarray数组的索引和切片 
..　张量的计算 
.　微积分 
..　函数 
..　四则运算和复合运算 
..　极限和导数 
..　导数的四则运算和链式法则 
..　计算图、正向计算和反向传播求导 
..　多变量函数的偏导数与梯度 
..　向量值函数的导数与Jacobian矩阵 
..　积分 
.　概率基础 
..　概率 
..　条件概率、联合概率、全概率公式、贝叶斯公式 
..　随机变量 
..　离散型随机变量的概率分布 
..　连续型随机变量的概率密度 
..　随机变量的分布函数 
..　期望、方差、协方差、协变矩阵 
第章　梯度下降法 
.　函数极值的必要条件 
.　梯度下降法基础 
.　梯度下降法的参数优化策略 
..　Momentum法 
..　AdaGrad法 
..　AdaDelta法 
..　RMSprop法 
..　Adam法 
.　梯度验证 
..　比较数值梯度和分析梯度 
..　通用的数值梯度 
.　分离梯度下降法与参数优化策略 
..　参数优化器 
..　接受参数优化器的梯度下降法 
第章　线性回归、逻辑回归和softmax回归 
.　线性回归 
..　餐车利润问题 
..　机器学习与人工智能 
..　什么是线性回归 
..　用正规方程法求解线性回归问题 
..　用梯度下降法求解线性回归问题 
..　调试学习率 
..　梯度验证 
..　预测 
..　多特征线性回归 
.　数据的规范化 
..　预测大坝出水量 
..　数据的规范化过程 
.　模型的评估 
..　欠拟合和过拟合 
..　验证集和测试集 
..　学习曲线 
..　偏差和方差 
.　正则化 
.　逻辑回归 
..　逻辑回归基础 
..　逻辑回归的NumPy实现 
..　实战：鸢尾花分类的NumPy实现 
.　softmax回归 
..　spiral数据集 
..　softmax函数 
..　softmax回归模型 
..　多分类交叉熵损失 
..　通过加权和计算交叉熵损失 
..　softmax回归的梯度计算 
..　softmax回归的梯度下降法的实现 
..　spiral数据集的softmax回归模型 
.　批梯度下降法和随机梯度下降法 
..　MNIST手写数字集 
..　用部分训练样本训练逻辑回归模型 
..　批梯度下降法 
..　随机梯度下降法 
第章　神经网络 
.　神经网络概述 
..　感知机和神经元 
..　激活函数 
..　神经网络与深度学习 
..　多个样本的正向计算 
..　输出 
..　损失函数 
..　基于数值梯度的神经网络训练 
.　反向求导 
..　正向计算和反向求导 
..　计算图 
..　损失函数关于输出的梯度 
..　层神经网络的反向求导 
..　层神经网络的Python实现 
..　任意层神经网络的反向求导 
.　实现一个简单的深度学习框架 
..　神经网络的训练过程 
..　网络层的代码实现 
..　网络层的梯度检验 
..　神经网络的类 
..　神经网络的梯度检验 
..　基于深度学习框架的MNIST手写数字识别 
..　改进的通用神经网络框架：分离加权和与激活函数 
..　独立的参数优化器 
..　fashion-mnist的分类训练 
..　读写模型参数 
第章　改进神经网络性能的基本技巧 
.　数据处理 
..　数据增强 
..　规范化 
..　特征工程 
.　参数调试 
..　权重初始化 
..　优化参数 
.　批规范化 
..　什么是批规范化 
..　批规范化的反向求导 
..　批规范化的代码实现 
.　正则化 
..　权重正则化 
..　Dropout 
..　早停法 
.　梯度爆炸和梯度消失 
第章　卷积神经网络 
.　卷积入门 
..　什么是卷积 
..　一维卷积 
..　二维卷积 
..　多通道输入和多通道输出 
..　池化 
.　卷积神经网络概述 
..　全连接神经元和卷积神经元 
..　卷积层和卷积神经网络 
..　卷积层和池化层的反向求导及代码实现 
..　卷积神经网络的代码实现 
.　卷积的矩阵乘法 
..　一维卷积的矩阵乘法 
..　二维卷积的矩阵乘法 
..　一维卷积反向求导的矩阵乘法 
..　二维卷积反向求导的矩阵乘法 
.　基于坐标索引的快速卷积 
.　典型卷积神经网络结构 
..　LeNet- 
..　AlexNet 
..　VGG 
..　残差网络 
..　Inception网络 
..　NiN 
第章　循环神经网络 
.　序列问题和模型 
..　股票价格预测问题 
..　概率序列模型和语言模型 
..　自回归模型 
..　生成自回归数据 
..　时间窗方法 
..　时间窗采样 
..　时间窗方法的建模和训练 
..　长期预测和短期预测 
..　股票价格预测的代码实现 
..　k-gram语言模型 
.　循环神经网络基础 
..　无记忆功能的非循环神经网络 
..　具有记忆功能的循环神经网络 
.　穿过时间的反向传播 
.　单层循环神经网络的实现 
..　初始化模型参数 
..　正向计算 
..　损失函数 
..　反向求导 
..　梯度验证 
..　梯度下降训练 
..　序列数据的采样 
..　序列数据的循环神经网络训练和预测 
.　循环神经网络语言模型和文本的生成 
..　字符表 
..　字符序列样本的采样 
..　模型的训练和预测 
.　循环神经网络中的梯度爆炸和梯度消失 
.　长短期记忆网络 
..　LSTM的神经元 
..　LSTM的反向求导 
..　LSTM的代码实现 
..　LSTM的变种 
.　门控循环单元 
..　门控循环单元的工作原理 
..　门控循环单元的代码实现 
.　循环神经网络的类及其实现 
..　用类实现循环神经网络 
..　循环神经网络单元的类实现 
.　多层循环神经网络和双向循环神经网络 
..　多层循环神经网络 
..　多层循环神经网络的训练和预测 
..　双向循环神经网络 
.　SeqSeq模型 
..　机器翻译概述 
..　SeqSeq模型的实现 
..　字符级的SeqSeq模型 
..　基于WordVec的SeqSeq模型 
..　基于词嵌入层的SeqSeq模型 
..　注意力机制 
第章　生成模型 
.　生成模型概述 
.　自动编码器 
..　什么是自动编码器 
..　稀疏编码器 
..　自动编码器的代码实现 
.　变分自动编码器 
..　什么是变分自动编码器 
..　变分自动编码器的损失函数 
..　变分自动编码器的参数重采样 
..　变分自动编码器的反向求导 
..　变分自动编码器的代码实现 
.　生成对抗网络 
..　生成对抗网络的原理 
..　生成对抗网络训练过程的代码实现 
.　生成对抗网络建模实例 
..　一组实数的生成对抗网络建模 
..　二维坐标点的生成对抗网络建模 
..　MNIST手写数字集的生成对抗网络建模 
..　生成对抗网络的训练技巧 
.　生成对抗网络的损失函数及其概率解释 
..　生成对抗网络的损失函数的全局最优解 
..　Kullback-Leibler散度和Jensen-Shannon散度 
..　生成对抗网络的最大似然解释 
.　改进的损失函数――Wasserstein GAN 
..　Wasserstein GAN的原理 
..　Wasserstein GAN的代码实现 
.　深度卷积对抗网络 
..　一维转置卷积 
..　二维转置卷积 
..　卷积对抗网络的代码实现 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第一部分　元编程基础技术
第章 基本技巧　
.　元函数与type_traits　
..　元函数介绍　
..　类型元函数　
..　各式各样的元函数　
..　type_traits　
..　元函数与宏　
..　本书中元函数的命名方式　
.　模板型模板参数与容器模板　
..　模板作为元函数的输入　
..　模板作为元函数的输出　
..　容器模板　
.　顺序、分支与循环代码的编写　
..　顺序执行的代码　
..　分支执行的代码　
..　循环执行的代码　
..　小心：实例化爆炸与编译崩溃　
..　分支选择与短路逻辑　
.　奇特的递归模板式　
.　小结　
.　练习　
第章 异类词典与policy模板　
.　具名参数简介　
.　异类词典　
..　模块的使用方式　
..　键的表示　
..　异类词典的实现　
..　VarTypeDict的性能简析　
..　用std::tuple作为缓存　
.　policy模板　
..　policy介绍　
..　定义policy与policy对象（模板）　
..　使用policy　
..　背景知识：支配与虚继承　
..　policy对象与policy支配结构　
..　policy选择元函数　
..　使用宏简化policy对象的声明　
.　小结　
.　练习　
第二部分 深度学习框架
第章　深度学习概述　
.　深度学习简介　
..　从机器学习到深度学习　
..　各式各样的人工神经网络　
..　深度学习系统的组织与训练　
.　本书所实现的框架：MetaNN　
..　从矩阵计算工具到深度学习框架　
..　MetaNN介绍　
..　本书将要讨论的内容　
..　本书不会涉及的主题　
.　小结　
第章　类型体系与基本数据类型　
.　类型体系　
..　类型体系介绍　
..　迭代器分类体系　
..　将标签作为模板参数　
..　MetaNN的类型体系　
..　与类型体系相关的元函数　
.　设计理念　
..　支持不同的计算设备与计算单元　
..　存储空间的分配与维护　
..　浅拷贝与写操作检测　
..　底层接口扩展　
..　类型转换与求值　
..　数据接口规范　
.　标量　
..　类模板的声明　
..　基于CPU的特化版本　
..　标量的主体类型　
.　矩阵　
..　Matrix类模板　
..　特殊矩阵：平凡矩阵、全零矩阵与独热向量　
..　引入新的矩阵类　
.　列表　
..　Batch模板　
..　Array模板　
..　重复与Duplicate模板　
.　小结　
.　练习　
第章　运算与表达式模板　
.　表达式模板简介　
.　MetaNN运算模板的设计思想　
..　Add模板的问题　
..　运算模板的行为分析　
.　运算分类　
.　辅助模板　
..　辅助类模板OperElementType_/OperDeviceType_　
..　辅助类模板OperXXX_　
..　辅助类模板OperCateCal　
..　辅助类模板OperOrganizer　
..　辅助类模板OperSeq　
.　运算模板的框架　
..　运算模板的类别标签　
..　UnaryOp的定义　
.　运算实现示例　
..　Sigmoid运算　
..　Add运算　
..　转置运算　
..　折叠运算　
.　MetaNN已支持的运算列表　
..　一元运算　
..　二元运算　
..　三元运算　
.　运算的折衷与局限性　
..　运算的折衷　
..　运算的局限性　
.　小结　
.　练习　
第章　基本层　
.　层的设计理念　
..　层的介绍　
..　层对象的构造　
..　参数矩阵的初始化与加载　
..　正向传播　
..　存储中间结果　
..　反向传播　
..　参数矩阵的更新　
..　参数矩阵的获取　
..　层的中性检测　
.　层的辅助逻辑　
..　初始化模块　
..　DynamicData类模板　
..　层的常用policy对象　
..　InjectPolicy元函数　
..　通用I/O结构　
..　通用操作函数　
.　层的具体实现　
..　AddLayer　
..　ElementMulLayer　
..　BiasLayer　
.　MetaNN已实现的基本层　
.　小结　
.　练习　
第章　复合层与循环层　
.　复合层的接口与设计理念　
..　基本结构　
..　结构描述语法　
..　policy的继承关系　
..　policy的修正　
..　复合层的构造函数　
..　一个完整的复合层构造示例　
.　policy继承与修正逻辑的实现　
..　policy继承逻辑的实现　
..　policy修正逻辑的实现　
.　ComposeTopology的实现　
..　功能介绍　
..　拓扑排序算法介绍　
..　ComposeTopology包含的主要步骤　
..　结构描述子句与其划分　
..　结构合法性检查　
..　拓扑排序的实现　
..　子层实例化元函数　
.　ComposeKernel的实现　
..　类模板的声明　
..　子层对象管理　
..　参数获取、梯度收集与中性检测　
..　参数初始化与加载　
..　正向传播　
..　反向传播　
.　复合层实现示例　
.　循环层　
..　GruStep　
..　构建RecurrentLayer类模板　
..　RecurrentLayer的使用　
.　小结　
.　练习　
第章　求值与优化　
.　MetaNN的求值模型　
..　运算的层次结构　
..　求值子系统的模块划分　
.　基本求值逻辑　
..　主体类型的求值接口　
..　非主体基本数据类型的求值　
..　运算模板的求值　
..　DyanmicData与求值　
.　求值过程的优化　
..　避免重复计算　
..　同类计算合并　
..　多运算协同优化　
.　小结　
.　练习　
后记―方家休见笑，吾道本艰难　
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
序
前言
第章　打造深度学习工具箱
.　TensorFlow
..　安装
..　使用举例
.　TFLearn
.　PaddlePaddle
..　安装
..　使用举例
.　Karas
.　本章小结
第章　卷积神经网络
.　传统的图像分类算法
.　基于CNN的图像分类算法
..　局部连接
..　参数共享
..　池化
..　典型的CNN结构及实现
..　AlexNet的结构及实现
..　VGG的结构及实现
.　基于CNN的文本处理
..　典型的CNN结构
..　典型的CNN代码实现
.　本章小结
第章　循环神经网络
.　循环神经算法概述
.　单向循环神经网络结构与实现
.　双向循环神经网络结构与实现
.　循环神经网络在序列分类的应用
.　循环神经网络在序列生成的应用
.　循环神经网络在序列标记的应用
.　循环神经网络在序列翻译的应用
.　本章小结
第章　基于OpenSOC的机器学习框架
.　OpenSOC框架
.　数据源系统
.　数据收集层
.　消息系统层
.　实时处理层
.　存储层
..　HDFS
..　HBase
..　Elasticsearch
.　分析处理层
.　计算系统
.　实战演练
.　本章小结
第章　验证码识别
.　数据集
.　特征提取
.　模型训练与验证
..　K近邻算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　垃圾邮件识别
.　数据集
.　特征提取
..　词袋模型
..　TF-IDF模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
..　深度学习算法之RNN
.　本章小结
第章　负面评论识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　骚扰短信识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之MLP
.　本章小结
第章　Linux后门检测
.　数据集
.　特征提取
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　用户行为分析与恶意行为检测
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词袋和N-Gram模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　隐式马尔可夫算法
..　深度学习算法之MLP
.　本章小结
第章　WebShell检测
.　数据集
..　WordPress
..　PHPCMS
..　phpMyAdmin
..　Smarty
..　Yii
.　特征提取
..　词袋和TF-IDF模型
..　opcode和N-Gram模型
..　opcode调用序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　智能扫描器
.　自动生成XSS攻击载荷
..　数据集
..　特征提取
..　模型训练与验证
.　自动识别登录界面
..　数据集
..　特征提取
..　模型训练与验证
.　本章小结
第章　DGA域名识别
.　数据集
.　特征提取
..　N-Gram模型
..　统计特征模型
..　字符序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
..　深度学习算法之RNN
.　本章小结
第章　恶意程序分类识别
.　数据集
.　特征提取
.　模型训练与验证
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　反信用卡欺诈
.　数据集
.　特征提取
..　标准化
..　标准化和降采样
..　标准化和过采样
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
・ ・ ・ ・ ・ ・ (收起)第章 数据科学概述 
.　挑战　
..　工程实现的挑战　
..　模型搭建的挑战　
.　机器学习　
..　机器学习与传统编程　
..　监督式学习和非监督式学习　
.　统计模型　
.　关于本书　
第章 Python安装指南与简介：告别空谈　
.　Python简介　
..　什么是Python　
..　Python在数据科学中的地位　
..　不可能绕过的第三方库　
.　Python安装　
..　Windows下的安装　
..　Mac下的安装　
..　Linux下的安装　
.　Python上手实践　
..　Python shell　
..　第 一个Python程序：Word Count　
..　Python编程基础　
..　Python的工程结构　
.　本章小结　
第章　数学基础：恼人但又不可或缺的知识　
.　矩阵和向量空间　
..　标量、向量与矩阵　
..　特殊矩阵　
..　矩阵运算　
..　代码实现　
..　向量空间　
.　概率：量化随机　
..　定义概率：事件和概率空间　
..　条件概率：信息的价值　
..　随机变量：两种不同的随机　
..　正态分布：殊途同归　
..　P-value：自信的猜测　
.　微积分　
..　导数和积分：位置、速度　
..　极限：变化的终点　
..　复合函数：链式法则　
..　多元函数：偏导数　
..　极值与最值：最优选择　
.　本章小结　
第章　线性回归：模型之母　
.　一个简单的例子　
..　从机器学习的角度看这个问题　
..　从统计学的角度看这个问题　
.　上手实践：模型实现　
..　机器学习代码实现　
..　统计方法代码实现　
.　模型陷阱　
..　过度拟合：模型越复杂越好吗　
..　模型幻觉之统计学方案：假设检验　
..　模型幻觉之机器学习方案：惩罚项　
..　比较两种方案　
.　模型持久化　
..　模型的生命周期　
..　保存模型　
.　本章小结　
第章　逻辑回归：隐藏因子　
.　二元分类问题：是与否　
..　线性回归：为何失效　
..　窗口效应：看不见的才是关键　
..　逻辑分布：胜者生存　
..　参数估计之似然函数：统计学角度　
..　参数估计之损失函数：机器学习角度　
..　参数估计之最终预测：从概率到选择　
..　空间变换：非线性到线性　
.　上手实践：模型实现　
..　初步分析数据：直观印象　
..　搭建模型　
..　理解模型结果　
.　评估模型效果：孰优孰劣　
..　查准率与查全率　
..　ROC曲线与AUC　
.　多元分类问题：超越是与否　
..　多元逻辑回归：逻辑分布的威力　
..　One-vs.-all：从二元到多元　
..　模型实现　
.　非均衡数据集　
..　准确度悖论　
..　一个例子　
..　解决方法　
.　本章小结　
第章　工程实现：计算机是怎么算的　
.　算法思路：模拟滚动　
.　数值求解：梯度下降法　
.　上手实践：代码实现　
..　TensorFlow基础　
..　定义模型　
..　梯度下降　
..　分析运行细节　
.　更优化的算法：随机梯度下降法　
..　算法细节　
..　代码实现　
..　两种算法比较　
.　本章小结　
第章　计量经济学的启示：他山之石　
.　定量与定性：变量的数学运算合理吗　
.　定性变量的处理　
..　虚拟变量　
..　上手实践：代码实现　
..　从定性变量到定量变量　
.　定量变量的处理　
..　定量变量转换为定性变量　
..　上手实践：代码实现　
..　基于卡方检验的方法　
.　显著性　
.　多重共线性：多变量的烦恼　
..　多重共线性效应　
..　检测多重共线性　
..　解决方法　
..　虚拟变量陷阱　
.　内生性：变化来自何处　
..　来源　
..　内生性效应　
..　工具变量　
..　逻辑回归的内生性　
..　模型的联结　
.　本章小结　
第章　监督式学习： 目标明确　
.　支持向量学习机　
..　直观例子　
..　用数学理解直观　
..　从几何直观到最优化问题　
..　损失项　
..　损失函数与惩罚项　
..　Hard margin 与soft margin比较　
..　支持向量学习机与逻辑回归：隐藏的假设　
.　核函数　
..　空间变换：从非线性到线性　
..　拉格朗日对偶　
..　支持向量　
..　核函数的定义：优化运算　
..　常用的核函数　
..　Scale variant　
.　决策树　
..　决策规则　
..　评判标准　
..　代码实现　
..　决策树预测算法以及模型的联结　
..　剪枝　
.　树的集成　
..　随机森林　
..　Random forest embedding　
..　GBTs之梯度提升　
..　GBTs之算法细节　
.　本章小结　
第章　生成式模型：量化信息的价值　
.　贝叶斯框架　
..　蒙提霍尔问题　
..　条件概率　
..　先验概率与后验概率　
..　参数估计与预测公式　
..　贝叶斯学派与频率学派　
.　朴素贝叶斯　
..　特征提取：文字到数字　
..　伯努利模型　
..　多项式模型　
..　TF-IDF　
..　文本分类的代码实现　
..　模型的联结　
.　判别分析　
..　线性判别分析　
..　线性判别分析与逻辑回归比较　
..　数据降维　
..　代码实现　
..　二次判别分析　
.　隐马尔可夫模型　
..　一个简单的例子　
..　马尔可夫链　
..　模型架构　
..　中文分词：监督式学习　
..　中文分词之代码实现　
..　股票市场：非监督式学习　
..　股票市场之代码实现　
.　本章小结　
第章 非监督式学习：聚类与降维　
.　K-means　
..　模型原理　
..　收敛过程　
..　如何选择聚类个数　
..　应用示例　
.　其他聚类模型　
..　混合高斯之模型原理　
..　混合高斯之模型实现　
..　谱聚类之聚类结果　
..　谱聚类之模型原理　
..　谱聚类之图片分割　
.　Pipeline　
.　主成分分析　
..　模型原理　
..　模型实现　
..　核函数　
..　Kernel PCA的数学原理　
..　应用示例　
.　奇异值分解　
..　定义　
..　截断奇异值分解　
..　潜在语义分析　
..　大型推荐系统　
.　本章小结　
第章 分布式机器学习：集体力量　
.　Spark简介　
..　Spark安装　
..　从MapReduce到Spark　
..　运行Spark　
..　Spark DataFrame　
..　Spark的运行架构　
.　最优化问题的分布式解法　
..　分布式机器学习的原理　
..　一个简单的例子　
.　大数据模型的两个维度　
..　数据量维度　
..　模型数量维度　
.　开源工具的另一面　
..　一个简单的例子　
..　开源工具的阿喀琉斯之踵　
.　本章小结　
第章 神经网络：模拟人的大脑　
.　神经元　
..　神经元模型　
..　Sigmoid神经元与二元逻辑回归　
..　Softmax函数与多元逻辑回归　
.　神经网络　
..　图形表示　
..　数学基础　
..　分类例子　
..　代码实现　
..　模型的联结　
.　反向传播算法　
..　随机梯度下降法回顾　
..　数学推导　
..　算法步骤　
.　提高神经网络的学习效率　
..　学习的原理　
..　激活函数的改进　
..　参数初始化　
..　不稳定的梯度　
.　本章小结　
第章 深度学习：继续探索　
.　利用神经网络识别数字　
..　搭建模型　
..　防止过拟合之惩罚项　
..　防止过拟合之dropout　
..　代码实现　
.　卷积神经网络　
..　模型结构之卷积层　
..　模型结构之池化层　
..　模型结构之完整结构　
..　代码实现　
..　结构真的那么重要吗　
.　其他深度学习模型　
..　递归神经网络　
..　长短期记忆　
..　非监督式学习　
.　本章小结　
・ ・ ・ ・ ・ ・ (收起)基础篇
第章 深度学习概述 
. 深度学习发展简史 
. 有监督学习 
.. 图像分类 
.. 目标检测 
.. 人脸识别 
.. 语音识别 
. 无监督学习 
.. 无监督学习概述 
.. 生成对抗网络 
. 强化学习 
.. AlphaGo 
.. AlphaGo Zero 
. 小结 
参考文献 
第章 深度神经网络 
. 神经元 
. 感知机 
. 前向传递 
.. 前向传递的流程 
.. 激活函数 
.. 损失函数 
. 后向传递 
.. 后向传递的流程 
.. 梯度下降 
.. 参数修正 
. 防止过拟合 
.. dropout 
.. 正则化 
. 小结 
第章 卷积神经网络 
. 卷积层 
.. valid 卷积 
.. full 卷积 
.. same 卷积 
. 池化层 
. 反卷积 
. 感受野 
. 卷积网络实例 
.. Lenet- 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. ResNet 
.. MobileNet 
. 小结 
进阶篇
第章 两阶段目标检测方法 
. R-CNN 
.. 算法流程 
.. 训练过程 
. SPP-Net 
.. 网络结构 
.. 空间金字塔池化 
. Fast R-CNN 
.. 感兴趣区域池化层 
.. 网络结构 
.. 全连接层计算加速 
.. 目标分类 
.. 边界框回归 
.. 训练过程 
. Faster R-CNN 
.. 网络结构 
.. RPN 
.. 训练过程 
. R-FCN 
.. R-FCN 网络结构 
.. 位置敏感的分数图 
.. 位置敏感的RoI 池化 
.. R-FCN 损失函数 
.. Caffe 网络模型解析 
. Mask R-CNN 
.. 实例分割简介 
.. COCO 数据集的像素级标注 
.. 网络结构 
.. U-Net 
.. SegNet 
. 小结 
第章 单阶段目标检测方法 
. SSD 
.. default box 
.. 网络结构 
.. Caffe 网络模型解析 
.. 训练过程 
. RetinaNet 
.. FPN 
.. 聚焦损失函数 
. RefineDet 
.. 网络模型 
.. Caffe 网络模型解析 
.. 训练过程 
. YOLO 
.. YOLO v 
.. YOLO v 
.. YOLO v 
. 目标检测算法应用 
.. 高速公路坑洞检测 
.. 息肉检测 
. 小结 
应用篇
第章 肋骨骨折检测 
. 国内外研究现状 
. 解决方案 
. 预处理 
. 肋骨骨折检测 
. 实验结果分析 
. 小结 
参考文献 
第章 肺结节检测 
. 国内外研究现状 
.. 肺结节可疑位置推荐算法 
.. 假阳性肺结节抑制算法 
. 总体框架 
.. 肺结节数据集 
.. 肺结节检测难点 
.. 算法框架 
. 肺结节可疑位置推荐算法 
.. CT图像的预处理 
.. 肺结节分割算法 
.. 优化方法 
.. 推断方法 
. 可疑肺结节定位算法 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
. 假阳性肺结节抑制算法 
.. 假阳性肺结节抑制网络 
.. 优化策略 
.. 推断策略 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
.. 可疑位置推荐与假阳抑制算法整合 
. 小结 
参考文献 
第章 车道线检测 
. 国内外研究现状 
. 主要研究内容 
.. 总体解决方案 
.. 各阶段概述 
. 车道线检测系统的设计与实现 
.. 车道线图像数据标注与筛选 
.. 车道线图片预处理 
.. 车道线分割模型训练 
.. 车道线检测 
.. 车道线检测结果 
. 车道线检测系统的性能测试 
.. 车道线检测质量测试 
.. 车道线检测时间测试 
. 小结 
参考文献 
第章 交通视频分析 
. 国内外研究现状 
. 主要研究内容 
.. 总体设计 
.. 精度和性能要求 
. 交通视频分析 
.. 车辆检测和车牌检测 
.. 车牌识别功能设计详解 
.. 车辆品牌及颜色的识别 
.. 目标跟踪设计详解 
. 系统测试 
.. 车辆检测 
.. 车牌检测 
.. 车牌识别 
.. 车辆品牌识别 
.. 目标跟踪 
. 小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
序
前言
第章　打造深度学习工具箱
.　TensorFlow
..　安装
..　使用举例
.　TFLearn
.　PaddlePaddle
..　安装
..　使用举例
.　Karas
.　本章小结
第章　卷积神经网络
.　传统的图像分类算法
.　基于CNN的图像分类算法
..　局部连接
..　参数共享
..　池化
..　典型的CNN结构及实现
..　AlexNet的结构及实现
..　VGG的结构及实现
.　基于CNN的文本处理
..　典型的CNN结构
..　典型的CNN代码实现
.　本章小结
第章　循环神经网络
.　循环神经算法概述
.　单向循环神经网络结构与实现
.　双向循环神经网络结构与实现
.　循环神经网络在序列分类的应用
.　循环神经网络在序列生成的应用
.　循环神经网络在序列标记的应用
.　循环神经网络在序列翻译的应用
.　本章小结
第章　基于OpenSOC的机器学习框架
.　OpenSOC框架
.　数据源系统
.　数据收集层
.　消息系统层
.　实时处理层
.　存储层
..　HDFS
..　HBase
..　Elasticsearch
.　分析处理层
.　计算系统
.　实战演练
.　本章小结
第章　验证码识别
.　数据集
.　特征提取
.　模型训练与验证
..　K近邻算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　垃圾邮件识别
.　数据集
.　特征提取
..　词袋模型
..　TF-IDF模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
..　深度学习算法之RNN
.　本章小结
第章　负面评论识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　骚扰短信识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之MLP
.　本章小结
第章　Linux后门检测
.　数据集
.　特征提取
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　用户行为分析与恶意行为检测
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词袋和N-Gram模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　隐式马尔可夫算法
..　深度学习算法之MLP
.　本章小结
第章　WebShell检测
.　数据集
..　WordPress
..　PHPCMS
..　phpMyAdmin
..　Smarty
..　Yii
.　特征提取
..　词袋和TF-IDF模型
..　opcode和N-Gram模型
..　opcode调用序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　智能扫描器
.　自动生成XSS攻击载荷
..　数据集
..　特征提取
..　模型训练与验证
.　自动识别登录界面
..　数据集
..　特征提取
..　模型训练与验证
.　本章小结
第章　DGA域名识别
.　数据集
.　特征提取
..　N-Gram模型
..　统计特征模型
..　字符序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
..　深度学习算法之RNN
.　本章小结
第章　恶意程序分类识别
.　数据集
.　特征提取
.　模型训练与验证
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　反信用卡欺诈
.　数据集
.　特征提取
..　标准化
..　标准化和降采样
..　标准化和过采样
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
・ ・ ・ ・ ・ ・ (收起)第章　编程和数学基础 
.　Python快速入门 
..　快速安装Python 
..　Python基础 
..　Python中的常见运算 
..　Python控制语句 
..　Python常用容器类型 
..　Python常用函数 
..　类和对象 
..　Matplotlib入门 
.　张量库NumPy 
..　什么是张量 
..　创建ndarray对象 
..　ndarray数组的索引和切片 
..　张量的计算 
.　微积分 
..　函数 
..　四则运算和复合运算 
..　极限和导数 
..　导数的四则运算和链式法则 
..　计算图、正向计算和反向传播求导 
..　多变量函数的偏导数与梯度 
..　向量值函数的导数与Jacobian矩阵 
..　积分 
.　概率基础 
..　概率 
..　条件概率、联合概率、全概率公式、贝叶斯公式 
..　随机变量 
..　离散型随机变量的概率分布 
..　连续型随机变量的概率密度 
..　随机变量的分布函数 
..　期望、方差、协方差、协变矩阵 
第章　梯度下降法 
.　函数极值的必要条件 
.　梯度下降法基础 
.　梯度下降法的参数优化策略 
..　Momentum法 
..　AdaGrad法 
..　AdaDelta法 
..　RMSprop法 
..　Adam法 
.　梯度验证 
..　比较数值梯度和分析梯度 
..　通用的数值梯度 
.　分离梯度下降法与参数优化策略 
..　参数优化器 
..　接受参数优化器的梯度下降法 
第章　线性回归、逻辑回归和softmax回归 
.　线性回归 
..　餐车利润问题 
..　机器学习与人工智能 
..　什么是线性回归 
..　用正规方程法求解线性回归问题 
..　用梯度下降法求解线性回归问题 
..　调试学习率 
..　梯度验证 
..　预测 
..　多特征线性回归 
.　数据的规范化 
..　预测大坝出水量 
..　数据的规范化过程 
.　模型的评估 
..　欠拟合和过拟合 
..　验证集和测试集 
..　学习曲线 
..　偏差和方差 
.　正则化 
.　逻辑回归 
..　逻辑回归基础 
..　逻辑回归的NumPy实现 
..　实战：鸢尾花分类的NumPy实现 
.　softmax回归 
..　spiral数据集 
..　softmax函数 
..　softmax回归模型 
..　多分类交叉熵损失 
..　通过加权和计算交叉熵损失 
..　softmax回归的梯度计算 
..　softmax回归的梯度下降法的实现 
..　spiral数据集的softmax回归模型 
.　批梯度下降法和随机梯度下降法 
..　MNIST手写数字集 
..　用部分训练样本训练逻辑回归模型 
..　批梯度下降法 
..　随机梯度下降法 
第章　神经网络 
.　神经网络概述 
..　感知机和神经元 
..　激活函数 
..　神经网络与深度学习 
..　多个样本的正向计算 
..　输出 
..　损失函数 
..　基于数值梯度的神经网络训练 
.　反向求导 
..　正向计算和反向求导 
..　计算图 
..　损失函数关于输出的梯度 
..　层神经网络的反向求导 
..　层神经网络的Python实现 
..　任意层神经网络的反向求导 
.　实现一个简单的深度学习框架 
..　神经网络的训练过程 
..　网络层的代码实现 
..　网络层的梯度检验 
..　神经网络的类 
..　神经网络的梯度检验 
..　基于深度学习框架的MNIST手写数字识别 
..　改进的通用神经网络框架：分离加权和与激活函数 
..　独立的参数优化器 
..　fashion-mnist的分类训练 
..　读写模型参数 
第章　改进神经网络性能的基本技巧 
.　数据处理 
..　数据增强 
..　规范化 
..　特征工程 
.　参数调试 
..　权重初始化 
..　优化参数 
.　批规范化 
..　什么是批规范化 
..　批规范化的反向求导 
..　批规范化的代码实现 
.　正则化 
..　权重正则化 
..　Dropout 
..　早停法 
.　梯度爆炸和梯度消失 
第章　卷积神经网络 
.　卷积入门 
..　什么是卷积 
..　一维卷积 
..　二维卷积 
..　多通道输入和多通道输出 
..　池化 
.　卷积神经网络概述 
..　全连接神经元和卷积神经元 
..　卷积层和卷积神经网络 
..　卷积层和池化层的反向求导及代码实现 
..　卷积神经网络的代码实现 
.　卷积的矩阵乘法 
..　一维卷积的矩阵乘法 
..　二维卷积的矩阵乘法 
..　一维卷积反向求导的矩阵乘法 
..　二维卷积反向求导的矩阵乘法 
.　基于坐标索引的快速卷积 
.　典型卷积神经网络结构 
..　LeNet- 
..　AlexNet 
..　VGG 
..　残差网络 
..　Inception网络 
..　NiN 
第章　循环神经网络 
.　序列问题和模型 
..　股票价格预测问题 
..　概率序列模型和语言模型 
..　自回归模型 
..　生成自回归数据 
..　时间窗方法 
..　时间窗采样 
..　时间窗方法的建模和训练 
..　长期预测和短期预测 
..　股票价格预测的代码实现 
..　k-gram语言模型 
.　循环神经网络基础 
..　无记忆功能的非循环神经网络 
..　具有记忆功能的循环神经网络 
.　穿过时间的反向传播 
.　单层循环神经网络的实现 
..　初始化模型参数 
..　正向计算 
..　损失函数 
..　反向求导 
..　梯度验证 
..　梯度下降训练 
..　序列数据的采样 
..　序列数据的循环神经网络训练和预测 
.　循环神经网络语言模型和文本的生成 
..　字符表 
..　字符序列样本的采样 
..　模型的训练和预测 
.　循环神经网络中的梯度爆炸和梯度消失 
.　长短期记忆网络 
..　LSTM的神经元 
..　LSTM的反向求导 
..　LSTM的代码实现 
..　LSTM的变种 
.　门控循环单元 
..　门控循环单元的工作原理 
..　门控循环单元的代码实现 
.　循环神经网络的类及其实现 
..　用类实现循环神经网络 
..　循环神经网络单元的类实现 
.　多层循环神经网络和双向循环神经网络 
..　多层循环神经网络 
..　多层循环神经网络的训练和预测 
..　双向循环神经网络 
.　SeqSeq模型 
..　机器翻译概述 
..　SeqSeq模型的实现 
..　字符级的SeqSeq模型 
..　基于WordVec的SeqSeq模型 
..　基于词嵌入层的SeqSeq模型 
..　注意力机制 
第章　生成模型 
.　生成模型概述 
.　自动编码器 
..　什么是自动编码器 
..　稀疏编码器 
..　自动编码器的代码实现 
.　变分自动编码器 
..　什么是变分自动编码器 
..　变分自动编码器的损失函数 
..　变分自动编码器的参数重采样 
..　变分自动编码器的反向求导 
..　变分自动编码器的代码实现 
.　生成对抗网络 
..　生成对抗网络的原理 
..　生成对抗网络训练过程的代码实现 
.　生成对抗网络建模实例 
..　一组实数的生成对抗网络建模 
..　二维坐标点的生成对抗网络建模 
..　MNIST手写数字集的生成对抗网络建模 
..　生成对抗网络的训练技巧 
.　生成对抗网络的损失函数及其概率解释 
..　生成对抗网络的损失函数的全局最优解 
..　Kullback-Leibler散度和Jensen-Shannon散度 
..　生成对抗网络的最大似然解释 
.　改进的损失函数――Wasserstein GAN 
..　Wasserstein GAN的原理 
..　Wasserstein GAN的代码实现 
.　深度卷积对抗网络 
..　一维转置卷积 
..　二维转置卷积 
..　卷积对抗网络的代码实现 
参考文献 
・ ・ ・ ・ ・ ・ (收起)基础篇
第章 深度学习概述 
. 深度学习发展简史 
. 有监督学习 
.. 图像分类 
.. 目标检测 
.. 人脸识别 
.. 语音识别 
. 无监督学习 
.. 无监督学习概述 
.. 生成对抗网络 
. 强化学习 
.. AlphaGo 
.. AlphaGo Zero 
. 小结 
参考文献 
第章 深度神经网络 
. 神经元 
. 感知机 
. 前向传递 
.. 前向传递的流程 
.. 激活函数 
.. 损失函数 
. 后向传递 
.. 后向传递的流程 
.. 梯度下降 
.. 参数修正 
. 防止过拟合 
.. dropout 
.. 正则化 
. 小结 
第章 卷积神经网络 
. 卷积层 
.. valid 卷积 
.. full 卷积 
.. same 卷积 
. 池化层 
. 反卷积 
. 感受野 
. 卷积网络实例 
.. Lenet- 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. ResNet 
.. MobileNet 
. 小结 
进阶篇
第章 两阶段目标检测方法 
. R-CNN 
.. 算法流程 
.. 训练过程 
. SPP-Net 
.. 网络结构 
.. 空间金字塔池化 
. Fast R-CNN 
.. 感兴趣区域池化层 
.. 网络结构 
.. 全连接层计算加速 
.. 目标分类 
.. 边界框回归 
.. 训练过程 
. Faster R-CNN 
.. 网络结构 
.. RPN 
.. 训练过程 
. R-FCN 
.. R-FCN 网络结构 
.. 位置敏感的分数图 
.. 位置敏感的RoI 池化 
.. R-FCN 损失函数 
.. Caffe 网络模型解析 
. Mask R-CNN 
.. 实例分割简介 
.. COCO 数据集的像素级标注 
.. 网络结构 
.. U-Net 
.. SegNet 
. 小结 
第章 单阶段目标检测方法 
. SSD 
.. default box 
.. 网络结构 
.. Caffe 网络模型解析 
.. 训练过程 
. RetinaNet 
.. FPN 
.. 聚焦损失函数 
. RefineDet 
.. 网络模型 
.. Caffe 网络模型解析 
.. 训练过程 
. YOLO 
.. YOLO v 
.. YOLO v 
.. YOLO v 
. 目标检测算法应用 
.. 高速公路坑洞检测 
.. 息肉检测 
. 小结 
应用篇
第章 肋骨骨折检测 
. 国内外研究现状 
. 解决方案 
. 预处理 
. 肋骨骨折检测 
. 实验结果分析 
. 小结 
参考文献 
第章 肺结节检测 
. 国内外研究现状 
.. 肺结节可疑位置推荐算法 
.. 假阳性肺结节抑制算法 
. 总体框架 
.. 肺结节数据集 
.. 肺结节检测难点 
.. 算法框架 
. 肺结节可疑位置推荐算法 
.. CT图像的预处理 
.. 肺结节分割算法 
.. 优化方法 
.. 推断方法 
. 可疑肺结节定位算法 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
. 假阳性肺结节抑制算法 
.. 假阳性肺结节抑制网络 
.. 优化策略 
.. 推断策略 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
.. 可疑位置推荐与假阳抑制算法整合 
. 小结 
参考文献 
第章 车道线检测 
. 国内外研究现状 
. 主要研究内容 
.. 总体解决方案 
.. 各阶段概述 
. 车道线检测系统的设计与实现 
.. 车道线图像数据标注与筛选 
.. 车道线图片预处理 
.. 车道线分割模型训练 
.. 车道线检测 
.. 车道线检测结果 
. 车道线检测系统的性能测试 
.. 车道线检测质量测试 
.. 车道线检测时间测试 
. 小结 
参考文献 
第章 交通视频分析 
. 国内外研究现状 
. 主要研究内容 
.. 总体设计 
.. 精度和性能要求 
. 交通视频分析 
.. 车辆检测和车牌检测 
.. 车牌识别功能设计详解 
.. 车辆品牌及颜色的识别 
.. 目标跟踪设计详解 
. 系统测试 
.. 车辆检测 
.. 车牌检测 
.. 车牌识别 
.. 车辆品牌识别 
.. 目标跟踪 
. 小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)序言
前言
如何使用本书 ――写在第十次印刷之际
主要符号表
第章 绪论
. 引言
. 基本术语
. 假设空间
. 归纳偏好
. 发展历程
. 应用现状
. 阅读材料
习题
参考文献
休息一会儿
第章 模型评估与选择
. 经验误差与过拟合
. 评估方法
. 性能度量
. 比较检验
. 偏差与方差
. 阅读材料
习题
参考文献
休息一会儿
第章 线性模型
. 基本形式
. 线性回归
. 对数几率回归
. 线性判别分析
. 多分类学习
. 类别不平衡问题
. 阅读材料
习题
参考文献
休息一会儿
第章 决策树
. 基本流程
. 划分选择
. 剪枝处理
. 连续与缺失值
. 多变量决策树
. 阅读材料
习题
参考文献
休息一会儿
第章 神经网络
. 神经元模型
. 感知机与多层网络
. 误差逆传播算法
. 全局最小与局部极小
. 其他常见神经网络
. 深度学习
. 阅读材料
习题
参考文献
休息一会儿
第章 支持向量机
. 间隔与支持向量
. 对偶问题
. 核函数
. 软间隔与正则化
. 支持向量回归
. 核方法
. 阅读材料
习题
参考文献
休息一会儿
第章 贝叶斯分类器
. 贝叶斯决策论
. 极大似然估计
. 朴素贝叶斯分类器
. 半朴素贝叶斯分类器
. 贝叶斯网
. EM算法
. 阅读材料
习题
参考文献
休息一会儿
第章 集成学习
. 个体与集成
. Boosting
. Bagging与随机森林
. 结合策略
. 多样性
. 阅读材料
习题
参考文献
休息一会儿
第章 聚类
. 聚类任务
. 性能度量
. 距离计算
. 原型聚类
. 密度聚类
. 层次聚类
. 阅读材料
习题
参考文献
休息一会儿
第章 降维与度量学习
. k近邻学习
. 低维嵌入
. 主成分分析
. 归纳偏好
. 流形学习
. 度量学习
. 阅读材料
习题
参考文献
休息一会儿
第章 特征选择与稀疏学习
. 子集搜索与评价
. 过滤式选择
.包裹式选择
. 嵌入式选择与L正则化
. 稀疏表示与字典学习
. 压缩感知
. 阅读材料
习题
参考文献
休息一会儿
第章 计算学习理论
. 基础知识
. PAC学习
. 有限假设空间
. VC维
. Rademacher复杂度
. 稳定性
. 阅读材料
习题
参考文献
休息一会儿
第章 半监督学习
. 未标记样本
. 生成式方法
. 半监督SVM
. 图半监督学习
. 基于分歧的方法
. 半监督聚类
. 阅读材料
习题
参考文献
休息一会儿
第章 概率图模型
. 隐马尔可夫模型
. 马尔可夫随机场
. 条件随机场
.学习与推断
. 近似推断
. 话题模型
. 阅读材料
习题
参考文献
休息一会儿
第章 规则学习
. 基本概念
. 序贯覆盖
. 剪枝优化
. 一阶规则学习
. 归纳逻辑程序设计
. 阅读材料
习题
参考文献
休息一会儿
第章 强化学习
. 任务与奖赏
. K-摇臂赌博机
. 有模型学习
. 免模型学习
. 值函数近似
. 模仿学习
. 阅读材料
习题
参考文献
休息一会儿
附录
A 矩阵
B 优化
C 概率分布
后记
・ ・ ・ ・ ・ ・ (收起)前言 
第一部分 机器学习的基础知识 
第  章 机器学习概览
 . 什么是机器学习 
. 为什么使用机器学习 
. 机器学习的应用示例 
. 机器学习系统的类型 
. 机器学习的主要挑战 
. 测试与验证 
. 练习题 
第  章 端到端的机器学习项目 
. 使用真实数据
 . 观察大局 
. 获取数据 
. 从数据探索和可视化中获得洞见 
. 机器学习算法的数据准备 
. 选择和训练模型 
. 微调模型 
. 启动、监控和维护你的系统 .
. 试试看 
. 练习题 
第  章 分类 
. MNIST 
. 训练二元分类器 
. 性能测量 
. 多类分类器 
. 误差分析 
. 多标签分类 
. 多输出分类 
. 练习题 
第  章 训练模型 
. 线性回归 
. 梯度下降 
. 多项式回归 
. 学习曲线 
. 正则化线性模型 
. 逻辑回归 
. 练习题 
第  章 支持向量机 
. 线性 SVM 分类 
. 非线性 SVM 分类 
. SVM 回归 
. 工作原理 
. 练习题 
第  章 决策树 
. 训练和可视化决策树 
. 做出预测 
. 估计类概率 
. CART 训练算法 
. 计算复杂度 
. 基尼不纯度或熵 
. 正则化超参数 
. 回归 
. 不稳定性 
. 练习题 
第  章 集成学习和随机森林 
. 投票分类器 
. bagging 和 pasting 
. 随机补丁和随机子空间 
. 随机森林 
. 提升法 
. 堆叠法 
. 练习题 
第  章 降维 
. 维度的诅咒 
. 降维的主要方法 
. PCA 
. 内核 PCA . 
. LLE 
. 其他降维技术 
. 练习题 
第  章 无监督学习技术 
. 聚类 
. 高斯混合模型 
. 练习题 
第二部分 神经网络与深度学习 
第  章 Keras 人工神经网络简介 
. 从生物神经元到人工神经元 
. 使用 Keras 实现 MLP 
. 微调神经网络超参数 
. 练习题 
第  章 训练深度神经网络 
. 梯度消失与梯度爆炸问题 
. 重用预训练层 
. 更快的优化器 
. 通过正则化避免过拟合 
. 总结和实用指南 
. 练习题 
第  章 使用 TensorFlow 自定义模型和训练 
. TensorFlow 快速浏览 
. 像 NumPy 一样使用 TensorFlow 
. 定制模型和训练算法 
. TensorFlow 函数和图 
. 练习题 
第  章 使用 TensorFlow 加载和预处理数据 
. 数据 API 
. TFRecord 格式 
. 预处理输入特征 
. TF Transform 
. TensorFlow 数据集项目 
. 练习题 
第  章 使用卷积神经网络的深度计算机视觉 
. 视觉皮层的架构 
. 卷积层 
. 池化层 
. CNN 架构 
. 使用 Keras 实现 ResNet- CNN 
. 使用 Keras 的预训练模型 
. 迁移学习的预训练模型 
. 分类和定位 
. 物体检测 
. 语义分割 
. 练习题 
第  章 使用 RNN 和 CNN 处理序列 
. 循环神经元和层 
. 训练 RNN 
. 预测时间序列 
. 处理长序列 
. 练习题 
第  章 使用 RNN 和注意力机制进行自然语言处理 
. 使用字符 RNN 生成莎士比亚文本 
. 情感分析 
. 神经机器翻译的编码器 - 解码器网络 
. 注意力机制 
. 最近语言模型的创新 
. 练习题 ... 
第  章 使用自动编码器和 GAN 的表征学习和生成学习 
. 有效的数据表征 
. 使用不完整的线性自动编码器执行 PCA 
. 堆叠式自动编码器 
. 卷积自动编码器 
. 循环自动编码器 
. 去噪自动编码器 
. 稀疏自动编码器 
. 变分自动编码器 
. 生成式对抗网络 
. 练习题 
第  章 强化学习 
. 学习优化奖励 
. 策略搜索 
. OpenAI Gym 介绍 
. 神经网络策略 
. 评估动作：信用分配问题 
. 策略梯度 
. 马尔可夫决策过程 
. 时序差分学习 
. Q 学习 
. 实现深度 Q 学习 
. 深度 Q 学习的变体 
. TF-Agents 库 
. 一些流行的 RL 算法概述 
. 练习题 
第  章 大规模训练和部署TensorFlow 模型 
. 为 TensorFlow 模型提供服务 
. 将模型部署到移动端或嵌入式设备 
. 使用 GPU 加速计算 
. 跨多个设备的训练模型 
. 练习题 
. 致谢 
附录 A 课后练习题解答 .....
附录 B 机器学习项目清单 ..
附录 C SVM 对偶问题 
附录 D 自动微分 .
附录 E 其他流行的人工神经网络架构 ...
附录 F 特殊数据结构..
附录 G TensorFlow 图 ......
・ ・ ・ ・ ・ ・ (收起)引子：AI 菜鸟的挑战― 天上线智能预警系统
第壹 课 机器学习快速上手路径―唯有实战
． 机器学习的家族谱
．． 新手入门机器学习的 个好消息
．． 机器学习*是从数据中发现规律
．． 机器学习的类别―监督学习及其他
．． 机器学习的重要分支―深度学习
．． 机器学习新热点―强化学习
．． 机器学习的两大应用场景―回归与分类
．． 机器学习的其他应用场景
． 快捷的云实战学习模式
．． 在线学习平台上的机器学习课程
．． 用Jupyter Notebook 直接实战
．． 用Google Colab 开发第壹个机器学习程序
．． 在Kaggle 上参与机器学习竞赛
．． 在本机上“玩”机器学习
． 基本机器学习术语
．． 特征
．． 标签
．． 模型
． Python 和机器学习框架
．． 为什么选择用Python
．． 机器学习和深度学习框架
． 机器学习项目实战架构
．． 第壹 个环节：问题定义
．． 第 个环节：数据的收集和预处理
．． 第 个环节：选择机器学习模型
．． 第 个环节：训练机器，确定参数
．． 第 个环节：超参数调试和性能优化
． 本课内容小结
． 课后练习
第 课 数学和Python 基础知识―*天搞定
． 函数描述了事物间的关系
．． 什么是函数
．． 机器学习中的函数
． 捕捉函数的变化趋势
．． 连续性是求导的前提条件
．． 通过求导发现y 如何随x 而变
．． 凸函数有一个全局*低点
． 梯度下降是机器学习的动力之源
．． 什么是梯度
．． 梯度下降：下山的隐喻
．． 梯度下降有什么用
． 机器学习的数据结构―张量
．． 张量的轴、阶和形状
．． 标量―D（阶）张量
．． 向量―D（阶）张量
．． 矩阵―D（阶）张量
．． 序列数据 ―D（阶）张量
．． 图像数据 ―D（阶）张量
．． 视频数据―D（阶）张量
．． 数据的维度和空间的维度
． Python 的张量运算
．． 机器学习中张量的创建
．． 通过索引和切片访问张量中的数据
．． 张量的整体操作和逐元素运算
．． 张量的变形和转置
．． Python 中的广播
．． 向量和矩阵的点积运算
． 机器学习的几何意义
．． 机器学习的向量空间
．． 深度学习和数据流形
． 概率与统计研究了随机事件的规律
．． 什么是概率
．． 正态分布
．． 标准差和方差
． 本课内容小结
． 课后练习
第 课 线性回归―预测网店的销售额
． 问题定义：小冰的网店广告该如何投放
． 数据的收集和预处理
．． 收集网店销售额数据
．． 数据读取和可视化
．． 数据的相关分析
．． 数据的散点图
．． 数据集清洗和规范化
．． 拆分数据集为训练集和测试集
．． 把数据归一化
． 选择机器学习模型
．． 确定线性回归模型
．． 假设（预测）函数―h （x ）
．． 损失（误差）函数―L （w ，b ）
． 通过梯度下降找到*佳参数
．． 训练机器要有正确的方向
．． 凸函数确保有*小损失点
．． 梯度下降的实现
．． 学习速率也很重要
． 实现一元线性回归模型并调试超参数
．． 权重和偏置的初始值
．． 进行梯度下降
．． 调试学习速率
．． 调试迭代次数
．． 在测试集上进行预测
．． 用轮廓图描绘L 、w 和b 的关系
． 实现多元线性回归模型
．． 向量化的点积运算
．． 多变量的损失函数和梯度下降
．． 构建一个线性回归函数模型
．． 初始化权重并训练机器
． 本课内容小结
． 课后练习
第 课 逻辑回归―给病患和鸢尾花分类
． 问题定义：判断客户是否患病
． 从回归问题到分类问题
．． 机器学习中的分类问题
．． 用线性回归+ 阶跃函数完成分类
．． 通过Sigmiod 函数进行转换
．． 逻辑回归的假设函数
．． 逻辑回归的损失函数
．． 逻辑回归的梯度下降
． 通过逻辑回归解决二元分类问题
．． 数据的准备与分析
．． 建立逻辑回归模型
．． 开始训练机器
．． 测试分类结果
．． 绘制损失曲线
．． 直接调用Sklearn 库
．． 哑特征的使用
． 问题定义：确定鸢尾花的种类
． 从二元分类到多元分类
．． 以一对多
．． 多元分类的损失函数
． 正则化、欠拟合和过拟合
．． 正则化
．． 欠拟合和过拟合
．． 正则化参数
． 通过逻辑回归解决多元分类问题
．． 数据的准备与分析
．． 通过Sklearn 实现逻辑回归的多元分类
．． 正则化参数―C 值的选择
． 本课内容小结
． 课后练习
第 课 深度神经网络―找出可能流失的客户
． 问题定义：咖哥接手的金融项目
． 神经网络的原理
．． 神经网络极简史
．． 传统机器学习算法的局限性
．． 神经网络的优势
． 从感知器到单隐层网络
．． 感知器是*基本的神经元
．． 假设空间要能覆盖特征空间
．． 单神经元特征空间的局限性
．． 分层：加入一个网络隐层
． 用Keras 单隐层网络预测客户流失率
．． 数据的准备与分析
．． 先尝试逻辑回归算法
．． 单隐层神经网络的Keras 实现
．． 训练单隐层神经网络
．． 训练过程的图形化显示
． 分类数据不平衡问题：只看准确率够用吗
．． 混淆矩阵、精que率、召回率和F 分数
．． 使用分类报告和混淆矩阵
．． 特征缩放的魔力
．． 阈值调整、欠采样和过采样
． 从单隐层神经网络到深度神经网络
．． 梯度下降：正向传播和反向传播
．． 深度神经网络中的一些可调超参数
．． 梯度下降优化器
．． 激活函数：从Sigmoid 到ReLU
．． 损失函数的选择
．． 评估指标的选择
． 用Keras 深度神经网络预测客户流失率
．． 构建深度神经网络
．． 换一换优化器试试
．． 神经网络正则化：添加Dropout 层
． 深度神经网络的调试及性能优化
．． 使用回调功能
．． 使用TensorBoard
．． 神经网络中的过拟合
．． 梯度消失和梯度bao炸
． 本课内容小结
． 课后练习
第课 卷积神经网络―识别狗狗的图像
． 问题定义：有趣的狗狗图像识别
． 卷积网络的结构
． 卷积层的原理
．． 机器通过“模式”进行图像识别
．． 平移不变的模式识别
．． 用滑动窗口抽取局部特征
．． 过滤器和响应通道
．． 对特征图进行卷积运算
．． 模式层级结构的形成
．． 卷积过程中的填充和步幅
． 池化层的功能
． 用卷积网络给狗狗图像分类
．． 图像数据的读入
．． 构建简单的卷积网络
．． 训练网络并显示误差和准确率
． 卷积网络性能优化
．． 第壹招：更新优化器并设置学习速率
．． 第招：添加Dropout 层
．． “大杀器”：进行数据增强
． 卷积网络中特征通道的可视化
． 各种大型卷积网络模型
．． 经典的VGGNet
．． 采用Inception 结构的GoogLeNet
．． 残差网络ResNet
． 本课内容小结
． 课后练习
第 课 循环神经网络―鉴定留言及探索系外行星
． 问题定义：鉴定评论文本的情感属性
． 循环神经网络的原理和结构
．． 什么是序列数据
．． 前馈神经网络处理序列数据的局限性
．． 循环神经网络处理序列问题的策略
．． 循环神经网络的结构
． 原始文本如何转化成向量数据
．． 文本的向量化：分词
．． 通过One-hot 编码分词
．． 词嵌入
． 用SimpleRNN 鉴定评论文本
．． 用Tokenizer 给文本分词
．． 构建包含词嵌入的SimpleRNN
．． 训练网络并查看验证准确率
． 从SimpleRNN 到LSTM
．． SimpleRNN 的局限性
．． LSTM 网络的记忆传送带
． 用LSTM 鉴定评论文本
． 问题定义：太阳系外哪些恒星有行星环绕
． 用循环神经网络处理时序问题
．． 时序数据的导入与处理
．． 建模：CNN 和RNN 的组合
．． 输出阈值的调整
．． 使用函数式API
． 本课内容小结
． 课后练习
第 课 经典算法“宝刀未老”
． K *近邻
． 支持向量机
． 朴素贝叶斯
． 决策树
．． 熵和特征节点的选择
．． 决策树的深度和剪枝
． 随机森林
． 如何选择*佳机器学习算法
． 用网格搜索超参数调优
． 本课内容小结
． 课后练习
第 课 集成学习“笑傲江湖”
． 偏差和方差―机器学习性能优化的风向标
．． 目标：降低偏差与方差
．． 数据集大小对偏差和方差的影响
．． 预测空间的变化带来偏差和方差的变化
． Bagging 算法―多个基模型的聚合
．． 决策树的聚合
．． 从树的聚合到随机森林
．． 从随机森林到ji端随机森林
．． 比较决策树、树的聚合、随机森林、ji端随机森林的效率
． Boosting 算法―锻炼弱模型的“肌肉”
．． AdaBoost 算法
．． 梯度提升算法
．． XGBoost 算法
．． Bagging 算法与Boosting 算法的不同之处
． Stacking/Blending 算法―以预测结果作为新特征
．． Stacking 算法
．． Blending 算法
． Voting/Averaging 算法―集成基模型的预测结果
．． 通过Voting 进行不同算法的集成
．． 通过Averaging 集成不同算法的结果
． 本课内容小结
． 课后练习
第壹 课 监督学习之外―其他类型的机器学习
． 无监督学习―聚类
．． K 均值算法
．． K 值的选取：手肘法
．． 用聚类辅助理解营销数据
． 无监督学习―降维
．． PCA 算法
．． 通过PCA 算法进行图像特征采样
． 半监督学习
．． 自我训练
．． 合作训练
．． 半监督聚类
． 自监督学习
．． 潜隐空间
．． 自编码器
．． 变分自编码器
． 生成式学习
．． 机器学习的生成式
．． 生成式对抗网络
． 本课内容小结
． 课后练习
第壹 课 强化学习实战―咖哥的冰湖挑战
． 问题定义：帮助智能体完成冰湖挑战
． 强化学习基础知识
．． 延迟满足
．． 更复杂的环境
．． 强化学习中的元素
．． 智能体的视角
． 强化学习基础算法Q-Learning 详解
．． 迷宫游戏的示例
．． 强化学习中的局部*优
．． ε -Greedy 策略
．． Q-Learning 算法的伪代码
． 用Q-Learning 算法来解决冰湖挑战问题
．． 环境的初始化
．． Q-Learning 算法的实现
．． Q-Table 的更新过程
． 从Q-Learning 算法到SARSA算法
．． 异策略和同策略
．． SARSA 算法的实现
． 用SARSA 算法来解决冰湖挑战问题
． Deep Q Network 算法：用深度网络实现Q-Learning
． 本课内容小结
． 课后练习
尾声：如何实现机器学习中的知识迁移及持续性的学习
练习答案
・ ・ ・ ・ ・ ・ (收起)目 录
草  蒲 血 督 学 习
第  章 机器学习及监督学习概论 
. 机器学习 
. 机器学习的分类 
.. 基本分类 
.. 按模型分类 
.. 按算法分类 
.. 按技巧分类 
. 机器学习方法主要素 
.. 模型 
.. 策略 
.. 算法 
. 模型评估与模型选择 
.. 训练误差与测试误差 
.. 过拟合与模型选择 
. 正则化与交叉验证 
.. 正则化 
.. 交叉验证 
. 泛化能力 
.. 泛化误差 
.. 泛化误差上界 
. 生成模型与判别模型 
. 监督学习应用 
.. 分类问题 
.. 标注问题 
.. 回归问题 
本章概要 
继续阅读 
习题 
参考文献 
VIII 机器学习方法
第  章 感知机 
. 感知机模型 
. 感知机学习策略 
.. 数据集的线性可分性 
.. 感知机学习策略 
. 感知机学习算法 
.. 感知机学习算法的原始形式 
.. 算法的收敛性 
.. 感知机学习算法的对偶形式 
本章概要 
继续阅读 
习题 
参考文献 
第  章 k 近邻法 
. k 近邻算法 
. k 近邻模型 
.. 模型 
.. 距离度量 
.. k 值的选择 
.. 分类决策规则 
. k 近邻法的实现：kd 树 
.. 构造 kd 树 
.. 搜索 kd 树 
本章概要 
继续阅读 
习题 
参考文献 
第  章 朴素贝叶斯法 
. 朴素贝叶斯法的学习与分类 
.. 基本方法 
.. 后验概率最大化的含义 
. 朴素贝叶斯法的参数估计 
.. 极大似然估计 
.. 学习与分类算法 
.. 贝叶斯估计 
本章概要 
继续阅读 
目录 IX
习题 
参考文献 
第  章 决策树 
. 决策树模型与学习 
.. 决策树模型 
.. 决策树与 if-then 规则 
.. 决策树与条件概率分布 
.. 决策树学习 
. 特征选择 
.. 特征选择问题 
.. 信息增益 
.. 信息增益比 
. 决策树的生成 
.. ID 算法 
.. C. 的生成算法 
. 决策树的剪枝 
. CART 算法 
.. CART 生成 
.. CART 剪枝 
本章概要 
继续阅读 
习题 
参考文献 
第  章 逻辑斯谛回归与最大烟模型 
. 逻辑斯谛回归模型 
.. 逻辑斯谛分布 
.. 二项逻辑斯谛回归模型 
.. 模型参数估计 
.. 多项逻辑斯谛回归 
. 最大煽模型 
.. 最大煽原理 
.. 最大煽模型的定义 
.. 最大煽模型的学习 
.. 极大似然估计 
. 模型学习的最优化算法 
.. 改进的迭代尺度法 
.. 拟牛顿法 
X 机器学习方法
本章概要 
继续阅读 
习题 
参考文献 
第  章 支持向量机 
. 线性可分支持向量机与硬间隔最大化 
.. 线性可分支持向量机 
.. 函数间隔和儿何间隔 
.. 间隔最大化 
.. 学习的对偶算法 
. 线性支持向量机与软间隔最大化 
.. 线性支持向量机 
.. 学习的对偶算法 
.. 支持向量 
.. 合页损失函数 
. 非线性支持向量机与核函数 
.. 核技巧 
.. 正定核 
.. 常用核函数 
.. 非线性支持向量分类机 
. 序列最小最优化算法 
.. 两个变量二次规划的求解方法 
.. 变量的选择方法 
.. SMO 算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 Boosting 
AdaBoost 算法 
.. Boosting 的基本思路 
AdaBoost 算法 
AdaBoost 的例子 
. AdaBoost 算法的训练误差分析 
. AdaBoost 算法的解释 
.. 前向分步算法 
.. 前向分步算法与 AdaBoost 
目录 XI
. 提升树 
.. 提升树模型 
.. 提升树算法 
.. 梯度提升 
本章概要 
继续阅读 
习题 
参考文献 
第  章 EM 算法及其推广 
. EM 算法的引入 
.. EM 算法 
.. EM 算法的导出 
.. EM 算法在无监督学习中的应用 
. EM 算法的收敛性 
. EM 算法在高斯混合模型学习中的应用 
.. 高斯混合模型 
.. 高斯混合模型参数估计的 EM 算法 
. EM 算法的推广 
.. F 函数的极大-极大算法 
.. GEM 算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 隐马尔可夫模型 
. 隐马尔可夫模型的基本概念 
.. 隐马尔可夫模型的定义 
.. 观测序列的生成过程 
.. 隐马尔可夫模型的  个基本问题 
. 概率计算算法 
.. 直接计算法 
.. 前向算法 
.. 后向算法 
.. 一些概率与期望值的计算 
. 学习算法 
.. 监督学习方法 
.. Baum-Welch 算法 
XII 机器学习方法
.. Baum-Welch 模型参数估计公式 
. 预测算法 
.. 近似算法 
.. 维特比算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 条件随机场 
. 概率无向图模型 
.. 模型定义 
.. 概率无向图模型的因子分解 
. 条件随机场的定义与形式 
.. 条件随机场的定义 
.. 条件随机场的参数化形式 
.. 条件随机场的简化形式 
.. 条件随机场的矩阵形式 
. 条件随机场的概率计算问题 
.. 前向-后向算法 
.. 概率计算 
.. 期望值的计算 
. 条件随机场的学习算法 
.. 改进的迭代尺度法 
.. 拟牛顿法 
. 条件随机场的预测算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 监督学习方法总结 
草  蒲 元元血血督学学习习
第  章 无监督学习概论 
. 无监督学习基本原理 
. 基本问题 
. 机器学习主要素 
. 无监督学习方法 
目录 XIII
本章概要 
继续阅读 
参考文献 
第  章 聚类方法 
. 聚类的基本概念 
.. 相似度或距离 
.. 类或簇 
.. 类与类之间的距离 
. 层次聚类 
. k 均值聚类 
.. 模型 
.. 策略 
.. 算法 
.. 算法特性 
本章概要 
继续阅读 
习题 
参考文献 
第  章 奇异值分解 
. 奇异值分解的定义与性质 
.. 定义与定理 
.. 紧奇异值分解与截断奇异值分解 
.. 儿何解释 
.. 主要性质 
. 奇异值分解的计算 
. 奇异值分解与矩阵近似 
.. 弗罗贝尼乌斯范数 
.. 矩阵的最优近似 
.. 矩阵的外积展开式 
本章概要 
继续阅读 
习题 
参考文献 
第  章 主成分分析 
. 总体主成分分析 
.. 基本想法 
XIV 机器学习方法
.. 定义和导出 
.. 主要性质 
.. 主成分的个数 
.. 规范化变量的总体主成分 
. 样本主成分分析 
.. 样本主成分的定义和性质 
.. 相关矩阵的特征值分解算法 
.. 数据矩阵的奇异值分解算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 潜在语义分析 
. 单词向量空间与话题向量空间 
.. 单词向量空间 
.. 话题向量空间 
. 潜在语义分析算法 
.. 矩阵奇异值分解算法 
.. 例子 
. 非负矩阵分解算法 
.. 非负矩阵分解 
.. 潜在语义分析模型 
.. 非负矩阵分解的形式化 
.. 算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 概率潜在语义分析 
. 概率潜在语义分析模型 
.. 基本想法 
.. 生成模型 
.. 共现模型 
.. 模型性质 
. 概率潜在语义分析的算法 
本章概要 
继续阅读 
目录 XV
习题 
参考文献 
第  章 马尔可夫链蒙特卡罗法 
. 蒙特卡罗法 
.. 随机抽样 
.. 数学期望估计 
.. 积分计算 
. 马尔可夫链 
.. 基本定义 
.. 离散状态马尔可夫链 
.. 连续状态马尔可夫链 
.. 马尔可夫链的性质 
. 马尔可夫链蒙特卡罗法 
.. 基本想法 
.. 基本步骤 
.. 马尔可夫链蒙特卡罗法与统计学习 
Metropolis-Hastings 算法 
.. 基本原理 
Metropolis-Hastings 算法 
单分量 Metropolis-Hastings 算法 
. 吉布斯抽样 
.. 基本原理 
.. 吉布斯抽样算法 
.. 抽样计算 
本章概要 
继续阅读 
习题 
参考文献 
第  章 潜在狄利克雷分配 
. 狄利克雷分布 
.. 分布定义 
.. 共辄先验 
. 潜在狄利克雷分自模型 
.. 基本想法 
.. 模型定义 
.. 概率图模型 
.. 随机变量序列的可交换性 
XVI 机器学习方法
.. 概率公式 
. LDA 的吉布斯抽样算法 
.. 基本想法 
.. 算法的主要部分 
.. 算法的后处理 
.. 算法 
. LDA 的变分 EM 算法 
.. 变分推理 
.. 变分 EM 算法 
.. 算法推导 
.. 算法总结 
本章概要 
继续阅读 
习题 
参考文献 
第  章 PageRank 算法 
PageRank 的定义 
.. 基本想法 
.. 有向图和随机游走模型 
.. PageRank 的基本定义 
.. PageRank 的一般定义 
PageRank 的计算 
.. 迭代算法 
.. 幕法 
.. 代数算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 无监督学习方法总结 
. 无监督学习方法的关系和特点 
.. 各种方法之间的关系 
.. 无监督学习方法 
.. 基础机器学习方法 
. 话题模型之间的关系和特点 
参考文献 
目录 XVII
草  蒲 深 反 学 习
第  章 前馈神经网络 
. 前馈神经网络的模型 
.. 前馈神经网络定义 
.. 前馈神经网络的例子 
.. 前馈神经网络的表示能力 
. 前馈神经网络的学习算法 
.. 前馈神经网络学习 
.. 前馈神经网络学习的优化算法 
.. 反向传播算法 
.. 在计算图上的实现 
.. 算法的实现技巧 
. 前馈神经网络学习的正则化 
.. 深度学习中的正则化 
.. 早停法 
.. 暂返法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 卷积神经网络 
. 卷积神经网络的模型 
.. 背景 
.. 卷积 
.. 汇聚 
.. 卷积神经网络 
.. 卷积神经网络性质 
. 卷积神经网络的学习算法 
.. 卷积导数 
.. 反向传播算法 
. 图像分类中的应用 
.. AlexNet 
.. 残差网络 
本章概要 
继续阅读 
习题 
参考文献 
XVIII 机器学习方法
第  章 循环神经网络 
. 简单循环神经网络 
.. 模型 
.. 学习算法 
. 常用循环神经网络 
.. 长短期记忆网络 
.. 门控循环单元网络 
.. 深度循环神经网络 
.. 双向循环神经网络 
. 自然语言生成中的应用 
.. 词向量 
.. 语言模型与语言生成 
本章概要 
继续阅读 
习题 
参考文献 
第  章 序列到序列模型 
. 序列到序列基本模型 
.. 序列到序列学习 
.. 基本模型 
RNN Search 模型 
.. 注意力 
.. 模型定义 
.. 模型特点 
Transformer 模型 
.. 模型架构 
.. 模型特点 
本章概要 
继续阅读 
习题 
参考文献 
第  章 预训练语言模型 
. GPT 模型 
.. 预训练语言模型 
.. 模型和学习 
. BERT 模型 
.. 去噪自动编码器 
.. 模型和学习 
目录 XIX
.. 模型特点 
本章概要 
继续阅读 
习题 
参考文献 
第  章 生成对抗网络 
. GAN 基本模型 
.. 模型 
.. 学习算法 
.. 理论分析 
. 图像生成中的应用 
.. 转置卷积 
.. DCGAN 
本章概要 
继续阅读 
习题 
参考文献 
第  章 深度学习方法总结 
. 深度学习的模型 
. 深度学习的方法 
. 深度学习的优化算法 
. 深度学习的优缺点 
参考文献 
附录 A 梯度下降法 
附录 B 牛顿法和拟牛顿法 
附录 C 拉格朗日对偶性 
附录 D 矩阵的基本子空间 
附录 E KL 散度的定义和狄利克雷分布的性质 
附录 F 软最大化函数的偏导数和交叉烟损失函数的偏导数 
索引 
・ ・ ・ ・ ・ ・ (收起)目录
前言 ix
第  章　引言 
.　为何选择机器学习 
..　机器学习能够解决的问题 
..　熟悉任务和数据 
.　为何选择Python 
.　scikit-learn 
.　必要的库和工具 
..　Jupyter Notebook 
..　NumPy 
..　SciPy 
..　matplotlib 
..　pandas 
..　mglearn 
.　Python  与Python  的对比 
.　本书用到的版本 
.　第 一个应用：鸢尾花分类 
..　初识数据 
..　衡量模型是否成功：训练数据与测试数据 
..　要事第 一：观察数据 
..　构建第 一个模型：k 近邻算法 
..　做出预测 
..　评估模型 
.　小结与展望 
第  章　监督学习 
.　分类与回归 
.　泛化、过拟合与欠拟合 
.　监督学习算法 
..　一些样本数据集 
..　k 近邻 
..　线性模型 
..　朴素贝叶斯分类器 
..　决策树 
..　决策树集成 
..　核支持向量机 
..　神经网络（深度学习） 
.　分类器的不确定度估计 
..　决策函数 
..　预测概率 
..　多分类问题的不确定度 
.　小结与展望 
第 章　无监督学习与预处理 
.　无监督学习的类型 
.　无监督学习的挑战 
.　预处理与缩放 
..　不同类型的预处理 
..　应用数据变换 
..　对训练数据和测试数据进行相同的缩放 
..　预处理对监督学习的作用 
.　降维、特征提取与流形学习 
..　主成分分析 
..　非负矩阵分解 
..　用t-SNE 进行流形学习 
.　聚类 
..　k 均值聚类 
..　凝聚聚类 
..　DBSCAN 
..　聚类算法的对比与评估 
..　聚类方法小结 
.　小结与展望 
第 章　数据表示与特征工程 
.　分类变量 
..　One-Hot 编码（虚拟变量） 
..　数字可以编码分类变量 
.　分箱、离散化、线性模型与树 
.　交互特征与多项式特征 
.　单变量非线性变换 
.　自动化特征选择 
..　单变量统计 
..　基于模型的特征选择 
..　迭代特征选择 
.　利用专家知识 
.　小结与展望 
第 章　模型评估与改进 
.　交叉验证 
..　scikit-learn 中的交叉验证 
..　交叉验证的优点 
..　分层k 折交叉验证和其他策略 
.　网格搜索 
..　简单网格搜索 
..　参数过拟合的风险与验证集 
..　带交叉验证的网格搜索 
.　评估指标与评分 
..　牢记目标 
..　二分类指标 
..　多分类指标 
..　回归指标 
..　在模型选择中使用评估指标 
.　小结与展望 
第 章　算法链与管道 
.　用预处理进行参数选择 
.　构建管道 
.　在网格搜索中使用管道 
.　通用的管道接口 
..　用make_pipeline 方便地创建管道 
..　访问步骤属性 
..　访问网格搜索管道中的属性 
.　网格搜索预处理步骤与模型参数 
.　网格搜索选择使用哪个模型 
.　小结与展望 
第 章　处理文本数据 
.　用字符串表示的数据类型 
.　示例应用：电影评论的情感分析 
.　将文本数据表示为词袋 
..　将词袋应用于玩具数据集 
..　将词袋应用于电影评论 
.　停用词 
.　用tf-idf 缩放数据 
.　研究模型系数 
.　多个单词的词袋（n 元分词） 
.　分词、词干提取与词形还原 
.　主题建模与文档聚类 
.　小结与展望 
第 章　全书总结 
.　处理机器学习问题 
.　从原型到生产 
.　测试生产系统 
.　构建你自己的估计器 
.　下一步怎么走 
..　理论 
..　其他机器学习框架和包 
..　排序、推荐系统与其他学习类型 
..　概率建模、推断与概率编程 
..　神经网络 
..　推广到更大的数据集 
..　磨练你的技术 
.　总结 
关于作者 
关于封面 
・ ・ ・ ・ ・ ・ (收起)序（王斌 小米AI 实验室主任、NLP 首席科学家）
前言
主要符号表
第章 绪论
式(.)
式(.)
第章 模型评估与选择
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 线性模型
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 决策树
式(.)
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 神经网络
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
ii j 目录
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 支持向量机
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 贝叶斯分类器
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 集成学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 聚类
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 降维与度量学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 特征选择与稀疏学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 计算学习理论
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
参考文献
第章 半监督学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 概率图模型
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 规则学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 强化学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
・ ・ ・ ・ ・ ・ (收起)序
前言
第章 概率思想：构建理论基础 
. 理论基石：条件概率、独立性与贝叶斯 
.. 从概率到条件概率 
.. 条件概率的具体描述 
.. 条件概率的表达式分析 
.. 两个事件的独立性 
.. 从条件概率到全概率公式 
.. 聚焦贝叶斯公式 
.. 本质内涵：由因到果，由果推因 
. 事件的关系：深入理解独立性 
.. 重新梳理两个事件的独立性 
.. 不相容与独立性 
.. 条件独立 
.. 独立与条件独立 
.. 独立重复实验 
第章 变量分布：描述随机世界 
. 离散型随机变量：分布与数字特征 
.. 从事件到随机变量 
.. 离散型随机变量及其要素 
.. 离散型随机变量的分布列 
.. 分布列和概率质量函数 
.. 二项分布及二项随机变量 
.. 几何分布及几何随机变量 
.. 泊松分布及泊松随机变量 
. 连续型随机变量：分布与数字特征 
.. 概率密度函数 
.. 连续型随机变量区间概率的计算 
.. 连续型随机变量的期望与方差 
.. 正态分布及正态随机变量 
.. 指数分布及指数随机变量 
.. 均匀分布及其随机变量 
. 多元随机变量（上）：联合、边缘与条件 
.. 实验中引入多个随机变量 
.. 联合分布列 
.. 边缘分布列 
.. 条件分布列 
.. 集中梳理核心的概率理论 
. 多元随机变量（下）：独立与相关 
.. 随机变量与事件的独立性 
.. 随机变量之间的独立性 
.. 独立性示例 
.. 条件独立的概念 
.. 独立随机变量的期望和方差 
.. 随机变量的相关性分析及量化方法 
.. 协方差及协方差矩阵 
.. 相关系数的概念 
. 多元随机变量实践：聚焦多元正态分布 
.. 再谈相关性：基于二元标准正态分布 
.. 二元一般正态分布 
.. 聚焦相关系数 
.. 独立和相关性的关系 
. 多元高斯分布：参数特征和几何意义 
.. 从一元分布到多元分布 
.. 多元高斯分布的参数形式 
.. 二元高斯分布的具体示例 
.. 多元高斯分布的几何特征 
.. 二元高斯分布几何特征实例分析 
第章 参数估计：探寻最大可能 
. 极限思维：大数定律与中心极限定理 
.. 一个背景话题 
.. 大数定律 
.. 大数定律的模拟 
.. 中心极限定理 
.. 中心极限定理的工程意义 
.. 中心极限定理的模拟 
.. 大数定律的应用：蒙特卡罗方法 
. 推断未知：统计推断的基本框架 
.. 进入统计学 
.. 统计推断的例子 
.. 统计推断中的一些重要概念 
.. 估计量的偏差与无偏估计 
.. 总体均值的估计 
.. 总体方差的估计 
. 极大似然估计 
.. 极大似然估计法的引例 
.. 似然函数的由来 
.. 极大似然估计的思想 
.. 极大似然估计值的计算 
.. 简单极大似然估计案例 
.. 高斯分布参数的极大似然估计 
. 含有隐变量的参数估计问题 
.. 参数估计问题的回顾 
.. 新情况：场景中含有隐变量 
.. 迭代法：解决含有隐变量情形的抛硬币问题 
.. 代码实验 
. 概率渐增：EM算法的合理性 
.. EM算法的背景介绍 
.. 先抛出EM算法的迭代公式 
.. EM算法为什么是有效的 
. 探索EM公式的底层逻辑与由来 
.. EM公式中的E步和M步 
.. 剖析EM算法的由来 
. 探索高斯混合模型：EM 迭代实践 
.. 高斯混合模型的引入 
.. 从混合模型的角度看内部机理 
.. 高斯混合模型的参数估计 
. 高斯混合模型的参数求解 
.. 利用 EM 迭代模型参数的思路 
.. 参数估计示例 
.. 高斯混合模型的应用场景 
第章 随机过程：聚焦动态特征 
. 由静向动：随机过程导引 
.. 随机过程场景举例：博彩 
.. 随机过程场景举例：股价的变化 
.. 随机过程场景举例：股价变化过程的展现 
.. 两类重要的随机过程概述 
. 状态转移：初识马尔可夫链 
.. 马尔可夫链三要素 
.. 马尔可夫性：灵魂特征 
.. 转移概率和状态转移矩阵 
.. 马尔可夫链性质的总结 
.. 一步到达与多步转移的含义 
.. 多步转移与矩阵乘法 
.. 路径概率问题 
. 变与不变：马尔可夫链的极限与稳态 
.. 极限与初始状态无关的情况 
.. 极限依赖于初始状态的情况 
.. 吸收态与收敛分析 
.. 可达与常返 
.. 周期性问题 
.. 马尔可夫链的稳态分析和判定 
.. 稳态的求法 
. 隐马尔可夫模型：明暗两条线 
.. 从马尔可夫链到隐马尔可夫模型 
.. 典型实例：盒子摸球实验 
.. 典型实例：小宝宝的日常生活 
.. 隐马尔可夫模型的外在表征 
.. 推动模型运行的内核三要素 
.. 关键性质：齐次马尔可夫性和观测独立性 
. 概率估计：隐马尔可夫模型观测序列描述 
.. 隐马尔可夫模型的研究内容 
.. 模型研究问题的描述 
.. 一个直观的思路 
.. 更优的方法：前向概率算法 
.. 概率估计实践 
.. 代码实践 
. 状态解码：隐马尔可夫模型隐状态揭秘 
.. 隐状态解码问题的描述 
.. 最大路径概率与维特比算法 
.. 应用维特比算法进行解码 
.. 维特比算法的案例实践 
.. 代码实践 
. 连续域上的无限维：高斯过程 
.. 高斯过程的一个实际例子 
.. 高斯过程的核心要素和严谨描述 
.. 径向基函数的代码演示 
.. 高斯过程回归原理详解 
.. 高斯过程回归代码演示 
第章 统计推断：贯穿近似策略 
. 统计推断的基本思想和分类 
.. 统计推断的根源和场景 
.. 后验分布：推断过程的关注重点 
.. 精确推断和近似推断 
.. 确定性近似：变分推断概述 
. 随机近似方法 
.. 蒙特卡罗方法的理论支撑 
.. 随机近似的核心：蒙特卡罗 
.. 接受-拒绝采样的问题背景 
.. 接受-拒绝采样的方法和步骤 
.. 接受-拒绝采样的实践 
.. 接受-拒绝采样方法背后的内涵挖掘 
.. 重要性采样 
.. 两种采样方法的问题及思考 
. 采样绝佳途径：借助马尔可夫链的稳态性质 
.. 马尔可夫链回顾 
.. 核心：马尔可夫链的平稳分布 
.. 马尔可夫链进入稳态的转移过程 
.. 稳态及转移过程演示 
.. 马尔可夫链稳态的价值和意义 
.. 基于马尔可夫链进行采样的原理分析 
.. 采样过程实践与分析 
.. 一个显而易见的问题和难点 
. 马尔可夫链-蒙特卡罗方法详解 
.. 稳态判定：细致平稳条件 
.. Metropolis-Hastings采样方法的原理 
.. 如何理解随机游走叠加接受概率 
.. 如何实现随机游走叠加接受概率 
.. 建议转移概率矩阵Q的设计 
.. Metropolis-Hastings方法的步骤和代码演示 
. Gibbs采样方法简介 
.. Gibbs方法核心流程 
.. Gibbs采样的合理性 
.. Gibbs采样代码实验 
・ ・ ・ ・ ・ ・ (收起)第章　初识Python与Jupyter 
.　Python概要 
..　为什么要学习Python 
..　Python中常用的库 
.　Python的版本之争 
.　安装Anaconda 
..　Linux环境下的Anaconda安装 
..　conda命令的使用 
..　Windows环境下的Anaconda安装 
.　运行Python 
..　验证Python 
..　Python版本的Hello World 
..　Python的脚本文件 
..　代码缩进 
..　代码注释 
.　Python中的内置函数 
.　文学化编程―Jupyter 
..　Jupyter的由来 
..　Jupyter的安装 
..　Jupyter的使用 
..　Markdown编辑器 
.　Jupyter中的魔法函数 
..　%lsmagic函数 
..　%matplotlib inline函数 
..　%timeit函数 
..　%%writefile函数 
..　其他常用的魔法函数 
..　在Jupyter中执行shell命令 
.　本章小结 
.　思考与提高 
第章　数据类型与程序控制结构 
.　为什么需要不同的数据类型 
.　Python中的基本数据类型 
..　数值型（Number） 
..　布尔类型（Boolean） 
..　字符串型（String） 
..　列表（List） 
..　元组（Tuple） 
..　字典（Dictionary） 
..　集合（Set） 
.　程序控制结构 
..　回顾那段难忘的历史 
.. 顺序结构 
.. 选择结构 
.. 循环结构 
.　高效的推导式 
..　列表推导式 
..　字典推导式 
..　集合推导式 
.　本章小结 
.　思考与提高 
第章　自建Python模块与第三方模块 
.　导入Python标准库 
.　编写自己的模块 
.　模块的搜索路径 
.　创建模块包 
.　常用的内建模块 
.. collection模块 
..　datetime模块 
..　json模块 
..　random模块 
.　本章小结 
.　思考与提高 
第章　Python函数 
.　Python中的函数 
..　函数的定义 
..　函数返回多个值 
.. 函数文档的构建 
.　函数参数的“花式”传递 
..　关键字参数 
..　可变参数 
..　默认参数 
..　参数序列的打包与解包 
..　传值还是传引用 
.　函数的递归 
.. 感性认识递归 
.. 思维与递归思维 
.. 递归调用的函数 
.　函数式编程的高阶函数 
..　lambda表达式 
.. filter()函数 
.. map()函数 
.. reduce()函数 
.. sorted()函数 
. 本章小结 
. 思考与提高 
第章　Python高级特性 
.　面向对象程序设计 
..　面向过程与面向对象之辩 
.. 类的定义与使用 
.. 类的继承 
.　生成器与迭代器 
.. 生成器 
.. 迭代器 
. 文件操作 
.. 打开文件 
.. 读取一行与读取全部行 
.. 写入文件 
.　异常处理 
.. 感性认识程序中的异常 
.. 异常处理的三步走 
. 错误调试 
.. 利用print()输出观察变量 
.. assert断言 
.　本章小结 
.　思考与提高 
第章　NumPy向量计算 
.　为何需要NumPy 
.　如何导入NumPy 
. 生成NumPy数组 
..　利用序列生成 
..　利用特定函数生成 
.. Numpy数组的其他常用函数 
.　N维数组的属性 
. NumPy数组中的运算 
.. 向量运算 
.. 算术运算 
.. 逐元素运算与张量点乘运算 
.　爱因斯坦求和约定 
..　不一样的标记法 
..　NumPy中的einsum()方法 
. NumPy中的“轴”方向 
. 操作数组元素 
.. 通过索引访问数组元素 
.. NumPy中的切片访问 
.. 二维数组的转置与展平 
. NumPy中的广播 
. NumPy数组的高级索引 
.. “花式”索引 
.. 布尔索引 
. 数组的堆叠操作 
.. 水平方向堆叠hstack() 
.. 垂直方向堆叠vstack() 
.. 深度方向堆叠hstack() 
.. 列堆叠与行堆叠 
.. 数组的分割操作 
. NumPy中的随机数模块 
. 本章小结 
. 思考与提高 
第章　Pandas数据分析 
. Pandas简介 
. Pandas的安装 
. Series类型数据 
.. Series的创建 
.. Series中的数据访问 
.. Series中的向量化操作与布尔索引 
.. Series中的切片操作 
.. Series中的缺失值 
.. Series中的删除与添加操作 
.. Series中的name属性 
. DataFrame 类型数据 
.. 构建DataFrame 
.. 访问DataFrame中的列与行 
.. DataFrame中的删除操作 
.. DataFrame中的“轴”方向 
.. DataFrame中的添加操作 
. 基于Pandas的文件读取与分析 
.. 利用Pandas读取文件 
.. DataFrame中的常用属性 
.. DataFrame中的常用方法 
.. DataFrame的条件过滤 
.. DataFrame的切片操作 
.. DataFrame的排序操作 
.. Pandas的聚合和分组运算 
.. DataFrame的透视表 
.. DataFrame的类SQL操作 
.. DataFrame中的数据清洗方法 
. 泰坦尼克幸存者数据预处理 
.. 数据集简介 
.. 数据集的拼接 
.. 缺失值的处理 
. 本章小结 
. 思考与提高 
第章　Matplotlib与Seaborn可视化分析 
. Matplotlib与图形绘制 
. 绘制简单图形 
. pyplot的高级功能 
.. 添加图例与注释 
.. 设置图形标题及坐标轴 
.. 添加网格线 
.. 绘制多个子图 
.. Axes与Subplot的区别 
. 散点图 
. 条形图与直方图 
.. 垂直条形图 
.. 水平条形图 
.. 并列条形图 
.. 叠加条形图 
.. 直方图 
. 饼图 
. 箱形图 
. 误差条 
. 绘制三维图形 
. 与Pandas协作绘图―以谷歌流感趋势数据为例 
.. 谷歌流感趋势数据描述 
.. 导入数据与数据预处理 
.. 绘制时序曲线图 
.. 选择合适的数据可视化表达 
.. 基于条件判断的图形绘制 
.. 绘制多个子图 
. 惊艳的Seaborn 
.. pairplot（对图） 
.. heatmap（热力图） 
.. boxplot（箱形图） 
.. violin plot（小提琴图） 
.. Density Plot（密度图） 
. 本章小结 
. 思考与提高 
第章　机器学习初步 
. 机器学习定义 
..　什么是机器学习 
.. 机器学习的三个步骤 
.. 传统编程与机器学习的差别 
.. 为什么机器学习不容易 
.　监督学习 
..　感性认识监督学习 
..　监督学习的形式化描述 
.. 损失函数 
.　非监督学习 
.　半监督学习 
. 机器学习的哲学视角 
. 模型性能评估 
.. 经验误差与测试误差 
.. 过拟合与欠拟合 
.. 模型选择与数据拟合 
. 性能度量 
..　二分类的混淆矩阵 
.. 查全率、查准率与F分数 
.. P-R曲线 
.. ROC曲线 
.. AUC 
.　本章小结 
.　思考与提高 
第章　sklearn与经典机器学习算法 
. 机器学习的利器―sklearn 
.. sklearn简介 
.. sklearn的安装 
. 线性回归 
..　线性回归的概念 
.. 使用sklearn实现波士顿房价预测 
.　k-近邻算法 
.. 算法简介 
..　k值的选取 
..　特征数据的归一化 
..　邻居距离的度量 
.. 分类原则的制定 
..　基于sklearn的k-近邻算法实战 
. Logistic回归 
.. 为什么需要Logistic回归 
.. Logistic源头初探 
.. Logistic回归实战 
. 神经网络学习算法 
.. 人工神经网络的定义 
.. 神经网络中的“学习”本质 
.. 神经网络结构的设计 
.. 利用sklearn搭建多层神经网络 
. 非监督学习的代表―k均值聚类 
.. 聚类的基本概念 
.. 簇的划分 
.. k均值聚类算法核心 
.. k均值聚类算法优缺点 
.. 基于sklearn的k均值聚类算法实战 
. 本章小结 
. 思考与提高 
・ ・ ・ ・ ・ ・ (收起)赛题一 工业蒸汽量预测
 赛题理解 
. 赛题背景 
. 赛题目标 
. 数据概览 
. 评估指标 
. 赛题模型 
 数据探索 
. 理论知识 
.. 变量识别 
.. 变量分析 
.. 缺失值处理 
.. 异常值处理 
.. 变量转换 
.. 新变量生成 
. 赛题数据探索 
.. 导入工具包 
.. 读取数据 
.. 查看数据 
.. 可视化数据分布 
.. 查看特征变量的相关性 
 特征工程 
. 特征工程的重要性和处理 
. 数据预处理和特征处理 
.. 数据预处理 
.. 特征处理 
. 特征降维 
.. 特征选择 
.. 线性降维 
. 赛题特征工程 
.. 异常值分析 
.. 最大值和最小值的
归一化 
.. 查看数据分布 
.. 特征相关性 
.. 特征降维 
.. 多重共线性分析 
.. PCA处理 
 模型训练 
. 回归及相关模型 
.. 回归的概念 
.. 回归模型训练和预测 
.. 线性回归模型 
.. K近邻回归模型 
.. 决策树回归模型 
.. 集成学习回归模型 
. 赛题模型训练 
.. 导入相关库 
.. 切分数据 
.. 多元线性回归 
.. K近邻回归 
.. 随机森林回归 
.. LGB模型回归 
 模型验证 
. 模型评估的概念和方法 
.. 欠拟合与过拟合 
.. 模型的泛化与正则化 
.. 回归模型的评估指标和
调用方法 
.. 交叉验证 
. 模型调参 
.. 调参 
.. 网格搜索 
.. 学习曲线 
.. 验证曲线 
. 赛题模型验证和调参 
.. 模型过拟合与欠拟合 
.. 模型正则化 
.. 模型交叉验证 
.. 模型超参空间及调参 
.. 学习曲线和验证曲线 
 特征优化 
. 特征优化的方法 
.. 合成特征 
.. 特征的简单变换 
.. 用决策树创造新特征 
.. 特征组合 
. 赛题特征优化 
.. 导入数据 
.. 特征构造方法 
.. 特征构造函数 
.. 特征降维处理 
.. 模型训练和评估 
 模型融合 
. 模型优化 
.. 模型学习曲线 
.. 模型融合提升技术 
.. 预测结果融合策略 
.. 其他提升方法 
. 赛题模型融合 
.. 导入工具包 
.. 获取训练数据和测试
数据 
.. 模型评价函数 
.. 采用网格搜索训练
模型 
.. 单一模型预测效果 
.. 模型融合Boosting方法 
.. 多模型预测Bagging
方法 
.. 多模型融合Stacking
方法 
.. 模型验证 
.. 使用lr_reg和lgb_reg
进行融合预测 

赛题二 天猫用户重复购买预测
 赛题理解 
. 赛题背景 
. 数据介绍 
. 评估指标 
. 赛题分析 
 数据探索 
. 理论知识 
.. 缺失数据处理 
.. 不均衡样本 
.. 常见的数据分布 
. 赛题数据探索 
.. 导入工具包 
.. 读取数据 
.. 数据集样例查看 
.. 查看数据类型和数据
大小 
.. 查看缺失值 
.. 观察数据分布 
.. 探查影响复购的各种
因素 
 特征工程 
. 特征工程介绍 
.. 特征工程的概念 
.. 特征归一化 
.. 类别型特征的转换 
.. 高维组合特征的处理 
.. 组合特征 
.. 文本表示模型 
. 赛题特征工程思路 
. 赛题特征工程构造 
.. 工具导入 
.. 数据读取 
.. 对数据进行内存压缩 
.. 数据处理 
.. 定义特征统计函数 
.. 提取统计特征 
.. 利用Countvector和
TF-IDF提取特征 
.. 嵌入特征 

.. Stacking分类特征 
 模型训练 
. 分类的概念 
. 分类相关模型 
.. 逻辑回归分类模型 
.. K近邻分类模型 
.. 高斯贝叶斯分类模型 
.. 决策树分类模型 
.. 集成学习分类模型 
 模型验证 
. 模型验证指标 
.. 准确度 
.. 查准率和查全率 
.. F值 
.. 分类报告 
.. 混淆矩阵 
.. ROC 
.. AUC曲线 
. 赛题模型验证和评估 
.. 基础代码 
.. 简单验证 
.. 设置交叉验证方式 
.. 模型调参 
.. 混淆矩阵 
.. 不同的分类模型 
.. 自己封装模型 
 特征优化 
. 特征选择技巧 
. 赛题特征优化 
.. 基础代码 
.. 缺失值补全 
.. 特征选择 
赛题三 OO优惠券预测
 赛题理解 
. 赛题介绍 
. 赛题分析 
 数据探索 
. 理论知识 
.. 数据探索的定义 
.. 数据探索的目的 
.. 相关Python包 
. 初步的数据探索 
.. 数据读取 
.. 数据查看 
.. 数据边界探索 
.. 训练集与测试集的
相关性 
.. 数据统计 
. 数据分布 
.. 对文本数据的数值化
处理 
.. 数据分布可视化 
 特征工程 
. 赛题特征工程思路 
. 赛题特征构建 
.. 工具函数 
.. 特征群生成函数 
.. 特征集成函数 
.. 特征输出 
. 对特征进行探索 
.. 特征读取函数 
.. 特征总览 
.. 查看特征的分布 
.. 特征相关性分析 
 模型训练 
. 模型训练与评估 
. 不同算法模型的性能对比 
.. 朴素贝叶斯 
.. 逻辑回归 
.. 决策树 
.. 随机森林 
.. XGBoost 
.. LightGBM 
.. 不同特征效果对比 
. 结果输出 
 模型验证 
. 评估指标 
. 交叉验证 
. 模型比较 
. 验证结果可视化 
. 结果分析 
. 模型调参 
. 实际方案 
 提交结果 
. 整合及输出结果 
. 结果提交及线上验证 
赛题四 阿里云安全恶意程序检测
 赛题理解 
. 赛题介绍 
. 赛题分析 
 数据探索 
. 训练集数据探索 
.. 数据特征类型 
.. 数据分布 
.. 缺失值 
.. 异常值 
.. 标签分布 
. 测试集数据探索 
.. 数据信息 
.. 缺失值 
.. 数据分布 
.. 异常值 
. 数据集联合分析 
.. file_id分析 
.. API分析 
 特征工程与基线模型 
. 特征工程概述 
.. 特征工程介绍 
.. 构造特征 
.. 特征选择 
. 构造线下验证集 
.. 评估穿越 
.. 训练集和测试集的特征
差异性 
.. 训练集和测试集的分布
差异性 
. 基线模型 
.. 数据读取 
.. 特征工程 

.. 基线构建 
.. 特征重要性分析 
.. 模型测试 
 高阶数据探索 
. 变量分析 
. 高阶数据探索实战 
.. 数据读取 
.. 多变量交叉探索 
 特征工程进阶与方案优化 
. pivot特征构建 
.. pivot特征 
.. pivot特征构建时间 
.. pivot特征构建细节和
特点 
. 业务理解和结果分析 
.. 结合模型理解业务 
.. 多分类问题预测结果
分析 
. 特征工程进阶实践 
.. 特征工程基础部分 
.. 特征工程进阶部分 
.. 基于LightGBM的模型
验证 
.. 模型结果分析 
.. 模型测试 
 优化技巧与解决方案升级 
. 优化技巧：Python处理大数据
的技巧 
.. 内存管理控制 
.. 加速数据处理的技巧 
.. 其他开源工具包 
. 深度学习解决方案：TextCNN
建模 
.. 问题转化 
.. TextCNN建模 
.. 数据预处理 
.. TextCNN网络结构 
.. TextCNN训练和测试 
.. 结果提交 
 开源方案学习 
・ ・ ・ ・ ・ ・ (收起)第一部分 通用流程
第　章 问题建模　
.　评估指标　
..　分类指标　
..　回归指标　
..　排序指标　
.　样本选择　
..　数据去噪　
..　采样　
..　原型选择和训练集选择　
.　交叉验证　
..　留出法　
..　K折交叉验证　
..　自助法　
参考文献　
第　章 特征工程　
.　特征提取　
..　探索性数据分析　
..　数值特征　
..　类别特征　
..　时间特征　
..　空间特征　
..　文本特征　
.　特征选择　
..　过滤方法　
..　封装方法　
..　嵌入方法　
..　小结　
..　工具介绍　
参考文献　
第章　常用模型　
.　逻辑回归　
..　逻辑回归原理　
..　逻辑回归应用　
.　场感知因子分解机　
..　因子分解机原理　
..　场感知因子分解机原理　
..　场感知因子分解机的应用　
.　梯度提升树　
..　梯度提升树原理　
..　梯度提升树的应用　
参考文献　
第章　模型融合　
.　理论分析　
..　融合收益　
..　模型误差 分歧分解　
..　模型多样性度量　
..　多样性增强　
.　融合方法　
..　平均法　
..　投票法　
..　Bagging　
..　Stacking　
..　小结　
参考文献　
第二部分　数据挖掘
第章　用户画像　
.　什么是用户画像　
.　用户画像数据挖掘　
..　画像数据挖掘整体架构　
..　用户标识　
..　特征数据　
..　样本数据　
..　标签建模　
.　用户画像应用　
..　用户画像实时查询系统　
..　人群画像分析系统　
..　其他系统　
..　线上应用效果　
.　小结　
参考文献　
第章　POI实体链接　
.　问题的背景与难点　
.　国内酒店POI实体链接解决方案　
..　酒店POI实体链接　
..　数据清洗　
..　特征生成　
..　模型选择与效果评估　
..　索引粒度的配置　
.　其他场景的策略调整　
.　小结　
第章　评论挖掘　
.　评论挖掘的背景　
..　评论挖掘的粒度　
..　评论挖掘的维度　
..　评论挖掘的整合思考　
.　评论标签提取　
..　数据的获取及预处理　
..　无监督的标签提取方法　
..　基于深度学习的标签提取方法　
.　标签情感分析　
..　评论标签情感分析的特殊性　
..　基于深度学习的情感分析方法　
..　评论标签情感分析的后续优 化与思考　
.　评论挖掘的未来应用及实践　
.　小结　
参考文献　
第三部分　搜索和推荐
第章　OO场景下的查询理解与 用户引导　
.　现代搜索引擎原理　
.　精确理解查询　
..　用户查询意图的定义与识别　
..　查询实体识别与结构化　
..　召回策略的变迁　
..　查询改写　
..　词权重与相关性计算　
..　类目相关性与人工标注　
..　查询理解小结　
.　引导用户完成搜索　
..　用户引导的产品定义与衡量 标准　
..　搜索前的引导――查询词 推荐　
..　搜索中的引导――查询补全　
..　搜索后的引导――相关搜索　
..　效率提升与效果提升　
..　用户引导小结　
.　小结　
参考文献　
第章　OO场景下排序的特点　
.　系统概述　
.　在线排序服务　
.　多层正交A/B测试　
.　特征获取　
.　离线调研系统　
.　特征工程　
.　排序模型　
.　场景化排序　
.　小结　
第　章 推荐在OO场景的应用　
.　典型的OO推荐场景　
.　OO推荐场景特点　
..　OO场景的地理位置因素　
..　OO场景的用户历史行为　
..　OO场景的实时推荐　
.　美团推荐实践――推荐框架　
.　美团推荐实践――推荐召回　
..　基于协同过滤的召回　
..　基于位置的召回　
..　基于搜索查询的召回　
..　基于图的召回　
..　基于实时用户行为的召回　
..　替补策略　
.　美团推荐实践――推荐排序　
..　排序特征　
..　排序样本　
..　排序模型　
.　推荐评价指标　
参考文献　
第四部分　计算广告
第　章 OO场景下的广告营销　
.　OO场景下的广告业务特点　
.　商户、用户和平台三者利益平衡　
..　商户效果感知　
..　用户体验　
..　平台收益　
.　OO广告机制设计　
..　广告位设定　
..　广告召回机制　
..　广告排序机制　
.　OO推送广告　
.　OO广告系统工具　
..　面向开发人员的系统工具　
..　面向广告主和运营人员的 工具　
.　小结　
参考文献　
第　章 用户偏好和损失建模　
.　如何定义用户偏好　
..　什么是用户偏好　
..　如何衡量用户偏好　
..　对不同POI 的偏好　
..　用户对 POI 偏好的衡量　
.　广告价值与偏好损失的兑换　
..　优化目标　
..　模型建模　
.　Pairwise 模型学习　
..　GBRank　
..　RankNet　
参考文献　
第五部分　深度学习
第　章 深度学习概述　
.　深度学习技术发展历程　
.　深度学习基础结构　
.　深度学习研究热点　
..　基于深度学习的生成式模型　
..　深度强化学习　
参考文献　
第　章 深度学习在文本领域的应用　
.　基于深度学习的文本匹配　
.　基于深度学习的排序模型　
..　排序模型简介　
..　深度学习排序模型的演进　
..　美团的深度学习排序模型 尝试　
.　小结　
参考文献　
第　章 深度学习在计算机视觉中的 应用　
.　基于深度学习的OCR　
..　OCR技术发展历程　
..　基于深度学习的文字检测　
..　基于序列学习的文字识别　
..　小结　
.　基于深度学习的图像智能审核　
..　基于深度学习的水印检测　
..　明星脸识别　
..　色情图片检测　
..　场景分类　
.　基于深度学习的图像质量排序　
..　图像美学质量评价　
..　面向点击预测的图像质量 评价　
.　小结　
参考文献　
第六部分　算法工程
第　章 大规模机器学习　
.　并行计算编程技术　
..　向量化　
..　多核并行OpenMP　
..　GPU编程　
..　多机并行MPI　
..　并行编程技术小结　
.　并行计算模型　
..　BSP　
..　SSP　
..　ASP　
..　参数服务器　
.　并行计算案例　
..　XGBoost并行库Rabit　
..　MXNet并行库PS-Lite　
.　美团并行计算机器学习平台　
参考文献　
第　章 特征工程和实验平台　
.　特征平台　
..　特征生产　
..　特征上线　
..　在线特征监控　
.　实验管理平台　
..　实验平台概述　
..　美团实验平台――Gemini　
・ ・ ・ ・ ・ ・ (收起)第章 向量和向量空间 
. 向量 
.. 描述向量 
.. 向量的加法 
.. 向量的数量乘法 
. 向量空间 
.. 什么是向量空间 
.. 线性组合 
.. 线性无关 
.. 子空间 
. 基和维数 
.. 极大线性无关组 
.. 基 
.. 维数 
. 内积空间 
.. 什么是内积空间 
.. 点积和欧几里得空间 
. 距离和角度 
.. 距离 
.. 基于距离的分类 
.. 范数和正则化 
.. 角度 
. 非欧几何 
第章 矩阵 
. 基础知识 
.. 什么是矩阵 
.. 初等变换 
.. 矩阵加法 
.. 数量乘法 
.. 矩阵乘法 
. 线性映射 
.. 理解什么是线性 
.. 线性映射 
.. 矩阵与线性映射 
.. 齐次坐标系 
. 矩阵的逆和转置 
.. 逆矩阵 
.. 转置矩阵 
.. 矩阵LU分解 
. 行列式 
.. 计算方法和意义 
.. 线性方程组 
. 矩阵的秩 
. 稀疏矩阵 
.. 生成稀疏矩阵 
.. 稀疏矩阵压缩 
. 图与矩阵 
.. 图的基本概念 
.. 邻接矩阵 
.. 关联矩阵 
.. 拉普拉斯矩阵 
第章 特征值和特征向量 
. 基本概念 
.. 定义 
.. 矩阵的迹 
.. 一般性质 
. 应用示例 
.. 动力系统微分方程 
.. 马尔科夫矩阵 
. 相似矩阵 
.. 相似变换 
.. 几何理解 
.. 对角化 
. 正交和投影 
.. 正交集和标准正交基 
.. 正交矩阵 
.. 再探对称矩阵 
.. 投影 
. 矩阵分解 
.. QR分解 
.. 特征分解 
.. 奇异值分解 
.. 数据压缩 
.. 降噪 
. 最小二乘法（） 
.. 正规方程 
.. 线性回归（） 
第章 向量分析 
. 向量的代数运算 
.. 叉积 
.. 张量和外积 
. 向量微分 
.. 函数及其导数 
.. 偏导数 
.. 梯度 
.. 矩阵导数 
. 最优化方法 
.. 简单的线性规划 
.. 最小二乘法（） 
.. 梯度下降法 
.. 线性回归（） 
.. 牛顿法 
. 反向传播算法 
.. 神经网络 
.. 参数学习 
.. 损失函数 
.. 激活函数 
.. 理论推导 
第章 概率 
. 基本概念 
.. 试验和事件 
.. 理解概率 
.. 条件概率 
. 贝叶斯定理 
.. 事件的独立性 
.. 全概率公式 
.. 理解贝叶斯定理 
. 随机变量和概率分布 
.. 随机变量 
.. 离散型随机变量的分布 
.. 连续型随机变量的分布 
.. 多维随机变量及分布 
.. 条件概率分布 
. 随机变量的和 
.. 离散型随机变量的和 
.. 连续型随机变量的和 
. 随机变量的数字特征 
.. 数学期望 
.. 方差和协方差 
.. 计算相似度 
.. 协方差矩阵 
第章 数理统计 
. 样本和抽样 
.. 总体和样本 
.. 统计量 
. 点估计 
.. 最大似然估计 
.. 线性回归（） 
.. 最大后验估计 
.. 估计的选择标准 
. 区间估计 
. 参数检验 
.. 基本概念 
.. 正态总体均值的假设检验 
.. 正态总体方差的假设检验 
.. p值检验 
.. 用假设检验比较模型 
. 非参数检验 
.. 拟合优度检验 
.. 列联表检验 
第章 信息与熵 
. 度量信息 
. 信息熵 
. 联合熵和条件熵 
. 相对熵和交叉熵 
. 互信息 
. 连续分布 
附录 
后记 
・ ・ ・ ・ ・ ・ (收起)目　录

第一部分　分类
第章　机器学习基础　　
. 　何谓机器学习　　
.. 　传感器和海量数据　　
.. 　机器学习非常重要　　
. 　关键术语　　
. 　机器学习的主要任务　　
. 　如何选择合适的算法　　
. 　开发机器学习应用程序的步骤　　
. 　Python语言的优势　　
.. 　可执行伪代码　　
.. 　Python比较流行　　
.. 　Python语言的特色　　
.. 　Python语言的缺点　　
. 　NumPy函数库基础　　
. 　本章小结　　
第章　k-近邻算法 　　
. 　k-近邻算法概述　　
.. 　准备：使用Python导入数据　　
.. 　从文本文件中解析数据　　
.. 　如何测试分类器　　
. 　示例：使用k-近邻算法改进约会网站的配对效果　　
.. 　准备数据：从文本文件中解析数据　　
.. 　分析数据：使用Matplotlib创建散点图　　
.. 　准备数据：归一化数值　　
.. 　测试算法：作为完整程序验证分类器　　
.. 　使用算法：构建完整可用系统　　
. 　示例：手写识别系统　　
.. 　准备数据：将图像转换为测试向量　　
.. 　测试算法：使用k-近邻算法识别手写数字　　
. 　本章小结　　
第章　决策树 　　
. 　决策树的构造　　
.. 　信息增益　　
.. 　划分数据集　　
.. 　递归构建决策树　　
. 　在Python中使用Matplotlib注解绘制树形图　　
.. 　Matplotlib注解　　
.. 　构造注解树　　
. 　测试和存储分类器　　
.. 　测试算法：使用决策树执行分类　　
.. 　使用算法：决策树的存储　　
. 　示例：使用决策树预测隐形眼镜类型　　
. 　本章小结　　
第章　基于概率论的分类方法：朴素贝叶斯 　　
. 　基于贝叶斯决策理论的分类方法　　
. 　条件概率　　
. 　使用条件概率来分类　　
. 　使用朴素贝叶斯进行文档分类　　
. 　使用Python进行文本分类　　
.. 　准备数据：从文本中构建词向量　　
.. 　训练算法：从词向量计算概率　　
.. 　测试算法：根据现实情况修改分类器　　
.. 　准备数据：文档词袋模型　　
. 　示例：使用朴素贝叶斯过滤垃圾邮件　　
.. 　准备数据：切分文本　　
.. 　测试算法：使用朴素贝叶斯进行交叉验证　　
. 　示例：使用朴素贝叶斯分类器从个人广告中获取区域倾向　　
.. 　收集数据：导入RSS源　　
.. 　分析数据：显示地域相关的用词　　
. 　本章小结　　
第章　Logistic回归 　　
. 　基于Logistic回归和Sigmoid函数的分类　　
. 　基于最优化方法的最佳回归系数确定　　
.. 　梯度上升法　　
.. 　训练算法：使用梯度上升找到最佳参数　　
.. 　分析数据：画出决策边界　　
.. 　训练算法：随机梯度上升　　
. 　示例：从疝气病症预测病马的死亡率　　
.. 　准备数据：处理数据中的缺失值　　
.. 　测试算法：用Logistic回归进行分类　　
. 　本章小结　　
第章　支持向量机　　
. 　基于最大间隔分隔数据　　
. 　寻找最大间隔　　
.. 　分类器求解的优化问题　　
.. 　SVM应用的一般框架　　
. 　SMO高效优化算法　　
.. 　Platt的SMO算法　　
.. 　应用简化版SMO算法处理小规模数据集　　
. 　利用完整Platt SMO算法加速优化　　
. 　在复杂数据上应用核函数　　
.. 　利用核函数将数据映射到高维空间　　
.. 　径向基核函数　　
.. 　在测试中使用核函数　　
. 　示例：手写识别问题回顾　　
. 　本章小结　　
第章　利用AdaBoost元算法提高分类
性能 　　
. 　基于数据集多重抽样的分类器　　
.. 　bagging：基于数据随机重抽样的分类器构建方法　　
.. 　boosting　　
. 　训练算法：基于错误提升分类器的性能　　
. 　基于单层决策树构建弱分类器　　
. 　完整AdaBoost算法的实现　　
. 　测试算法：基于AdaBoost的分类　　
. 　示例：在一个难数据集上应用AdaBoost　　
. 　非均衡分类问题　　
.. 　其他分类性能度量指标：正确率、召回率及ROC曲线　　
.. 　基于代价函数的分类器决策控制　　
.. 　处理非均衡问题的数据抽样方法　　
. 　本章小结　　
第二部分　利用回归预测数值型数据
第章　预测数值型数据：回归 　　
. 　用线性回归找到最佳拟合直线　　
. 　局部加权线性回归　　
. 　示例：预测鲍鱼的年龄　　
. 　缩减系数来“理解”数据　　
.. 　岭回归　　
.. 　lasso　　
.. 　前向逐步回归　　
. 　权衡偏差与方差　　
. 　示例：预测乐高玩具套装的价格　　
.. 　收集数据：使用Google购物的API　　
.. 　训练算法：建立模型　　
. 　本章小结　　
第章　树回归　　
. 　复杂数据的局部性建模　　
. 　连续和离散型特征的树的构建　　
. 　将CART算法用于回归　　
.. 　构建树　　
.. 　运行代码　　
. 　树剪枝　　
.. 　预剪枝　　
.. 　后剪枝　　
. 　模型树　　
. 　示例：树回归与标准回归的比较　　
. 　使用Python的Tkinter库创建GUI　　
.. 　用Tkinter创建GUI　　
.. 　集成Matplotlib和Tkinter　　
. 　本章小结　　
第三部分　无监督学习
第章　利用K-均值聚类算法对未标注数据分组　　
. 　K-均值聚类算法　　
. 　使用后处理来提高聚类性能　　
. 　二分K-均值算法　　
. 　示例：对地图上的点进行聚类　　
.. 　Yahoo! PlaceFinder API　　
.. 　对地理坐标进行聚类　　
. 　本章小结　　
第章　使用Apriori算法进行关联分析　　
. 　关联分析　　
. 　Apriori原理　　
. 　使用Apriori算法来发现频繁集　　
.. 　生成候选项集　　
.. 　组织完整的Apriori算法　　
. 　从频繁项集中挖掘关联规则　　
. 　示例：发现国会投票中的模式　　
.. 　收集数据：构建美国国会投票记录的事务数据集　　
.. 　测试算法：基于美国国会投票记录挖掘关联规则　　
. 　示例：发现毒蘑菇的相似特征　　
. 　本章小结　　
第章　使用FP-growth算法来高效发现频繁项集　　
. 　FP树：用于编码数据集的有效方式　　
. 　构建FP树　　
.. 　创建FP树的数据结构　　
.. 　构建FP树　　
. 　从一棵FP树中挖掘频繁项集　　
.. 　抽取条件模式基　　
.. 　创建条件FP树　　
. 　示例：在Twitter源中发现一些共现词　　
. 　示例：从新闻网站点击流中挖掘　　
. 　本章小结　　
第四部分　其他工具
第章　利用PCA来简化数据　　
. 　降维技术　　
. 　PCA　　
.. 　移动坐标轴　　
.. 　在NumPy中实现PCA　　
. 　示例：利用PCA对半导体制造数据降维　　
. 　本章小结　　
第章　利用SVD简化数据　　
. 　SVD的应用　　
.. 　隐性语义索引　　
.. 　推荐系统　　
. 　矩阵分解　　
. 　利用Python实现SVD　　
. 　基于协同过滤的推荐引擎　　
.. 　相似度计算　　
.. 　基于物品的相似度还是基于用户的相似度？　　
.. 　推荐引擎的评价　　
. 　示例：餐馆菜肴推荐引擎　　
.. 　推荐未尝过的菜肴　　
.. 　利用SVD提高推荐的效果　　
.. 　构建推荐引擎面临的挑战　　
. 　基于SVD的图像压缩　　
. 　本章小结　　
第章　大数据与MapReduce　　
. 　MapReduce：分布式计算的框架　　
. 　Hadoop流　　
.. 　分布式计算均值和方差的mapper　　
.. 　分布式计算均值和方差的reducer　　
. 　在Amazon网络服务上运行Hadoop程序　　
.. 　AWS上的可用服务　　
.. 　开启Amazon网络服务之旅　　
.. 　在EMR上运行Hadoop作业　　
. 　MapReduce上的机器学习　　
. 　在Python中使用mrjob来自动化MapReduce　　
.. 　mrjob与EMR的无缝集成　　
.. 　mrjob的一个MapReduce脚本剖析　　
. 　示例：分布式SVM的Pegasos算法　　
.. 　Pegasos算法　　
.. 　训练算法：用mrjob实现MapReduce版本的SVM　　
. 　你真的需要MapReduce吗？　　
. 　本章小结　　
附录A 　Python入门　　
附录B 　线性代数　　
附录C 　概率论复习　　
附录D 　资源　　
索引　　
版权声明　　
・ ・ ・ ・ ・ ・ (收起)第章　Spark的环境搭建与运行　　
.　Spark的本地安装与配置　　
.　Spark集群　　
.　Spark编程模型　　
..　SparkContext类与SparkConf 类　　
..　Spark shell　　
..　弹性分布式数据集　　
..　广播变量和累加器　　
.　Spark Scala编程入门　　
.　Spark Java编程入门　　
.　Spark Python编程入门　　
.　在Amazon EC上运行Spark　　
.　小结　　
第章　设计机器学习系统　　
.　MovieStream介绍　　
.　机器学习系统商业用例　　
..　个性化　　
..　目标营销和客户细分　　
..　预测建模与分析　　
.　机器学习模型的种类　　
.　数据驱动的机器学习系统的组成　　
..　数据获取与存储　　
..　数据清理与转换　　
..　模型训练与测试回路　　
..　模型部署与整合　　
..　模型监控与反馈　　
..　批处理或实时方案的选择　　
.　机器学习系统架构　　
.　小结　　
第章　Spark上数据的获取、处理与准备　　
.　获取公开数据集　　
.　探索与可视化数据　　
..　探索用户数据　　
..　探索电影数据　　
..　探索评级数据　　
.　处理与转换数据　　
.　从数据中提取有用特征　　
..　数值特征　　
..　类别特征　　
..　派生特征　　
..　文本特征　　
..　正则化特征　　
..　用软件包提取特征　　
.　小结　　
第章　构建基于Spark的推荐引擎　　
.　推荐模型的分类　　
..　基于内容的过滤　　
..　协同过滤　　
..　矩阵分解　　
.　提取有效特征　　
.　训练推荐模型　　
..　使用MovieLens k数据集训练模型　　
..　使用隐式反馈数据训练模型　　
.　使用推荐模型　　
..　用户推荐　　
..　物品推荐　　
.　推荐模型效果的评估　　
..　均方差　　
..　K值平均准确率　　
..　使用MLlib内置的评估函数　　
.　小结　　
第章　Spark构建分类模型　　
.　分类模型的种类　　
..　线性模型　　
..　朴素贝叶斯模型　　
..　决策树　　
.　从数据中抽取合适的特征　　
.　训练分类模型　　
.　使用分类模型　　
.　评估分类模型的性能　　
..　预测的正确率和错误率　　
..　准确率和召回率　　
..　ROC曲线和AUC　　
.　改进模型性能以及参数调优　　
..　特征标准化　　
..　其他特征　　
..　使用正确的数据格式　　
..　模型参数调优　　
.　小结　　
第章　Spark构建回归模型　　
.　回归模型的种类　　
..　最小二乘回归　　
..　决策树回归　　
.　从数据中抽取合适的特征　　
.　回归模型的训练和应用　　
.　评估回归模型的性能　　
..　均方误差和均方根误差　　
..　平均绝对误差　　
..　均方根对数误差　　
..　R-平方系数　　
..　计算不同度量下的性能　　
.　改进模型性能和参数调优　　
..　变换目标变量　　
..　模型参数调优　　
.　小结　　
第章　Spark构建聚类模型　　
.　聚类模型的类型　　
..　K-均值聚类　　
..　混合模型　　
..　层次聚类　　
.　从数据中提取正确的特征　　
.　训练聚类模型　　
.　使用聚类模型进行预测　　
.　评估聚类模型的性能　　
..　内部评价指标　　
..　外部评价指标　　
..　在MovieLens数据集计算性能　　
.　聚类模型参数调优　　
.　小结　　
第章　Spark应用于数据降维　　
.　降维方法的种类　　
..　主成分分析　　
..　奇异值分解　　
..　和矩阵分解的关系　　
..　聚类作为降维的方法　　
.　从数据中抽取合适的特征　　
.　训练降维模型　　
.　使用降维模型　　
..　在LFW数据集上使用PCA投影数据　　
..　PCA和SVD模型的关系　　
.　评价降维模型　　
.　小结　　
第章　Spark高级文本处理技术　　
.　处理文本数据有什么特别之处　　
.　从数据中抽取合适的特征　　
..　短语加权表示　　
..　特征哈希　　
..　从新闻组数据集中提取TF-IDF特征　　
.　使用TF-IDF模型　　
..　 Newsgroups数据集的文本相似度和TF-IDF特征　　
..　基于 Newsgroups数据集使用TF-IDF训练文本分类器　　
.　评估文本处理技术的作用　　
.　WordVec 模型　　
.　小结　　
第章　Spark Streaming在实时机器学习上的应用　　
.　在线学习　　
.　流处理　　
..　Spark Streaming介绍　　
..　使用Spark Streaming缓存和容错　　
.　创建Spark Streaming应用　　
..　消息生成端　　
..　创建简单的流处理程序　　
..　流式分析　　
..　有状态的流计算　　
.　使用Spark Streaming进行在线学习　　
..　流回归　　
..　一个简单的流回归程序　　
..　流K-均值　　
.　在线模型评估　　
.　小结　　
・ ・ ・ ・ ・ ・ (收起)第 章一元函数微积分
. 极限与连续. . . . . . . . . . . . . . 
.. 可数集与不可数集. . . . . . . . 
.. 数列的极限. . . . . . . . . . . . 
.. 函数的极限. . . . . . . . . . . . 
.. 函数的连续性与间断点. . . . . 
.. 上确界与下确界. . . . . . . . . 
.. 李普希茨连续性. . . . . . . . . 
.. 无穷小量. . . . . . . . . . . . . 
. 导数与微分. . . . . . . . . . . . . . 
.. 一阶导数. . . . . . . . . . . . . 
.. 机器学习中的常用函数. . . . . 
.. 高阶导数. . . . . . . . . . . . . 
.. 微分. . . . . . . . . . . . . . . . 
.. 导数与函数的单调性. . . . . . 
.. 极值判别法则. . . . . . . . . . 
.. 导数与函数的凹凸性. . . . . . 
. 微分中值定理. . . . . . . . . . . . . 
.. 罗尔中值定理. . . . . . . . . . 
.. 拉格朗日中值定理. . . . . . . . 
.. 柯西中值定理. . . . . . . . . . 
. 泰勒公式. . . . . . . . . . . . . . . . 
. 不定积分. . . . . . . . . . . . . . . . 
.. 不定积分的定义与性质. . . . . 
.. 换元积分法. . . . . . . . . . . . 
.. 分部积分法. . . . . . . . . . . . 
. 定积分. . . . . . . . . . . . . . . . . 
.. 定积分的定义与性质. . . . . . 
.. 牛顿-莱布尼茨公式. . . . . . . 
.. 定积分的计算. . . . . . . . . . 
.. 变上限积分. . . . . . . . . . . . 
.. 定积分的应用. . . . . . . . . . 
.. 广义积分. . . . . . . . . . . . . 
. 常微分方程. . . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 一阶线性微分方程. . . . . . . . 
第 章线性代数与矩阵论
. 向量及其运算. . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 基本运算. . . . . . . . . . . . . 
.. 向量的范数. . . . . . . . . . . . 
.. 解析几何. . . . . . . . . . . . . 
.. 线性相关性. . . . . . . . . . . . 
.. 向量空间. . . . . . . . . . . . . 
.. 应用――线性回归. . . . . . . . 
.. 应用――线性分类器与支持
向量机. . . . . . . . . . . . . . 
. 矩阵及其运算. . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 基本运算. . . . . . . . . . . . . 
.. 逆矩阵. . . . . . . . . . . . . . 
.. 矩阵的范数. . . . . . . . . . . . 
.. 应用――人工神经网络. . . . . 
.. 线性变换. . . . . . . . . . . . . 
. 行列式. . . . . . . . . . . . . . . . . 
.. 行列式的定义与性质. . . . . . 
.. 计算方法. . . . . . . . . . . . . 
. 线性方程组. . . . . . . . . . . . . . 
.. 高斯消元法. . . . . . . . . . . . 
.. 齐次方程组. . . . . . . . . . . . 
.. 非齐次方程组. . . . . . . . . . 
. 特征值与特征向量. . . . . . . . . . 
.. 特征值与特征向量. . . . . . . . 
.. 相似变换. . . . . . . . . . . . . 
.. 正交变换. . . . . . . . . . . . . 
.. QR 算法. . . . . . . . . . . . . . 
.. 广义特征值. . . . . . . . . . . . 
.. 瑞利商. . . . . . . . . . . . . . 
.. 谱范数与特征值的关系. . . . . 
.. 条件数. . . . . . . . . . . . . . 
.. 应用――谱归一化与谱正则化. . . . . . . . . . . . . . . . . 
. 二次型. . . . . . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 正定二次型与正定矩阵. . . . . 
.. 标准型. . . . . . . . . . . . . . 
. 矩阵分解. . . . . . . . . . . . . . . . 
.. 楚列斯基分解. . . . . . . . . . 
.. QR 分解. . . . . . . . . . . . . . 
.. 特征值分解. . . . . . . . . . . . 
.. 奇异值分解. . . . . . . . . . . . 
第 章多元函数微积分
. 偏导数. . . . . . . . . . . . . . . . . 
.. 一阶偏导数. . . . . . . . . . . . 
.. 高阶偏导数. . . . . . . . . . . . 
.. 全微分. . . . . . . . . . . . . . 
.. 链式法则. . . . . . . . . . . . . 
. 梯度与方向导数. . . . . . . . . . . . 
.. 梯度. . . . . . . . . . . . . . . . 
.. 方向导数. . . . . . . . . . . . . 
.. 应用――边缘检测与HOG
特征. . . . . . . . . . . . . . . . 
. 黑塞矩阵. . . . . . . . . . . . . . . . 
.. 黑塞矩阵的定义与性质. . . . . 
.. 凹凸性. . . . . . . . . . . . . . 
.. 极值判别法则. . . . . . . . . . 
.. 应用――最小二乘法. . . . . . . 
. 雅可比矩阵. . . . . . . . . . . . . . 
.. 雅可比矩阵的定义和性质. . . . 
.. 链式法则的矩阵形式. . . . . . 
. 向量与矩阵求导. . . . . . . . . . . . 
.. 常用求导公式. . . . . . . . . . 
.. 应用――反向传播算法. . . . . 
. 微分算法. . . . . . . . . . . . . . . . 
.. 符号微分. . . . . . . . . . . . . 
.. 数值微分. . . . . . . . . . . . . 
.. 自动微分. . . . . . . . . . . . . 
. 泰勒公式. . . . . . . . . . . . . . . . 
. 多重积分. . . . . . . . . . . . . . . . 
.. 二重积分. . . . . . . . . . . . . 
.. 三重积分. . . . . . . . . . . . . 
.. n 重积分. . . . . . . . . . . . . 
. 无穷级数. . . . . . . . . . . . . . . . 
.. 常数项级数. . . . . . . . . . . . 
.. 函数项级数. . . . . . . . . . . . 
第 章最优化方法
. 基本概念. . . . . . . . . . . . . . . . 
.. 问题定义. . . . . . . . . . . . . 
.. 迭代法的基本思想. . . . . . . . 
. 一阶优化算法. . . . . . . . . . . . . 
.. 梯度下降法. . . . . . . . . . . . 
.. 最速下降法. . . . . . . . . . . . 
.. 梯度下降法的改进. . . . . . . . 
.. 随机梯度下降法. . . . . . . . . 
.. 应用――人工神经网络. . . . . 
. 二阶优化算法. . . . . . . . . . . . . 
.. 牛顿法. . . . . . . . . . . . . . 
.. 拟牛顿法. . . . . . . . . . . . . 
. 分治法. . . . . . . . . . . . . . . . . 
.. 坐标下降法. . . . . . . . . . . . 
.. SMO 算法. . . . . . . . . . . . . 
.. 分阶段优化. . . . . . . . . . . . 
.. 应用――logistic 回归. . . . . . 
. 凸优化问题. . . . . . . . . . . . . . 
.. 数值优化算法面临的问题. . . . 
.. 凸集. . . . . . . . . . . . . . . . 
.. 凸优化问题及其性质. . . . . . 
.. 机器学习中的凸优化问题. . . . 
. 带约束的优化问题. . . . . . . . . . 
.. 拉格朗日乘数法. . . . . . . . . 
.. 应用――线性判别分析. . . . . 
.. 拉格朗日对偶. . . . . . . . . . 
.. KKT 条件. . . . . . . . . . . . . 
.. 应用――支持向量机. . . . . . . 
. 多目标优化问题. . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 求解算法. . . . . . . . . . . . . 
.. 应用――多目标神经结构搜
索. . . . . . . . . . . . . . . . . 
. 泛函极值与变分法. . . . . . . . . . 
.. 泛函与变分. . . . . . . . . . . . 
.. 欧拉―拉格朗日方程. . . . . . 
.. 应用――证明两点之间直线
最短. . . . . . . . . . . . . . . . 
. 目标函数的构造. . . . . . . . . . . . 
.. 有监督学习. . . . . . . . . . . . 
.. 无监督学习. . . . . . . . . . . . 
.. 强化学习. . . . . . . . . . . . . 
第 章概率论
. 随机事件与概率. . . . . . . . . . . . 
.. 随机事件概率. . . . . . . . . . 
.. 条件概率. . . . . . . . . . . . . 
.. 全概率公式. . . . . . . . . . . . 
.. 贝叶斯公式. . . . . . . . . . . . 
.. 条件独立. . . . . . . . . . . . . 
. 随机变量. . . . . . . . . . . . . . . . 
.. 离散型随机变量. . . . . . . . . 
.. 连续型随机变量. . . . . . . . . 
.. 数学期望. . . . . . . . . . . . . 
.. 方差与标准差. . . . . . . . . . 
.. Jensen 不等式. . . . . . . . . . . 
. 常用概率分布. . . . . . . . . . . . . 
.. 均匀分布. . . . . . . . . . . . . 
.. 伯努利分布. . . . . . . . . . . . 
.. 二项分布. . . . . . . . . . . . . 
.. 多项分布. . . . . . . . . . . . . 
.. 几何分布. . . . . . . . . . . . . 
.. 正态分布. . . . . . . . . . . . . 
.. t 分布. . . . . . . . . . . . . . . 
.. 应用――颜色直方图. . . . . . . 
.. 应用――贝叶斯分类器. . . . . 
. 分布变换. . . . . . . . . . . . . . . . 
.. 随机变量函数. . . . . . . . . . 
.. 逆变换采样算法. . . . . . . . . 
. 随机向量. . . . . . . . . . . . . . . . 
.. 离散型随机向量. . . . . . . . . 
.. 连续型随机向量. . . . . . . . . 
.. 数学期望. . . . . . . . . . . . . 
.. 协方差. . . . . . . . . . . . . . 
.. 常用概率分布. . . . . . . . . . 
.. 分布变换. . . . . . . . . . . . . 
.. 应用――高斯混合模型. . . . . 
. 极限定理. . . . . . . . . . . . . . . . 
.. 切比雪夫不等式. . . . . . . . . 
.. 大数定律. . . . . . . . . . . . . 
.. 中心极限定理. . . . . . . . . . 
. 参数估计. . . . . . . . . . . . . . . . 
.. 最大似然估计. . . . . . . . . . 
.. 最大后验概率估计. . . . . . . . 
.. 贝叶斯估计. . . . . . . . . . . . 
.. 核密度估计. . . . . . . . . . . . 
.. 应用――logistic 回归. . . . . . 
.. 应用――EM 算法. . . . . . . . 
.. 应用――Mean Shift 算法. . . . 
. 随机算法. . . . . . . . . . . . . . . . 
.. 基本随机数生成算法. . . . . . 
.. 遗传算法. . . . . . . . . . . . . 
.. 蒙特卡洛算法. . . . . . . . . . 
. 采样算法. . . . . . . . . . . . . . . . 
.. 拒绝采样. . . . . . . . . . . . . 
.. 重要性采样. . . . . . . . . . . . 
第 章信息论
. 熵与联合熵. . . . . . . . . . . . . . 
.. 信息量与熵. . . . . . . . . . . . 
.. 熵的性质. . . . . . . . . . . . . 
.. 应用――决策树. . . . . . . . . 
.. 联合熵. . . . . . . . . . . . . . 
. 交叉熵. . . . . . . . . . . . . . . . . 
.. 交叉熵的定义. . . . . . . . . . 
.. 交叉熵的性质. . . . . . . . . . 
.. 应用――softmax 回归. . . . . . 
. Kullback-Leibler 散度. . . . . . . . . 
.. KL 散度的定义. . . . . . . . . . 
.. KL 散度的性质. . . . . . . . . . 
.. 与交叉熵的关系. . . . . . . . . 
.. 应用――流形降维. . . . . . . . 
.. 应用――变分推断. . . . . . . . 
. Jensen-Shannon 散度. . . . . . . . . 
.. JS 散度的定义. . . . . . . . . . 
.. JS 散度的性质. . . . . . . . . . 
.. 应用――生成对抗网络. . . . . 
. 互信息. . . . . . . . . . . . . . . . . 
.. 互信息的定义. . . . . . . . . . 
.. 互信息的性质. . . . . . . . . . 
.. 与熵的关系. . . . . . . . . . . . 
.. 应用――特征选择. . . . . . . . 
. 条件熵. . . . . . . . . . . . . . . . . 
.. 条件熵定义. . . . . . . . . . . . 
.. 条件熵的性质. . . . . . . . . . 
.. 与熵以及互信息的关系. . . . . 
. 总结. . . . . . . . . . . . . . . . . . 
第 章随机过程
. 马尔可夫过程. . . . . . . . . . . . . 
.. 马尔可夫性. . . . . . . . . . . . 
.. 马尔可夫链的基本概念. . . . . 
.. 状态的性质与分类. . . . . . . . 
.. 平稳分布与极限分布. . . . . . 
.. 细致平衡条件. . . . . . . . . . 
.. 应用――隐马尔可夫模型. . . . 
.. 应用――强化学习. . . . . . . . 
. 马尔可夫链采样算法. . . . . . . . . 
.. 基本马尔可夫链采样. . . . . . 
.. MCMC 采样算法. . . . . . . . . 
.. Metropolis-Hastings 算法. . . . . 
.. Gibbs 算法. . . . . . . . . . . . 
. 高斯过程. . . . . . . . . . . . . . . . 
.. 高斯过程性质. . . . . . . . . . 
.. 高斯过程回归. . . . . . . . . . 
.. 应用――贝叶斯优化. . . . . . . 
第 章图论
. 图的基本概念. . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 应用――计算图与自动微分. . . 
.. 应用――概率图模型. . . . . . . 
.. 邻接矩阵与加权度矩阵. . . . . 
.. 应用――样本集的相似度图. . . 
. 若干特殊的图. . . . . . . . . . . . . 
.. 联通图. . . . . . . . . . . . . . 
.. 二部图. . . . . . . . . . . . . . 
.. 应用――受限玻尔兹曼机. . . . 
.. 有向无环图. . . . . . . . . . . . 
.. 应用――神经结构搜索. . . . . 
. 重要的算法. . . . . . . . . . . . . . 
.. 遍历算法. . . . . . . . . . . . . 
.. 最短路径算法. . . . . . . . . . 
.. 拓扑排序算法. . . . . . . . . . 
. 谱图理论. . . . . . . . . . . . . . . . 
.. 拉普拉斯矩阵. . . . . . . . . . 
.. 归一化拉普拉斯矩阵. . . . . . 
.. 应用――流形降维. . . . . . . . 
・ ・ ・ ・ ・ ・ (收起)绪论　机器学习概述　　
第章　机器学习的构成要素　　
.　任务：可通过机器学习解决的问题　　
..　探寻结构　　
..　性能评价　　
.　模型：机器学习的输出　　
..　几何模型　　
..　概率模型　　
..　逻辑模型　　
..　分组模型与评分模型　　
.　特征：机器学习的马达　　
..　特征的两种用法　　
..　特征的构造与变换　　
..　特征之间的交互　　
.　总结与展望　　
第章　两类分类及相关任务　　
.　分类　　
..　分类性能的评价　　
..　分类性能的可视化　　
.　评分与排序　　
..　排序性能的评价及可视化　　
..　将排序器转化为分类器　　
.　类概率估计　　
..　类概率估计量　　
..　将排序器转化为概率估计子　　
.　小结与延伸阅读　　
第章　超越两类分类　　
.　处理多类问题　　
..　多类分类　　
..　多类得分及概率　　
.　回归　　
.　无监督学习及描述性学习　　
..　预测性聚类与描述性聚类　　
..　其他描述性模型　　
.　小结与延伸阅读　　
第章　概念学习　　
.　假设空间　　
..　最小一般性　　
..　内部析取　　
.　通过假设空间的路径　　
..　最一般相容假设　　
..　封闭概念　　
.　超越合取概念　　
.　可学习性　　
.　小结与延伸阅读　　
第章　树模型　　
.　决策树　　
.　排序与概率估计树　　
.　作为减小方差的树学习方法　　
..　回归树　　
..　聚类树　　
.　小结与延伸阅读　　
第章　规则模型　　
.　学习有序规则列表　　
.　学习无序规则集　　
..　用于排序和概率估计的规则集　　
..　深入探究规则重叠　　
.　描述性规则学习　　
..　用于子群发现的规则学习　　
..　关联规则挖掘　　
.　一阶规则学习　　
.　小结与延伸阅读　　
第章　线性模型　　
.　最小二乘法　　
..　多元线性回归　　
..　正则化回归　　
..　利用最小二乘回归实现分类　　
.　感知机　　
.　支持向量机　　
.　从线性分类器导出概率　　
.　超越线性的核方法　　
.　小结与延伸阅读　　
第章　基于距离的模型　　
.　距离测度的多样性　　
.　近邻与范例　　
.　最近邻分类器　　
.　基于距离的聚类　　
..　K均值算法　　
..　K中心点聚类　　
..　silhouette　　
.　层次聚类　　
.　从核函数到距离　　
.　小结与延伸阅读　　
第章　概率模型　　
.　正态分布及其几何意义　　
.　属性数据的概率模型　　
..　利用朴素贝叶斯模型实现分类　　
..　训练朴素贝叶斯模型　　
.　通过优化条件似然实现鉴别式学习　　
.　含隐变量的概率模型　　
..　期望最大化算法　　
..　高斯混合模型　　
.　基于压缩的模型　　
.　小结与延伸阅读　　
第章　特征　　
.　特征的类型　　
..　特征上的计算　　
..　属性特征、有序特征及数量特征　　
..　结构化特征　　
.　特征变换　　
..　阈值化与离散化　　
..　归一化与标定　　
..　特征缺失　　
.　特征的构造与选择　　
.　小结与延伸阅读　　
第章　模型的集成　　
.　Bagging与随机森林　　
.　Boosting　　
.　集成学习进阶　　
..　偏差、方差及裕量　　
..　其他集成方法　　
..　元学习　　
.　小结与延伸阅读　　
第章　机器学习的实验　　
.　度量指标的选择　　
.　量指标的获取　　
.　如何解释度量指标　　
.　小结与延伸阅读　　
后记　路在何方　　
记忆要点　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)出版者的话
译者序
前言
缩写和符号
术语
第章 导言
. 什么是神经网络
. 人类大脑
. 神经元模型
. 被看作有向图的神经网络
. 反馈
. 网络结构
. 知识表示
. 学习过程
. 学习任务
. 结束语
注释和参考文献
第章 Rosenblatt感知器
. 引言
. 感知器
. 感知器收敛定理
. 高斯环境下感知器与贝叶斯分类器的关系
. 计算机实验：模式分类
. 批量感知器算法
. 小结和讨论
注释和参考文献
习题
第章 通过回归建立模型
. 引言
. 线性回归模型：初步考虑
. 参数向量的最大后验估计
. 正则最小二乘估计和MAP估计之间的关系
. 计算机实验：模式分类
. 最小描述长度原则
. 固定样本大小考虑
. 工具变量方法
. 小结和讨论
注释和参考文献
习题
第章 最小均方算法
. 引言
. LMS算法的滤波结构
. 无约束最优化：回顾
. 维纳滤波器
. 最小均方算法
. 用马尔可夫模型来描画LMS算法和维纳滤波器的偏差
. 朗之万方程：布朗运动的特点
. Kushner直接平均法
. 小学习率参数下统计LMS学习理论
. 计算机实验Ⅰ：线性预测
. 计算机实验Ⅱ：模式分类
. LMS算法的优点和局限
. 学习率退火方案
. 小结和讨论
注释和参考文献
习题
第章 多层感知器
. 引言
. 一些预备知识
. 批量学习和在线学习
. 反向传播算法
. 异或问题
. 改善反向传播算法性能的试探法
. 计算机实验：模式分类
. 反向传播和微分
. Hessian矩阵及其在在线学习中的规则
. 学习率的最优退火和自适应控制
. 泛化
. 函数逼近
. 交叉验证
. 复杂度正则化和网络修剪
. 反向传播学习的优点和局限
. 作为最优化问题看待的监督学习
. 卷积网络
. 非线性滤波
. 小规模和大规模学习问题
. 小结和讨论
注释和参考文献
习题
第章 核方法和径向基函数网络
. 引言
. 模式可分性的Cover定理
. 插值问题
. 径向基函数网络
. K-均值聚类
. 权向量的递归最小二乘估计
. RBF网络的混合学习过程
. 计算机实验：模式分类
. 高斯隐藏单元的解释
. 核回归及其与RBF网络的关系
. 小结和讨论
注释和参考文献
习题
第章 支持向量机
. 引言
. 线性可分模式的最优超平面
. 不可分模式的最优超平面
. 使用核方法的支持向量机
. 支持向量机的设计
. XOR问题
. 计算机实验:模式分类
. 回归：鲁棒性考虑
. 线性回归问题的最优化解
. 表示定理和相关问题
. 小结和讨论
注释和参考文献
习题
第章 正则化理论
. 引言
. 良态问题的Hadamard条件
. Tikhonov正则化理论
. 正则化网络
. 广义径向基函数网络
. 再论正则化最小二乘估计
. 对正则化的附加要点
. 正则化参数估计
. 半监督学习
. 流形正则化：初步的考虑
. 可微流形
. 广义正则化理论
. 光谱图理论
. 广义表示定理
. 拉普拉斯正则化最小二乘算法
. 用半监督学习对模式分类的实验
. 小结和讨论
注释和参考文献
习题
第章 主分量分析
. 引言
. 自组织原则
. 自组织的特征分析
. 主分量分析：扰动理论
. 基于Hebb的最大特征滤波器
. 基于Hebb的主分量分析
. 计算机实验：图像编码
. 核主分量分析
. 自然图像编码中的基本问题
. 核Hebb算法
. 小结和讨论
注释和参考文献
习题
第章 自组织映射
. 引言
. 两个基本的特征映射模型
. 自组织映射
. 特征映射的性质
. 计算机实验Ⅰ：利用SOM解网格动力学问题
. 上下文映射
. 分层向量量化
. 核自组织映射
. 计算机实验Ⅱ：利用核SOM解点阵动力学问题
. 核SOM和相对熵之间的关系
. 小结和讨论
注释和参考文献
习题
第章 信息论学习模型
. 引言
. 熵
. 最大熵原则
. 互信息
. 相对熵
. 系词
. 互信息作为最优化的目标函数
. 最大互信息原则
. 最大互信息和冗余减少
. 空间相干特征
. 空间非相干特征
. 独立分量分析
. 自然图像的稀疏编码以及与ICA编码的比较
. 独立分量分析的自然梯度学习
. 独立分量分析的最大似然估计
. 盲源分离的最大熵学习
. 独立分量分析的负熵最大化
. 相关独立分量分析
. 速率失真理论和信息瓶颈
. 数据的最优流形表达
. 计算机实验：模式分类
. 小结和讨论
注释和参考文献
习题
第章 植根于统计力学的随机方法
. 引言
. 统计力学
. 马尔可夫链
. Metropolis算法
. 模拟退火
. Gibbs抽样
. Boltzmann机
. logistic信度网络
. 深度信度网络
. 确定性退火
. 和EM算法的类比
. 小结和讨论
注释和参考文献
习题
第章 动态规划
. 引言
. 马尔可夫决策过程
. Bellman最优准则
. 策略迭代
. 值迭代
. 逼近动态规划：直接法
. 时序差分学习
. Q学习
. 逼近动态规划：非直接法
. 最小二乘策略评估
. 逼近策略迭代
. 小结和讨论
注释和参考文献
习题
第章 神经动力学
. 引言
. 动态系统
. 平衡状态的稳定性
. 吸引子
. 神经动态模型
. 作为递归网络范例的吸引子操作
. Hopfield模型
. Cohen-Grossberg定理
. 盒中脑状态模型
. 奇异吸引子和混沌
. 混沌过程的动态重构
. 小结和讨论
注释和参考文献
习题
第章 动态系统状态估计的贝叶斯滤波
. 引言
. 状态空间模型
. 卡尔曼滤波器
. 发散现象及平方根滤波
. 扩展的卡尔曼滤波器
. 贝叶斯滤波器
. 数值积分卡尔曼滤波器:基于卡尔曼滤波器
. 粒子滤波器
. 计算机实验：扩展的卡尔曼滤波器和粒子滤波器对比评价
. 大脑功能建模中的
卡尔曼滤波
. 小结和讨论
注释和参考文献
习题
第章 动态驱动递归网络
. 引言
. 递归网络体系结构
. 通用逼近定理
. 可控性和可观测性
. 递归网络的计算能力
. 学习算法
. 通过时间的反向传播
. 实时递归学习
. 递归网络的消失梯度
. 利用非线性逐次状态估计的递归网络监督学习框架
. 计算机实验：Mackay-Glass吸引子的动态重构
. 自适应考虑
. 实例学习：应用于神经控制的模型参考
. 小结和讨论
注释和参考文献
习题
参考文献
・ ・ ・ ・ ・ ・ (收起)推荐序
译者序
前言
致谢
关于技术评审人
第章　机器学习简介 
.　机器学习的起源 
.　机器学习的使用与滥用 
.　机器如何学习 
..　抽象化和知识表达 
..　一般化 
..　评估学习的成功性 
.　将机器学习应用于数据中的步骤 
.　选择机器学习算法 
..　考虑输入的数据 
..　考虑机器学习算法的类型 
..　为数据匹配合适的算法 
.　使用R进行机器学习 
.　总结 
第章　数据的管理和理解 
.　R数据结构 
.　向量 
.　因子 
..　列表 
..　数据框 
..　矩阵和数组 
.　用R管理数据 
..　保存和加载R数据结构 
..　用CSV文件导入和保存数据 
..　从SQL数据库导入数据 
.　探索和理解数据 
..　探索数据的结构 
..　探索数值型变量 
..　探索分类变量 
..　探索变量之间的关系 
.　总结 
第章　懒惰学习――使用近邻分类 
.　理解使用近邻进行分类 
..　kNN算法 
..　为什么kNN算法是懒惰的 
.　用kNN算法诊断乳腺癌 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　概率学习――朴素贝叶斯分类 
.　理解朴素贝叶斯 
..　贝叶斯方法的基本概念 
..　朴素贝叶斯算法 
.　例子――基于贝叶斯算法的手机垃圾短信过滤 
..　第步――收集数据 
..　第步――探索和准备数据 
..　数据准备――处理和分析文本数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提升模型的性能 
.　总结 
第章　分而治之――应用决策树和规则进行分类 
.　理解决策树 
..　分而治之 
..　C.决策树算法 
.　例子――使用C.决策树识别高风险银行贷款 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　理解分类规则 
..　独立而治之 
..　单规则（R）算法 
..　RIPPER算法 
..　来自决策树的规则 
.　例子――应用规则学习识别有毒的蘑菇 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　预测数值型数据――回归方法 
.　理解回归 
..　简单线性回归 
..　普通最小二乘估计 
..　相关系数 
..　多元线性回归 
.　例子――应用线性回归预测医疗费用 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　理解回归树和模型树 
.　例子――用回归树和模型树估计葡萄酒的质量 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　黑箱方法――神经网络和支持向量机 
.　理解神经网络 
..　从生物神经元到人工神经元 
..　激活函数 
..　网络拓扑 
..　用后向传播训练神经网络 
.　用人工神经网络对混凝土的强度进行建模 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　理解支持向量机 
..　用超平面分类 
..　寻找最大间隔 
..　对非线性空间使用核函数 
.　用支持向量机进行光学字符识别 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　探寻模式――基于关联规则的购物篮分析 
.　理解关联规则 
.　例子――用关联规则确定经常一起购买的食品杂货 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　寻找数据的分组――k均值聚类 
.　理解聚类 
..　聚类――一种机器学习任务 
..　k均值聚类算法 
..　用k均值聚类探寻青少年市场细分 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　模型性能的评价 
.　度量分类方法的性能 
..　在R中处理分类预测数据 
..　深入探讨混淆矩阵 
..　使用混淆矩阵度量性能 
..　准确度之外的其他性能评价指标 
..　性能权衡的可视化 
.　评估未来的性能 
..　保持法 
..　交叉验证 
..　自助法抽样 
.　总结 
第章　提高模型的性能 
.　调整多个模型来提高性能 
.　使用元学习来提高模型的性能 
..　理解集成学习 
..　bagging 
..　boosting 
..　随机森林 
.　总结 
第章　其他机器学习主题 
.　分析专用数据 
..　用RCurl添加包从网上获取数据 
..　用XML添加包读/写XML格式数据 
..　用rjson添加包读/写JSON 
..　用xlsx添加包读/写Microsoft Excel电子表格 
..　生物信息学数据 
..　社交网络数据和图数据 
.　提高R语言的性能 
..　处理非常大的数据集 
..　使用并行处理来加快学习过程 
..　GPU计算 
..　部署最优的学习算法 
.　总结 
・ ・ ・ ・ ・ ・ (收起)第章　Python机器学习入门　　
. 　梦之队：机器学习与Python　　
. 　这本书将教给你什么（以及不会教什么）　　
. 　遇到困难的时候怎么办　　
. 　开始　　
.. 　NumPy、SciPy和Matplotlib简介　　
.. 　安装Python　　
.. 　使用NumPy和SciPy智能高效地处理数据　　
.. 　学习NumPy　　
.. 　学习SciPy　　
. 　我们第一个（极小的）机器学习应用　　
.. 　读取数据　　
.. 　预处理和清洗数据　　
.. 　选择正确的模型和学习算法　　
. 　小结　　
第章　如何对真实样本分类　　
. 　Iris数据集　　
.. 　第一步是可视化　　
.. 　构建第一个分类模型　　
. 　构建更复杂的分类器　　
. 　更复杂的数据集和更复杂的分类器　　
.. 　从Seeds数据集中学习　　
.. 　特征和特征工程　　
.. 　最邻近分类　　
. 　二分类和多分类　　
. 　小结　　
第章　聚类：寻找相关的帖子　　
. 　评估帖子的关联性　　
.. 　不应该怎样　　
.. 　应该怎样　　
. 　预处理：用相近的公共词语个数来衡量相似性　　
.. 　将原始文本转化为词袋　　
.. 　统计词语　　
.. 　词语频次向量的归一化　　
.. 　删除不重要的词语　　
.. 　词干处理　　
.. 　停用词兴奋剂　　
.. 　我们的成果和目标　　
. 　聚类　　
.. 　K均值　　
.. 　让测试数据评估我们的想法　　
.. 　对帖子聚类　　
. 　解决我们最初的难题　　
. 　调整参数　　
. 　小结　　
第章　主题模型　　
. 　潜在狄利克雷分配（LDA）　　
. 　在主题空间比较相似度　　
. 　选择主题个数　　
. 　小结　　
第章　分类：检测劣质答案　　
. 　路线图概述　　
. 　学习如何区分出优秀的答案　　
.. 　调整样本　　
.. 　调整分类器　　
. 　获取数据　　
.. 　将数据消减到可处理的程度　　
.. 　对属性进行预选择和处理　　
.. 　定义什么是优质答案　　
. 　创建第一个分类器　　
.. 　从k邻近（kNN）算法开始　　
.. 　特征工程　　
.. 　训练分类器　　
.. 　评估分类器的性能　　
.. 　设计更多的特征　　
. 　决定怎样提升效果　　
.. 　偏差?方差及其折中　　
.. 　解决高偏差　　
.. 　解决高方差　　
.. 　高偏差或低偏差　　
. 　采用逻辑回归　　
.. 　一点数学和一个小例子　　
.. 　在帖子分类问题上应用逻辑回归　　
. 　观察正确率的背后：准确率和召回率　　
. 　为分类器瘦身　　
. 　出货　　
. 　小结　　
第章　分类II：情感分析　　
. 　路线图概述　　
. 　获取推特（Twitter）数据　　
. 　朴素贝叶斯分类器介绍　　
.. 　了解贝叶斯定理　　
.. 　朴素　　
.. 　使用朴素贝叶斯进行分类　　
.. 　考虑未出现的词语和其他古怪情况　　
.. 　考虑算术下溢　　
. 　创建第一个分类器并调优　　
.. 　先解决一个简单问题　　
.. 　使用所有的类　　
.. 　对分类器的参数进行调优　　
. 　清洗推文　　
. 　将词语类型考虑进去　　
.. 　确定词语的类型　　
.. 　用SentiWordNet成功地作弊　　
.. 　我们第一个估算器　　
.. 　把所有东西融合在一起　　
. 　小结　　
第章　回归：推荐　　
. 　用回归预测房价　　
.. 　多维回归　　
.. 　回归里的交叉验证　　
. 　惩罚式回归　　
.. 　L和L惩罚　　
.. 　在Scikit-learn中使用Lasso或弹性网　　
. 　P大于N的情形　　
.. 　基于文本的例子　　
.. 　巧妙地设置超参数（hyperparameter）　　
.. 　评分预测和推荐　　
. 　小结　　
第章　回归：改进的推荐　　
. 　改进的推荐　　
.. 　使用二值推荐矩阵　　
.. 　审视电影的近邻　　
.. 　组合多种方法　　
. 　购物篮分析　　
.. 　获取有用的预测　　
.. 　分析超市购物篮　　
.. 　关联规则挖掘　　
.. 　更多购物篮分析的高级话题　　
. 　小结　　
第章　分类III：音乐体裁分类　　
. 　路线图概述　　
. 　获取音乐数据　　
. 　观察音乐　　
. 　用FFT构建第一个分类器　　
.. 　增加实验敏捷性　　
.. 　训练分类器　　
.. 　在多分类问题中用混淆矩阵评估正确率　　
.. 　另一种方式评估分类器效果：受试者工作特征曲线（ROC）　　
. 　用梅尔倒频谱系数（MFCC）提升分类效果　　
. 　小结　　
第章　计算机视觉：模式识别　　
. 　图像处理简介　　
. 　读取和显示图像　　
.. 　图像处理基础　　
.. 　加入椒盐噪声　　
.. 　模式识别　　
.. 　计算图像特征　　
.. 　设计你自己的特征　　
. 　在更难的数据集上分类　　
. 　局部特征表示　　
. 　小结　　
第章　降维　　
. 　路线图　　
. 　选择特征　　
.. 　用筛选器检测冗余特征　　
.. 　用封装器让模型选择特征　　
. 　其他特征选择方法　　
. 　特征抽取　　
.. 　主成分分析（PCA）　　
.. 　PCA的局限性以及LDA会有什么帮助　　
. 　多维标度法（MDS）　　
. 　小结　　
第章　大数据　　
. 　了解大数据　　
. 　用Jug程序包把你的处理流程分解成几个任务　　
.. 　关于任务　　
.. 　复用部分结果　　
.. 　幕后的工作原理　　
.. 　用Jug分析数据　　
. 　使用亚马逊Web服务（AWS）　　
.. 　构建你的第一台机器　　
.. 　用starcluster自动创建集群　　
. 　小结　　
附录A 　更多机器学习知识　　
A. 　在线资源　　
A. 　参考书　　
A.. 　问答网站　　
A.. 　博客　　
A.. 　数据资源　　
A.. 　竞争日益加剧　　
A. 　还剩下什么　　
A. 　小结　　
索引　　
・ ・ ・ ・ ・ ・ (收起)第章 引言 
. 学习与智能优化：燎原之火 
. 寻找黄金和寻找伴侣 
. 需要的只是数据 
. 超越传统的商业智能 
. LION方法的实施 
. “动手”的方法 
第章 懒惰学习：最近邻方法 
第章 学习需要方法 
. 从已标记的案例中学习：最小化和泛化 
. 学习、验证、测试 
. 不同类型的误差 
第一部分 监督学习
第章 线性模型 
. 线性回归 
. 处理非线性函数关系的技巧 
. 用于分类的线性模型 
. 大脑是如何工作的 
. 线性模型为何普遍，为何成功 
. 最小化平方误差和 
. 数值不稳定性和岭回归 
第章 广义线性最小二乘法 
. 拟合的优劣和卡方分布 
. 最小二乘法与最大似然估计 
.. 假设检验 
.. 交叉验证 
. 置信度的自助法 
第章 规则、决策树和森林 
. 构造决策树 
. 民主与决策森林 
第章 特征排序及选择 
. 特征选择：情境 
. 相关系数 
. 相关比 
. 卡方检验拒绝统计独立性 
. 熵和互信息 
第章 特定非线性模型 
. logistic 回归 
. 局部加权回归 
. 用LASSO来缩小系数和选择输入值 
第章 神经网络：多层感知器 
. 多层感知器 
. 通过反向传播法学习 
.. 批量和bold driver反向传播法 
.. 在线或随机反向传播 
.. 训练多层感知器的高级优化 
第章 深度和卷积网络 
. 深度神经网络 
.. 自动编码器 
.. 随机噪声、屏蔽和课程 
. 局部感受野和卷积网络 
第章 统计学习理论和支持向量机 
. 经验风险最小化 
.. 线性可分问题 
.. 不可分问题 
.. 非线性假设 
.. 用于回归的支持向量 
第章 最小二乘法和健壮内核机器 
. 最小二乘支持向量机分类器 
. 健壮加权最小二乘支持向量机 
. 通过修剪恢复稀疏 
. 算法改进：调谐QP、原始版本、无补偿 
第章 机器学习中的民主 
. 堆叠和融合 
. 实例操作带来的多样性：装袋法和提升法 
. 特征操作带来的多样性 
. 输出值操作带来的多样性：纠错码 
. 训练阶段随机性带来的多样性 
. 加性logistic回归 
. 民主有助于准确率－拒绝的折中 
第章 递归神经网络和储备池计算 
. 递归神经网络 
. 能量极小化霍普菲尔德网络 
. 递归神经网络和时序反向传播 
. 递归神经网络储备池学习 
. 超限学习机 
第二部分 无监督学习和聚类
第章 自顶向下的聚类：K均值 
. 无监督学习的方法 
. 聚类：表示与度量 
. 硬聚类或软聚类的K均值方法 
第章 自底向上（凝聚）聚类 
. 合并标准以及树状图 
. 适应点的分布距离：马氏距离 
. 附录：聚类的可视化 
第章 自组织映射 
. 将实体映射到原型的人工皮层 
. 使用成熟的自组织映射进行分类 
第章 通过线性变换降维（投影） 
. 线性投影 
. 主成分分析 
. 加权主成分分析：结合坐标和关系 
. 通过比值优化进行线性判别 
. 费希尔线性判别分析 
第章 通过非线性映射可视化图与网络 
. 最小应力可视化 
. 一维情况：谱图绘制 
. 复杂图形分布标准 
第章 半监督学习 
. 用部分无监督数据进行学习 
.. 低密度区域中的分离 
.. 基于图的算法 
.. 学习度量 
.. 集成约束和度量学习 
第三部分 优化：力量之源
第章 自动改进的局部方法 
. 优化和学习 
. 基于导数技术的一维情况 
.. 导数可以由割线近似 
.. 一维最小化 
. 求解高维模型（二次正定型） 
.. 梯度与最速下降法 
.. 共轭梯度法 
. 高维中的非线性优化 
.. 通过线性查找的全局收敛 
.. 解决不定黑塞矩阵 
.. 与模型信赖域方法的关系 
.. 割线法 
.. 缩小差距：二阶方法与线性复杂度 
. 不涉及导数的技术：反馈仿射振荡器 
.. RAS：抽样区域的适应性 
.. 为健壮性和多样化所做的重复 
第章 局部搜索和反馈搜索优化 
. 基于扰动的局部搜索 
. 反馈搜索优化：搜索时学习 
. 基于禁忌的反馈搜索优化 
第章 合作反馈搜索优化 
. 局部搜索过程的智能协作 
. CoRSO：一个政治上的类比 
. CoRSO的例子：RSO与RAS合作 
第章 多目标反馈搜索优化 
. 多目标优化和帕累托最优 
. 脑－计算机优化：循环中的用户 
第四部分 应用精选
第章 文本和网页挖掘 
. 网页信息检索与组织 
.. 爬虫 
.. 索引 
. 信息检索与排名 
.. 从文档到向量：向量－空间模型 
.. 相关反馈 
.. 更复杂的相似性度量 
. 使用超链接来进行网页排名 
. 确定中心和权威：HITS 
. 聚类 
第章 协同过滤和推荐 
. 通过相似用户结合评分 
. 基于矩阵分解的模型 
参考文献 
索引 
・ ・ ・ ・ ・ ・ (收起)序言一
序言二
前　言
作者介绍
第章　绪论/ 
.　人工智能及其飞速发展/ 
.　大规模、分布式机器学习/ 
.　本书的安排/ 
参考文献/ 
第章　机器学习基础/ 
.　机器学习的基本概念/ 
.　机器学习的基本流程/ 
.　常用的损失函数/ 
..　Hinge损失函数/ 
..　指数损失函数/ 
..　交叉熵损失函数/ 
.　常用的机器学习模型/ 
..　线性模型/ 
..　核方法与支持向量机/ 
..　决策树与Boosting/ 
..　神经网络/ 
.　常用的优化方法/ 
.　机器学习理论/ 
..　机器学习算法的泛化误差/ 
..　泛化误差的分解/ 
..　基于容度的估计误差的上界/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习框架/ 
.　大数据与大模型的挑战/ 
.　分布式机器学习的基本流程/ 
.　数据与模型划分模块/ 
.　单机优化模块/ 
.　通信模块/ 
..　通信的内容/ 
..　通信的拓扑结构/ 
..　通信的步调/ 
..　通信的频率/ 
.　数据与模型聚合模块/ 
.　分布式机器学习理论/ 
.　分布式机器学习系统/ 
.　总结/ 
参考文献/ 
第章　单机优化之确定性算法/ 
.　基本概述/ 
..　机器学习的优化框架/ 
..　优化算法的分类和发展历史/ 
.　一阶确定性算法/ 
..　梯度下降法/ 
..　投影次梯度下降法/ 
..　近端梯度下降法/ 
..　Frank-Wolfe算法/ 
..　Nesterov加速法/ 
..　坐标下降法/ 
.　二阶确定性算法/ 
..　牛顿法/ 
..　拟牛顿法/ 
.　对偶方法/ 
.　总结/ 
参考文献/ 
第章　单机优化之随机算法/ 
.　基本随机优化算法/ 
..　随机梯度下降法/ 
..　随机坐标下降法/ 
..　随机拟牛顿法/ 
..　随机对偶坐标上升法/ 
..　小结/ 
.　随机优化算法的改进/ 
..　方差缩减方法/ 
..　算法组合方法/ 
.　非凸随机优化算法/ 
..　Ada系列算法/ 
..　非凸理论分析/ 
..　逃离鞍点问题/ 
..　等级优化算法/ 
.　总结/ 
参考文献/ 
第章　数据与模型并行/ 
.　基本概述/ 
.　计算并行模式/ 
.　数据并行模式/ 
..　数据样本划分/ 
..　数据维度划分/ 
.　模型并行模式/ 
..　线性模型/ 
..　神经网络/ 
.　总结/ 
参考文献/ 
第章　通信机制/ 
.　基本概述/ 
.　通信的内容/ 
..　参数或参数的更新/ 
..　计算的中间结果/ 
..　讨论/ 
.　通信的拓扑结构/ 
..　基于迭代式MapReduce/AllReduce的通信拓扑/ 
..　基于参数服务器的通信拓扑/ 
..　基于数据流的通信拓扑/ 
..　讨论/ 
.　通信的步调/ 
..　同步通信/ 
..　异步通信/ 
..　同步和异步的平衡/ 
..　讨论/ 
.　通信的频率/ 
..　时域滤波/ 
..　空域滤波/ 
..　讨论/ 
.　总结/ 
参考文献/ 
第章　数据与模型聚合/ 
.　基本概述/ 
.　基于模型加和的聚合方法/ 
..　基于全部模型加和的聚合/ 
..　基于部分模型加和的聚合/ 
.　基于模型集成的聚合方法/ 
..　基于输出加和的聚合/ 
..　基于投票的聚合/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习算法/ 
.　基本概述/ 
.　同步算法/ 
..　同步SGD方法/ 
..　模型平均方法及其改进/ 
..　ADMM算法/ 
..　弹性平均SGD算法/ 
..　讨论/ 
.　异步算法/ 
..　异步SGD/ 
..　Hogwild!算法/ 
..　Cyclades算法/ 
..　带延迟处理的异步算法/ 
..　异步方法的进一步加速/ 
..　讨论/ 
.　同步和异步的对比与融合/ 
..　同步和异步算法的实验对比/ 
..　同步和异步的融合/ 
.　模型并行算法/ 
..　DistBelief/ 
..　AlexNet/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习理论/ 
.　基本概述/ 
.　收敛性分析/ 
..　优化目标和算法/ 
..　数据和模型并行/ 
..　同步和异步/ 
.　加速比分析/ 
..　从收敛速率到加速比/ 
..　通信量的下界/ 
.　泛化分析/ 
..　优化的局限性/ 
..　具有更好泛化能力的非凸优化算法/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习系统/ 
.　基本概述/ 
.　基于IMR的分布式机器学习系统/ 
..　IMR和Spark/ 
..　Spark MLlib/ 
.　基于参数服务器的分布式机器学习系统/ 
..　参数服务器/ 
..　Multiverso参数服务器/ 
.　基于数据流的分布式机器学习系统/ 
..　数据流/ 
..　TensorFlow数据流系统/ 
.　实战比较/ 
.　总结/ 
参考文献/ 
第章　结语/ 
.　全书总结/ 
.　未来展望/ 
索引/ 
・ ・ ・ ・ ・ ・ (收起)前言
第一部分 机器学习基础
第章 机器学习概览
什么是机器学习
为什么要使用机器学习
机器学习系统的种类
监督式/无监督式学习
批量学习和在线学习
基于实例与基于模型的学习
机器学习的主要挑战
训练数据的数量不足
训练数据不具代表性
质量差的数据
无关特征
训练数据过度拟合
训练数据拟合不足
退后一步
测试与验证
练习
第章 端到端的机器学习项目
使用真实数据
观察大局
框架问题
选择性能指标
检查假设
获取数据
创建工作区
下载数据
快速查看数据结构
创建测试集
从数据探索和可视化中获得洞见
将地理数据可视化
寻找相关性
试验不同属性的组合
机器学习算法的数据准备
数据清理
处理文本和分类属性
自定义转换器
特征缩放
转换流水线
选择和训练模型
培训和评估训练集
使用交叉验证来更好地进行评估
微调模型
网格搜索
随机搜索
集成方法
分析最佳模型及其错误
通过测试集评估系统
启动、监控和维护系统
试试看
练习
第章 分类
MNIST
训练一个二元分类器
性能考核
使用交叉验证测量精度
混淆矩阵
精度和召回率
精度/召回率权衡
ROC曲线
多类别分类器
错误分析
多标签分类
多输出分类
练习
第章 训练模型
线性回归
标准方程
计算复杂度
梯度下降
批量梯度下降
随机梯度下降
小批量梯度下降
多项式回归
学习曲线
正则线性模型
岭回归
套索回归
弹性网络
早期停止法
逻辑回归
概率估算
训练和成本函数
决策边界
Softmax回归
练习
第章 支持向量机
线性SVM分类
软间隔分类
非线性SVM分类
多项式核
添加相似特征
高斯RBF核函数
计算复杂度
SVM回归
工作原理
决策函数和预测
训练目标
二次规划
对偶问题
核化SVM
在线SVM
练习
第章 决策树
决策树训练和可视化
做出预测
估算类别概率
CART训练算法
计算复杂度
基尼不纯度还是信息熵
正则化超参数
回归
不稳定性
练习
第章 集成学习和随机森林
投票分类器
bagging和pasting
Scikit-Learn的bagging和pasting
包外评估
Random Patches和随机子空间
随机森林
极端随机树
特征重要性
提升法
AdaBoost
梯度提升
堆叠法
练习
第章 降维
维度的诅咒
数据降维的主要方法
投影
流形学习
PCA
保留差异性
主成分
低维度投影
使用Scikit-Learn
方差解释率
选择正确数量的维度
PCA压缩
增量PCA
随机PCA
核主成分分析
选择核函数和调整超参数
局部线性嵌入
其他降维技巧
练习
第二部分 神经网络和深度学习
第章 运行TensorFlow
安装
创建一个计算图并在会话中执行
管理图
节点值的生命周期
TensorFlow中的线性回归
实现梯度下降
手工计算梯度
使用自动微分
使用优化器
给训练算法提供数据
保存和恢复模型
用TensorBoard来可视化图和训练曲线
命名作用域
模块化
共享变量
练习
第章 人工神经网络简介
从生物神经元到人工神经元
生物神经元
具有神经元的逻辑计算
感知器
多层感知器和反向传播
用TensorFlow的高级API来训练MLP
使用纯TensorFlow训练DNN
构建阶段
执行阶段
使用神经网络
微调神经网络的超参数
隐藏层的个数
每个隐藏层中的神经元数
激活函数
练习
第章 训练深度神经网络
梯度消失/爆炸问题
Xavier初始化和He初始化
非饱和激活函数
批量归一化
梯度剪裁
重用预训练图层
重用TensorFlow模型
重用其他框架的模型
冻结低层
缓存冻结层
调整、丢弃或替换高层
模型动物园
无监督的预训练
辅助任务中的预训练
快速优化器
Momentum优化
Nesterov梯度加速
AdaGrad
RMSProp
Adam优化
学习速率调度
通过正则化避免过度拟合
提前停止
和正则化
dropout
最大范数正则化
数据扩充
实用指南
练习
第章 跨设备和服务器的分布式TensorFlow
一台机器上的多个运算资源
安装
管理GPU RAM
在设备上操作
并行执行
控制依赖
多设备跨多服务器
开启一个会话
master和worker服务
分配跨任务操作
跨多参数服务器分片变量
用资源容器跨会话共享状态
使用TensorFlow队列进行异步通信
直接从图中加载数据
在TensorFlow集群上并行化神经网络
一台设备一个神经网络
图内与图间复制
模型并行化
数据并行化
练习
第章 卷积神经网络
・ ・ ・ ・ ・ ・ (收起)译者序
前言
第章　引言
.　应用与问题
.　定义与术语
.　交叉验证
.　学习情境
.　本书概览
第章　PAC学习框架
.　PAC学习模型
.　对有限假设集的学习保证――一致的情况
.　对有限假设集的学习保证――不一致的情况
.　泛化性
..　确定性与随机性情境
..　贝叶斯误差与噪声
..　估计误差与近似误差
..　模型选择
.　文献评注
.　习题
第章　Rademacher复杂度和VC-维
.　Rademacher复杂度
.　生长函数
.　VC-维
.　下界
.　文献评注
.　习题
第章　支持向量机
.　线性分类
.　可分情况下的支持向量机
..　原始优化问题
..　支持向量
..　对偶优化问题
..　留一法
.　不可分情况下的支持向量机
..　原始优化问题
..　支持向量
..　对偶优化问题
.　间隔理论
.　文献评注
.　习题
第章　核方法
.　引言
.　正定对称核
..　定义
..　再生核希尔伯特空间
..　性质
.　基于核的算法
..　具有PDS核的SVM
..　表示定理
..　学习保证
.　负定对称核
.　序列核
..　加权转换器
..　有理核
.　文献评注
.　习题
第章　boosting
.　引言
.　AdaBoost算法
..　经验误差的界
..　与坐标下降的关系
..　与逻辑回归的关系
..　实践中的标准使用方式
.　理论结果
..　基于VC-维的分析
..　基于间隔的分析
..　间隔最大化
..　博弈论解释
.　讨论
.　文献评注
.　习题
第章　在线学习
.　引言
.　有专家建议的预测
..　错误界和折半算法
..　加权多数算法
..　随机加权多数算法
..　指数加权平均算法
.　线性分类
..　感知机算法
..　Winnow算法
.　在线到批处理的转换
.　与博弈论的联系
.　文献评注
.　习题
第章　多分类
.　多分类问题
.　泛化界
.　直接型多分类算法
..　多分类SVM
..　多分类boosting算法
..　决策树
.　类别分解型多分类算法
..　一对多
..　一对一
..　纠错编码
.　结构化预测算法
.　文献评注
.　习题
第章　排序
.　排序问题
.　泛化界
.　使用SVM进行排序
.　RankBoost
..　经验误差界
..　与坐标下降的关系
..　排序问题集成算法的间隔界
.　二部排序
..　二部排序中的boosting算法
..　ROC曲线下面积
.　基于偏好的情境
..　两阶段排序问题
..　确定性算法
..　随机性算法
..　关于其他损失函数的扩展
.　讨论
.　文献评注
.　习题
第章　回归
.　回归问题
.　泛化界
..　有限假设集
..　Rademacher复杂度界
..　伪维度界
.　回归算法
..　线性回归
..　核岭回归
..　支持向量回归
..　Lasso
..　组范数回归算法
..　在线回归算法
.　文献评注
.　习题
第章　算法稳定性
.　定义
.　基于稳定性的泛化保证
.　基于核的正则化算法的稳定性
..　应用于回归算法：SVR和KRR
..　应用于分类算法：SVM
..　讨论
.　文献评述
.　习题
第章　降维
.　主成分分析
.　核主成分分析
.　KPCA和流形学习
..　等距映射
..　拉普拉斯特征映射
..　局部线性嵌入
.　Johnson-Lindenstrauss引理
.　文献评注
.　习题
第章　学习自动机和语言
.　引言
.　有限自动机
.　高效精确学习
..　被动学习
..　通过查询学习
..　通过查询学习自动机
.　极限下的识别
.　文献评注
.　习题
第章　强化学习
.　学习情境
.　马尔可夫决策过程模型
.　策略
..　定义
..　策略值
..　策略评估
..　最优策略
.　规划算法
..　值迭代
..　策略迭代
..　线性规划
.　学习算法
..　随机逼近
..　TD（）算法
..　Q-学习算法
..　SARSA
..　TD（λ）算法
..　大状态空间
.　文献评注
结束语
附录A　线性代数回顾
附录B　凸优化
附录C　概率论回顾
附录D　集中不等式
附录E　符号
索引
参考文献
・ ・ ・ ・ ・ ・ (收起)序言
第 一章 机器学习概述 
． 机器学习简介 
．． 机器学习简史 
．． 机器学习主要流派 
． 机器学习、人工智能和数据挖掘 
．． 什么是人工智能 
．． 机器学习、人工智能与数据挖掘 
． 典型机器学习应用领域 
． 机器学习算法 
． 机器学习的一般流程 
第 二章 机器学习基本方法 
． 统计分析 
．． 统计基础 
．． 常见概率分布 
．． 参数估计 
．． 假设检验 
．． 线性回归 
．． Logistics回归 
．． 判别分析 
．． 非线性模型 
． 高维数据降维 
．． 主成分分析 
．． 线性判别分析 
．． 局部线性嵌入 
． 特征工程 
．． 特征构造 
．． 特征选择 
．． 特征提取 
． 模型训练 
．． 模型训练常见术语 
．． 训练数据收集 
． 可视化分析 
．． 可视化分析的作用 
．． 可视化分析方法 
．． 可视化分析常用工具 
．． 常见的可视化图表 
．． 可视化分析面临的挑战 
第三章 决策树与分类算法 
． 决策树算法 
．． 分支处理 
．． 连续属性离散化 
．． 过拟合问题 
．． 分类效果评价 
． 集成学习 
．． 装袋法 
．． 提升法 
．． GBDT 
．． 随机森林 
． 决策树应用 
第四章 聚类分析 
． 聚类分析概念 
．． 聚类方法分类 
．． 良好聚类算法的特征 
． 聚类分析的度量 
．． 外部指标 
．． 内部指标 
． 基于划分的方法 
．． k-均值算法 
．． k-medoids算法 
．． k-prototype算法 
． 基于密度聚类 
．． DBSCAN算法 
．． OPTICS算法 
．． DENCLUE算法 
． 基于层次的聚类 
．． BIRCH聚类 
．． CURE算法 
． 基于网格的聚类 
． 基于模型的聚类 
．． 概率模型聚类 
．． 模糊聚类 
．． Kohonen神经网络聚类 
第五章 文本分析 
． 文本分析介绍 
． 文本特征提取及表示 
．． TF-IDF 
．． 信息增益 
．． 互信息 
．． 卡方统计量 
．． 词嵌入 
．． 语言模型 
．． 向量空间模型 
． 知识图谱 
．． 知识图谱相关概念 
．． 知识图谱的存储 
．． 知识图谱挖掘与计算 
．． 知识图谱的构建过程 
． 词法分析 
．． 文本分词 
．． 命名实体识别 
．． 词义消歧 
． 句法分析 
． 语义分析 
． 文本分析应用 
．． 文本分类 
．． 信息抽取 
．． 问答系统 
．． 情感分析 
．． 自动摘要 
第六章 神经网络 
． 神经网络介绍 
．． 前馈神经网络 
．． 反馈神经网络 
．． 自组织神经网络 
． 神经网络相关概念 
．． 激活函数 
．． 损失函数 
．． 学习率 
．． 过拟合 
．． 模型训练中的问题 
．． 神经网络效果评价 
． 神经网络应用 
第七章 贝叶斯网络 
． 贝叶斯理论概述 
．． 贝叶斯方法的基本观点 
．． 贝叶斯网络的应用 
． 贝叶斯概率基础 
．． 概率论 
．． 贝叶斯概率 
． 朴素贝叶斯分类模型 
． 贝叶斯网络 
． 贝叶斯网络的应用 
．． 中文分词 
．． 机器翻译 
．． 故障诊断 
．． 疾病诊断 
第八章 支持向量机 
． 支持向量机模型 
．． 核函数 
．． 模型原理分析 
． 支持向量机应用 
第九章 进化计算 
． 遗传算法的基础 
．． 基因重组（交叉）与基因突变 
．． 遗传算法实现技术 
．． 遗传算法案例 
． 蚁群算法 
．． 蚁群算法应用案例 
． 蜂群算法简介 
．． 蜂群算法应用案例 
第十章 分布式机器学习 
． 分布式机器学习基础 
．． 参数服务器 
．． 分布式并行计算类型 
． 分布式机器学习框架 
． 并行决策树 
． 并行k-均值算法 
第十一章 深度学习 
． 卷积神经网络 
．． 卷积神经网络的整体结构 
．． 常见卷积神经网络 
． 循环神经网络 
．． RNN基本原理 
．． 长短期记忆网络 
．． 门限循环单元 
． 深度学习流行框架 
第十二章 高等级深度学习 
． 高等级卷积神经网络 
．． 目标检测与追踪 
．． 目标分割 
． 高等级循环神经网络应用 
．． Encoder-Decoder模型 
．． 注意力模型 
．． LSTM高等级应用 
． 无监督式深度学习 
．． 深度信念网络 
．． 自动编码器网络 
．． 生成对抗网络模型 
． 强化学习 
．． 增强学习基础 
．． 深度增强学习 
． 迁移学习 
． 对偶学习 
第十三章 推荐系统 
． 推荐系统介绍 
．． 推荐系统的应用场景 
． 推荐系统通用模型 
．． 推荐系统结构 
．． 基于内容的推荐 
．． 基于协同过滤的推荐算法 
．． 基于图的模型 
．． 基于关联规则的推荐 
．． 基于知识的推荐 
．． 基于标签的推荐 
． 推荐系统评测 
．． 评测方法 
．． 评测指标 
． 推荐系统常见问题 
．． 冷启动问题 
．． 推荐系统注意事项 
． 推荐系统实例 
第十四章 实验 
． 华为FusionInsight产品平台介绍 
． 银行定期存款业务预测 
．． 上传银行客户及存贷款数据 
．． 准备存款业务分析工作区 
．． 创建数据挖掘流程 
．． 定期存款业务模型保存和应用 
． 客户分群 
．． 分析业务需求 
．． 上传客户信息数据 
．． 准备客户分群工作区 
．． 创建数据挖掘流程 
．． 客户分群模型保存和应用 
・ ・ ・ ・ ・ ・ (收起)第章 基础知识 
.　准备数据 
..　数据格式 
..　变量类型 
..　变量选择 
..　特征工程 
..　缺失数据 
.　选择算法 
..　无监督学习 
..　监督学习 
..　强化学习 
..　注意事项 
.　参数调优 
.　评价模型 
..　分类指标 
..　回归指标 
..　验证 
.　小结 
第章　k均值聚类 
.　找出顾客群 
.　示例：影迷的性格特征 
.　定义群组 
..　有多少个群组 
..　每个群组中有谁 
.　局限性 
.　小结 
第章　主成分分析 
.　食物的营养成分 
.　主成分 
.　示例：分析食物种类 
.　局限性 
.　小结 
第章　关联规则 
.　发现购买模式 
.　支持度、置信度和提升度 
.　示例：分析杂货店的销售数据 
.　先验原则 
..　寻找具有高支持度的项集 
..　寻找具有高置信度或高提升度的关联规则 
.　局限性 
.　小结 
第章　社会网络分析 
.　展现人际关系 
.　示例：国际贸易 
.　Louvain方法 
.　PageRank算法 
.　局限性 
.　小结 
第章　回归分析 
.　趋势线 
.　示例：预测房价 
.　梯度下降法 
.　回归系数 
.　相关系数 
.　局限性 
.　小结 
第章　k最近邻算法和异常检测 
.　食品检测 
.　物以类聚，人以群分 
.　示例：区分红白葡萄酒 
.　异常检测 
.　局限性 
.　小结 
第章　支持向量机 
.　医学诊断 
.　示例：预测心脏病 
.　勾画最佳分界线 
.　局限性 
.　小结 
第章　决策树 
.　预测灾难幸存者 
.　示例：逃离泰坦尼克号 
.　生成决策树 
.　局限性 
.　小结 
第章　随机森林 
.　集体智慧 
.　示例：预测犯罪行为 
.　集成模型 
.　自助聚集法 
.　局限性 
.　小结 
第章　神经网络 
.　建造人工智能大脑 
.　示例：识别手写数字 
.　神经网络的构成 
.　激活规则 
.　局限性 
.　小结 
第章　A/B测试和多臂老虎机 
.　初识A/B测试 
.　A/B测试的局限性 
.　epsilon递减策略 
.　示例：多臂老虎机 
.　胜者为先 
.　epsilon递减策略的局限性 
.　小结 
附录A　无监督学习算法概览 
附录B　监督学习算法概览 
附录C　调节参数列表 
附录D　更多评价指标 
术语表 
关于作者 
・ ・ ・ ・ ・ ・ (收起)推荐序
作者序
致谢
译者序
关于本书
作者简介
关于封面插图
第部分机器学习工作流程
第章什么是机器学习
.理解机器学习
.使用数据进行决策
..传统方法
..机器学习方法
..机器学习的五大优势
..面临的挑战
.跟踪机器学习流程：从数据到部署
..数据集合和预处理
..数据构建模型
..模型性能评估
..模型性能优化
.提高模型性能的高级技巧
..数据预处理和特征工程
..用在线算法持续改进模型
..具有数据量和速度的规模化模型
.总结
.本章术语
第章实用数据处理
.起步：数据收集
..应包含哪些特征
..如何获得目标变量的真实值
..需要多少训练数据
..训练集是否有足够的代表性
.数据预处理
..分类特征
..缺失数据处理
..简单特征工程
..数据规范化
.数据可视化
..马赛克图
..盒图
..密度图
..散点图
.总结
.本章术语
第章建模和预测
.基础机器学习建模
..寻找输入和目标间的关系
..寻求好模型的目的
..建模方法类型
..有监督和无监督学习
.分类：把数据预测到桶中
..构建分类器并预测
..非线性数据与复杂分类
..多类别分类
.回归：预测数值型数据
..构建回归器并预测
..对复杂的非线性数据进行回归
.总结
.本章术语
第章模型评估与优化
.模型泛化：评估新数据的预测准确性
..问题：过度拟合与乐观模型
..解决方案：交叉验证
..交叉验证的注意事项
.分类模型评估
..分类精度和混淆矩阵
..准确度权衡与ROC曲线
..多类别分类
.回归模型评估
..使用简单回归性能指标
..检验残差
.参数调整优化模型
..机器学习算法和它们的调整参数
..网格搜索
.总结
.本章术语
第章基础特征工程
.动机：为什么特征工程很有用
..什么是特征工程
..使用特征工程的个原因
..特征工程与领域专业知识
.基本特征工程过程
..实例：事件推荐
..处理日期和时间特征
..处理简单文本特征
.特征选择
..前向选择和反向消除
..数据探索的特征选择
..实用特征选择实例
.总结
.本章术语
第部分实 际 应 用
第章案例：NYC出租车数据
.数据：NYC出租车旅程和收费信息
..数据可视化
..定义问题并准备数据
.建模
..基本线性模型
..非线性分类器
..包含分类特征
..包含日期-时间特征
..模型的启示
.总结
.本章术语
第章高级特征工程
.高级文本特征
..词袋模型
..主题建模
..内容拓展
.图像特征
..简单图像特征
..提取物体和形状
.时间序列特征
..时间序列数据的类型
..时间序列数据的预测
..经典时间序列特征
..事件流的特征工程
.总结
.本章术语
第章NLP高级案例：电影评论情感预测
.研究数据和应用场景
..数据集初探
..检查数据
..应用场景有哪些
.提取基本NLP特征并构建初始模型
..词袋特征
..用朴素贝叶斯算法构建模型
..tf-idf算法规范词袋特征
..优化模型参数
.高级算法和模型部署的考虑
..wordvec特征
..随机森林模型
.总结
.本章术语
第章扩展机器学习流程
.扩展前需考虑的问题
..识别关键点
..选取训练数据子样本代替扩展性
..可扩展的数据管理系统
.机器学习建模流程扩展
.预测扩展
..预测容量扩展
..预测速度扩展
.总结
.本章术语
第章案例：数字显示广告
.显示广告
.数字广告数据
.特征工程和建模策略
.数据大小和形状
.奇异值分解
.资源估计和优化
.建模
.K近邻算法
.随机森林算法
.其他实用考虑
.总结
.本章术语
.摘要和结论
附录常用机器学习算法
名词术语中英文对照
・ ・ ・ ・ ・ ・ (收起)第  章 机器学习是什么――机器学习定义 .. 
引言.. 
. 数据. 
.. 结构型与非结构型数据 
.. 原始数据与加工.. 
.. 样本内数据与样本外数据 . 
. 机器学习类别 
.. 有监督学习 
.. 无监督学习 
.. 半监督学习. 
.. 增强学习 
.. 深度学习 
.. 迁移学习.. 
. 性能度量. 
.. 误差函数.. 
.. 回归度量.. 
.. 分类度量.. 
. 总结.. 
参考资料.. 
第  章 机器学习可行吗――计算学习理论 
引言 
. 基础知识. 
.. 二分类. 
.. 对分 
.. 增长函数.. 
.. 突破点. 
. 核心推导. 
.. 机器学习可行条件 . 
.. 从已知推未知. 
.. 从民意调查到机器学习 
.. 从单一到有限. 
.. 从有限到无限. 
.. 从无限到有限. 
. 结论应用. 
.. VC 不等式 
.. VC 维度 .. 
.. 模型复杂度 
.. 样本复杂度 
. 总结.. 
参考资料.. 
技术附录.. 
第  章 机器学习怎么学――模型评估选择 
引言 
. 模型评估. 
. 训练误差和测试误差. 
.. 训练误差.. 
.. 真实误差.. 
.. 测试误差.. 
.. 学习理论.. 
. 验证误差和交叉验证误差. 
.. 验证误差.. 
.. 交叉验证误差. 
.. 学习理论.. 
. 误差剖析. 
.. 误差来源.. 
.. 偏差―方差权衡 
. 模型选择. 
. 总结.. 
参考资料.. 
技术附录.. 
第  章 线性回归 
引言 
. 基础知识. 
.. 标量微积分 
.. 向量微积分 
. 模型介绍. 
.. 核心问题.. 
.. 通用线性回归模型 . 
.. 特征缩放.. 
.. 学习率设定 
.. 数值算法比较. 
.. 代码实现.. 
. 总结.. 
参考资料.. 
第  章 对率回归 
引言 
. 基础内容. 
.. 联系函数.. 
.. 函数绘图.. 
. 模型介绍. 
.. 核心问题.. 
.. 查准和查全. 
.. 类别不平衡. 
.. 线性不可分. 
.. 多分类问题. 
.. 代码实现 
. 总结. 
参考资料. 
第  章 正则化回归 . 
引言. 
. 基础知识 
.. 等值线图. 
.. 坐标下降. 
. 模型介绍 
.. 核心问题. 
.. 模型对比 
.. 最佳模型 
.. 代码实现 
. 总结 
参考资料 
第  章 支持向量机 . 
引言 
. 基础知识.. 
.. 向量初体验. 
.. 拉格朗日量. 
.. 原始和对偶. 
. 模型介绍.. 
.. 硬间隔 SVM 原始问题. 
.. 硬间隔 SVM 对偶问题. 
.. 软间隔 SVM 原始问题. 
.. 软间隔 SVM 对偶问题. 
.. 空间转换 
.. 核技巧. 
.. 核 SVM . 
.. SMO 算法 .. 
.. 模型选择 
. 总结 
参考资料 
技术附录 
第  章 朴素贝叶斯 . 
引言 
. 基础知识.. 
.. 两种概率学派.. 
.. 两种独立类别.. 
.. 两种学习算法.. 
.. 两种估计方法.. 
.. 两类概率分布.. 
. 模型介绍.. 
.. 问题剖析 
.. 朴素贝叶斯算法 
.. 多元伯努利模型 
.. 多项事件模型.. 
.. 高斯判别分析模型 . 
.. 多分类问题. 
.. 拉普拉斯校正.. 
.. 最大似然估计和最大后验估计 . 
. 总结 
参考资料 
技术附录 
第  章 决策树 . 
引言 
. 基础知识.. 
.. 多数规则 
.. 熵和条件熵. 
.. 信息增益和信息增益比 . 
.. 基尼指数 
. 模型介绍.. 
.. 二分类决策树.. 
.. 多分类决策树.. 
.. 连续值分裂. 
.. 欠拟合和过拟合. 
.. 预修剪和后修剪 
.. 数据缺失 
.. 代码实现 
. 总结 
参考资料 
第  章 人工神经网络 
引言 
. 基本知识 
.. 转换函数 
.. 单输入单层单输出神经网络 . 
.. 多输入单层单输出神经网络 . 
.. 多输入单层多输出神经网络 . 
.. 多输入多层多输出神经网络 . 
. 模型应用 
.. 创建神经网络模型 .. 
.. 回归应用 
.. 分类应用 
第  章 正向/反向传播 
引言 
. 基础知识 
.. 神经网络元素 
.. 链式法则 
. 算法介绍 
.. 正向传播 
.. 梯度下降 
.. 反向传播 
.. 代码实现 
. 总结 
参考资料 
技术附录 
第  章 集成学习. 
引言 
. 结合假设 
.. 语文和数学. 
.. 准确和多样. 
.. 独裁和民主. 
.. 学习并结合. 
. 装袋法. 
.. 基本概念 
.. 自助采样 
.. 结合假设 
. 提升法. 
.. 基本概念 
.. 最优加权 
.. 结合假设 
. 集成方式 
.. 同质学习器. 
.. 异质学习器. 
. 总结 
参考资料 
第  章 随机森林和提升树 . 
引言 
. 基础知识 
.. 分类回归树. 
.. 前向分布算法 
.. 置换检验 
. 模型介绍 
.. 随机森林 
.. 提升树.. 
.. 代码实现 
. 总结 
参考资料 
第  章 极度梯度提升 
引言 
. 基础知识. 
.. 树的重定义 
.. 树的复杂度. 
. 模型介绍 
.. XGB 简介. 
.. XGB 的泛化度 
.. XGB 的精确度 
.. XGB 的速度.. 
.. 代码实现 
. 总结 
参考资料 
第  章 本书总结. 
. 正交策略 
. 单值评估指标.. 
. 偏差和方差. 
.. 理论定义 
.. 实用定义 
.. 最优误差 
.. 两者权衡 
.. 学习曲线 
结语 
・ ・ ・ ・ ・ ・ (收起)前言
第章　机器学习概述 
.　什么是机器学习 
.　机器学习的几个需求层次 
.　机器学习的基本原理 
.　机器学习的基本概念 
..　书中用到的术语介绍 
..　机器学习的基本模式 
..　优化方法 
.　机器学习问题分类 
.　常用的机器学习算法 
.　机器学习算法的性能衡量指标 
.　数据对算法结果的影响 
第章　机器学习所需的环境 
.　常用环境 
.　Python简介 
..　Python的安装 
..　Python的基本用法 
.　Numpy简介 
..　Numpy的安装 
..　Numpy的基本用法 
.　Scikit-Learn简介 
..　Scikit-Learn的安装 
..　Scikit-Learn的基本用法 
.　Pandas简介 
..　Pandas的安装 
..　Pandas的基本用法 
第章　线性回归算法 
.　线性回归：“钢铁直男”解决回归问题的正确方法 
..　用于预测未来的回归问题 
..　怎样预测未来 
..　线性方程的“直男”本性 
..　最简单的回归问题―线性回归问题 
.　线性回归的算法原理 
..　线性回归算法的基本思路 
..　线性回归算法的数学解析 
..　线性回归算法的具体步骤 
.　在Python中使用线性回归算法 
.　线性回归算法的使用场景 
第章　Logistic回归分类算法 
.　Logistic回归：换上“S型曲线马甲”的线性回归 
..　分类问题：选择困难症患者的自我救赎 
..　Logistic函数介绍 
..　此回归非彼回归：“LR”辨析 
.　Logistic回归的算法原理 
..　Logistic回归算法的基本思路 
..　Logistic回归算法的数学解析 
..　Logistic回归算法的具体步骤 
.　在Python中使用Logistic回归算法 
.　Logistic回归算法的使用场景 
第章　KNN分类算法 
.　KNN分类算法：用多数表决进行分类 
..　用“同类相吸”的办法解决分类问题 
..　KNN分类算法的基本方法：多数表决 
..　表决权问题 
..　KNN的具体含义 
.　KNN分类的算法原理 
..　KNN分类算法的基本思路 
..　KNN分类算法的数学解析 
..　KNN分类算法的具体步骤 
.　在Python中使用KNN分类算法 
.　KNN分类算法的使用场景 
第章　朴素贝叶斯分类算法 
.　朴素贝叶斯：用骰子选择 
..　从统计角度看分类问题 
..　贝叶斯公式的基本思想 
..　用贝叶斯公式进行选择 
.　朴素贝叶斯分类的算法原理 
..　朴素贝叶斯分类算法的基本思路 
..　朴素贝叶斯分类算法的数学解析 
..　朴素贝叶斯分类算法的具体步骤 
.　在Python中使用朴素贝叶斯分类算法 
.　朴素贝叶斯分类算法的使用场景 
第章　决策树分类算法 
.　决策树分类：用“老朋友”if-else进行选择 
..　程序员的选择观：if-else 
..　如何种植一棵有灵魂的“树” 
..　决策条件的选择艺术 
..　决策树的剪枝问题 
.　决策树分类的算法原理 
..　决策树分类算法的基本思路 
..　决策树分类算法的数学解析 
..　决策树分类算法的具体步骤 
.　在Python中使用决策树分类算法 
.　决策树分类算法的使用场景 
第章　支持向量机分类算法 
.　支持向量机：线性分类器的“王者” 
..　距离是不同类别的天然间隔 
..　何为“支持向量” 
..　从更高维度看“线性不可分” 
.　支持向量机分类的算法原理 
..　支持向量机分类算法的基本思路 
..　支持向量机分类算法的数学解析 
..　支持向量机分类算法的具体步骤 
.　在Python中使用支持向量机分类算法 
.　支持向量机分类算法的使用场景 
第章　K-means聚类算法 
.　用投票表决实现“物以类聚” 
..　聚类问题就是“物以类聚”的实施问题 
..　用“K”来决定归属类别 
..　度量“相似”的距离 
..　聚类问题中的多数表决 
.　K-means聚类的算法原理 
..　K-means聚类算法的基本思路 
..　K-means聚类算法的数学解析 
..　K-means聚类算法的具体步骤 
.　在Python中使用K-means聚类算法 
.　K-means聚类算法的使用场景 
第章　神经网络分类算法 
.　用神经网络解决分类问题 
..　神经元的“内心世界” 
..　从神经元看分类问题 
..　神经网络的“细胞”：人工神经元 
..　构成网络的魔力 
..　神经网络与深度学习 
.　神经网络分类的算法原理 
..　神经网络分类算法的基本思路 
..　神经网络分类算法的数学解析 
..　神经网络分类算法的具体步骤 
.　在Python中使用神经网络分类算法 
.　神经网络分类算法的使用场景 
第章　集成学习方法 
.　集成学习方法：三个臭皮匠赛过诸葛亮 
..　集成学习方法与经典机器学习算法的关系 
..　集成学习的主要思想 
..　几种集成结构 
.　集成学习方法的具体实现方式 
..　Bagging算法 
..　Boosting算法 
..　Stacking算法 
.　在Python中使用集成学习方法 
.　集成学习方法的使用场景 
・ ・ ・ ・ ・ ・ (收起)第章　机器学习应用快速入门　　
.　机器学习与数据科学　　
..　机器学习能够解决的问题　　
..　机器学习应用流程　　
.　数据与问题定义　　
.　数据收集　　
..　发现或观察数据　　
..　生成数据　　
..　采样陷阱　　
.　数据预处理　　
..　数据清洗　　
..　填充缺失值　　
..　剔除异常值　　
..　数据转换　　
..　数据归约　　
.　无监督学习　　
..　查找相似项目　　
..　聚类　　
.　监督学习　　
..　分类　　
..　回归　　
.　泛化与评估　　
.　小结　　
第章　面向机器学习的Java库与平台　　
.　Java环境　　
.　机器学习库　　
..　Weka　　
..　Java机器学习　　
..　Apache Mahout　　
..　Apache Spark　　
..　Deeplearningj　　
..　MALLET　　
..　比较各个库　　
.　创建机器学习应用　　
.　处理大数据　　
.　小结　　
第章　基本算法――分类、回归和聚类　　
.　开始之前　　
.　分类　　
..　数据　　
..　加载数据　　
..　特征选择　　
..　学习算法　　
..　对新数据分类　　
..　评估与预测误差度量　　
..　混淆矩阵　　
..　选择分类算法　　
.　回归　　
..　加载数据　　
..　分析属性　　
..　创建与评估回归模型　　
..　避免常见回归问题的小技巧　　
.　聚类　　
..　聚类算法　　
..　评估　　
.　小结　　
第章　利用集成方法预测客户关系　　
.　客户关系数据库　　
..　挑战　　
..　数据集　　
..　评估　　
.　最基本的朴素贝叶斯分类器基准　　
..　获取数据　　
..　加载数据　　
.　基准模型　　
..　评估模型　　
..　实现朴素贝叶斯基准线　　
.　使用集成方法进行高级建模　　
..　开始之前　　
..　数据预处理　　
..　属性选择　　
..　模型选择　　
..　性能评估　　
.　小结　　
第章　关联分析　　
.　购物篮分析　　
.　关联规则学习　　
..　基本概念　　
..　Apriori算法　　
..　FP-增长算法　　
..　超市数据集　　
.　发现模式　　
..　Apriori算法　　
..　FP-增长算法　　
.　在其他领域中的应用　　
..　医疗诊断　　
..　蛋白质序列　　
..　人口普查数据　　
..　客户关系管理　　
..　IT运营分析　　
.　小结　　
第章　使用Apache Mahout制作推荐引擎　　
.　基本概念　　
..　关键概念　　
..　基于用户与基于项目的分析　　
..　计算相似度的方法　　
..　利用与探索　　
.　获取Apache Mahout　　
.　创建一个推荐引擎　　
..　图书评分数据集　　
..　加载数据　　
..　协同过滤　　
.　基于内容的过滤　　
.　小结　　
第章　欺诈与异常检测　　
.　可疑与异常行为检测　　
.　可疑模式检测　　
.　异常模式检测　　
..　分析类型　　
..　事务分析　　
..　规划识别　　
.　保险理赔欺诈检测　　
..　数据集　　
..　为可疑模式建模　　
.　网站流量异常检测　　
..　数据集　　
..　时序数据中的异常检测　　
.　小结　　
第章　利用Deeplearningj进行图像识别　　
.　图像识别简介　　
.　图像分类　　
..　Deeplearningj　　
..　MNIST数据集　　
..　加载数据　　
..　创建模型　　
.　小结　　
第章　利用手机传感器进行行为识别　　
.　行为识别简介　　
..　手机传感器　　
..　行为识别流水线　　
..　计划　　
.　从手机收集数据　　
..　安装Android Studio　　
..　加载数据采集器　　
..　收集训练数据　　
.　创建分类器　　
..　减少假性转换　　
..　将分类器嵌入移动应用　　
.　小结　　
第章　利用Mallet进行文本挖掘――主题模型与垃圾邮件检测　　
.　文本挖掘简介　　
..　主题模型　　
..　文本分类　　
.　安装Mallet　　
.　使用文本数据　　
..　导入数据　　
..　对文本数据做预处理　　
.　为BBC新闻做主题模型　　
..　BBC数据集　　
..　建模　　
..　评估模型　　
..　重用模型　　
.　垃圾邮件检测　　
..　垃圾邮件数据集　　
..　特征生成　　
..　训练与测试模型　　
.　小结　　
第章　机器学习进阶　　
.　现实生活中的机器学习　　
..　噪声数据　　
..　类不平衡　　
..　特征选择困难　　
..　模型链　　
..　评价的重要性　　
..　从模型到产品　　
..　模型维护　　
.　标准与标记语言　　
..　CRISP-DM　　
..　SEMMA方法　　
..　预测模型标记语言　　
.　云端机器学习　　
.　Web资源与比赛　　
..　数据集　　
..　在线课程　　
..　比赛　　
..　网站与博客　　
..　场馆与会议　　
.　小结　　
・ ・ ・ ・ ・ ・ (收起)第部分 背景知识
第章 机器学习概述 
. 背景 
. 发展现状 
.. 数据现状 
.. 机器学习算法现状 
. 机器学习基本概念 
.. 机器学习流程 
.. 数据源结构 
.. 算法分类 
.. 过拟合问题 
.. 结果评估 
. 本章小结 
第部分 算法流程
第章 场景解析 
. 数据探查 
. 场景抽象 
. 算法选择 
. 本章小结 
第章 数据预处理 
. 采样 
.. 随机采样 
.. 系统采样 
.. 分层采样 
. 归一化 
. 去除噪声 
. 数据过滤 
. 本章小结 
第章 特征工程 
. 特征抽象 
. 特征重要性评估 
. 特征衍生 
. 特征降维 
.. 特征降维的基本概念 
.. 主成分分析 
. 本章小结 
第章 机器学习算法――常规算法 
. 分类算法 
.. K近邻 
.. 朴素贝叶斯 
.. 逻辑回归 
.. 支持向量机 
.. 随机森林 
. 聚类算法 
.. K-means 
.. DBSCAN 
. 回归算法 
. 文本分析算法 
.. 分词算法――Hmm 
.. TF-IDF 
.. LDA 
. 推荐类算法 
. 关系图算法 
.. 标签传播 
.. Dijkstra最短路径 
. 本章小结 
第章 机器学习算法――深度学习 
. 深度学习概述 
.. 深度学习的发展 
.. 深度学习算法与传统
算法的比较 
. 深度学习的常见结构 
.. 深度神经网络 
.. 卷积神经网络 
.. 循环神经网络 
. 本章小结 
第部分 工具介绍
第章 常见机器学习工具介绍 
. 概述 
. 单机版机器学习工具 
.. SPSS 
.. R语言 
.. 工具对比 
. 开源分布式机器学习工具 
.. Spark MLib 
.. TensorFlow 
. 企业级云机器学习工具 
.. 亚马逊AWS ML 
.. 阿里云机器学习PAI 
. 本章小结 
第部分 实战应用
第章 业务解决方案 
. 心脏病预测 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 商品推荐系统 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 金融风控案例 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 新闻文本分析 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 农业贷款发放预测 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 雾霾天气成因分析 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 图片识别 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 本章小结 
第部分 知识图谱
第章 知识图谱 
. 未来数据采集 
. 知识图谱的概述 
. 知识图谱开源
工具 
. 本章小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第一部分 场景化机器学习
第章 机器学习如何应用于业务　
. 为什么我们的业务系统如此糟糕　
. 为什么如今自动化很重要　
.. 什么是生产率　
.. 机器学习如何提高生产率　
. 机器如何做出决策　
.. 人：是否基于规则　
.. 你能相信一个基于模式的答案吗　
.. 机器学习如何能提升你的业务系统　
. 机器能帮Karen做决策吗　
.. 目标变量　
.. 特征　
. 机器如何学习　
. 在你的公司落实使用机器学习进行决策　
. 工具　
.. AWS和SageMaker是什么，它们如何帮助你　
.. Jupyter笔记本是什么　
. 配置SageMaker为解决第~章中的场景做准备　
. 是时候行动了　
. 小结　
第二部分 公司机器学习的六个场景
第章 你是否应该将采购订单发送给技术审批人　
. 决策　
. 数据　
. 开始你的训练过程　
. 运行Jupyter笔记本并进行预测　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集、验证集和测试集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 小结　
第章 你是否应该致电客户以防客户流失　
. 你在决策什么　
. 处理流程　
. 准备数据集　
.. 转换操作：标准化数据　
.. 转换操作：计算周与周之间的变化　
. XGBoost基础　
.. XGBoost的工作原理　
.. 机器学习模型如何确定函数的AUC的好坏　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集、验证集和测试集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第章 你是否应该将事件上报给支持团队　
. 你在决策什么　
. 处理流程　
. 准备数据集　
. NLP　
.. 生成词向量　
.. 决定每组包含多少单词　
. BlazingText及其工作原理　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集和验证集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第章 你是否应该质疑供应商发送给你的发票　
. 你在决策什么　
. 处理流程　
. 准备数据集　
. 什么是异常　
. 监督机器学习与无监督机器学习　
. 随机裁剪森林及其工作原理　
.. 样本　
.. 样本　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集和验证集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第章 预测你公司的每月能耗　
. 你在决策什么　
.. 时间序列数据介绍　
.. Kiara的时间序列数据：每日能耗　
. 加载处理时间序列数据的Jupyter笔记本　
. 准备数据集：绘制时间序列数据　
.. 通过循环展示数据列　
.. 创建多个图表　
. 神经网络是什么　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集和测试集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：进行预测并绘制结果　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第 章 优化你公司的每月能耗预测　
. DeepAR对周期性事件的处理能力　
. DeepAR的最大优势：整合相关的时间序列　
. 整合额外的数据集到Kiara的能耗模型　
. 准备构建模型　
.. 下载我们准备的笔记本　
.. 在SageMaker上设置文件夹　
.. 将笔记本上传到SageMaker　
.. 从S存储桶下载数据集　
.. 在S上创建文件夹以保存你的数据　
.. 将数据集上传到你的AWS存储桶　
. 构建模型　
.. 第一部分：设置笔记本　
.. 第二部分：导入数据集　
.. 第三部分：将数据转换为正确的格式　
.. 第四部分：创建训练集和测试集　
.. 第五部分：配置模型并设置服务器以构建模型　
.. 第六部分：进行预测并绘制结果　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第三部分 将机器学习应用到生产环境中
第章 通过Web提供预测服务　
. 为什么通过Web提供决策和预测服务这么难　
. 本章的步骤概述　
. SageMaker端点　
. 设置SageMaker端点　
.. 上传笔记本　
.. 上传数据　
.. 运行笔记本并创建端点　
. 设置无服务器API端点　
.. 在AWS账户上设置AWS证书　
.. 在本地计算机上设置AWS证书　
.. 配置证书　
. 创建Web端点　
.. 安装Chalice　
.. 创建Hello World API　
.. 添加为SageMaker端点提供服务的代码　
.. 配置权限　
.. 更新requirements.txt文件　
.. 部署Chalice　
. 提供决策服务　
. 小结　
第章 案例研究　
. 案例研究：WorkPac　
.. 项目设计　
.. 第一阶段：准备并测试模型　
.. 第二阶段：实施POC　
.. 第三阶段：将流程嵌入公司的运营中　
.. 接下来的工作　
.. 吸取的教训　
. 案例研究：Faethm　
.. AI核心　
.. 使用机器学习优化Faethm公司的流程　
.. 第一阶段：获取数据　
.. 第二阶段：识别特征　
.. 第三阶段：验证结果　
.. 第四阶段：应用到生产环境中　
. 结论　
.. 观点：建立信任　
.. 观点：正确获取数据　
.. 观点：设计操作模式以充分利用机器学习能力　
.. 观点：在各个方面都使用了机器学习后，你的公司看起来怎么样　
. 小结　
附录A 注册AWS　
附录B 设置并使用S以存储文件　
附录C 设置并使用AWS SageMaker来构建机器学习系统　
附录D 停止全部服务　
附录E 安装Python　
・ ・ ・ ・ ・ ・ (收起)第 章 MATLAB机器学习初体验 
.　机器学习基础　
.　机器学习算法的分类　
..　监督学习　
..　非监督学习　
..　强化学习　
.　选择正确的算法　
.　构建机器学习模型的流程　
.　MATLAB中的机器学习支持简介　
..　操作系统、硬件平台要求　
..　MATLAB安装要求　
.　统计机器学习工具箱　
..　数据类型　
..　统计机器学习工具箱功能简介　
.　神经网络工具箱　
.　MATLAB中的统计学和线性代数　
.　总结　
第　章 使用MATLAB导入数据和组织数据　
.　熟悉MATLAB桌面　
.　将数据导入MATLAB　
..　导入向导　
..　通过程序语句导入数据　
.　从MATLAB导出数据　
.　处理媒体文件　
..　处理图像数据　
..　音频的导入/导出　
.　数据组织　
..　元胞数组　
..　结构体数组　
..　table类型　
..　分类数组　
.　总结　
第章　从数据到知识挖掘　
.　区分变量类别　
..　定量变量　
..　定性变量　
.　数据准备　
..　初步查看数据　
..　找到缺失值　
..　改变数据类型　
..　替换缺失值　
..　移除缺失值　
..　为表格排序　
..　找到数据中的异常值　
..　将多个数据源合并成一个数据源　
.　探索性统计指标―数值测量　
..　位置测量　
..　分散度的测量　
..　分布形状的测量　
.　探索性可视化　
..　图形数据统计分析对话框　
..　柱状图　
..　箱形图　
..　散点图　
.　总结　
第章　找到变量之间的关系―回归方法　
.　寻找线性关系　
..　最小二乘回归　
..　基本拟合接口　
.　如何创建一个线性回归模型　
..　通过稳健回归消除异常值的影响　
..　多元线性回归　
.　多项式回归　
.　回归学习器App　
.　总结　
第章　模式识别之分类算法　
.　决策树分类　
.　概率分类模型―朴素贝叶斯分类　
..　概率论基础　
..　使用朴素贝叶斯进行分类　
..　MATLAB中的贝叶斯方法　
.　判别分析分类　
.　k邻近算法　
.　MATLAB分类学习器App　
.　总结　
第章　无监督学习　
.　聚类分析简介　
..　相似度与离散度指标　
..　聚类方法类型简介　
.　层次聚类算法　
..　层次聚类中的相似度指标　
..　定义层次聚类中的簇　
..　如何理解层次聚类图　
..　验证聚类结果　
.　k均值聚类―基于均值聚类　
..　k均值算法　
..　函数kmeans()　
..　silhouette图―可视化聚类结果　
.　k中心点聚类―基于样本中心聚类　
..　什么是中心点　
..　函数kmedoids()　
..　评估聚类结果　
.　高斯混合模型聚类　
..　高斯分布　
..　MATLAB中的GMM支持　
..　使用后验概率分布进行聚类　
.　总结　
第章　人工神经网络――模拟人脑的思考方式　
.　神经网络简介　
.　神经网络基础构成　
..　隐藏层数量　
..　每层的节点数量　
..　神经网络训练方法　
.　神经网络工具箱　
.　工具箱的用户界面　
.　使用神经网络进行数据拟合　
..　如何使用拟合App（nftool）　
..　脚本分析　
.　总结　
第章　降维――改进机器学习模型的性能　
.　特征选择　
..　分步回归　
..　MATLAB中的分步回归　
.　特征提取　
.　总结　
第章　机器学习实战　
.　用于预测混凝土质量的数据拟合　
.　使用神经网络诊断甲状腺疾病　
.　使用模糊聚类对学生进行分簇　
.　总结　
・ ・ ・ ・ ・ ・ (收起)译者序
前 言
致 谢
第章 引言
. 传统机器学习范式
. 案例
. 终身学习简史
. 终身学习的定义
. 知识类型和关键挑战
. 评估方法和大数据的角色
. 本书大纲
第章 相关学习范式
. 迁移学习
.. 结构对应学习
.. 朴素贝叶斯迁移分类器
.. 迁移学习中的深度学习
.. 迁移学习与终身学习的区别
. 多任务学习
.. 多任务学习中的任务相关性
.. GO-MTL：使用潜在基础任务的多任务学习
.. 多任务学习中的深度学习
.. 多任务学习与终身学习的区别
. 在线学习
. 强化学习
. 元学习
. 小结
第章 终身监督学习
. 定义和概述
. 基于记忆的终身学习
.. 两个基于记忆的学习方法
.. 终身学习的新表达
. 终身神经网络
.. MTL网络
.. 终身EBNN
. ELLA：高效终身学习算法
.. 问题设定
.. 目标函数
.. 解决一个低效问题
.. 解决第二个低效问题
.. 主动的任务选择
. 终身朴素贝叶斯分类
.. 朴素贝叶斯文本分类
.. LSC的基本思想
.. LSC技术
.. 讨论
. 基于元学习的领域词嵌入
. 小结和评估数据集
第章 持续学习与灾难性遗忘
. 灾难性遗忘
. 神经网络中的持续学习
. 无遗忘学习
. 渐进式神经网络
. 弹性权重合并
. iCaRL：增量分类器与表示学习
.. 增量训练
.. 更新特征表示
.. 为新类构建范例集
.. 在iCaRL中完成分类
. 专家网关
.. 自动编码网关
.. 测量训练的任务相关性
.. 为测试选择相关的专家
.. 基于编码器的终身学习
. 生成式重放的持续学习
.. 生成式对抗网络
.. 生成式重放
评估灾难性遗忘
. 小结和评估数据集
第章 开放式学习
. 问题定义和应用
. 基于中心的相似空间学习
.. 逐步更新CBS学习模型
.. 测试CBS学习模型
.. 用于未知类检测的CBS学习
. DOC：深度开放式分类
.. 前馈层和一对其余层
.. 降低开放空间
.. DOC用于图像分类
.. 发现未知类
. 小结和评估数据集
第章 终身主题建模
. 终身主题建模的主要思想
. LTM：终身主题模型
.. LTM模型
.. 主题知识挖掘
.. 融合过去的知识
.. Gibbs采样器的条件分布
. AMC：少量数据的终身主题模型
.. AMC整体算法
.. 挖掘must-link知识
.. 挖掘cannot-link知识
.. 扩展的Pólya瓮模型
.. Gibbs采样器的采样分布
. 小结和评估数据集
第章 终身信息提取
. NELL：停止语言学习器
.. NELL结构
.. NELL中的提取器与学习
.. NELL中的耦合约束
. 终身评价目标提取
.. 基于的终身学习
.. AER算法
.. 知识学习
.. 使用过去知识
. 在工作中学习
.. 条件随机场
.. 一般依赖特征
.. L-CRF算法
. Lifelong-RL：终身松弛标记法
.. 松弛标记法
.. 终身松弛标记法
. 小结和评估数据集
第章 聊天机器人的持续知识学习
. LiLi：终身交互学习与推理
. LiLi的基本思想
. LiLi的组件
. 运行示例
. 小结和评估数据集
第章 终身强化学习
. 基于多环境的终身强化学习
. 层次贝叶斯终身强化学习
.. 动机
.. 层次贝叶斯方法
.. MTRL算法
.. 更新层次模型参数
.. 对MDP进行采样
. PG-ELLA：终身策略梯度强化学习
.. 策略梯度强化学习
.. 策略梯度终身学习设置
.. 目标函数和优化
.. 终身学习的安全策略搜索
.. 跨领域终身强化学习
. 小结和评估数据集
第章 结论及未来方向
参考文献
・ ・ ・ ・ ・ ・ (收起)第章　Python机器学习实践入门 
.　机器学习常用概念 
.　数据的准备、处理和可视化
―NumPy、pandas和matplotlib教程 
..　NumPy的用法 
..　理解pandas模块 
..　matplotlib教程 
.　本书使用的科学计算库 
.　机器学习的应用场景 
.　小结 
第章　无监督机器学习 
.　聚类算法 
..　分布方法 
..　质心点方法 
..　密度方法 
..　层次方法 
.　降维 
.　奇异值分解（SVD） 
.　小结 
第章　有监督机器学习 
.　模型错误评估 
.　广义线性模型 
..　广义线性模型的概率
解释 
..　k近邻 
.　朴素贝叶斯 
..　多项式朴素贝叶斯 
..　高斯朴素贝叶斯 
.　决策树 
.　支持向量机 
.　有监督学习方法的对比 
..　回归问题 
..　分类问题 
.　隐马尔可夫模型 
.　小结 
第章　Web挖掘技术 
.　Web结构挖掘 
..　Web爬虫 
..　索引器 
..　排序―PageRank
算法 
.　Web内容挖掘 
句法解析 
.　自然语言处理 
.　信息的后处理 
..　潜在狄利克雷分配 
..　观点挖掘（情感
分析） 
.　小结 
第章　推荐系统 
.　效用矩阵 
.　相似度度量方法 
.　协同过滤方法 
..　基于记忆的协同
过滤 
..　基于模型的协同
过滤 
.　CBF方法 
..　商品特征平均得分
方法 
..　正则化线性回归
方法 
.　用关联规则学习，构建推荐
系统 
.　对数似然比推荐方法 
.　混合推荐系统 
.　推荐系统评估 
..　均方根误差（RMSE）
评估 
..　分类效果的度量方法 
.　小结 
第章　开始Django之旅 
.　HTTP―GET和POST方法的
基础 
..　Django的安装和
服务器的搭建 
..　配置 
.　编写应用―Django
最重要的功能 
..　model 
..　HTML网页背后的
URL和view 
..　URL声明和view 
.　管理后台 
..　shell接口 
..　命令 
..　RESTful应用编程
接口（API） 
.　小结 
第章　电影推荐系统Web应用 
.　让应用跑起来 
.　model 
.　命令 
.　实现用户的注册、登录和
登出功能 
.　信息检索系统（电影查询） 
.　打分系统 
.　推荐系统 
.　管理界面和API 
.　小结 
第章　影评情感分析应用 
.　影评情感分析应用用法
简介 
.　搜索引擎的选取和应用的
代码 
.　Scrapy的配置和情感分析
应用代码 
..　Scrapy的设置 
..　Scraper 
..　Pipeline 
..　爬虫 
.　Django model 
.　整合Django和Scrapy 
..　命令（情感分析模型和
删除查询结果） 
..　情感分析模型加载器 
..　删除已执行过的查询 
..　影评情感分析器―
Django view和HTML
代码 
.　PageRank：Django view和
算法实现 
.　管理后台和API 
.　小结 
・ ・ ・ ・ ・ ・ (收起)第章　监督学习　　
.　简介　　
.　数据预处理技术　　
..　准备工作　　
..　详细步骤　　
.　标记编码方法　　
.　创建线性回归器　　
..　准备工作　　
..　详细步骤　　
.　计算回归准确性　　
..　准备工作　　
..　详细步骤　　
.　保存模型数据　　
.　创建岭回归器　　
..　准备工作　　
..　详细步骤　　
.　创建多项式回归器　　
..　准备工作　　
..　详细步骤　　
.　估算房屋价格　　
..　准备工作　　
..　详细步骤　　
.　计算特征的相对重要性　　
.　评估共享单车的需求分布　　
..　准备工作　　
..　详细步骤　　
..　更多内容　　
第章　创建分类器　　
.　简介　　
.　建立简单分类器　　
..　详细步骤　　
..　更多内容　　
.　建立逻辑回归分类器　　
.　建立朴素贝叶斯分类器　　
.　将数据集分割成训练集和测试集　　
.　用交叉验证检验模型准确性　　
..　准备工作　　
..　详细步骤　　
.　混淆矩阵可视化　　
.　提取性能报告　　
.　根据汽车特征评估质量　　
..　准备工作　　
..　详细步骤　　
.　生成验证曲线　　
.　生成学习曲线　　
.　估算收入阶层　　
第章　预测建模　　
.　简介　　
.　用SVM建立线性分类器　　
..　准备工作　　
..　详细步骤　　
.　用SVM建立非线性分类器　　
.　解决类型数量不平衡问题　　
.　提取置信度　　
.　寻找最优超参数　　
.　建立事件预测器　　
..　准备工作　　
..　详细步骤　　
.　估算交通流量　　
..　准备工作　　
..　详细步骤　　
第章　无监督学习――聚类　　
.　简介　　
.　用k-means算法聚类数据　　
.　用矢量量化压缩图片　　
.　建立均值漂移聚类模型　　
.　用凝聚层次聚类进行数据分组　　
.　评价聚类算法的聚类效果　　
.　用DBSCAN算法自动估算集群数量　　
.　探索股票数据的模式　　
.　建立客户细分模型　　
第章　构建推荐引擎　　
.　简介　　
.　为数据处理构建函数组合　　
.　构建机器学习流水线　　
..　详细步骤　　
..　工作原理　　
.　寻找最近邻　　
.　构建一个KNN分类器　　
..　详细步骤　　
..　工作原理　　
.　构建一个KNN回归器　　
..　详细步骤　　
..　工作原理　　
.　计算欧氏距离分数　　
.　计算皮尔逊相关系数　　
.　寻找数据集中的相似用户　　
.　生成电影推荐　　
第章　分析文本数据　　
.　简介　　
.　用标记解析的方法预处理数据　　
.　提取文本数据的词干　　
..　详细步骤　　
..　工作原理　　
.　用词形还原的方法还原文本的基本形式　　
.　用分块的方法划分文本　　
.　创建词袋模型　　
..　详细步骤　　
..　工作原理　　
.　创建文本分类器　　
..　详细步骤　　
..　工作原理　　
.　识别性别　　
.　分析句子的情感　　
..　详细步骤　　
..　工作原理　　
.　用主题建模识别文本的模式　　
..　详细步骤　　
..　工作原理　　
第章　语音识别　　
.　简介　　
.　读取和绘制音频数据　　
.　将音频信号转换为频域　　
.　自定义参数生成音频信号　　
.　合成音乐　　
.　提取频域特征　　
.　创建隐马尔科夫模型　　
.　创建一个语音识别器　　
第章　解剖时间序列和时序数据　　
.　简介　　
.　将数据转换为时间序列格式　　
.　切分时间序列数据　　
.　操作时间序列数据　　
.　从时间序列数据中提取统计数字　　
.　针对序列数据创建隐马尔科夫模型　　
..　准备工作　　
..　详细步骤　　
.　针对序列文本数据创建条件随机场　　
..　准备工作　　
..　详细步骤　　
.　用隐马尔科夫模型分析股票市场数据　　
第章　图像内容分析　　
.　简介　　
.　用OpenCV-Pyhon操作图像　　
.　检测边　　
.　直方图均衡化　　
.　检测棱角　　
.　检测SIFT特征点　　
.　创建Star特征检测器　　
.　利用视觉码本和向量量化创建特征　　
.　用极端随机森林训练图像分类器　　
.　创建一个对象识别器　　
第章　人脸识别　　
.　简介　　
.　从网络摄像头采集和处理视频信息　　
.　用Haar级联创建一个人脸识别器　　
.　创建一个眼睛和鼻子检测器　　
.　做主成分分析　　
.　做核主成分分析　　
.　做盲源分离　　
.　用局部二值模式直方图创建一个人脸识别器　　
第章　深度神经网络　　
.　简介　　
.　创建一个感知器　　
.　创建一个单层神经网络　　
.　创建一个深度神经网络　　
.　创建一个向量量化器　　
.　为序列数据分析创建一个递归神经网络　　
.　在光学字符识别数据库中将字符可视化　　
.　用神经网络创建一个光学字符识别器　　
第章　可视化数据　　
.　简介　　
.　画D散点图　　
.　画气泡图　　
.　画动态气泡图　　
.　画饼图　　
.　画日期格式的时间序列数据　　
.　画直方图　　
.　可视化热力图　　
.　动态信号的可视化模拟　　
・ ・ ・ ・ ・ ・ (收起)目录
第章　机器学习基础　　
.　机器学习概要　　
什么是机器学习　　
机器学习的种类　　
机器学习的应用　　
.　机器学习的步骤　　
数据的重要性　　
有监督学习（分类）的例子　　
无监督学习（聚类）的例子　　
可视化　　
图形的种类和画法：使用Matplotlib显示图形的方法　　
使用pandas理解和处理数据　　
本章小结　　
第章　有监督学习　　
.　算法：线性回归　　
概述　　
算法说明　　
详细说明　　
.　算法：正则化　　
概述　　
算法说明　　
详细说明　　
.　算法：逻辑回归　　
概述　　
算法说明　　
详细说明　　
.　算法：支持向量机　　
概述　　
算法说明　　
详细说明　　
.　算法：支持向量机（核方法）　　
概述　　
算法说明　　
详细说明　　
.　算法：朴素贝叶斯　　
概述　　
算法说明　　
详细说明　　
.　算法：随机森林　　
概述　　
算法说明　　
详细说明　　
.　算法：神经网络　　
概述　　
算法说明　　
详细说明　　
.　算法：KNN　　
概述　　
算法说明　　
详细说明　　
第章　无监督学习　　
.　算法：PCA　　
概述　　
算法说明　　
详细说明　　
.　算法：LSA　　
概述　　
算法说明　　
详细说明　　
.　算法：NMF　　
概述　　
算法说明　　
详细说明　　
.　算法：LDA　　
概述　　
算法说明　　
详细说明　　
.　算法：k-means算法　　
概述　　
算法说明　　
详细说明　　
.　算法：混合高斯分布　　
概述　　
算法说明　　
详细说明　　
.　算法：LLE　　
概述　　
算法说明　　
详细说明　　
.　算法：t-SNE　　
概述　　
算法说明　　
详细说明　　
第章　评估方法和各种数据的处理　　
.　评估方法　　
有监督学习的评估　　
分类问题的评估方法　　
回归问题的评估方法　　
均方误差和决定系数指标的不同　　
与其他算法进行比较　　
超参数的设置　　
模型的过拟合　　
防止过拟合的方法　　
将数据分为训练数据和验证数据　　
交叉验证　　
搜索超参数　　
.　文本数据的转换处理　　
基于单词出现次数的转换　　
基于tf-idf的转换　　
应用于机器学习模型　　
.　图像数据的转换处理　　
直接将像素信息作为数值使用　　
将转换后的向量数据作为输入来应用机器学习模型　　
第章　环境搭建 
.　Python 的安装　　
Windows　　
macOS　　
Linux　　
使用Anaconda在Windows上安装　　
.　虚拟环境　　
通过官方安装程序安装Python的情况　　
通过Anaconda安装Python的情况　　
.　第三方包的安装　　
什么是第三方包　　
安装第三方包的方法　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)第章　学习前的准备　　
.　关于机器学习 
..　学习机器学习的窍门 
..　机器学习中问题的分类 
..　本书的结构 
.　安装Python 
.　Jupyter Notebook 
..　Jupyter Notebook的用法 
..　输入Markdown格式文本 
..　更改文件名 
.　安装Keras和TensorFlow 
第章　Python基础知识　　
.　四则运算 
..　四则运算的用法 
..　幂运算 
.　变量 
..　利用变量进行计算 
..　变量的命名 
.　类型 
..　类型的种类 
..　检查类型 
..　字符串 
.　print 语句 
..　print语句的用法 
..　同时显示数值和字符串的方法 
..　同时显示数值和字符串的方法 
.　list（数组变量） 
..　list的用法 
..　二维数组 
..　创建连续的整数数组 
.　tuple（数组） 
..　tuple的用法 
..　读取元素 
..　长度为的tuple 
.　if 语句 
..　if语句的用法 
..　比较运算符 
.　for 语句 
..　for语句的用法 
..　enumerate的用法 
.　向量 
..　NumPy的用法 
..　定义向量 
..　读取元素 
..　替换元素 
..　创建连续整数的向量 
..　ndarray的注意事项 
.　矩阵 
..　定义矩阵 
..　矩阵的大小 
..　读取元素 
..　替换元素 
..　生成元素为和的ndarray 
..　生成元素随机的矩阵 
..　改变矩阵的大小 
.　矩阵的四则运算 
..　矩阵的四则运算 
..　标量×矩阵 
..　算术函数 
..　计算矩阵乘积 
.　切片 
.　替换满足条件的数据 
.　help 
.　函数 
..　函数的用法 
..　参数与返回值 
.　保存文件 
..　保存一个ndarray类型变量 
..　保存多个ndarray类型变量 
第章　数据可视化　　
.　绘制二维图形 
..　绘制随机图形 
..　代码清单的格式 
..　绘制三次函数f (x) = (x - ) x (x + ) 
..　确定绘制范围 
..　绘制图形 
..　装饰图形 
..　并列显示多张图形 
.　绘制三维图形 
..　包含两个变量的函数 
..　用颜色表示数值：pcolor 
..　绘制三维图形：surface 
..　绘制等高线：contour 
第章　机器学习中的数学　　
.　向量 
..　什么是向量 
..　用Python定义向量 
..　列向量的表示方法 
..　转置的表示方法 
..　加法和减法 
..　标量积 
..　内积 
..　向量的模 
.　求和符号 
..　带求和符号的数学式的变形 
..　通过内积求和 
.　累乘符号 
.　导数 
..　多项式的导数 
..　带导数符号的数学式的变形 
..　复合函数的导数 
..　复合函数的导数：链式法则 
.　偏导数 
..　什么是偏导数 
..　偏导数的图形 
..　绘制梯度的图形 
..　多变量的复合函数的偏导数 
..　交换求和与求导的顺序 
.　矩阵 
..　什么是矩阵 
..　矩阵的加法和减法 
..　标量积 
..　矩阵的乘积 
..　单位矩阵 
..　逆矩阵 
..　转置 
..　矩阵和联立方程式 
..　矩阵和映射 
.　指数函数和对数函数 
..　指数 
..　对数 
..　指数函数的导数 
..　对数函数的导数 
..　Sigmoid函数 
..　Softmax函数 
..　Softmax函数和Sigmoid函数 
..　高斯函数 
..　二维高斯函数 
第章　有监督学习：回归　　
.　一维输入的直线模型 
..　直线模型 
..　平方误差函数 
..　求参数（梯度法） 
..　直线模型参数的解析解 
.　二维输入的平面模型 
..　数据的表示方法 
..　平面模型 
..　平面模型参数的解析解 
.　D维线性回归模型 
..　D维线性回归模型 
..　参数的解析解 
..　扩展到不通过原点的平面 
.　线性基底函数模型 
.　过拟合问题 
.　新模型的生成 
.　模型的选择 
.　小结 
第章　有监督学习：分类　　
.　一维输入的二元分类 
..　问题设置 
..　使用概率表示类别分类 
..　最大似然估计 
..　逻辑回归模型 
..　交叉熵误差 
..　学习法则的推导 
..　通过梯度法求解 
.　二维输入的二元分类 
..　问题设置 
..　逻辑回归模型 
.　二维输入的三元分类 
..　三元分类逻辑回归模型 
..　交叉熵误差 
..　通过梯度法求解 
第章　神经网络与深度学习　　
.　神经元模型 
..　神经细胞 
..　神经元模型 
.　神经网络模型 
..　二层前馈神经网络 
..　二层前馈神经网络的实现 
..　数值导数法 
..　通过数值导数法应用梯度法 
..　误差反向传播法 
..　求.E / .vkj 
..　求.E / .wji 
..　误差反向传播法的实现 
..　学习后的神经元的特性 
.　使用Keras实现神经网络模型 
..　二层前馈神经网络 
..　Keras的使用流程 
第章　神经网络与深度学习的应用（手写数字识别）　　
.　MINST数据集 
.　二层前馈神经网络模型 
.　ReLU激活函数 
.　空间过滤器 
.　卷积神经网络 
.　池化 
.　Dropout 
.　融合了各种特性的MNIST识别网络模型 
第章　无监督学习　　
.　二维输入数据 
.　K-means算法 
..　K-means算法的概要 
..　步骤：准备变量与初始化 
..　步骤：更新R 
..　步骤：更新μ 
..　失真度量 
.　混合高斯模型 
..　基于概率的聚类 
..　混合高斯模型 
..　EM算法的概要 
..　步骤：准备变量与初始化 
..　步骤（步骤E）：更新γ 
..　步骤（步骤M）：更新π、μ和Σ 
..　似然 
第章　本书小结　　
后记　　
・ ・ ・ ・ ・ ・ (收起)译者序
原书前言
致谢
第章 文本机器学习导论
.导论
..本章内容组织结构
.文本学习有何特别之处
.文本分析模型
..文本预处理和相似度计算
..降维与矩阵分解
..文本聚类
..文本分类与回归建模
..结合文本与异构数据的联合分析
..信息检索与网页搜索
..序列语言建模与嵌入
..文本摘要
..信息提取
..意见挖掘与情感分析
..文本分割与事件检测
.本章小结
.参考资料
..软件资源
.习题
第章 文本预处理与相似度计算
.导论
..本章内容组织结构
.原始文本提取与词条化
..文本提取中与网页相关的问题
.从词条中提取词项
..停用词移除
..连字符
..大小写转换
..基于用法的合并
..词干提取
.向量空间表示与归一化
.文本中的相似度计算
..idf归一化和词干提取是否总是有用
.本章小结
.参考资料
..软件资源
.习题
第章 矩阵分解与主题建模
.导论
..本章内容组织结构
..将二分解归一化为标准的三分解
.奇异值分解（SVD)
..SVD的例子
..实现SVD的幂迭代法
..SVD/LSA的应用
..SVD/LSA的优缺点
.非负矩阵分解
..非负矩阵分解的可解释性
..非负矩阵分解的例子
..融入新文档
..非负矩阵分解的优缺点
.概率潜在语义分析（PLSA）
..与非负矩阵分解的联系
..与SVD的比较
..PLSA的例子
..PLSA的优缺点
.隐含狄利克雷分布（LDA）概览
..简化的LDA模型
..平滑的LDA模型
.非线性变换和特征工程
..选择一个相似度函数
..Nystrom估计
..相似度矩阵的部分可用性
.本章小结
.参考资料
..软件资源
.习题
第章 文本聚类
.导论
..本章内容组织结构
.特征选择与特征工程
..特征选择
..特征工程
.主题建模和矩阵分解
..混合隶属度模型与重叠簇
..非重叠簇与双聚类：矩阵分解的角度
.面向聚类的生成混合模型
..伯努利模型
..多项式模型
..与混合隶属度主题模型的比较
..与朴素贝叶斯分类模型的联系
.k均值算法
..收敛与初始化
..计算复杂度
..与概率模型的联系
.层次聚类算法
..高效实现与计算复杂度
..与k均值的自然联姻
.聚类集成
..选择集成分量
..混合来自不同分量的结果
.将文本当作序列来进行聚类
..面向聚类的核方法
..数据相关的核方法：谱聚类
.聚类到有监督学习的转换
..实际问题
.聚类评估
..内部有效性度量的缺陷
..外部有效性度量
.本章小结
.参考资料
..软件资源
.习题
第章 文本分类：基本模型
.导论
..标记的类型与回归建模
..训练与测试
..归纳、直推和演绎学习器
..基本模型
..分类器中与文本相关的挑战
.特征选择与特征工程
..基尼系数
..条件熵
..逐点互信息
..紧密相关的度量方式
..χ-统计量
..嵌入式特征选择模型
..特征工程技巧
.朴素贝叶斯模型
..伯努利模型
..多项式模型
..实际观察
..利用朴素贝叶斯对输出进行排序
..朴素贝叶斯的例子
..半监督朴素贝叶斯
.最近邻分类器
..-最近邻分类器的属性
..Rocchio与最近质心分类
..加权最近邻
..自适应最近邻：一系列有效的方法
.决策树与随机森林
..构造决策树的基本步骤
..分裂一个节点
..多变量分裂
..决策树在文本分类中的问题
..随机森林
..把随机森林看作自适应最近邻方法
.基于规则的分类器
..顺序覆盖算法
..从决策树中生成规则
..关联分类器
..预测
.本章小结
.参考资料
..软件资源
.习题
第章 面向文本的线性分类与回归
.导论
..线性模型的几何解释
..我们需要偏置变量吗
..使用正则化的线性模型的一般定义
..将二值预测推广到多类
..面向文本的线性模型的特点
.最小二乘回归与分类
..使用L正则化的最小二乘回归
..LASSO:使用L正则化的最小二乘回归
..Fisher线性判别与最小二乘分类器
.支持向量机(SVM)
..正则优化解释
..最大间隔解释
..Pegasos：在原始空间中求解SVM 
..对偶SVM优化形式
..对偶SVM的学习算法
..对偶SVM的自适应最近邻解释
.对数几率回归
..正则优化解释
..对数几率回归的训练算法
..对数几率回归的概率解释
..多元对数几率回归与其他推广
..关于对数几率回归性能的评述
.线性模型的非线性推广
..基于显式变换的核SVM
..为什么传统的核函数能够提升线性可分性
..不同核函数的优缺点
..核技巧
..核技巧的系统性应用
.本章小结
.参考资料
..软件资源
.习题
第章 分类器的性能与评估
.导论
..本章内容组织结构
.偏置-方差权衡
..一个形式化的观点
..偏置和方差的迹象
.偏置-方差权衡在性能方面可能的影响
..训练数据规模的影响
..数据维度的影响
..文本中模型选择可能的影响
.利用集成方法系统性地提升性能
..bagging与子采样
..boosting
.分类器评估
..分割为训练部分和测试部分
..绝对准确率度量
..面向分类和信息检索的排序度量
.本章小结
.参考资料
..boosting与对数几率回归的联系
..分类器评估
..软件资源
..用于评估的数据集
.习题
第章 结合异构数据的联合文本挖掘
.导论
..本章内容组织结构
.共享矩阵分解的技巧
..分解图
..应用：结合文本和网页链接进行共享分解
..应用：结合文本与无向社交网络
..应用：结合文本的图像迁移学习
..应用：结合评分和文本的推荐系统
..应用：跨语言文本挖掘
.分解机
.联合概率建模技术
..面向聚类的联合概率模型
..朴素贝叶斯分类器
.到图挖掘技术的转换
.本章小结
.参考资料
..软件资源
.习题
第章 信息检索与搜索引擎
.导论
..本章内容组织结构
.索引和查询处理
..词典数据结构
..倒排索引
..线性时间的索引构建
..查询处理
..效率优化
.信息检索模型的评分
..基于tf-idf的向量空间模型
..二值独立模型
..使用词项频率的BM模型
..信息检索中的统计语言模型
.网络爬虫与资源发现
..一个基本的爬虫算法
..带偏好的爬虫
..多线程
..避开蜘蛛陷阱
..用于近似重复检测的Shingling方法
.搜索引擎中的查询处理
..分布式索引构建
..动态索引更新
..查询处理
..信誉度的重要性
.基于链接的排序算法
..PageRank
..HITS
.本章小结
.参考资料
..软件资源
.习题
第章 文本序列建模与深度学习
.导论
..本章内容组织结构
.统计语言模型
..skip-gram模型
..与嵌入的关系
.核方法
.单词-上下文矩阵分解模型 
..使用计数的矩阵分解
..GloVe嵌入
..PPMI矩阵分解
..位移PPMI矩阵分解
..融入句法和其他特征
.单词距离的图形化表示
.神经语言模型
..神经网络简介
..基于wordvec的神经嵌入
..wordvec(SGNS)是对数几率矩阵分解
..除了单词以外：基于docvec的段落嵌入
.循环神经网络(RNN)
..实际问题
..RNN的语言建模示例
..图像描述应用
..序列到序列学习与机器翻译
..句子级分类应用
..使用语言特征的词条级分类
..多层循环网络
.本章小结
.参考资料
..软件资源
.习题
第章 文本摘要
.导论
..提取式摘要与抽象式摘要
..提取式摘要中的关键步骤
..提取式摘要中的分割阶段
..本章内容组织结构
.提取式摘要的主题词方法
..词项概率
..归一化频率权重
..主题签名
..句子选择方法
.提取式摘要的潜在方法
..潜在语义分析
..词汇链
..基于图的方法
..质心摘要
.面向提取式摘要的机器学习
..特征提取
..使用哪种分类器
.多文档摘要
..基于质心的摘要
..基于图的方法
.抽象式摘要
..句子压缩
..信息融合
..信息排列
.本章小结
.参考资料
..软件资源
.习题
第章 信息提取
.导论
..历史演变
..自然语言处理的角色
..本章内容组织结构
.命名实体识别
..基于规则的方法
..转化为词条级分类任务
..隐马尔可夫模型
..最大熵马尔可夫模型
..条件随机场
.关系提取
..转换为分类问题
..利用显式的特征工程进行关系预测
..利用隐式的特征工程进行关系预测：核方法
.本章小结
.参考资料
..弱监督学习方法
..无监督与开放式信息提取 
..软件资源
.习题
第章 意见挖掘与情感分析
.导论
..意见词典
..把意见挖掘看作槽填充和信息提取任务
..本章内容组织结构
.文档级情感分析
..面向分类的无监督方法
.短语级与句子级情感分类
..句子级与短语级分析的应用
..主观性分类到最小割问题的归约
..句子级与短语级极性分析中的上下文
.把基于方面的意见挖掘看作信息提取任务
..Hu和Liu的无监督方法
..OPINE：一种无监督方法
..把有监督意见提取看作词条级分类任务
.虚假意见
..面向虚假评论检测的有监督方法
..面向虚假评论制造者检测的无监督方法
.意见摘要
..评分总结
..情感总结
..基于短语与句子的情感总结
..提取式与抽象式总结
.本章小结
.参考资料
..软件资源
.习题
第章 文本分割与事件检测
.导论
..与话题检测和追踪的关系
..本章内容组织结构
.文本分割
..TextTiling
..C方法
..基于现成的分类器的有监督的分割
..基于马尔可夫模型的有监督的分割
.文本流挖掘
..流式文本聚类
..面向首次报道检测的应用 
.事件检测
..无监督的事件检测
..把有监督的事件检测看作有监督的分割任务
..把事件检测看作一个信息提取问题
.本章小结
.参考资料
..软件资源
.习题
参考文献
・ ・ ・ ・ ・ ・ (收起)译者序
前言
第章探索数据分析
.Scala入门
.去除分类字段的重复值
.数值字段概述
.基本抽样、分层抽样和一致抽样
.使用Scala和Spark的Note―book工作
.相关性的基础
.总结
第章数据管道和建模
.影响图
.序贯试验和风险处理
.探索与利用问题
.不知之不知
.数据驱动系统的基本组件
..数据收集
..数据转换层
..数据分析与机器学习
..UI组件
..动作引擎
..关联引擎
..监控
.优化和交互
.总结
第章使用Spark和MLlib
.安装Spark
.理解Spark的架构
..任务调度
..Spark的组件
..MQTT、ZeroMQ、Flume和Kafka
..HDFS、Cassandra、S和Tachyon
..Mesos、YARN和Standa―lone
.应用
..单词计数
..基于流的单词计数
..SparkSQL和数据框
.机器学习库
..SparkR
..图算法：Graphx和Graph―Frames
.Spark的性能调整
.运行Hadoop的HDFS
.总结
第章监督学习和无监督学习
.记录和监督学习
..Iirs数据集
..类标签点
..SVMWithSGD
..logistic回归
..决策树
..bagging和boosting：集成学习方法
.无监督学习
.数据维度
.总结
第章回归和分类
.回归是什么
.连续空间和度量
.线性回归
.logistic回归
.正则化
.多元回归
.异方差
.回归树
.分类的度量
.多分类问题
.感知机
.泛化误差和过拟合
.总结
第章使用非结构化数据
.嵌套数据
.其他序列化格式
.Hive和Impala
.会话化
.使用特质
.使用模式匹配
.非结构化数据的其他用途
.概率结构
.投影
.总结
第章使用图算法
.图简介
.SBT
.Scala的图项目
..增加节点和边
..图约束
..JSON
.GraphX
..谁收到电子邮件
..连通分量
..三角形计数
..强连通分量
..PageRank
..SVD++
.总结
第章Scala与R和Python的集成
.R的集成
..R和SparkR的相关配置
..数据框
..线性模型
..广义线性模型
..在SparkR中读取JSON文件
..在SparkR中写入Parquet文件
..从R调用Scala
.Python的集成
..安装Python
..PySpark
..从Java／Scala调用Python
.总结
第章Scala中的NLP
.文本分析流程
.Spark的MLlib库
..TF―IDF
..LDA
.分词、标注和分块
.POS标记
.使用wordvec寻找词关系
.总结
第章高级模型监控
.系统监控
.进程监控
.模型监控
..随时间变化的性能
..模型停用标准
..A／B测试
.总结
・ ・ ・ ・ ・ ・ (收起)目 录
第章 概 述
. 什么是机器学习――从一个小故事开始 / 
. 机器学习的一些应用场景――蝙蝠公司的业务单元 / 
. 机器学习应该如何入门――世上无难事 / 
. 有监督学习与无监督学习 / 
. 机器学习中的分类与回归 / 
. 模型的泛化、过拟合与欠拟合 / 
. 小结 / 
第章 基于Python语言的环境配置
. Python的下载和安装 / 
. Jupyter Notebook的安装与使用方法 / 
.. 使用pip进行Jupyter Notebook的下载和安装 / 
.. 运行Jupyter Notebook / 
.. Jupyter Notebook的使用方法 / 
. 一些必需库的安装及功能简介 / 
.. Numpy――基础科学计算库 / 
.. Scipy――强大的科学计算工具集 / 
.. pandas――数据分析的利器 / 
.. matplotlib――画出优美的图形 / 
深入浅出Python 机器学习
VIII
. scikit-learn――非常流行的Python机器学习库 / 
. 小结 / 
第章 K最近邻算法――近朱者赤，近墨者黑
. K最近邻算法的原理 / 
. K最近邻算法的用法 / 
.. K最近邻算法在分类任务中的应用 / 
.. K最近邻算法处理多元分类任务 / 
.. K最近邻算法用于回归分析 / 
. K最近邻算法项目实战――酒的分类 / 
.. 对数据集进行分析 / 
.. 生成训练数据集和测试数据集 / 
.. 使用K最近邻算法进行建模 / 
.. 使用模型对新样本的分类进行预测 / 
. 小结 / 
第章 广义线性模型――“耿直”的算法模型
. 线性模型的基本概念 / 
.. 线性模型的一般公式 / 
.. 线性模型的图形表示 / 
.. 线性模型的特点 / 
. 最基本的线性模型――线性回归 / 
.. 线性回归的基本原理 / 
.. 线性回归的性能表现 / 
. 使用L正则化的线性模型――岭回归 / 
.. 岭回归的原理 / 
.. 岭回归的参数调节 / 
. 使用L正则化的线性模型――套索回归 / 
.. 套索回归的原理 / 
.. 套索回归的参数调节 / 
.. 套索回归与岭回归的对比 / 
目
录
IX
. 小结 / 
第章 朴素贝叶斯――打雷啦，收衣服啊
. 朴素贝叶斯基本概念 / 
.. 贝叶斯定理 / 
.. 朴素贝叶斯的简单应用 / 
. 朴素贝叶斯算法的不同方法 / 
.. 贝努利朴素贝叶斯 / 
.. 高斯朴素贝叶斯 / 
.. 多项式朴素贝叶斯 / 
. 朴素贝叶斯实战――判断肿瘤是良性还是恶性 / 
.. 对数据集进行分析 / 
.. 使用高斯朴素贝叶斯进行建模 / 
.. 高斯朴素贝叶斯的学习曲线 / 
. 小结 / 
第章 决策树与随机森林――会玩读心术的算法
. 决策树 / 
.. 决策树基本原理 / 
.. 决策树的构建 / 
.. 决策树的优势和不足 / 
. 随机森林 / 
.. 随机森林的基本概念 / 
.. 随机森林的构建 / 
.. 随机森林的优势和不足 / 
. 随机森林实例――要不要和相亲对象进一步发展 / 
.. 数据集的准备 / 
.. 用get_dummies处理数据 / 
.. 用决策树建模并做出预测 / 
. 小结 / 
第章 支持向量机SVM――专治线性不可分
. 支持向量机SVM基本概念 / 
.. 支持向量机SVM的原理 / 
.. 支持向量机SVM的核函数 / 
. SVM的核函数与参数选择 / 
.. 不同核函数的SVM对比 / 
.. 支持向量机的gamma参数调节 / 
.. SVM算法的优势与不足 / 
. SVM实例――波士顿房价回归分析 / 
.. 初步了解数据集 / 
.. 使用SVR进行建模 / 
. 小结 / 
第章 神经网络――曾入“冷宫”，如今得宠
. 神经网络的前世今生 / 
.. 神经网络的起源 / 
.. 第一个感知器学习法则 / 
.. 神经网络之父――杰弗瑞・欣顿 / 
. 神经网络的原理及使用 / 
.. 神经网络的原理 / 
.. 神经网络中的非线性矫正 / 
.. 神经网络的参数设置 / 
. 神经网络实例――手写识别 / 
.. 使用MNIST数据集 / 
.. 训练MLP神经网络 / 
.. 使用模型进行数字识别 / 
. 小结 / 
第章 数据预处理、降维、特征提取及聚类――快
刀斩乱麻
. 数据预处理 / 
.. 使用StandardScaler进行数据预处理 / 
.. 使用MinMaxScaler进行数据预处理 / 
.. 使用RobustScaler进行数据预处理 / 
.. 使用Normalizer进行数据预处理 / 
.. 通过数据预处理提高模型准确率 / 
. 数据降维 / 
.. PCA主成分分析原理 / 
.. 对数据降维以便于进行可视化 / 
.. 原始特征与PCA主成分之间的关系 / 
. 特征提取 / 
.. PCA主成分分析法用于特征提取 / 
.. 非负矩阵分解用于特征提取 / 
. 聚类算法 / 
.. K均值聚类算法 / 
.. 凝聚聚类算法 / 
.. DBSCAN算法 / 
. 小结 / 
第章 数据表达与特征工程――锦上再添花
. 数据表达 / 
.. 使用哑变量转化类型特征 / 
.. 对数据进行装箱处理 / 
. 数据“升维” / 
.. 向数据集添加交互式特征 / 
.. 向数据集添加多项式特征 / 
. 自动特征选择 / 
.. 使用单一变量法进行特征选择 / 
.. 基于模型的特征选择 / 
.. 迭代式特征选择 / 
. 小结 / 
第章 模型评估与优化――只有更好，没有最好
. 使用交叉验证进行模型评估 / 
.. scikit-learn中的交叉验证法 / 
.. 随机拆分和“挨个儿试试” / 
.. 为什么要使用交叉验证法 / 
. 使用网格搜索优化模型参数 / 
.. 简单网格搜索 / 
.. 与交叉验证结合的网格搜索 / 
. 分类模型的可信度评估 / 
.. 分类模型中的预测准确率 / 
.. 分类模型中的决定系数 / 
. 小结 / 
第章 建立算法的管道模型――团结就是力量
. 管道模型的概念及用法 / 
.. 管道模型的基本概念 / 
.. 使用管道模型进行网格搜索 / 
. 使用管道模型对股票涨幅进行回归分析 / 
.. 数据集准备 / 
.. 建立包含预处理和MLP模型的管道模型 / 
.. 向管道模型添加特征选择步骤 / 
. 使用管道模型进行模型选择和参数调优 / 
.. 使用管道模型进行模型选择 / 
.. 使用管道模型寻找更优参数 / 
. 小结 / 
第章 文本数据处理――亲，见字如“数”
. 文本数据的特征提取、中文分词及词袋模型 / 
.. 使用CountVectorizer对文本进行特征提取 / 
.. 使用分词工具对中文文本进行分词 / 
.. 使用词袋模型将文本数据转为数组 / 
. 对文本数据进一步进行优化处理 / 
.. 使用n-Gram改善词袋模型 / 
.. 使用tf-idf模型对文本数据进行处理 / 
.. 删除文本中的停用词 / 
. 小结 / 
第章 从数据获取到话题提取――从“研究员”
到“段子手”
. 简单页面的爬取 / 
.. 准备Requests库和User Agent / 
.. 确定一个目标网站并分析其结构 / 
.. 进行爬取并保存为本地文件 / 
. 稍微复杂一点的爬取 / 
.. 确定目标页面并进行分析 / 
.. Python中的正则表达式 / 
.. 使用BeautifulSoup进行HTML解析 / 
.. 对目标页面进行爬取并保存到本地 / 
. 对文本数据进行话题提取 / 
.. 寻找目标网站并分析结构 / 
.. 编写爬虫进行内容爬取 / 
.. 使用潜在狄利克雷分布进行话题提取 / 
. 小结 / 
第章 人才需求现状与未来学习方向――你是不
是下一个“大牛”
. 人才需求现状 / 
.. 全球AI从业者达万，人才需求年翻倍 / 
.. AI人才需求集中于一线城市，七成从业者月薪过万 / 
.. 人才困境仍难缓解，政策支援亟不可待 / 
. 未来学习方向 / 
.. 用于大数据分析的计算引擎 / 
.. 深度学习开源框架 / 
.. 使用概率模型进行推理 / 
. 技能磨炼与实际应用 / 
.. Kaggle算法大赛平台和OpenML平台 / 
.. 在工业级场景中的应用 / 
.. 对算法模型进行A/B测试 / 
. 小结 / 
参考文献 / 
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
序一
序二
序三
前言
第章　通向智能安全的旅程 
.　人工智能、机器学习与深度学习 
.　人工智能的发展 
.　国内外网络安全形势 
.　人工智能在安全领域的应用 
.　算法和数据的辩证关系 
.　本章小结 
参考资源 
第章　打造机器学习工具箱 
.　Python在机器学习领域的优势 
..　NumPy 
..　SciPy 
..　NLTK 
..　Scikit-Learn 
.　TensorFlow简介与环境搭建 
.　本章小结 
参考资源 
第章　机器学习概述 
.　机器学习基本概念 
.　数据集 
..　KDD 数据 
..　HTTP DATASET CSIC  
..　SEA数据集 
..　ADFA-LD数据集 
..　Alexa域名数据 
..　Scikit-Learn数据集 
..　MNIST数据集 
..　Movie Review Data 
..　SpamBase数据集 
..　Enron数据集 
.　特征提取 
..　数字型特征提取 
..　文本型特征提取 
..　数据读取 
.　效果验证 
.　本章小结 
参考资源 
第章　Web安全基础 
.　XSS攻击概述 
..　XSS的分类 
..　XSS特殊攻击方式 
..　XSS平台简介 
..　近年典型XSS攻击事件分析 
.　SQL注入概述 
..　常见SQL注入攻击 
..　常见SQL注入攻击载荷 
..　SQL常见工具 
..　近年典型SQL注入事件分析 
.　WebShell概述 
..　WebShell功能 
..　常见WebShell 
.　僵尸网络概述 
..　僵尸网络的危害 
..　近年典型僵尸网络攻击事件分析 
.　本章小结 
参考资源 
第章　K近邻算法 
.　K近邻算法概述 
.　示例：hello world！K近邻 
.　示例：使用K近邻算法检测异常操作（一） 
.　示例：使用K近邻算法检测异常操作（二） 
.　示例：使用K近邻算法检测Rootkit 
.　示例：使用K近邻算法检测WebShell 
.　本章小结 
参考资源 
第章　决策树与随机森林算法 
.　决策树算法概述 
.　示例：hello world！决策树 
.　示例：使用决策树算法检测POP暴力破解 
.　示例：使用决策树算法检测FTP暴力破解 
.　随机森林算法概述 
.　示例：hello world！随机森林 
.　示例：使用随机森林算法检测FTP暴力破解 
.　本章小结 
参考资源 
第章　朴素贝叶斯算法 
.　朴素贝叶斯算法概述 
.　示例：hello world！朴素贝叶斯 
.　示例：检测异常操作 
.　示例：检测WebShell（一） 
.　示例：检测WebShell（二） 
.　示例：检测DGA域名 
.　示例：检测针对Apache的DDoS攻击 
.　示例：识别验证码 
.　本章小结 
参考资源 
第章　逻辑回归算法 
.　逻辑回归算法概述 
.　示例：hello world！逻辑回归 
.　示例：使用逻辑回归算法检测Java溢出攻击 
.　示例：识别验证码 
.　本章小结 
参考资源 
第章　支持向量机算法 
.　支持向量机算法概述 
.　示例：hello world！支持向量机 
.　示例：使用支持向量机算法识别XSS 
.　示例：使用支持向量机算法区分僵尸网络DGA家族 
..　数据搜集和数据清洗 
..　特征化 
..　模型验证 
.　本章小结 
参考资源 
第章　K-Means与DBSCAN算法 
.　K-Means算法概述 
.　示例：hello world！K-Means 
.　示例：使用K-Means算法检测DGA域名 
.　DBSCAN算法概述 
.　示例：hello world！DBSCAN 
.　本章小结 
参考资源 
第章　Apriori与FP-growth算法 
.　Apriori算法概述 
.　示例：hello world！Apriori 
.　示例：使用Apriori算法挖掘XSS相关参数 
.　FP-growth算法概述 
.　示例：hello world！FP-growth 
.　示例：使用FP-growth算法挖掘疑似僵尸主机 
.　本章小结 
参考资源 
第章　隐式马尔可夫算法 
.　隐式马尔可夫算法概述 
.　hello world! 隐式马尔可夫 
.　示例：使用隐式马尔可夫算法识别XSS攻击（一） 
.　示例：使用隐式马尔可夫算法识别XSS攻击（二） 
.　示例：使用隐式马尔可夫算法识别DGA域名 
.　本章小结 
参考资源 
第章　图算法与知识图谱 
.　图算法概述 
.　示例：hello world！有向图 
.　示例：使用有向图识别WebShell 
.　示例：使用有向图识别僵尸网络 
.　知识图谱概述 
.　示例：知识图谱在风控领域的应用 
..　检测疑似账号被盗 
..　检测疑似撞库攻击 
..　检测疑似刷单 
.　示例：知识图谱在威胁情报领域的应用 
..　挖掘后门文件潜在联系 
..　挖掘域名潜在联系 
.　本章小结 
参考资源 
第章　神经网络算法 
.　神经网络算法概述 
.　示例：hello world！神经网络 
.　示例：使用神经网络算法识别验证码 
.　示例：使用神经网络算法检测Java溢出攻击 
.　本章小结 
参考资源 
第章　多层感知机与DNN算法 
.　神经网络与深度学习 
.　TensorFlow编程模型 
..　操作 
..　张量 
..　变量 
..　会话 
.　TensorFlow的运行模式 
.　示例：在TensorFlow下识别验证码（一） 
.　示例：在TensorFlow下识别验证码（二） 
.　示例：在TensorFlow下识别验证码（三） 
.　示例：在TensorFlow下识别垃圾邮件（一） 
.　示例：在TensorFlow下识别垃圾邮件（二） 
.　本章小结 
参考资源 
第章　循环神经网络算法 
.　循环神经网络算法概述 
.　示例：识别验证码 
.　示例：识别恶意评论 
.　示例：生成城市名称 
.　示例：识别WebShell 
.　示例：生成常用密码 
.　示例：识别异常操作 
.　本章小结 
参考资源 
第章　卷积神经网络算法 
.　卷积神经网络算法概述 
.　示例：hello world！卷积神经网络 
.　示例：识别恶意评论 
.　示例：识别垃圾邮件 
.　本章小结 
参考资源 
・ ・ ・ ・ ・ ・ (收起)第一部分 初始
 初识机器学习 
. 学习机器学习的误区 
. 什么是机器学习 
. Python 中的机器学习 
. 学习机器学习的原则 
. 学习机器学习的技巧 
. 这本书不涵盖以下内容 
. 代码说明 
. 总结 
 Python 机器学习的生态圈 
. Python 
. SciPy 
. scikit-learn 
. 环境安装 
. 总结 
 第一个机器学习项目 
. 机器学习中的 Hello World 项目 
. 导入数据 
. 概述数据 
. 数据可视化 
. 评估算法 
. 实施预测 
. 总结 
 Python 和 SciPy 速成 
. Python 速成 
. NumPy 速成 
. Matplotlib 速成 
. Pandas 速成 
. 总结 
第二部分 数据理解
 数据导入 
. CSV 文件 
. Pima Indians 数据集 
. 采用标准 Python 类库导入数据 
. 采用 NumPy 导入数据 
. 采用 Pandas 导入数据 
. 总结 
 数据理解 
. 简单地查看数据 
. 数据的维度 
. 数据属性和类型 
. 描述性统计 
. 数据分组分布（适用于分类算法） 
. 数据属性的相关性 
. 数据的分布分析 
. 总结 
 数据可视化 
. 单一图表 
. 多重图表 
. 总结 
第三部分 数据准备
 数据预处理 
. 为什么需要数据预处理 
. 格式化数据 
. 调整数据尺度 
. 正态化数据 
. 标准化数据 
. 二值数据 
. 总结 
 数据特征选定 
. 特征选定 
. 单变量特征选定 
. 递归特征消除 
. 主要成分分析 
. 特征重要性 
. 总结 
第四部分 选择模型
 评估算法 
. 评估算法的方法 
. 分离训练数据集和评估数据集 
. K 折交叉验证分离 
. 弃一交叉验证分离 
. 重复随机分离评估数据集与训练数据集 
. 总结 
 算法评估矩阵 
. 算法评估矩阵 
. 分类算法矩阵 
. 回归算法矩阵 
. 总结 
 审查分类算法 
. 算法审查 
. 算法概述 
. 线性算法 
. 非线性算法 
. 总结 
 审查回归算法 
. 算法概述 
. 线性算法 
. 非线性算法 
. 总结 
 算法比较 
. 选择最佳的机器学习算法 
. 机器学习算法的比较 
. 总结 
 自动流程 
. 机器学习的自动流程 
. 数据准备和生成模型的 Pipeline 
. 特征选择和生成模型的 Pipeline 
. 总结 
第五部分 优化模型
 集成算法 
. 集成的方法 
. 装袋算法 
. 提升算法 
. 投票算法 
. 总结 
 算法调参 
. 机器学习算法调参 
. 网格搜索优化参数 
. 随机搜索优化参数 
. 总结 
第六部分 结果部署
 持久化加载模型 
. 通过 pickle 序列化和反序列化机器学习的模型 
. 通过 joblib 序列化和反序列化机器学习的模型 
. 生成模型的技巧 
. 总结 
第七部分 项目实践
 预测模型项目模板 
. 在项目中实践机器学习 
. 机器学习项目的 Python 模板 
. 各步骤的详细说明 
. 使用模板的小技巧 
. 总结 
 回归项目实例 
. 定义问题 
. 导入数据 
. 理解数据 
. 数据可视化 
. 分离评估数据集 
. 评估算法 
. 调参改善算法 
. 集成算法 
. 集成算法调参 
. 确定最终模型 
. 总结 
 二分类实例 
. 问题定义 
. 导入数据 
. 分析数据 
. 分离评估数据集 
. 评估算法 
. 算法调参 
. 集成算法 
. 确定最终模型 
. 总结 
 文本分类实例 
. 问题定义 
. 导入数据 
. 文本特征提取 
. 评估算法 
. 算法调参 
. 集成算法 
. 集成算法调参 
. 确定最终模型 
. 总结 
・ ・ ・ ・ ・ ・ (收起)第 章 走进机器学习
. 机器学习概述
. 机器学习过程
第 章 了解Python
. 为什么选择Python
. 下载和安装Python
.. 在Windows中安装Python
.. Anaconda
. 首个Python程序
. Python基础
. 数据结构与循环
第章 特征工程
. 什么是特征
. 为什么执行特征工程
. 特征提取
. 特征选择
. 特征工程方法――通用准则
.. 处理数值特征
.. 处理分类特征
.. 处理基于时间的特征
.. 处理文本特征
.. 缺失数据
.. 降维
. 用Python进行特征工程
.. Pandas基本操作
.. 常见任务
第章 数据可视化
. 折线图
. 条形图
. 饼图
. 直方图
. 散点图
. 箱线图
. 采用面向对象的方式绘图
. Seaborn
.. 分布图
.. 双变量分布
.. 二元分布的核密度估计
.. 成对双变量分布
.. 分类散点图
.. 小提琴图
.. 点图
第章 回归
. 简单回归
. 多元回归
. 模型评价
.. 训练误差
.. 泛化误差
.. 测试误差
.. 不可约误差
.. 偏差―方差权衡
第章 更多回归
. 概述
. 岭回归
. 套索回归
.. 全子集算法
.. 用于特征选择的贪心算法
.. 特征选择的正则化
. 非参数回归
.. K-最近邻回归
.. 核回归
第章 分类
. 线性分类器
. 逻辑回归
. 决策树
.. 关于树的术语
.. 决策树学习
.. 决策边界
. 随机森林
. 朴素贝叶斯
第章 无监督学习
. 聚类
. K-均值聚类
.. 随机分配聚类质心的问题
.. 查找K的值
. 分层聚类
.. 距离矩阵
.. 连接
第章 文本分析
. 使用Python进行基本文本处理
.. 字符串比较
.. 字符串转换
.. 字符串操作
. 正则表达式
. 自然语言处理
.. 词干提取
.. 词形还原
.. 分词
. 文本分类
. 主题建模
第 章 神经网络与深度学习
. 矢量化
. 神经网络
.. 梯度下降
.. 激活函数
.. 参数初始化
.. 优化方法
.. 损失函数
. 深度学习
. 深度学习架构
.. 深度信念网络
.. 卷积神经网络
.. 循环神经网络
.. 长短期记忆网络
.. 深度堆栈网络
. 深度学习框架
第 章 推荐系统
. 基于流行度的推荐引擎
. 基于内容的推荐引擎
. 基于分类的推荐引擎
. 协同过滤
第 章 时间序列分析
. 处理日期和时间
. 窗口函数
. 相关性
. 时间序列预测
・ ・ ・ ・ ・ ・ (收起)前　言
第部分　实时机器学习方法论
第章　实时机器学习综述 
.　什么是机器学习 
.　机器学习发展的前世今生 
..　历史上机器学习无法调和的难题 
..　现代机器学习的新融合 
.　机器学习领域分类 
.　实时是个“万灵丹” 
.　实时机器学习的分类 
..　硬实时机器学习 
..　软实时机器学习 
..　批实时机器学习 
.　实时应用对机器学习的要求 
.　案例：Netflix在机器学习竞赛中学到的经验 
..　Netflix 用户信息被逆向工程 
..　Netflix 最终胜出者模型无法在生产环境中使用 
.　实时机器学习模型的生存期 
第章　实时监督式机器学习 
.　什么是监督式机器学习 
..　“江湖门派”对预测模型的
不同看法 
..　工业界的学术门派 
..　实时机器学习实战的思路 
.　怎样衡量监督式机器学习模型 
..　统计量的优秀 
..　应用业绩的优秀 
.　实时线性分类器介绍 
..　广义线性模型的定义 
..　训练线性模型 
..　冷启动问题 
第章　数据分析工具 Pandas 
.　颠覆 R 的 Pandas 
.　Pandas 的安装 
.　利用 Pandas 分析实时股票报价数据 
..　外部数据导入 
..　数据分析基本操作 
..　可视化操作 
..　秒级收盘价变化率初探 
.　数据分析的三个要点 
..　不断验证假设 
..　全面可视化，全面监控化 
第章　机器学习工具 Scikit-learn 
.　如何站在风口上？向Scikit-learn 学习 
..　传统的线下统计软件 R 
..　底层软件黑盒子 Weka 
..　跨界产品 Scikit-learn 
..　Scikit-learn的优势 
.　Scikit-learn 的安装 
.　Scikit-learn 的主要模块 
..　监督式、非监督式机器学习 
..　建模函数fit和predict 
..　数据预处理 
..　自动化建模预测 Pipeline 
.　利用 Scikit-learn 进行股票价格波动预测 
..　数据导入和预处理 
..　编写专有时间序列数据预处理模块 
..　利用 Pipeline 进行建模 
..　评价建模效果 
..　引入成交量和高维交叉项进行建模 
..　本书没有告诉你的 
第部分　实时机器学习架构
第章　实时机器学习架构设计 
.　设计实时机器学习架构的
四个要点 
.　Lambda 架构和主要成员 
..　实时响应层 
..　快速处理层 
..　批处理层 
.　常用的实时机器学习架构 
..　瀑布流架构 
..　并行响应架构 
..　实时更新模型混合架构 
.　小结 
第章　集群部署工具 Docker 
.　Docker 的前世今生 
.　容器虚拟机的基本组成部分 
.　Docker 引擎命令行工具 
..　Docker 引擎的安装 
..　Docker 引擎命令行的基本操作 
.　通过 Dockerfile 配置容器虚拟机 
..　利用 Dockerfile 配置基本容器虚拟机 
..　利用 Dockerfile 进行虚拟机和宿主机之间的文件传输 
.　服务器集群配置工具Docker Compose 
..　Docker Compose 的安装 
..　Docker Compose 的基本操作 
..　利用 Docker Compose 创建网页计数器集群 
.　远端服务器配置工具Docker Machine 
..　Docker Machine 的安装 
..　安装 Oracle VirtualBox 
..　创建和管理 VirtualBox中的虚拟机 
..　在 Docker Machine 和 VirtualBox的环境中运行集群 
..　利用 Docker Machine 在 Digital Ocean 上配置运行集群 
.　其他有潜力的 Docker 工具 
第章　实时消息队列和RabbitMQ 
.　实时消息队列 
.　AMQP 和 RabbitMQ 简介 
.　RabbitMQ的主要构成部分 
.　常用交换中心模式 
..　直连结构 
..　扇形结构 
..　话题结构 
..　报头结构 
.　消息传导设计模式 
..　任务队列 
..　Pub/Sub 发布/监听 
..　远程命令 
.　利用 Docker 快速部署RabbitMQ 
.　利用 RabbitMQ 开发队列服务 
..　准备案例材料 
..　实时报价存储服务 
..　实时走势预测服务 
..　整合运行实验 
..　总结和改进 
第章　实战数据库综述 
.　SQL 与 NoSQL，主流数据库分类 
..　关系型数据库 
..　非关系型数据库 NoSQL 
.　数据库的性能 
..　耐分割 
..　 一致性 
..　可用性 
..　CAP 定理 
.　SQL和NoSQL对比 
..　数据存储、读取方式 
..　数据库的扩展方式 
..　性能比较 
.　数据库的发展趋势 
..　不同数据库之间自动化同步更为方便 
..　云数据库的兴起 
..　底层和应用层多层化 
.　MySQL 简介 
.　Cassandra简介 
..　Cassandra交互方式简介 
..　利用Docker安装Cassandra 
..　使用Cassandra存储数据 
第章　实时数据监控 ELK 集群 
.　Elasticsearch、LogStash和Kibana 的前世今生 
..　Elasticsearch 的平凡起家 
..　LogStash 卑微的起源 
..　Kibana 惊艳登场 
..　ELK 协同作战 
.　Elasticsearch 基本架构 
..　文档 
..　索引和文档类型 
..　分片和冗余 
..　Elasticsearch 和数据库进行比较 
.　Elasticsearch 快速入门 
..　用 Docker 运行 Elasticsearch 容器虚拟机 
..　创建存储文档、文档类型和索引 
..　搜索文档 
..　对偶搜索 
.　Kibana 快速入门 
..　利用 Docker 搭建ELK 集群 
..　配置索引格式 
..　交互式搜索 
..　可视化操作 
..　实时检测面板 
第章　机器学习系统设计模式 
.　 设计模式的前世今生 
..　单机设计模式逐渐式微 
..　微服务取代设计模式的示例 
..　微服务设计模式的兴起 
.　读：高速键值模式 
..　问题场景 
..　解决方案 
..　其他使用场景 
.　读：缓存高速查询模式 
..　问题场景 
..　解决方案 
..　适用场景 
.　更新：异步数据库更新模式 
..　问题场景 
..　解决方案 
..　使用场景案例 
.　更新：请求重定向模式 
..　问题场景 
..　解决方案 
..　更新流程 
..　使用场景案例 
.　处理：硬实时并行模式 
..　问题场景 
..　解决方案 
..　使用场景案例 
.　处理：分布式任务队列模式 
..　问题场景 
..　解决方案 
..　Storm 作为分布式任务队列 
..　适用场景 
..　结构的演进 
.　处理：批实时处理模式 
..　问题场景 
..　解决方案 
..　适用场景 
第部分　未来展望
第章　Serverless 架构 
.　Serverless 架构的前世今生 
.　Serverless 架构对实时
机器学习的影响 
第章　深度学习的风口 
.　深度学习的前世今生 
.　深度学习的难点 
.　如何选择深度学习工具 
..　与现有编程平台、技能整合的难易程度 
..　此平台除做深度学习之外，还能做什么 
..　深度学习平台的成熟程度 
.　未来发展方向 
・ ・ ・ ・ ・ ・ (收起)I IMAGE FORMATION 
 Geometric Camera Models 
. Image Formation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Pinhole Perspective . . . . . . . . . . . . . . . . . . . . . . . 
.. Weak Perspective . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Cameras with Lenses . . . . . . . . . . . . . . . . . . . . . . . 
.. The Human Eye . . . . . . . . . . . . . . . . . . . . . . . . . 
. Intrinsic and Extrinsic Parameters . . . . . . . . . . . . . . . . . . . 
.. Rigid Transformations and Homogeneous Coordinates . . . . 
.. Intrinsic Parameters . . . . . . . . . . . . . . . . . . . . . . . 
.. Extrinsic Parameters . . . . . . . . . . . . . . . . . . . . . . . 
.. Perspective Projection Matrices . . . . . . . . . . . . . . . . . 
.. Weak-Perspective Projection Matrices . . . . . . . . . . . . . 
. Geometric Camera Calibration . . . . . . . . . . . . . . . . . . . . . 
.. ALinear Approach to Camera Calibration . . . . . . . . . . . 
.. ANonlinear Approach to Camera Calibration . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Light and Shading 
. Modelling Pixel Brightness . . . . . . . . . . . . . . . . . . . . . . . 
.. Reflection at Surfaces . . . . . . . . . . . . . . . . . . . . . . 
.. Sources and Their Effects . . . . . . . . . . . . . . . . . . . . 
.. The Lambertian+Specular Model . . . . . . . . . . . . . . . . 
.. Area Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Inference from Shading . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Radiometric Calibration and High Dynamic Range Images . . 
.. The Shape of Specularities . . . . . . . . . . . . . . . . . . . 
.. Inferring Lightness and Illumination . . . . . . . . . . . . . . 
.. Photometric Stereo: Shape from Multiple Shaded Images . . 
. Modelling Interreflection . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Illumination at a Patch Due to an Area Source . . . . . 
.. Radiosity and Exitance . . . . . . . . . . . . . . . . . . . . . 
.. An Interreflection Model . . . . . . . . . . . . . . . . . . . . . 
.. Qualitative Properties of Interreflections . . . . . . . . . . . . 
. Shape from One Shaded Image . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Color 
. Human Color Perception . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Color Matching . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Color Receptors . . . . . . . . . . . . . . . . . . . . . . . . . 
. The Physics of Color . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Color of Light Sources . . . . . . . . . . . . . . . . . . . 
.. The Color of Surfaces . . . . . . . . . . . . . . . . . . . . . . 
. Representing Color . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Linear Color Spaces . . . . . . . . . . . . . . . . . . . . . . . 
.. Non-linear Color Spaces . . . . . . . . . . . . . . . . . . . . . 
. AModel of Image Color . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Diffuse Term . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Specular Term . . . . . . . . . . . . . . . . . . . . . . . . 
. Inference from Color . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Finding Specularities Using Color . . . . . . . . . . . . . . . 
.. Shadow Removal Using Color . . . . . . . . . . . . . . . . . . 
.. Color Constancy: Surface Color from Image Color . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
II EARLY VISION: JUST ONE IMAGE 
 Linear Filters 
. Linear Filters and Convolution . . . . . . . . . . . . . . . . . . . . . 
.. Convolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Shift Invariant Linear Systems . . . . . . . . . . . . . . . . . . . . . 
.. Discrete Convolution . . . . . . . . . . . . . . . . . . . . . . . 
.. Continuous Convolution . . . . . . . . . . . . . . . . . . . . . 
.. Edge Effects in Discrete Convolutions . . . . . . . . . . . . . 
. Spatial Frequency and Fourier Transforms . . . . . . . . . . . . . . . 
.. Fourier Transforms . . . . . . . . . . . . . . . . . . . . . . . . 
. Sampling and Aliasing . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Aliasing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Smoothing and Resampling . . . . . . . . . . . . . . . . . . . 
. Filters as Templates . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Convolution as a Dot Product . . . . . . . . . . . . . . . . . 
.. Changing Basis . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Technique: Normalized Correlation and Finding Patterns . . . . . . 
.. Controlling the Television by Finding Hands by Normalized
Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Technique: Scale and Image Pyramids . . . . . . . . . . . . . . . . . 
.. The Gaussian Pyramid . . . . . . . . . . . . . . . . . . . . . 
.. Applications of Scaled Representations . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Local Image Features 
. Computing the Image Gradient . . . . . . . . . . . . . . . . . . . . . 
.. Derivative of Gaussian Filters . . . . . . . . . . . . . . . . . . 
. Representing the Image Gradient . . . . . . . . . . . . . . . . . . . . 
.. Gradient-Based Edge Detectors . . . . . . . . . . . . . . . . . 
.. Orientations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Finding Corners and Building Neighborhoods . . . . . . . . . . . . . 
.. Finding Corners . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Using Scale and Orientation to Build a Neighborhood . . . . 
. Describing Neighborhoods with SIFT and HOG Features . . . . . . 
.. SIFT Features . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. HOG Features . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Computing Local Features in Practice . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Texture 
. Local Texture Representations Using Filters . . . . . . . . . . . . . . 
.. Spots and Bars . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. From Filter Outputs to Texture Representation . . . . . . . . 
.. Local Texture Representations in Practice . . . . . . . . . . . 
. Pooled Texture Representations by Discovering Textons . . . . . . . 
.. Vector Quantization and Textons . . . . . . . . . . . . . . . . 
.. K-means Clustering for Vector Quantization . . . . . . . . . . 
. Synthesizing Textures and Filling Holes in Images . . . . . . . . . . 
.. Synthesis by Sampling Local Models . . . . . . . . . . . . . . 
.. Filling in Holes in Images . . . . . . . . . . . . . . . . . . . . 
. Image Denoising . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Non-local Means . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Block Matching D (BMD) . . . . . . . . . . . . . . . . . . 
.. Learned Sparse Coding . . . . . . . . . . . . . . . . . . . . . 
.. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Shape from Texture . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Shape from Texture for Planes . . . . . . . . . . . . . . . . . 
.. Shape from Texture for Curved Surfaces . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
III EARLY VISION: MULTIPLE IMAGES 
 Stereopsis 
. Binocular Camera Geometry and the Epipolar Constraint . . . . . . 
.. Epipolar Geometry . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Essential Matrix . . . . . . . . . . . . . . . . . . . . . . . 
.. The Fundamental Matrix . . . . . . . . . . . . . . . . . . . . 
. Binocular Reconstruction . . . . . . . . . . . . . . . . . . . . . . . . 
.. Image Rectification . . . . . . . . . . . . . . . . . . . . . . . . 
. Human Stereopsis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Local Methods for Binocular Fusion . . . . . . . . . . . . . . . . . . 
.. Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Multi-Scale Edge Matching . . . . . . . . . . . . . . . . . . . 
. Global Methods for Binocular Fusion . . . . . . . . . . . . . . . . . . 
.. Ordering Constraints and Dynamic Programming . . . . . . . 
.. Smoothness and Graphs . . . . . . . . . . . . . . . . . . . . . 
. Using More Cameras . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Application: Robot Navigation . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Structure from Motion 
. Internally Calibrated Perspective Cameras . . . . . . . . . . . . . . . 
.. Natural Ambiguity of the Problem . . . . . . . . . . . . . . . 
.. Euclidean Structure and Motion from Two Images . . . . . . 
.. Euclidean Structure and Motion from Multiple Images . . . . 
. Uncalibrated Weak-Perspective Cameras . . . . . . . . . . . . . . . . 
.. Natural Ambiguity of the Problem . . . . . . . . . . . . . . . 
.. Affine Structure and Motion from Two Images . . . . . . . . 
.. Affine Structure and Motion from Multiple Images . . . . . . 
.. From Affine to Euclidean Shape . . . . . . . . . . . . . . . . 
. Uncalibrated Perspective Cameras . . . . . . . . . . . . . . . . . . . 
.. Natural Ambiguity of the Problem . . . . . . . . . . . . . . . 
.. Projective Structure and Motion from Two Images . . . . . . 
.. Projective Structure and Motion from Multiple Images . . . . 
.. From Projective to Euclidean Shape . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
IV MID-LEVEL VISION 
 Segmentation by Clustering 
. Human Vision: Grouping and Gestalt . . . . . . . . . . . . . . . . . 
. Important Applications . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Background Subtraction . . . . . . . . . . . . . . . . . . . . . 
.. Shot Boundary Detection . . . . . . . . . . . . . . . . . . . . 
.. Interactive Segmentation . . . . . . . . . . . . . . . . . . . . 
.. Forming Image Regions . . . . . . . . . . . . . . . . . . . . . 
. Image Segmentation by Clustering Pixels . . . . . . . . . . . . . . . 
.. Basic Clustering Methods . . . . . . . . . . . . . . . . . . . . 
.. The Watershed Algorithm . . . . . . . . . . . . . . . . . . . . 
.. Segmentation Using K-means . . . . . . . . . . . . . . . . . . 
.. Mean Shift: Finding Local Modes in Data . . . . . . . . . . . 
.. Clustering and Segmentation with Mean Shift . . . . . . . . . 
. Segmentation, Clustering, and Graphs . . . . . . . . . . . . . . . . . 
.. Terminology and Facts for Graphs . . . . . . . . . . . . . . . 
.. Agglomerative Clustering with a Graph . . . . . . . . . . . . 
.. Divisive Clustering with a Graph . . . . . . . . . . . . . . . . 
.. Normalized Cuts . . . . . . . . . . . . . . . . . . . . . . . . . 
. Image Segmentation in Practice . . . . . . . . . . . . . . . . . . . . . 
.. Evaluating Segmenters . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Grouping and Model Fitting 
. The Hough Transform . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting Lines with the Hough Transform . . . . . . . . . . . . 
.. Using the Hough Transform . . . . . . . . . . . . . . . . . . . 
. Fitting Lines and Planes . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting a Single Line . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting Planes . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting Multiple Lines . . . . . . . . . . . . . . . . . . . . . . 
. Fitting Curved Structures . . . . . . . . . . . . . . . . . . . . . . . . 
. Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. M-Estimators . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. RANSAC: Searching for Good Points . . . . . . . . . . . . . 
. Fitting Using Probabilistic Models . . . . . . . . . . . . . . . . . . . 
.. Missing Data Problems . . . . . . . . . . . . . . . . . . . . . 
.. Mixture Models and Hidden Variables . . . . . . . . . . . . . 
.. The EM Algorithm for Mixture Models . . . . . . . . . . . . 
.. Difficulties with the EM Algorithm . . . . . . . . . . . . . . . 
. Motion Segmentation by Parameter Estimation . . . . . . . . . . . . 
.. Optical Flow and Motion . . . . . . . . . . . . . . . . . . . . 
.. Flow Models . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Motion Segmentation with Layers . . . . . . . . . . . . . . . 
. Model Selection: Which Model Is the Best Fit? . . . . . . . . . . . . 
.. Model Selection Using Cross-Validation . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Tracking 
. Simple Tracking Strategies . . . . . . . . . . . . . . . . . . . . . . . . 
.. Tracking by Detection . . . . . . . . . . . . . . . . . . . . . . 
.. Tracking Translations by Matching . . . . . . . . . . . . . . . 
.. Using Affine Transformations to Confirm a Match . . . . . . 
. Tracking Using Matching . . . . . . . . . . . . . . . . . . . . . . . . 
.. Matching Summary Representations . . . . . . . . . . . . . . 
.. Tracking Using Flow . . . . . . . . . . . . . . . . . . . . . . . 
. Tracking Linear Dynamical Models with Kalman Filters . . . . . . . 
.. Linear Measurements and Linear Dynamics . . . . . . . . . . 
.. The Kalman Filter . . . . . . . . . . . . . . . . . . . . . . . . 
.. Forward-backward Smoothing . . . . . . . . . . . . . . . . . . 
. Data Association . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Linking Kalman Filters with Detection Methods . . . . . . . 
.. Key Methods of Data Association . . . . . . . . . . . . . . . 
. Particle Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Sampled Representations of Probability Distributions . . . . 
.. The Simplest Particle Filter . . . . . . . . . . . . . . . . . . . 
.. The Tracking Algorithm . . . . . . . . . . . . . . . . . . . . . 
.. A Workable Particle Filter . . . . . . . . . . . . . . . . . . . . 
.. Practical Issues in Particle Filters . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
V HIGH-LEVEL VISION 
 Registration 
. Registering Rigid Objects . . . . . . . . . . . . . . . . . . . . . . . . 
.. Iterated Closest Points . . . . . . . . . . . . . . . . . . . . . . 
.. Searching for Transformations via Correspondences . . . . . . 
.. Application: Building Image Mosaics . . . . . . . . . . . . . . 
. Model-based Vision: Registering Rigid Objects with Projection . . . 
.. Verification: Comparing Transformed and Rendered Source
to Target . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Registering Deformable Objects . . . . . . . . . . . . . . . . . . . . . 
.. Deforming Texture with Active Appearance Models . . . . . 
.. Active Appearance Models in Practice . . . . . . . . . . . . . 
.. Application: Registration in Medical Imaging Systems . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Smooth Surfaces and Their Outlines 
. Elements of Differential Geometry . . . . . . . . . . . . . . . . . . . 
.. Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Contour Geometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Occluding Contour and the Image Contour . . . . . . . . 
.. The Cusps and Inflections of the Image Contour . . . . . . . 
.. Koenderink’s Theorem . . . . . . . . . . . . . . . . . . . . . . 
. Visual Events: More Differential Geometry . . . . . . . . . . . . . . 
.. The Geometry of the Gauss Map . . . . . . . . . . . . . . . . 
.. Asymptotic Curves . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Asymptotic Spherical Map . . . . . . . . . . . . . . . . . 
.. Local Visual Events . . . . . . . . . . . . . . . . . . . . . . . 
.. The Bitangent Ray Manifold . . . . . . . . . . . . . . . . . . 
.. Multilocal Visual Events . . . . . . . . . . . . . . . . . . . . . 
.. The Aspect Graph . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Range Data 
. Active Range Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Range Data Segmentation . . . . . . . . . . . . . . . . . . . . . . . . 
.. Elements of Analytical Differential Geometry . . . . . . . . . 
.. Finding Step and Roof Edges in Range Images . . . . . . . . 
.. Segmenting Range Images into Planar Regions . . . . . . . . 
. Range Image Registration and Model Acquisition . . . . . . . . . . . 
.. Quaternions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Registering Range Images . . . . . . . . . . . . . . . . . . . . 
.. Fusing Multiple Range Images . . . . . . . . . . . . . . . . . 
. Object Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Matching Using Interpretation Trees . . . . . . . . . . . . . . 
.. Matching Free-Form Surfaces Using Spin Images . . . . . . . 
. Kinect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Technique: Decision Trees and Random Forests . . . . . . . . 
.. Labeling Pixels . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Computing Joint Positions . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Learning to Classify 
. Classification, Error, and Loss . . . . . . . . . . . . . . . . . . . . . . 
.. Using Loss to Determine Decisions . . . . . . . . . . . . . . . 
.. Training Error, Test Error, and Overfitting . . . . . . . . . . 
.. Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Error Rate and Cross-Validation . . . . . . . . . . . . . . . . 
.. Receiver Operating Curves . . . . . . . . . . . . . . . . . . . 
. Major Classification Strategies . . . . . . . . . . . . . . . . . . . . . 
.. Example: Mahalanobis Distance . . . . . . . . . . . . . . . . 
.. Example: Class-Conditional Histograms and Naive Bayes . . 
.. Example: Classification Using Nearest Neighbors . . . . . . . 
.. Example: The Linear Support Vector Machine . . . . . . . . 
.. Example: Kernel Machines . . . . . . . . . . . . . . . . . . . 
.. Example: Boosting and Adaboost . . . . . . . . . . . . . . . 
. Practical Methods for Building Classifiers . . . . . . . . . . . . . . . 
.. Manipulating Training Data to Improve Performance . . . . . 
.. Building Multi-Class Classifiers Out of Binary Classifiers . . 
.. Solving for SVMS and Kernel Machines . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Classifying Images 
. Building Good Image Features . . . . . . . . . . . . . . . . . . . . . 
.. Example Applications . . . . . . . . . . . . . . . . . . . . . . 
.. Encoding Layout with GIST Features . . . . . . . . . . . . . 
.. Summarizing Images with Visual Words . . . . . . . . . . . . 
.. The Spatial Pyramid Kernel . . . . . . . . . . . . . . . . . . . 
.. Dimension Reduction with Principal Components . . . . . . . 
.. Dimension Reduction with Canonical Variates . . . . . . . . 
.. Example Application: Identifying Explicit Images . . . . . . 
.. Example Application: Classifying Materials . . . . . . . . . . 
.. Example Application: Classifying Scenes . . . . . . . . . . . . 
. Classifying Images of Single Objects . . . . . . . . . . . . . . . . . . 
.. Image Classification Strategies . . . . . . . . . . . . . . . . . 
.. Evaluating Image Classification Systems . . . . . . . . . . . . 
.. Fixed Sets of Classes . . . . . . . . . . . . . . . . . . . . . . . 
.. Large Numbers of Classes . . . . . . . . . . . . . . . . . . . . 
.. Flowers, Leaves, and Birds: Some Specialized Problems . . . 
. Image Classification in Practice . . . . . . . . . . . . . . . . . . . . . 
.. Codes for Image Features . . . . . . . . . . . . . . . . . . . . 
.. Image Classification Datasets . . . . . . . . . . . . . . . . . . 
.. Dataset Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Crowdsourcing Dataset Collection . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Detecting Objects in Images 
. The Sliding Window Method . . . . . . . . . . . . . . . . . . . . . . 
.. Face Detection . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Detecting Humans . . . . . . . . . . . . . . . . . . . . . . . . 
.. Detecting Boundaries . . . . . . . . . . . . . . . . . . . . . . 
. Detecting Deformable Objects . . . . . . . . . . . . . . . . . . . . . . 
. The State of the Art of Object Detection . . . . . . . . . . . . . . . 
.. Datasets and Resources . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Topics in Object Recognition 
. What Should Object Recognition Do? . . . . . . . . . . . . . . . . . 
.. What Should an Object Recognition System Do? . . . . . . . 
.. Current Strategies for Object Recognition . . . . . . . . . . . 
.. What Is Categorization? . . . . . . . . . . . . . . . . . . . . . 
.. Selection: What Should Be Described? . . . . . . . . . . . . . 
. Feature Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Improving Current Image Features . . . . . . . . . . . . . . . 
.. Other Kinds of Image Feature . . . . . . . . . . . . . . . . . . 
. Geometric Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Semantic Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Attributes and the Unfamiliar . . . . . . . . . . . . . . . . . . 
.. Parts, Poselets and Consistency . . . . . . . . . . . . . . . . . 
.. Chunks of Meaning . . . . . . . . . . . . . . . . . . . . . . . . 
VI APPLICATIONS AND TOPICS 
 Image-Based Modeling and Rendering 
. Visual Hulls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Main Elements of the Visual Hull Model . . . . . . . . . . . . 
.. Tracing Intersection Curves . . . . . . . . . . . . . . . . . . . 
.. Clipping Intersection Curves . . . . . . . . . . . . . . . . . . 
.. Triangulating Cone Strips . . . . . . . . . . . . . . . . . . . . 
.. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Going Further: Carved Visual Hulls . . . . . . . . . . . . . . 
. Patch-Based Multi-View Stereopsis . . . . . . . . . . . . . . . . . . . 
.. Main Elements of the PMVS Model . . . . . . . . . . . . . . 
.. Initial Feature Matching . . . . . . . . . . . . . . . . . . . . . 
.. Expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. The Light Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Looking at People 
. HMM’s, Dynamic Programming, and Tree-Structured Models . . . . 
.. Hidden Markov Models . . . . . . . . . . . . . . . . . . . . . 
.. Inference for an HMM . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting an HMM with EM . . . . . . . . . . . . . . . . . . . . 
.. Tree-Structured Energy Models . . . . . . . . . . . . . . . . . 
. Parsing People in Images . . . . . . . . . . . . . . . . . . . . . . . . 
.. Parsing with Pictorial Structure Models . . . . . . . . . . . . 
.. Estimating the Appearance of Clothing . . . . . . . . . . . . 
. Tracking People . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Why Human Tracking Is Hard . . . . . . . . . . . . . . . . . 
.. Kinematic Tracking by Appearance . . . . . . . . . . . . . . . 
.. Kinematic Human Tracking Using Templates . . . . . . . . . 
. D from D: Lifting . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Reconstruction in an Orthographic View . . . . . . . . . . . . 
.. Exploiting Appearance for Unambiguous Reconstructions . . 
.. Exploiting Motion for Unambiguous Reconstructions . . . . . 
. Activity Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Background: Human Motion Data . . . . . . . . . . . . . . . 
.. Body Configuration and Activity Recognition . . . . . . . . . 
.. Recognizing Human Activities with Appearance Features . . 
.. Recognizing Human Activities with Compositional Models . . 
. Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Image Search and Retrieval 
. The Application Context . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. User Needs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Types of Image Query . . . . . . . . . . . . . . . . . . . . . . 
.. What Users Do with Image Collections . . . . . . . . . . . . 
. Basic Technologies from Information Retrieval . . . . . . . . . . . . . 
.. Word Counts . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Smoothing Word Counts . . . . . . . . . . . . . . . . . . . . . 
.. Approximate Nearest Neighbors and Hashing . . . . . . . . . 
.. Ranking Documents . . . . . . . . . . . . . . . . . . . . . . . 
. Images as Documents . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Matching Without Quantization . . . . . . . . . . . . . . . . 
.. Ranking Image Search Results . . . . . . . . . . . . . . . . . 
.. Browsing and Layout . . . . . . . . . . . . . . . . . . . . . . 
.. Laying Out Images for Browsing . . . . . . . . . . . . . . . . 
. Predicting Annotations for Pictures . . . . . . . . . . . . . . . . . . 
.. Annotations from Nearby Words . . . . . . . . . . . . . . . . 
.. Annotations from the Whole Image . . . . . . . . . . . . . . 
.. Predicting Correlated Words with Classifiers . . . . . . . . . 
.. Names and Faces . . . . . . . . . . . . . . . . . . . . . . . . 
.. Generating Tags with Segments . . . . . . . . . . . . . . . . . 
. The State of the Art of Word Prediction . . . . . . . . . . . . . . . . 
.. Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Comparing Methods . . . . . . . . . . . . . . . . . . . . . . . 
.. Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
VII BACKGROUND MATERIAL 
 Optimization Techniques 
. Linear Least-Squares Methods . . . . . . . . . . . . . . . . . . . . . . 
.. Normal Equations and the Pseudoinverse . . . . . . . . . . . 
.. Homogeneous Systems and Eigenvalue Problems . . . . . . . 
.. Generalized Eigenvalues Problems . . . . . . . . . . . . . . . 
.. An Example: Fitting a Line to Points in a Plane . . . . . . . 
.. Singular Value Decomposition . . . . . . . . . . . . . . . . . . 
. Nonlinear Least-Squares Methods . . . . . . . . . . . . . . . . . . . . 
.. Newton’s Method: Square Systems of Nonlinear Equations. . 
.. Newton’s Method for Overconstrained Systems . . . . . . . . 
.. The Gauss―Newton and Levenberg―Marquardt Algorithms . 
. Sparse Coding and Dictionary Learning . . . . . . . . . . . . . . . . 
.. Sparse Coding . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Dictionary Learning . . . . . . . . . . . . . . . . . . . . . . . 
.. Supervised Dictionary Learning . . . . . . . . . . . . . . . . . 
. Min-Cut/Max-Flow Problems and Combinatorial Optimization . . . 
.. Min-Cut Problems . . . . . . . . . . . . . . . . . . . . . . . . 
.. Quadratic Pseudo-Boolean Functions . . . . . . . . . . . . . . 
.. Generalization to Integer Variables . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Bibliography 
Index 
List of Algorithms 
・ ・ ・ ・ ・ ・ (收起)序言
前言
第篇　基础知识
第章　引言 
.　人工智能的新焦点――深度学习 
..　人工智能――神话传说到影视漫画 
..　人工智能的诞生 
..　神经科学的研究 
..　人工神经网络的兴起 
..　神经网络的第一次寒冬 
..　神经网络的第一次复兴 
..　神经网络的第二次寒冬 
..　年――深度学习的起点 
..　生活中的深度学习 
..　常见深度学习框架简介 
.　给计算机一双眼睛――计算机视觉 
..　计算机视觉简史 
..　年――计算机视觉的新起点 
..　计算机视觉的应用 
..　常见计算机视觉工具包 
.　基于深度学习的计算机视觉 
..　从ImageNet竞赛到AlphaGo战胜李世石――计算机视觉超越人类 
..　GPU和并行技术――深度学习和计算视觉发展的加速器 
..　基于卷积神经网络的计算机视觉应用 
第章　深度学习和计算机视觉中的基础数学知识 
.　线性变换和非线性变换 
..　线性变换的定义 
..　高中教科书中的小例子 
..　点积和投影 
..　矩阵乘法的几何意义（） 
..　本征向量和本征值 
..　矩阵乘法的几何意义（） 
..　奇异值分解 
..　线性可分性和维度 
..　非线性变换 
.　概率论及相关基础知识 
..　条件概率和独立 
..　期望值、方差和协方差 
..　熵 
..　最大似然估计（Maximum Likelihood Estimation，MLE） 
..　KL散度（KullbackCLeibler divergence） 
..　KL散度和MLE的联系 
.　维度的诅咒 
..　采样和维度 
..　高维空间中的体积 
..　高维空间中的距离 
..　中心极限定理和高维样本距离分布的近似 
..　数据实际的维度 
..　局部泛化 
..　函数对实际维度的影响 
..　PCA――什么是主成分 
..　PCA――通过本征向量和本征值求主成分 
..　PCA――通过主成分分析降维 
..　PCA――归一化和相关性系数 
..　PCA――什么样的数据适合PCA 
..　其他降维手段 
.　卷积 
..　点积和卷积 
..　一维卷积 
..　卷积和互相关 
..　二维卷积和图像响应 
..　卷积的计算 
.　数学优化基础 
..　最小值和梯度下降 
..　冲量（Momentum） 
..　牛顿法 
..　学习率和自适应步长 
..　学习率衰减（Learning Rate Decay） 
..　AdaGrad：每个变量有自己的节奏 
..　AdaDelta的进一步改进 
..　其他自适应算法 
..　损失函数 
..　分类问题和负对数似然 
..　逻辑回归 
..　Softmax：将输出转换为概率 
..　链式求导法则 
第章　神经网络和机器学习基础 
.　感知机 
..　基本概念 
..　感知机和线性二分类 
..　激活函数 
.　神经网络基础 
..　从感知机到神经网络 
..　最简单的神经网络二分类例子 
..　隐层神经元数量的作用 
..　更加复杂的样本和更复杂的神经网络 
.　后向传播算法 
..　求神经网络参数的梯度 
..　计算图（Computational Graph） 
..　利用后向传播算法计算一个神经网络参数的梯度 
..　梯度消失 
..　修正线性单元（ReLU） 
..　梯度爆炸 
..　梯度检查（gradient check） 
..　从信息传播的角度看后向传播算法 
.　随机梯度下降和批量梯度下降 
..　全量数据（full-batch）梯度下降 
..　随机梯度下降（SGD）和小批量数据（mini-batch） 
..　数据均衡和数据增加（data augmentation） 
.　数据、训练策略和规范化 
..　欠拟合和过拟合 
..　训练误差和测试误差 
..　奥卡姆剃刀没有免费午餐 
..　数据集划分和提前停止 
..　病态问题和约束 
..　L规范化（L Regularization） 
..　L规范化（L Regularization） 
..　集成（Ensemble）和随机失活（Dropout） 
.　监督学习、非监督学习、半监督学习和强化学习 
..　监督学习、非监督学习和半监督学习 
..　强化学习（reinforcement learning） 
第章　深度卷积神经网络 
.　卷积神经网络 
..　基本概念 
..　卷积层和特征响应图 
..　参数共享 
..　稀疏连接 
..　多通道卷积 
..　激活函数 
..　池化、不变性和感受野 
..　分布式表征（Distributed Representation） 
..　分布式表征和局部泛化 
..　分层表达 
..　卷积神经网络结构 
.　LeNet――第一个卷积神经网络 
.　新起点――AlexNet 
..　网络结构 
..　局部响应归一化（Local Response Normalization，LRN） 
.　更深的网络――GoogLeNet 
..　×卷积和Network In Network 
..　Inception结构 
..　网络结构 
..　批规一化（Batch Normalization，BN） 
.　更深的网络――ResNet 
..　困难的深层网络训练：退化问题 
..　残差单元 
..　深度残差网络 
..　从集成的角度看待ResNet 
..　结构更复杂的网络 
第篇　实例精讲
第章　Python基础 
.　Python简介 
..　Python简史 
..　安装和使用Python 
.　Python基本语法 
..　基本数据类型和运算 
..　容器 
..　分支和循环 
..　函数、生成器和类 
..　map、reduce和filter 
..　列表生成（list comprehension） 
..　字符串 
..　文件操作和pickle 
..　异常 
..　多进程（multiprocessing） 
..　os模块 
.　Python的科学计算包――NumPy 
..　基本类型（array） 
..　线性代数模块（linalg） 
..　随机模块（random） 
.　Python的可视化包――matplotlib 
..　D图表 
..　D图表 
..　图像显示 
第章　OpenCV基础 
.　OpenCV简介 
..　OpenCV的结构 
..　安装和使用OpenCV 
.　Python-OpenCV基础 
..　图像的表示 
..　基本图像处理 
..　图像的仿射变换 
..　基本绘图 
..　视频功能 
.　用OpenCV实现数据增加小工具 
..　随机裁剪 
..　随机旋转 
..　随机颜色和明暗 
..　多进程调用加速处理 
..　代码：图片数据增加小工具 
.　用OpenCV实现物体标注小工具 
..　窗口循环 
..　鼠标和键盘事件 
..　代码：物体检测标注的小工具 
第章　Hello World! 
.　用MXNet实现一个神经网络 
..　基础工具、NVIDIA驱动和CUDA安装 
..　安装MXNet 
..　MXNet基本使用 
..　用MXNet实现一个两层神经网络 
.　用Caffe实现一个神经网络 
..　安装Caffe 
..　Caffe的基本概念 
..　用Caffe实现一个两层神经网络 
第章　最简单的图片分类――手写数字识别 
.　准备数据――MNIST 
..　下载MNIST 
..　生成MNIST的图片 
.　基于Caffe的实现 
..　制作LMDB数据 
..　训练LeNet- 
..　测试和评估 
..　识别手写数字 
..　增加平移和旋转扰动 
.　基于MXNet的实现 
..　制作Image Recordio数据 
..　用Module模块训练LeNet- 
..　测试和评估 
..　识别手写数字 
第章　利用Caffe做回归 
.　回归的原理 
..　预测值和标签值的欧式距离 
..　EuclideanLoss层 
.　预测随机噪声的频率 
..　生成样本：随机噪声 
..　制作多标签HDF数据 
..　网络结构和Solver定义 
..　训练网络 
..　批量装载图片并利用GPU预测 
..　卷积核可视化 
第章　迁移学习和模型微调 
.　吃货必备――通过Python采集美食图片 
..　通过关键词和图片搜索引擎下载图片 
..　数据预处理――去除无效和不相关图片 
..　数据预处理――去除重复图片 
..　生成训练数据 
.　美食分类模型 
..　迁移学习 
..　模型微调法（Finetune） 
..　混淆矩阵（Confusion Matrix） 
..　P-R曲线和ROC曲线 
..　全局平均池化和激活响应图 
第章　目标检测 
.　目标检测算法简介 
..　滑窗法 
..　PASCAL VOC、mAP和IOU简介 
..　Selective Search和R-CNN简介 
..　SPP、ROI Pooling和Fast R-CNN简介 
..　RPN和Faster R-CNN简介 
..　YOLO和SSD简介 
.　基于PASCAL VOC数据集训练SSD模型 
..　MXNet的SSD实现 
..　下载PASCAL VOC数据集 
..　训练SSD模型 
..　测试和评估模型效果 
..　物体检测结果可视化 
..　制作自己的标注数据 
第章　度量学习 
.　距离和度量学习 
..　欧氏距离和马氏距离 
..　欧式距离和余弦距离 
..　非线性度量学习和Siamese网络 
..　Contrastive Loss：对比损失函数 
.　用MNIST训练Siamese网络 
..　数据准备 
..　参数共享训练 
..　结果和可视化 
..　用τ-SNE可视化高维特征 
第章　图像风格迁移 
.　风格迁移算法简介 
..　通过梯度下降法进行图像重建 
..　图像风格重建和Gram矩阵 
..　图像风格迁移 
.　MXNet中的图像风格迁移例子 
..　MXNet的风格迁移实现 
..　对图片进行风格迁移 
・ ・ ・ ・ ・ ・ (收起)目 录
第章 概述 
. 什么是计算机视觉？ 
. 简史 
. 本书概述 
. 课程大纲样例 
. 标记法说明 
. 扩展阅读 
第章 图像形成 
. 几何基元和变换 
.. 几何基元 
.. D变换 
.. D变换 
.. D旋转 
.. D到D投影 
.. 镜头畸变 
. 光度测定学的图像形成 
.. 照明 
.. 反射和阴影 
.. 光学 
. 数字摄像机 
.. 采样与混叠 
.. 色彩 
.. 压缩 
. 补充阅读 
. 习题 
第章 图像处理 
. 点算子 
.. 像素变换 
.. 彩色变换 
.. 合成与抠图 
.. 直方图均衡化 
.. 应用：色调调整 
. 线性滤波 
.. 可分离的滤波 
.. 线性滤波示例 
.. 带通和导向滤波器 
. 更多的邻域算子 
.. 非线性滤波 
.. 形态学 
.. 距离变换 
.. 连通量 
. 傅里叶变换 
.. 傅里叶变换对 
.. 二维傅里叶变换 
.. 维纳滤波 
.. 应用：锐化，模糊
和去噪 
. 金字塔与小波 
.. 插值 
.. 降采样 
.. 多分辨率表达 
.. 小波 
.. 应用：图像融合 
. 几何变换 
.. 参数化变换 
.. 基于网格的卷绕 
.. 应用：基于特征的变形 
. 全局优化 
.. 正则化 
.. 马尔科夫随机场 
.. 应用：图像的恢复 
. 补充阅读 
. 习题 
第章 特征检测与匹配 
. 点和块 
.. 特征检测器 
.. 特征描述子 
.. 特征匹配 
.. 特征跟踪 
.. 应用：表演驱动的动画 
. 边缘 
.. 边缘检测 
.. 边缘连接 
.. 应用：边缘编辑和增强 
. 线条 
.. 逐次近似 
.. Hough变换 
.. 消失点 
.. 应用：矩形检测 
. 扩展阅读 
. 习题 
第章 分割 
. 活动轮廓 
.. 蛇行 
.. 动态蛇行和
CONDENSATION 
.. 剪刀 
.. 水平集 
.. 应用：轮廓跟踪和
转描机 
. 分裂与归并 
.. 分水岭 
.. 区域分裂(区分式聚类) 
.. 区域归并(凝聚式聚类) 
.. 基于图的分割 
.. 概率聚集 
. 均值移位和模态发现 
.. k-均值和高斯混合 
.. 均值移位 
. 规范图割 
. 图割和基于能量的方法 
. 补充阅读 
. 习题 
第章 基于特征的配准 
. 基于D和D特征的配准 
.. 使用最小二乘的
D配准 
.. 应用：全景图 
.. 迭代算法 
.. 鲁棒最小二乘
和RANSAC 
.. D配准 
. 姿态估计 
.. 线性算法 
.. 迭代算法 
.. 应用：增强现实 
. 几何内参数标定 
.. 标定模式 
.. 消失点 
.. 应用：单视图测量学 
.. 旋转运动 
.. 径向畸变 
. 补充阅读 
. 习题 
第章 由运动到结构 
. 三角测量 
. 二视图由运动到结构 
.. 投影(未标定的)重建 
.. 自标定 
.. 应用：视图变形 
. 因子分解 
.. 透视与投影因子分解 
.. 应用：稀疏D模型
提取 
. 光束平差法 
.. 挖掘稀疏性 
.. 应用：匹配运动和增强
现实 
.. 不确定性和二义性 
.. 应用：由因特网照片
重建 
. 限定结构和运动 
.. 基于线条的方法 
.. 基于平面的方法 
. 补充阅读 
. 习题 
第章 稠密运动估计 
. 平移配准 
.. 分层运动估计 
.. 基于傅里叶的配准 
.. 逐次求精 
. 参数化运动 
.. 应用：视频稳定化 
.. 学到的运动模型 
. 基于样条的运动 
. 光流 
.. 多帧运动估计 
.. 应用：视频去噪 
.. 应用：去隔行扫描 
. 层次运动 
.. 应用：帧插值 
.. 透明层和反射 
. 补充阅读 
. 习题 
第章 图像拼接 
. 运动模型 
.. 平面透视运动 
.. 应用：白板和文档扫描 
.. 旋转全景图 
.. 缝隙消除 
.. 应用：视频摘要和压缩 
.. 圆柱面和球面坐标 
. 全局配准 
.. 光束平差法 
.. 视差消除 
.. 认出全景图 
.. 直接配准和基于特征的
?配准 
. 合成 
.. 合成表面的选择 
.. 像素选择和加权
(去虚影) 
.. 应用：照片蒙太奇 
.. 融合 
. 补充阅读 
. 习题 
第章 计算摄影学 
. 光度学标定 
.. 辐射度响应函数 
.. 噪声水平估计 
.. 虚影 
.. 光学模糊(空间响应)
估计 
. 高动态范围成像 
.. 色调映射 
.. 应用：闪影术 
. 超分辨率和模糊去除 
.. 彩色图像去马赛克 
.. 应用：彩色化 
. 图像抠图和合成 
.. 蓝屏抠图 
.. 自然图像抠图 
.. 基于优化的抠图 
.. 烟、阴影和闪抠图 
.. 视频抠图 
. 纹理分析与合成 
.. 应用：空洞填充
与修图 
.. 应用：非真实感绘制 
. 补充阅读 
. 习题 
第章 立体视觉对应 
. 极线几何学 
.. 矫正 
.. 平面扫描 
. 稀疏对应 
. 稠密对应 
. 局部方法 
.. 亚像素估计
与不确定性 
.. 应用：基于立体视觉的
头部跟踪 
. 全局优化 
.. 动态规划 
.. 基于分割的方法 
.. 应用：z-键控与背景
替换 
. 多视图立体视觉 
.. 体积与D表面重建 
.. 由轮廓到形状 
. 补充阅读 
. 习题 
第章 D重建 
. 由X到形状 
.. 由阴影到形状与光度
测量立体视觉 
.. 由纹理到形状 
.. 由聚焦到形状 
. 主动距离获取 
.. 距离数据归并 
.. 应用：数字遗产 
. 表面表达 
.. 表面插值 
.. 表面简化 
.. 几何图像 
. 基于点的表达 
. 体积表达 
. 基于模型的重建 
.. 建筑结构 
.. 头部和人脸 
.. 应用：脸部动画 
.. 完整人体建模与跟踪 
. 恢复纹理映射与反照率 
.. 估计BRDF 
.. 应用：D摄影学 
. 补充阅读 
. 习题 
第章 基于图像的绘制 
. 视图插值 
.. 视图相关的纹理映射 
.. 应用：照片游览 
. 层次深度图像 
. 光场与发光图 
.. 非结构化发光图 
.. 表面光场 
.. 应用：同心拼图 
. 环境影像形板 
.. 更高维光场 
.. 从建模到绘制 
. 基于视频的绘制 
.. 基于视频的动画 
.. 视频纹理 
.. 应用：图片动画 
.. D视频 
.. 应用：基于视频的
游览 
. 补充阅读 
. 习题 
第章 识别 
. 物体检测 
.. 人脸检测 
.. 行人检测 
. 人脸识别 
.. 特征脸 
.. 活动表观与D形状
模型 
.. 应用：个人照片收藏 
. 实例识别 
.. 几何配准 
.. 大型数据库 
.. 应用：位置识别 
. 类别识别 
.. 词袋 
.. 基于部件的模型 
.. 基于分割的识别 
.. 应用：智能照片编辑 
. 上下文与场景理解 
.. 学习与大型图像收集 
.. 应用：图像搜索 
. 识别数据库和测试集 
. 补充阅读 
. 习题 
第章 结语 
附录A 线性代数与数值方法 
A. 矩阵分解 
A.. 奇异值分解 
A.. 特征值分解 
A.. QR因子分解 
A.. 乔里斯基分解 
A. 线性最小二乘 
A. 非线性最小二乘 
A. 直接稀疏矩阵方法 
A. 迭代方法 
A.. 共轭梯度 
A.. 预处理 
A.. 多重网格 
附录B 贝叶斯建模与推断 
B. 估计理论 
B. 最大似然估计与最小二乘 
B. 鲁棒统计学 
B. 先验模型与贝叶斯推断 
B. 马尔科夫随机场 
B.. 梯度下降与模拟退火 
B.. 动态规划 
B.. 置信传播 
B.. 图割 
B.. 线性规划 
B. 不确定性估计(误差分析) 
附录C 补充材料 
C. 数据集 
C. 软件 
C. 幻灯片与讲座 
C. 参考文献 
词汇表 
・ ・ ・ ・ ・ ・ (收起)《python计算机视觉编程》
推荐序 xi
前言 xiii
第章　基本的图像操作和处理 
.　pil：python图像处理类库 
..　转换图像格式 
..　创建缩略图 
..　复制和粘贴图像区域 
..　调整尺寸和旋转 
.　matplotlib 
..　绘制图像、点和线 
..　图像轮廓和直方图 
..　交互式标注 
.　numpy 
..　图像数组表示 
..　灰度变换 
..　图像缩放 
..　直方图均衡化 
..　图像平均 
..　图像的主成分分析（pca） 
..　使用pickle模块 
.　scipy 
..　图像模糊 
..　图像导数 
..　形态学：对象计数 
..　一些有用的scipy模块 
.　高级示例：图像去噪 
练习 
代码示例约定 
第章　局部图像描述子 
.　harris角点检测器 
.　sift（尺度不变特征变换） 
..　兴趣点 
..　描述子 
..　检测兴趣点 
..　匹配描述子 
.　匹配地理标记图像 
..　从panoramio下载地理标记图像 
..　使用局部描述子匹配 
..　可视化连接的图像 
练习 
第章　图像到图像的映射 
.　单应性变换 
..　直接线性变换算法 
..　仿射变换 
.　图像扭曲 
..　图像中的图像 
..　分段仿射扭曲 
..　图像配准 
.　创建全景图 
..　ransac 
..　稳健的单应性矩阵估计 
..　拼接图像 
练习 
第章　照相机模型与增强现实 
.　针孔照相机模型 
..　照相机矩阵 
..　三维点的投影 
..　照相机矩阵的分解 
..　计算照相机中心 
.　照相机标定 
.　以平面和标记物进行姿态估计 
.　增强现实 
..　pygame和pyopengl 
..　从照相机矩阵到opengl格式 
..　在图像中放置虚拟物体 
..　综合集成 
..　载入模型 
练习 
第章　多视图几何 
.　外极几何 
..　一个简单的数据集 
..　用matplotlib绘制三维数据 
..　计算f：八点法 
..　外极点和外极线 
.　照相机和三维结构的计算 
..　三角剖分 
..　由三维点计算照相机矩阵 
..　由基础矩阵计算照相机矩阵 
.　多视图重建 
..　稳健估计基础矩阵 
..　三维重建示例 
..　多视图的扩展示例 
.　立体图像 
练习 
第章　图像聚类 
.　k-means聚类 
..　scipy聚类包 
..　图像聚类 
..　在主成分上可视化图像 
..　像素聚类 
.　层次聚类 
.　谱聚类 
练习 
第章　图像搜索 
.　基于内容的图像检索 
.　视觉单词 
.　图像索引 
..　建立数据库 
..　添加图像 
.　在数据库中搜索图像 
..　利用索引获取候选图像 
..　用一幅图像进行查询 
..　确定对比基准并绘制结果 
.　使用几何特性对结果排序 
.　建立演示程序及web应用 
..　用cherrypy创建web应用 
..　图像搜索演示程序 
练习 
第章　图像内容分类 
.　k邻近分类法（knn） 
..　一个简单的二维示例 
..　用稠密sift作为图像特征 
..　图像分类：手势识别 
.　贝叶斯分类器 
.　支持向量机 
..　使用libsvm 
..　再论手势识别 
.　光学字符识别 
..　训练分类器 
..　选取特征 
..　多类支持向量机 
..　提取单元格并识别字符 
..　图像校正 
练习 
第章　图像分割 
.　图割（graph cut） 
..　从图像创建图 
..　用户交互式分割 
.　利用聚类进行分割 
.　变分法 
练习 
第章　opencv 
.　opencv的python接口 
.　opencv基础知识 
..　读取和写入图像 
..　颜色空间 
..　显示图像及结果 
.　处理视频 
..　视频输入 
..　将视频读取到numpy数组中 
.　跟踪 
..　光流 
..　lucas-kanade算法 
.　更多示例 
..　图像修复 
..　利用分水岭变换进行分割 
..　利用霍夫变换检测直线 
练习 
附录a　安装软件包 
a.　numpy和scipy 
a..　windows 
a..　mac os x 
a..　linux 
a.　matplotlib 
a.　pil 
a.　libsvm 
a.　opencv 
a..　windows 和 unix 
a..　mac os x 
a..　linux 
a.　vlfeat 
a.　pygame 
a.　pyopengl 
a.　pydot 
a.　python-graph 
a.　simplejson 
a.　pysqlite 
a.　cherrypy 
附录b　图像集 
b.　flickr 
b.　panoramio 
b.　牛津大学视觉几何组 
b.　肯塔基大学识别基准图像 
b.　其他 
b..　prague texture segmentation datagenerator与基准 
b..　微软研究院grab cut数据集 
b..　caltech  
b..　静态手势数据库 
b..　middlebury stereo数据集 
附录c　图片来源 
c.　来自flickr的图像 
c.　其他图像 
c.　插图 
参考文献 
索引 
・ ・ ・ ・ ・ ・ (收起)第章　图像编程入门　　
.　简介　　
.　安装OpenCV库　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　装载、显示和存储图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　深入了解cv::Mat　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　定义感兴趣区域　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　操作像素　　
.　简介　　
.　访问像素值　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用指针扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用迭代器扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　编写高效的图像扫描循环　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　扫描图像并访问相邻像素　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　实现简单的图像运算　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　图像重映射　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　处理图像的颜色　　
.　简介　　
.　用策略设计模式比较颜色　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用GrabCut算法分割图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　转换颜色表示法　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用色调、饱和度和亮度表示颜色　　
..　如何实现　　
..　实现原理　　
..　拓展阅读　　
..　参阅　　
第章　用直方图统计像素　　
.　简介　　
.　计算图像直方图　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　利用查找表修改图像外观　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　直方图均衡化　　
..　如何实现　　
..　实现原理　　
.　反向投影直方图检测特定图像内容　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用均值平移算法查找目标　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　比较直方图搜索相似图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用积分图像统计像素　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　用形态学运算变换图像　　
.　简介　　
.　用形态学滤波器腐蚀和膨胀图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用形态学滤波器开启和闭合图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　在灰度图像中应用形态学运算　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用分水岭算法实现图像分割　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用MSER算法提取特征区域　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　图像滤波　　
.　简介　　
.　低通滤波器　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用滤波器进行缩减像素采样　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　中值滤波器　　
..　如何实现　　
..　实现原理　　
.　用定向滤波器检测边缘　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算拉普拉斯算子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　提取直线、轮廓和区域　　
.　简介　　
.　用Canny算子检测图像轮廓　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用霍夫变换检测直线　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　点集的直线拟合　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　提取连续区域　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算区域的形状描述子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
第章　检测兴趣点　　
.　简介　　
.　检测图像中的角点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　快速检测特征　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　尺度不变特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　多尺度FAST特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　描述和匹配兴趣点　　
.　简介　　
.　局部模板匹配　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　描述并匹配局部强度值模式　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用二值描述子匹配关键点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　估算图像之间的投影关系　　
.　简介　　
.　计算图像对的基础矩阵　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用RANSAC（随机抽样一致性）算法匹配图像　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算两幅图像之间的单应矩阵　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　检测图像中的平面目标　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　三维重建　　
.　简介　　
.　相机标定　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　相机姿态还原　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用标定相机实现三维重建　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算立体图像的深度　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　处理视频序列　　
.　简介　　
.　读取视频序列　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　处理视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　写入视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　提取视频中的前景物体　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　跟踪运动目标　　
.　简介　　
.　跟踪视频中的特征点　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　估算光流　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　跟踪视频中的物体　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　实用案例　　
.　简介　　
.　人脸识别　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　人脸定位　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　行人检测　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
・ ・ ・ ・ ・ ・ (收起)第一章 绪论
・ 生物视觉通路简介
・ Marr的计算视觉理论框架
・ 本书各章内容简介
・ 计算机视觉的现状与阅读本书需注意的问题
思考题
参考文献
第二章 边缘检测
・ 边缘检测与微分滤波器
・ 边缘检测与正则化方法
・ 多尺度滤波器与过零点定理
・ 最优边缘检测滤波器
・ 边缘检测快速算法
・ 图像低层次处理的其他问题
思考题
参考文献
第三章 射影几何与几何元素表达
・ 仿射变换与射影变换的几何表达
・ 仿射坐标系与射影坐标系
・ 仿射变换与射影变换的代数表达
・ 不变量
・ 由对应点求射影变换
・ 点
・ 指向和方向
・ 平面直线及点线对偶关系
・ 空间平面及点面对偶关系
・ 空间直线
・ 二次曲线与二次曲面
思考题
参考文献
第四章 摄像机定标
・ 线性模型摄像机定标
・ 非线性模型摄像机定标
・ 立体视觉摄像机定标
・ 机器人手眼定标
・ 摄像机自定标技术
思考题
参考文献
第五章 立体视觉
・ 立体视觉与三维重建
・ 极线约束
・ 对应基元匹配
・ 射影几何意义下的三维重建
思考题
参考文献
第六章 运动与不确定性表达
・ 欧氏平面上的刚体运动
・ 欧氏空间中的刚体运动
・ 不确定性的描述
・ 不确定性的运算
・ 不确定性运算的几个例子
・ 三维直线段的不确定性
・ 不确定性的显示
思考题
参考文献
第七章 基于光流场的运动分析
・ 光流场和运动场
・ 光流的约束方程
・ 微分技术
・ 其他方法
・ 基于光流场的定性运动解释
思考题
参考文献
第八章 长序列运动图像特征跟踪
・ 引论
・ 参数估计理论初步
・ 特征运动模型
・ 特征跟踪的阐述
・ 匹配
・ 实际应用中需要考虑的问题
思考题
参考文献
第九章 基于二维特征对应的运动分析
・ 极线方程和本质矩阵
・ 基于点匹配的运动计算
・ 图像是一个空间平面的投影时的运动计算
・ 基于直线匹配的运动计算
・ 基本矩阵的估计
思考题
参考文献
第十章 基于三维特征对应的运动分析
・ 由三维点匹配估计运动
・ 不需显式匹配的方法
・ 从三维直线匹配估计运动
・ 从平面匹配估计运动
・ 二维-三维的物体定位
思考题
参考文献
第十一章 由图像灰度恢复三维物体形状
・ 辐射度学与光度学
・ 光照模型
・ 由多幅图像恢复三维物体形状
・ 由单幅图像恢复三维物体形状
思考题
参考文献
第十二章 建模与识别
・ CAD系统中的三维模型表达
・ 曲线与曲面的表达
・ 三维世界的多层次模型
・ 由二维图像建模
・ 识别的一般原则――问题与策略
・ 特征关系图匹配
・ “假设检验”识别方法
思考题
参考文献
第十三章 距离图像获取与处理
・ 距离传感器
・ 数据预处理
・ 深度图分割
思考题
参考文献
第十四章 计算机视觉系统体系结构讨论与展望
・ 计算机视觉系统的基本体系结构
・ 视觉系统体系结构讨论
・ 主动视觉
・ 计算机视觉的应用展望
参考文献
附录A 实验数据及参考结构
A・ 图像的格式
A・ 摄像机定标
A・ 立体视觉
A・ 基于光流场的运动分析
A・ 长序列运动图像特征跟踪
A・ 基于二维特征对应的运动分析
A・ 基于三维特征对应的运动分析
・ ・ ・ ・ ・ ・ (收起)译者序
前言
致老师
第一部分　导论
第章　计算机视觉的定义及其历史
.　简介
.　定义
.　局部全局问题
.　生物视觉
..　生物动因
..　视觉感知
参考文献
第章　编写图像处理程序
.　简介
.　图像处理的基本程序结构
.　良好的编程风格
.　计算机视觉的重点
.　图像分析软件工具包
.　makefile
.　作业
参考文献
第章　数学原理回顾
.　简介
.　线性代数简要回顾
..　向量
..　向量空间
..　零空间
..　函数空间
..　线性变换
..　导数和导数算子
..　特征值和特征向量
..　特征分解
..　奇异值分解
.　函数最小化简要回顾
..　梯度下降
..　局部最小值和全局最小值
..　模拟退火
.　概率论简要回顾
.　作业
参考文献
第章　图像：表示和创建
.　简介
.　图像表示
..　标志性表示（图像）
..　函数表示(方程)
..　线性表示(向量)
..　概率表示（随机场）
..　图形表示（图）
..　邻接悖论和六边形像素
.　作为曲面的图像
..　梯度
..　等值线
..　脊
.　作业
参考文献
第二部分　预处理
第章　卷积核算子
.　简介
.　线性算子
.　图像的向量表示
.　导数估计
..　使用核估计导数
..　通过函数拟合来估计导数
..　图像基向量
..　核作为采样可微分函数
..　其他高阶导数
..　尺度简介
.　边缘检测
.　尺度空间
..　金字塔
..　没有重采样的尺度空间
.　示例
.　数字梯度检测器的性能
..　方向导数
..　方向估计
..　讨论
.　总结
.　作业
参考文献
第章　去噪
.　简介
.　图像平滑
..　一维情况
..　二维情况
.　使用双边滤波器实现保边平滑
.　使用扩散方程实现保边平滑
..　一维空间的扩散方程
..　PDE模拟
..　二维空间的扩散方程
..　可变电导扩散
.　使用优化实现保边平滑
..　噪声消除的目标函数
..　寻找一个先验项
..　MAP算法实现和均场退火
..　病态问题和正则化
.　等效算法
.　总结
.　作业
参考文献
第章　数学形态学
.　简介
.　二值形态学
..　膨胀
..　腐蚀
..　膨胀和腐蚀的性质
..　开运算和闭运算
..　开运算和闭运算的性质
.　灰度形态学
..　使用平面结构元素的灰度图像
..　使用灰度结构元素的灰度图像
..　使用集合运算的灰度形态学
.　距离变换
..　使用迭代最近邻计算DT
..　使用二值形态运算计算DT
..　使用掩码计算DT
..　使用维诺图计算DT
.　边缘链接的应用
.　总结
.　作业
参考文献
第三部分　图像理解
第章　分割
.　简介
.　阈值：仅基于亮度的分割
..　阈值的局部性质
..　通过直方图分析选择阈值
..　用高斯和拟合直方图
..　高斯混合模型与期望最大化
.　聚类：基于颜色相似度的分割
..　k-均值聚类
..　均值移位聚类
.　连接组件：使用区域增长的空间分割
..　递归方法
..　迭代方法
..　示例应用
.　使用主动轮廓进行分割
..　snake：离散和连续
..　水平集：包含边或者不包含边
.　分水岭：基于亮度曲面的分割
.　图割：基于图论的分割
..　目标函数
..　求解目标函数
.　使用MFA进行分割
.　评估分割的质量
.　总结
.　作业
参考文献
第章　参数变换
.　简介
.　霍夫变换
..　垂线问题
..　如何找到交点――累加器数组
..　使用梯度降低计算复杂度
.　寻找圆
..　由任意三个非共线像素表示的圆的位置推导
..　当原点未知但半径已知时找圆
..　利用梯度信息减少找圆的计算
.　寻找椭圆
.　广义霍夫变换
.　寻找峰值
.　寻找三维形状――高斯图
.　寻找对应体――立体视觉中的参数一致性
.　总结
.　作业
参考文
・ ・ ・ ・ ・ ・ (收起)第章　图像编程入门　　
.　简介　　
.　安装OpenCV库　　
..　准备工作　　
..　安装　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　装载、显示和存储图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　深入了解cv::Mat　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　定义兴趣区域　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　操作像素　　
.　简介　　
.　访问像素值　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用指针扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用迭代器扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　编写高效的图像扫描循环　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　扫描图像并访问相邻像素　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　实现简单的图像运算　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　图像重映射　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　用类处理彩色图像　　
.　简介　　
.　在算法设计中使用策略模式　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用控制器设计模式实现功能模块间通信　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　转换颜色表示法　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用色调、饱和度、亮度表示颜色.
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
第章　用直方图统计像素　　
.　简介　　
.　计算图像直方图　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　利用查找表修改图像外观　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　直方图均衡化　　
..　如何实现　　
..　实现原理　　
.　反向投影直方图检测特定图像内容　　 
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　均值平移算法查找目标　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　比较直方图搜索相似图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用积分图像统计像素　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　用形态学运算变换图像　　
.　简介　　
.　形态学滤波器腐蚀和膨胀图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用形态学滤波器开启和闭合图像　　 
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用形态学滤波器检测边缘和角点　　 
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用分水岭算法实现图像分割　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用MSER算法提取特征区域　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用GrabCut算法提取前景物体　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　图像滤波　　
.　简介　　
.　低通滤波器　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　中值滤波器　　
..　如何实现　　
..　实现原理　　
.　用定向滤波器检测边缘　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算拉普拉斯算子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　提取直线、轮廓和区域　　
.　简介　　
.　用Canny算子检测图像轮廓　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用霍夫变换检测直线　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　点集的直线拟合　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　提取区域的轮廓　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算区域的形状描述子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
第章　检测兴趣点　　
.　简介　　
.　检测图像中的角点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　快速检测特征　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　尺度不变特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　多尺度FAST 特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　描述和匹配兴趣点　　
.　简介　　
.　局部模板匹配　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　描述局部强度值模式　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用二值特征描述关键点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　估算图像之间的投影关系　　
.　简介　　
.　相机校准　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算图像对的基础矩阵　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用RANSAC（随机抽样一致性）算法匹配图像　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算两幅图像之间的单应矩阵.
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　处理视频序列　　
.　简介　　
.　读取视频序列　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　处理视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　写入视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　跟踪视频中的特征点　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　提取视频中的前景物体　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
・ ・ ・ ・ ・ ・ (收起)第章 浅谈人工智能、神经网络和计算机视觉 
. 人工还是智能 
. 人工智能的三起两落 
.. 两起两落 
.. 卷土重来 
. 神经网络简史 
.. 生物神经网络和人工神经网络 
.. M-P模型 
.. 感知机的诞生 
.. 你好，深度学习 
. 计算机视觉 
. 深度学习+ 
.. 图片分类 
.. 图像的目标识别和语义分割 
.. 自动驾驶 
.. 图像风格迁移 
第章 相关的数学知识 
. 矩阵运算入门 
.. 标量、向量、矩阵和张量 
.. 矩阵的转置 
.. 矩阵的基本运算 
. 导数求解 
.. 一阶导数的几何意义 
.. 初等函数的求导公式 
.. 初等函数的和、差、积、商求导 
.. 复合函数的链式法则 
第章 深度神经网络基础 
. 监督学习和无监督学习 
.. 监督学习 
.. 无监督学习 
.. 小结 
. 欠拟合和过拟合 
.. 欠拟合 
.. 过拟合 
. 后向传播 
. 损失和优化 
.. 损失函数 
.. 优化函数 
. 激活函数 
.. Sigmoid 
.. tanh 
.. ReLU 
. 本地深度学习工作站 
.. GPU和CPU 
.. 配置建议 
第章 卷积神经网络 
. 卷积神经网络基础 
.. 卷积层 
.. 池化层 
.. 全连接层 
. LeNet模型 
. AlexNet模型 
. VGGNet模型 
. GoogleNet 
. ResNet 
第章 Python基础 
. Python简介 
. Jupyter Notebook 
.. Anaconda的安装与使用 
.. 环境管理 
.. 环境包管理 
.. Jupyter Notebook的安装 
.. Jupyter Notebook的使用 
.. Jupyter Notebook常用的快捷键 
. Python入门 
.. Python的基本语法 
.. Python变量 
.. 常用的数据类型 
.. Python运算 
.. Python条件判断语句 
.. Python循环语句 
.. Python中的函数 
.. Python中的类 
. Python中的NumPy 
.. NumPy的安装 
.. 多维数组 
.. 多维数组的基本操作 
. Python中的Matplotlib 
.. Matplotlib的安装 
.. 创建图 
第章 PyTorch基础 
. PyTorch中的Tensor 
.. Tensor的数据类型 
.. Tensor的运算 
.. 搭建一个简易神经网络 
. 自动梯度 
.. torch.autograd和Variable 
.. 自定义传播函数 
. 模型搭建和参数优化 
.. PyTorch之torch.nn 
.. PyTorch之torch.optim 
. 实战手写数字识别 
.. torch和torchvision 
.. PyTorch之torch.transforms 
.. 数据预览和数据装载 
.. 模型搭建和参数优化 
第章 迁移学习 
. 迁移学习入门 
. 数据集处理 
.. 验证数据集和测试数据集 
.. 数据预览 
. 模型搭建和参数优化 
.. 自定义VGGNet 
.. 迁移VGG 
.. 迁移ResNet 
. 小结 
第章 图像风格迁移实战 
. 风格迁移入门 
. PyTorch图像风格迁移实战 
.. 图像的内容损失 
.. 图像的风格损失 
.. 模型搭建和参数优化 
.. 训练新定义的卷积神经网络 
. 小结 
第章 多模型融合 
. 多模型融合入门 
.. 结果多数表决 
.. 结果直接平均 
.. 结果加权平均 
. PyTorch之多模型融合实战 
. 小结 
第章 循环神经网络 
. 循环神经网络入门 
. PyTorch之循环神经网络实战 
. 小结 
第章 自动编码器 
. 自动编码器入门 
. PyTorch之自动编码实战 
.. 通过线性变换实现自动编码器模型 
.. 通过卷积变换实现自动编码器模型 
. 小结 
・ ・ ・ ・ ・ ・ (收起)第章 视觉系统实践――图像显示、输入/输出和库函数调用 
. OpenCV 
. 基本的OpenCV代码 
.. IplImage数据结构 
.. 读写图像 
.. 图像显示 
.. 示例 
. 图像捕捉 
. 和AIPCV库的接口 
. 网站文件 
. 参考文献 
第章 边缘检测技术 
. 边缘检测的目的 
. 传统的方法和理论 
.. 边缘的模型 
.. 噪声 
.. 导数算子 
.. 基于模板的边缘检测 
. 边缘模型：Marr-Hildreth边缘检测器 
. Canny Edge边缘检测器 
. Shen-Castan(ISEF)边缘检测器 
. 两种最优边缘检测器的比较 
. 彩色边缘 
. Marr-Hildreth边缘检测器的源代码 
. Canny边缘检测器的源代码 
. Shen-Castan边缘检测器的源代码 
. 网站文件 
. 参考文献 
第章 数码形态学 
. 形态学定义 
. 连通性 
. 数码形态学的基本元素――二值操作 
.. 二值膨胀 
.. 实现二值膨胀 
.. 二值腐蚀 
.. 二值腐蚀的实现 
.. 开启和闭合 
.. MAX――用于形态学的高级程序设计语言 
.. “命中/不命中”变换 
.. 识别区域边缘 
.. 条件膨胀 
.. 区域计数 
. 灰阶形态学 
.. 开启操作和闭合操作 
.. 平滑操作 
.. 梯度 
.. 纹理的分割 
.. 对象的大小分布 
. 彩色形态学 
. 网站文件 
. 参考文献 
第章 灰阶分割 
. 灰阶分割的基础 
.. 使用边缘像素 
.. 迭代选择法 
.. 灰阶直方图法 
.. 使用熵 
.. 模糊集合 
.. 最小误差阈值法 
.. 单阈值选择的示例结果 
. 使用区域阈值 
.. Chow-Kaneko算法 
.. 通过边缘对光照进行
建模 
.. 实现和结果 
.. 对比 
. 松弛法 
. 移动平均法 
. 基于聚类的阈值 
. 多重阈值 
. 网站文件 
. 参考文献 
第章 纹理和色彩 
. 纹理和分割 
. 灰阶图像中纹理的简单分析 
. 灰阶共生矩阵 
.. 最大概率 
.. 矩 
.. 对比度 
.. 同质性 
.. 熵 
.. GLCM描述符的测试结果 
.. 纹理操作符的加速 
. 边缘和纹理 
. 能量和纹理 
. 表面和纹理 
.. 向量散射算法 
.. 表面曲度算法 
. 分形维度 
. 彩色分割 
. 彩色纹理 
. 网站文件 
. 参考文献 
第章 图像细化 
. 骨架概述 
. 中轴变换 
. 迭代式形态学方法 
. 等高线的使用 
. 把对象看做多边形 
. 基于力的图像细化 
.. 定义 
.. 力场的使用 
.. 子像素骨架 
. Zhang-Suen/Stentiford/Holt组合算法的源代码 
. 网站文件 
. 参考文献 
第章 图像还原 
. 图像降质――真实世界 
. 频域 
.. 傅里叶变换 
.. 快速傅里叶变换 
.. 逆傅里叶变换 
.. 二维傅里叶变换 
.. OpenCV中的傅里叶变换 
.. 创建人工模糊 
. 逆滤波器 
. Wiener滤波器 
. 结构化噪声 
. 运动模糊――一种特殊情况 
. 同态滤波器――过滤照度 
.. 通用频率过滤器 
.. 分离光照产生的效果 
. 网站文件 
. 参考文献 
第章 分类 
. 对象、模式和统计数据 
.. 特征和区域 
.. 训练和测试 
.. 类别内和类别外的差异 
. 最小距离分类器 
.. 距离度量 
.. 特征之间的距离 
. 交叉验证 
. 支持向量机 
. 多重分类器――整合分类器 
.. 合并多种方法 
.. 整合类型的响应 
.. 评估 
.. 响应类型之间的转换 
.. 整合类型的响应 
.. 整合类型的响应 
. bagging和boosting 
.. bagging 
.. boosting 
. 网站文件 
. 参考文献 
第章 符号识别 
. 问题描述 
. 对简单的完美图像进行
OCR 
. 在扫描的图像上进行OCR――图像分割 
.. 噪声 
.. 分离独立的字形 
.. 匹配模板 
.. 统计识别 
. 传真图像的OCR――针对印刷字符 
.. 朝向――倾斜检测 
.. 使用边缘 
. 手写字符 
.. 字符轮廓的属性 
.. 凸缺 
.. 向量模板 
.. 神经网络 
. 使用多重分类器 
.. 合并多种方法 
.. 多重分类器的结果 
. 印刷乐谱识别――案例研究 
.. 五线谱线 
.. 分割 
.. 音乐符号识别 
. 神经网络识别系统的源代码 
. 网站文件 
. 参考文献 
第章 基于内容的搜索――通过示例搜索图像 
. 搜索图像 
. 维护图像集合 
. 通过示例搜索的特征 
.. 彩色图像的特征 
.. 灰阶图像特征 
. 考虑空间因素 
.. 整体区域 
.. 矩形区域 
.. 角度区域 
.. 环状区域 
.. 混合区域 
.. 空间采样的测试 
. 其他要考虑的因素 
.. 纹理 
.. 对象、等高线和边缘 
.. 数据集 
. 网站文件 
. 参考文献 
第章 将高性能计算用于视觉处理和图像处理 
. 多处理器计算的范式 
.. 共享内存 
.. 消息传递 
. 执行时间 
.. 使用clock()函数 
.. 使用QueryPerformance-Counter函数 
. 消息传递接口系统 
.. 安装MPI 
.. 使用MPI 
.. 进程间通信 
.. 运行MPI程序 
.. 真实的图像计算 
.. 使用计算机网络――集群计算 
. 共享内存系统――使用PC的图形处理器 
.. GLSL 
.. OpenGL基础 
.. OpenGL中的纹理实践 
.. 着色器编程基础 
.. 读入并转换图像 
.. 向着色程序传递参数 
.. 整合以上内容 
.. 通过GPU加速 
.. 开发和测试着色器代码 
. 寻找所需的软件 
. 网站文件 
. 参考文献 
・ ・ ・ ・ ・ ・ (收起)第章 深度学习基础 
. 神经网络 
.. 感知机 
.. 神经网络原理 
. 卷积神经网络 
.. CNN基本操作 
.. CNN原理 
. 循环神经网络 
.. RNN 
.. LSTM与GRU 
. 经典网络 
.. AlexNet 
.. VGG 
.. GoogLeNet 
.. ResNet 
.. MobileNet 
. 进阶必备：如何学习深度学习并“落地”求职 
.. 深度学习如何快速入门 
.. 深度学习行业求职技巧 
第章 计算机视觉基础 
. 目标检测Two-stage算法 
.. R-CNN算法 
.. Fast R-CNN算法 
.. Faster R-CNN算法 
. 目标检测One-stage算法 
.. YOLO系列算法 
.. SSD算法 
. 图像分割算法 
.. FCN算法 
.. U-Net算法 
.. DeepLab系列算法 
.. Mask R-CNN算法 
. 进阶必备：计算机视觉方向知多少 
第章 基础图像处理 
. 线性滤波 
.. 案例：使用方框滤波 
.. 案例：使用均值滤波 
.. 案例：使用高斯滤波 
. 非线性滤波 
.. 案例：使用中值滤波例 
.. 案例：使用双边滤波 
.　OpenCV形态学运算 
.. 案例：进行膨胀操作 
.. 案例：进行腐蚀操作 
.. 案例：使用形态学运算 
.　案例：使用漫水填充 
.　图像金字塔 
.. 案例：使用高斯金字塔 
.. 案例：使用拉普拉斯金字塔 
.　阈值化 
.. 案例：使用基本阈值 
.. 案例：使用自适应阈值 
.　进阶必备：选择一款合适的图像处理工具 
.. OpenCV 
.. Matlab 
第章 图像变换 
.　边缘检测 
.. 案例：Sobel算法 
.. 案例：Scharr算法 
.. 案例：Laplacian算法 
.. 案例：Canny算法 
.　案例：绘制轮廓 
.　霍夫变换 
.. 案例：霍夫线变换 
.. 案例：霍夫圆变换 
.　案例：重映射 
.　案例：仿射变换 
.　案例：透视变换 
.　直方图 
.. 案例：直方图的计算与绘制 
.. 案例：直方图均衡化 
.　进阶必备：图像变换应用之文本图像矫正 
.. 图像变换知识总结 
.. 案例：文本图像矫正 
第章 角点检测 
. 案例：Harris角点检测 
.　案例：Shi-Tomasi角点检测 
.　案例：亚像素级角点检测 
.　进阶必备：角点检测知识总结 
第章 特征点检测与匹配 
.　特征点检测 
.. opencv-contrib环境安装 
.. 案例：SIFT特征点检测 
.. 案例：SURF特征点检测 
.　特征匹配 
.. 案例：BruteForce匹配 
.. 案例：FLANN匹配 
.　案例：ORB特征提取 
.　进阶必备：利用特征点拼接图像 
.. 特征点检测算法汇总 
.. 案例：基于特征点检测与匹配的图像拼接 
第章 手写数字识别 
.　Keras的应用 
.. Keras模型 
.. Keras层 
.. 模型编译 
.. 模型训练 
.　LeNet算法 
.　案例：使用Keras实现手写数字识别 
.. 模型训练 
.. 手写数字识别模型推理 
.　进阶必备：算法模型开发流程 
.. 数据准备 
.. 网络搭建 
.. 模型训练 
第章 CIFAR-图像分类 
.　图像分类数据集 
.. CIFAR-数据集和CIFAR-数据集 
.. ImageNet数据集 
.. PASCAL VOC数据集 
.　案例：CIFAR-图像分类 
.. 模型训练过程 
.. 模型推理 
.　进阶必备：COCO数据集与使用HOGTSVM方法实现图像分类 
.. COCO数据集 
.. 案例：使用HOG+SVM方法实现图像分类 
第章 验证码识别 
.　TensorFlow应用 
.. 案例：TensorFlow的基本使用 
.. TensorFlow的常用模块 
.　案例：验证码识别 
.. 生成验证码图片 
.. 基于TensorFlow的验证码识别 
.　进阶必备：算法模型开发技巧 
.. 数据预处理技巧 
.. 网络搭建技巧 
.. 模型训练技巧 
第章 文本检测实战 
.　文本检测算法 
.. CTPN算法 
.. EAST算法 
.　案例：基于EAST算法的文本检测 
.. 数据预处理 
.. 网络搭建 
.. 模型训练 
.. 文本检测验证 
.　进阶必备：在不同场景下文本检测的应对方式 
.. 复杂场景文本检测 
.. 案例：使用形态学运算实现简单场景文本检测 
.. 案例：使用MSER+NMS实现简单场景文本检测 
第章 文本识别实战 
.　文本识别算法 
.. CRNN算法 
.. Attention OCR算法 
.　案例：基于C-RNN算法的文本识别 
.. 数据预处理 
.. 网络搭建 
.. 模型训练 
.. 文本识别验证 
.　进阶必备：单字OCR 
.. OCR探究 
.. 案例：文本图片字符切割 
第章 TensorFlow Lite 
.　TensorFlow Lite介绍 
.. TensorFlow Lite基础 
.. TensorFlow Lite源码分析 
.　模型转换 
.. FlatBuffers文件格式 
.. 案例：其他格式转换为.tflite模型 
.　模型量化 
.. 案例：量化感知训练 
.. 案例：训练后量化 
.　进阶必备：模型转换与模型部署优化答疑 
.. 模型转换问题 
.. 模型部署优化 
第章 基于TensorFlow Lite的AI功能部署实战 
.　部署流程 
.　案例：移动端部署 
.. 搭建开发环境 
.. 编译运行项目 
.. 调用过程解析 
.　PC端部署 
.. 案例：Windows端部署 
.. 案例：Linux端部署 
.. 案例：ARM平台部署 
.. 案例：MIPS平台部署 
.　进阶必备：推理框架拓展与OpenCV编译部署 
.. 其他深度学习推理框架 
.. OpenCV编译 
・ ・ ・ ・ ・ ・ (收起)第 章 图像的获取和表示 
. 图像传感器技术 
.. 传感器材料 
.. 传感器光电二极管元件 
.. 传感器配置：马赛克、Faveon和BSI 
.. 动态范围和噪声 
.. 传感器处理 
.. 去马赛克 
.. 坏像素的校正 
.. 颜色和照明校正 
.. 几何校正 
. 摄像机和计算成像 
.. 计算成像概述 
.. 单像素的摄像头计算 
.. 二维可计算摄像机 
.. 三维深度的摄像机系统 
. 三维深度处理 
.. 方法概述 
.. 深度感知和处理中存在的问题 
.. 单目深度处理 
. 三维表示：体元、深度图、网格和点云 
. 总结 
第 章 图像预处理 
. 图像处理概述 
. 图像预处理要解决的问题 
.. 计算机视觉的流程和图像预处理 
.. 图像校正 
.. 图像增强 
.. 为特征提取准备图像 
. 图像处理方法分类 
.. 点运算 
.. 直线运算 
.. 区域运算 
.. 算法 
.. 数据转换 
. 色度学 
.. 色彩管理系统概述 
.. 光源、白点、黑点和中性轴 
.. 设备色彩模型 
.. 颜色空间与色彩感知 
.. 色域映射与渲染目的 
.. 色彩增强的实际考虑 
.. 色彩的准确度与精度 
. 空间滤波 
.. 卷积滤波与检测 
.. 核滤波与形状选择 
.. 点滤波 
.. 噪声与伪像滤波 
.. 积分图与盒式滤波器 
. 边缘检测器 
.. 核集合: Sobel, Scharr, Prewitt, Roberts, Kirsch, Robinson和Frei-Chen 
.. Canny检测器 
. 变换滤波、Fourier变换及其他 
.. Fourier变换 
.. 其他变换 
. 形态学与分割 
.. 二值形态学 
.. 灰度和彩色形态学 
.. 形态学优化和改进 
.. 欧氏距离映射 
.. 超像素分割 
.. 深度图分割 
.. 色彩分割 
. 阈值化 
.. 全局阈值化 
.. 局部阈值化 
. 总结 
第章 全局特征和区域特征 
. 视觉特征的历史概述 
.. 核心思想：全局、区域和局部 
.. 纹理分析 
.. 统计方法 
. 纹理区域度量 
.. 边缘度量 
.. 互相关和自相关 
.. Fourier频谱、小波和基签名 
.. 共生矩阵和Haralick特征 
.. Laws纹理度量 
.. LBP局部二值模式 
.. 动态纹理 
. 统计区域度量 
.. 图像矩特征 
.. 点度量特征 
.. 全局直方图 
.. 局部区域直方图 
.. 散点图和D直方图 
.. 多分辨率和多尺度直方图 
.. 径向直方图 
.. 轮廓或边缘直方图 
. 基空间度量 
.. Fourier描述 
.. Walsh-Hadamard变换 
.. HAAR变换 
.. 斜变换 
.. Zernike多项式 
.. 导向滤波器 
.. Karhunen-Loeve变换与Hotelling变换 
.. 小波变换和Gabor滤波器 
.. Hough变换与Radon变换 
. 总结 
第章 局部特征设计、分类和学习 
. 局部特征 
.. 检测器、兴趣点、关键点、锚点、标注 
.. 描述子、特征描述、特征提取 
.. 稀疏局部模式方法 
. 局部特征属性 
.. 选择特征描述子和兴趣点 
.. 特征描述子和特征匹配 
.. 好特征的标准 
.. 可重复性，相对于困难的查找算容易 
.. 判别性与非判别性 
.. 相对和绝 对位置 
.. 匹配代价和一致性 
. 距离函数 
.. 关于距离函数的早期研究成果 
.. 欧氏或笛卡儿距离度量 
.. 网格距离度量 
.. 基于统计学的差异性度量 
.. 二值或布尔距离度量 
. 描述子的表示 
.. 坐标空间和复数空间 
.. 笛卡儿坐标 
.. 极坐标和对数极坐标 
.. 径向坐标 
.. 球面坐标 
.. Gauge坐标 
.. 多元空间和多模数据 
.. 特征金字塔 
. 描述子的密度 
.. 丢弃兴趣点和描述子 
.. 稠密与稀疏特征描述 
. 描述子形状拓扑 
.. 关联性模板 
.. 块和形状 
.. 对象多边形 
. 局部二值描述与点对模式 
.. FREAK视网膜模式 
.. Brisk 模式 
.. ORB和BRIEF模式 
. 描述子判别性 
.. 谱的判别性 
.. 区域、形状和模式的判别性 
.. 几何判别因素 
.. 通过特征可视化来评价判别性 
.. 精度与可跟踪 
.. 精度优化、子区域重叠、Gaussian权重和池化 
.. 亚像素精度 
. 搜索策略与优化 
.. 密集搜索 
.. 网格搜索 
.. 多尺度金字塔搜索 
.. 尺度空间和图像金字塔 
.. 特征金字塔 
.. 稀疏预测搜索与跟踪 
.. 跟踪区域限制搜寻 
.. 分割限制搜索 
.. 深度或Z限制搜索 
. 计算机视觉、模型和结构 
.. 特征空间 
.. 对象模型 
.. 约束 
.. 选择检测器和特征 
.. 训练概述 
.. 特征和对象的分类 
.. 特征学习、稀疏编码和卷积网络 
. 总结 
第章 特征描述属性的分类学 
. 特征描述子系列 
. 计算机视觉分类学方面的早期研究成果 
. 鲁棒性和精度 
. 通用的鲁棒性分类学 
.. 光照 
.. 颜色准则 
.. 不完全性 
.. 分辨率和精度 
.. 几何失真 
.. 效率变量、费用和效益 
.. 判别性和唯 一性 
. 通用的视觉度量分类学 
.. 特征描述子族 
.. 频谱维度 
.. 频谱类型 
.. 兴趣点 
.. 存储格式 
.. 数据类型 
.. 描述子内存 
.. 特征形状 
.. 特征模式 
.. 特征密度 
.. 特征搜索方法 
.. 模式对采样 
.. 模式区域大小 
.. 距离函数 
. 特征度量评估 
.. 效率变量、成本和效益 
.. 图像重建的效率度量 
.. 特征度量评估举例 
. 总结 
第章 兴趣点检测与特征描述子研究 
. 兴趣点调整 
. 兴趣点概念 
. 兴趣点方法概述 
.. Laplacian 和Gaussian -Laplacian 
.. Moravac角点检测器 
.. Harris方法、Harris-Stephens、Shi-Tomasi以及Hessian类型的检测器 
.. Hessian矩阵检测器和Hessian-Laplace 
.. Gaussian差 
.. 显著性区域 
.. SUSAN、Trajkovic 以及 Hedly 
.. Fast、Faster以及 AGHAST 
.. 局部曲率方法 
.. 形态兴趣区域 
. 特征描述子介绍 
.. 局部二值描述子 
.. Census 
.. BRIEF 
.. ORB 
.. BRISK 
.. FREAK 
. 谱描述子 
.. SIFT 
.. SIFT-PCA 
.. SIFT-GLOH 
.. 改进的SIF-SIFER 
.. SIFT CS-LBP改造 
.. RootSIFT改造 
.. CenSurE和STAR 
.. 相关模板 
.. HAAR特征 
.. 使用类HAAR特征的Viola Jones算法 
.. SURF 
.. 其他SURF算法 
.. 梯度直方图及变种 
.. PHOG和相关方法 
.. Daisy和O-Daisy 
.. CARD 
.. 具有鲁棒性的快速特征匹配 
.. RIFF和CHOG 
.. 链码直方图 
.. D-NETS 
.. 局部梯度模式 
.. 局部相位量化 
. 基空间描述子 
.. 傅里叶描述子 
.. 用其他基函数来构建描述子 
.. 稀疏编码方法 
. 多边形形状描述 
.. MSER方法 
.. 针对斑点和多边形的物体形状度量 
.. 形状上下文 
. D、D、体积以及多模态描述子 
.. D HOG 
.. HON D 
.. D SIFT 
. 总结 
第章 基准数据、内容、度量和分析 
. 什么是基准数据？ 
. 先前关于标注数据方面的研究：艺术与科学 
.. 质量性能的一般度量 
.. 算法性能的衡量 
.. Rosin关于角点方面的研究工作 
. 构造基准数据的关键问题 
.. 内容：采用、修改或创建 
.. 可用的基准数据介绍 
.. 使用数据拟合算法 
.. 场景构成和标记 
. 定义目标和预期 
.. Mikolajczyk和Schmid的方法学 
.. 开放式评价系统 
.. 极 端情况和限制 
.. 兴趣点和特征 
. 基准数据的鲁棒性准则 
.. 举例说明鲁棒性准则 
.. 将鲁棒性准则用于实际应用 
. 度量与基准数据的配对 
.. 兴趣点、特征和基准数据的配对和优化 
.. 一般的视觉分类学的例子 
. 合成的特征字母表 
.. 合成数据集的目标 
.. 合成兴趣点字母表 
.. 将合成字母表叠加到真实图像上 
. 总结 
第章 可视流程及优化 
. 阶段、操作和资源 
. 计算资源预算 
.. 计算单元、ALU和加速器 
.. 能耗的使用 
.. 内存的利用 
.. I/O性能 
. 计算机视觉流程的实例 
.. 汽车识别 
.. 人脸检测、情感识别以及年龄识别 
.. 图像分类 
.. 增强现实 
. 可选的加速方案 
.. 内存优化 
.. 粗粒度并行 
.. 细粒度数据并行 
.. 高 级指令集和加速器 
. 计算机视觉算法的优化与调整 
.. 编译器优化与手工优化 
.. 特征描述子改造、检测器和距离函数 
.. Boxlets与卷积加速 
.. 数据类型优化，整型与浮点型 
. 优化资源 
. 总结 
附录A 合成特征分析 
A. 目标的背景与期望 
A. 测试方法和结果 
A. 合成字母基准图像概述 
A. 测试：合成兴趣点字母检测 
A. 测试：合成角点字母检测 
A. 测试：叠加到真实图像上的合成字母检测 
A. 测试：字母的旋转不变性 
A. 结果分析和不可重复性异常 
附录B 基准数据集概述 
附录C 成像和计算机视觉资源 
C. 商业产品 
C. 开放源码 
C. 组织、机构和标准 
C. 在线资源 
附录D 扩展SDM准则 
译后记 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第 章 机器学习与sklearn 
． sklearn 环境配置 
．． 环境要求 
．． 安装方法 
．． 修改pip 源 
．． 安装Jupyter Notebook 
． 数据集 
．． 自带的小型数据集 
．． 在线下载的数据集 
．． 计算机生成的数据集 
． 分类 
．． 加载数据与模型 
．． 建立分类模型 
．． 模型的训练及预测 
．． 模型评价 
． 回归 
．． 线性回归 
．． 回归模型评价 
． 聚类 
．． K-means 
．． DBSCAN 
．． 聚类实例 
． 降维 
．． PCA 降维 
．． LDA 降维 
． 模型验证 
． 模型持久化 
．． joblib 
．． pickle 
． 小结 
第 章 传统图像处理方法 
． 图像分类 
．． HOG 的原理 
．． 工具介绍 
．． CIFAR- 分类 
．． 手写字符分类 
． 目标检测 
． 图像分割 
． 图像搜索 
． 小结 
第章 深度学习与PyTorch 
． 框架介绍 
． 环境配置 
． 运算基本单元 
．． Tensor 数据类型 
．． Tensor 与ndarray 
．． CPU 与GPU 运算 
．． PyTorch 实现K-means 
． 自动求导 
． 数据加载 
．． Dataset 
．． DataLoader 
． 神经网络工具包 
．． Module 模块 
．． 线性层 
．． 卷积层 
．． 池化层 
．． BatchNorm 层 
．． 激活层 
．． 神经网络各层输出的可视化 
．． 循环神经网络 
．． Sequential 和ModuleList 
．． 损失函数 
． 模型优化器optim 
．． optim 用法 
．． 优化器的选择 
．． 学习率的选择 
． 参数初始化init 
． 模型持久化 
． JIT 编译器 
． 模型迁移ONNX 
． 数据可视化TensorBoard 
． 机器视觉工具包torchvision 
．． 数据 
．． 模型 
．． 图像处理 
． 小结 
第章 卷积神经网络中的分类与回归 
． 卷积神经网络中的分类问题 
．． CIFAR- 图像分类 
．． 卷积神经网络的发展 
．． 分类网络的实现 
．． 模型训练 
．． 模型展示 
．． 多标签分类 
． 卷积神经网络中的回归问题 
．． 生成数据集 
．． 模型训练 
．． 模型展示 
． 小结 
第章 目标检测 
． 深度学习物体检测算法 
．． 两段式检测 
．． 一段式检测 
． 数据集构建 
．． 选择目标物体图片 
．． 背景图片下载 
．． 图片合成 
． 数据加载 
． 数据标记与损失函数构建 
．． 数据标记 
．． 损失函数 
． 模型搭建与训练 
． 模型预测 
． 小结 
第章 图像分割 
． 数据加载 
． 模型搭建 
． 模型训练 
． 模型展示 
． 智能弹幕 
． 像素级回归问题：超分辨率重建 
．． 超分辨率重建算法的发展 
．． 数据加载 
．． 模型搭建与训练 
．． 模型展示 
． 小结 
第章 图像搜索 
． 分类网络的特征 
． 深度学习人脸识别技术 
．． FaceNet 
．． CosFace 和ArcFace 
． 数据处理 
．． 数据下载 
．． 数据检查 
．． 数据提取 
． 模型训练 
．． 普通分类模型 
．． CosFace 
． 图像搜索 
．． 图像比对 
．． KD-Tree 搜索 
． 小结 
第章 图像压缩 
． AutoEncoder 
．． AutoEncoder 的原理 
．． AutoEncoder 模型搭建 
．． 数据加载 
．． 模型训练 
．． 结果展示 
． GAN 
．． GAN 原理 
．． GAN 训练流程 
．． GAN 随机生成人脸图片 
．． GAN 与AutoEncoder 的结合 
．． 图像修复 
． 小结 
第章 不定长文本识别 
． 循环神经网络概述 
． 时间序列预测 
．． 创建模型 
．． 生成数据 
．． 模型训练 
．． 模型预测 
． CRNN 模型 
．． CRNN 算法简介 
．． CTCLoss 函数 
．． 模型结构 
．． 数据预处理 
．． 模型训练 
．． 模型预测 
． 小结 
第 章 神经网络压缩与部署 
． 剪枝 
．． 模型设计 
．． 训练基础模型 
．． 模型稀疏化 
．． 压缩模型通道 
． 量化 
． 混合精度训练 
． 深度学习模型的服务端部署 
．． 创建接口 
．． 访问接口 
． 小结 
・ ・ ・ ・ ・ ・ (收起)前言
作者简介
审校者简介
第章　OpenCV入门
.　了解人类视觉系统
.　人类如何理解图像内容
.　你能用OpenCV做什么
..　内置数据结构和输入/输出
..　图像处理操作
..　GUI
..　视频分析
..　D重建
..　特征提取
..　对象检测
..　机器学习
..　计算摄影
..　形状分析
..　光流算法
..　人脸和对象识别
..　表面匹配
..　文本检测和识别
..　深度学习
.　安装OpenCV
..　Windows
..　Mac OS X
..　Linux
.　总结
第章　OpenCV基础知识导论
.　技术要求
.　基本CMake配置文件
.　创建一个库
.　管理依赖项
.　让脚本更复杂
.　图像和矩阵
.　读/写图像
.　读取视频和摄像头
.　其他基本对象类型
..　Vec对象类型
..　Scalar对象类型
..　Point对象类型
..　Size对象类型
..　Rect对象类型
..　RotatedRect对象类型
.　基本矩阵运算
.　基本数据存储
.　总结
第章　学习图形用户界面
.　技术要求
.　OpenCV用户界面介绍
.　OpenCV的基本图形用户界面
.　Qt图形用户界面
.　OpenGL支持
.　总结
第章　深入研究直方图和滤波器
.　技术要求
.　生成CMake脚本文件
.　创建图形用户界面
.　绘制直方图
.　图像颜色均衡
.　Lomography效果
.　卡通效果
.　总结
第章　自动光学检查、对象分割和检测
.　技术要求
.　隔离场景中的对象
.　为AOI创建应用程序
.　预处理输入图像
..　噪声消除
..　用光模式移除背景进行分割
..　阈值
.　分割输入图像
..　连通组件算法
..　findContours算法
.　总结
第章　学习对象分类
.　技术要求
.　机器学习概念介绍
.　计算机视觉和机器学习工作流程
.　自动对象检查分类示例
..　特征提取
..　训练SVM模型
..　输入图像预测
.　总结
第章　检测面部部位与覆盖面具
.　技术要求
.　了解Haar级联
.　什么是积分图像
.　在实时视频中覆盖面具
.　戴上太阳镜
.　跟踪鼻子、嘴巴和耳朵
.　总结
第章　视频监控、背景建模和形态学操作
.　技术要求
.　理解背景减除
.　直接的背景减除
.　帧差分
.　高斯混合方法
.　形态学图像处理
.　使形状变细
.　使形状变粗
.　其他形态运算符
..　形态开口
..　形态闭合
..　绘制边界
..　礼帽变换
..　黑帽变换
.　总结
第章　学习对象跟踪
.　技术要求
.　跟踪特定颜色的对象
.　构建交互式对象跟踪器
.　用Harris角点检测器检测点
.　用于跟踪的好特征
.　基于特征的跟踪
..　Lucas-Kanade方法
..　Farneback算法
.　总结
第章　开发用于文本识别的分割算法
.　技术要求
.　光学字符识别介绍
.　预处理阶段
..　对图像进行阈值处理
..　文本分割
.　在你的操作系统上安装Tesseract OCR
..　在Windows上安装Tesseract
..　在Mac上安装Tesseract
.　使用Tesseract OCR库
.　总结
第章　用Tesseract进行文本识别
.　技术要求
.　文本API的工作原理
..　场景检测问题
..　极值区域
..　极值区域过滤
.　使用文本API
..　文本检测
..　文本提取
..　文本识别
.　总结
第章　使用OpenCV进行深度学习
.　技术要求
.　深度学习简介
..　什么是神经网络，我们如何从数据中学习
..　卷积神经网络
.　OpenCV中的深度学习
.　YOLO用于实时对象检测
..　YOLO v深度学习模型架构
..　YOLO数据集、词汇表和模型
..　将YOLO导入OpenCV
.　用SSD进行人脸检测
..　SSD模型架构
..　将SSD人脸检测导入OpenCV
.　总结
・ ・ ・ ・ ・ ・ (收起)译者序
前言
作者简介
审校者简介
译者简介
第章　安装OpenCV 
.　选择和使用合适的安装工具 
..　在Windows上安装 
..　在OS X系统中安装 
..　在Ubuntu及其衍生版本中安装 
..　在其他类Unix系统中安装 
.　安装Contrib模块 
.　运行示例 
.　查找文档、帮助及更新 
.　总结 
第章　处理文件、摄像头和图形用户界面 
.　基本I/O脚本 
..　读/写图像文件 
..　图像与原始字节之间的转换 
..　使用numpy.array访问图像数据 
..　视频文件的读/写 
..　捕获摄像头的帧 
..　在窗口显示图像 
..　在窗口显示摄像头帧 
.　Cameo项目（人脸跟踪和图像处理） 
.　Cameo―面向对象的设计 
..　使用managers. CaptureManager提取视频流 
..　使用managers.WindowManager抽象窗口和键盘 
..　cameo.Cameo的强大实现 
.　总结 
第章　使用OpenCV 处理图像 
.　不同色彩空间的转换 
.　傅里叶变换 
..　高通滤波器 
..　低通滤波器 
.　创建模块 
.　边缘检测 
.　用定制内核做卷积 
.　修改应用 
.　Canny边缘检测 
.　轮廓检测 
.　边界框、最小矩形区域和最小闭圆的轮廓 
.　凸轮廓与Douglas-Peucker算法 
.　直线和圆检测 
..　直线检测 
..　圆检测 
.　检测其他形状 
.　总结 
第章　深度估计与分割 
.　创建模块 
.　捕获深度摄像头的帧 
.　从视差图得到掩模 
.　对复制操作执行掩模 
.　使用普通摄像头进行深度估计 
.　使用分水岭和GrabCut算法进行物体分割 
..　用GrabCut进行前景检测的例子 
..　使用分水岭算法进行图像分割 
.　总结 
第章　人脸检测和识别 
.　Haar级联的概念 
.　获取Haar级联数据 
.　使用OpenCV进行人脸检测 
..　静态图像中的人脸检测 
..　视频中的人脸检测 
..　人脸识别 
.　总结 
第章　图像检索以及基于图像描述符的搜索 
.　特征检测算法 
..　特征定义 
..　使用DoG和SIFT进行特征提取与描述 
..　使用快速Hessian算法和SURF来提取和检测特征 
..　基于ORB的特征检测和特征匹配 
..　ORB特征匹配 
..　K-最近邻匹配 
..　FLANN匹配 
..　FLANN的单应性匹配 
..　基于文身取证的应用程序示例 
.　总结 
第章　目标检测与识别 
.　目标检测与识别技术 
..　HOG描述符 
..　检测人 
..　创建和训练目标检测器 
.　汽车检测 
..　代码的功能 
..　SVM和滑动窗口 
.　总结 
第章　目标跟踪 
.　检测移动的目标 
.　背景分割器：KNN、MOG和GMG 
..　均值漂移和CAMShift 
..　彩色直方图 
..　返回代码 
.　CAMShift 
.　卡尔曼滤波器 
..　预测和更新 
..　范例 
..　一个基于行人跟踪的例子 
..　Pedestrian类 
..　主程序 
.　总结 
第章　基于OpenCV的神经网络简介 
.　人工神经网络 
.　人工神经网络的结构 
..　网络层级示例 
..　学习算法 
.　OpenCV中的ANN 
..　基于ANN的动物分类 
..　训练周期 
.　用人工神经网络进行手写数字识别 
..　MNIST―手写数字数据库 
..　定制训练数据 
..　初始参数 
..　迭代次数 
..　其他参数 
..　迷你库 
..　主文件 
.　可能的改进和潜在的应用 
..　改进 
..　应用 
.　总结 
・ ・ ・ ・ ・ ・ (收起)第  部分 基于 OpenCV 的传统视觉应用
第  章 图像生成 /
. 图像显示 /
.. 使用 OpenCV 显示图像 /
.. 使用 Matplotlib 显示图像 /
.. 案例实现――使用OpenCV 显示图像 /
.. 案例实现――使用Matplotlib 显示图像 /
. 图像读取 /
.. 使用 OpenCV 读取图像 /
.. 使用 Matplotlib 读取图像 /
.. 案例实现――使用OpenCV 读取图像 /
.. 案例实现――使用Matplotlib 读取图像 /
. 图像保存 /
.. 使用 OpenCV 保存图像 /
.. 使用 Matplotlib 保存图像/
.. 案例实现――使用OpenCV 保存图像 /
.. 案例实现――使用Matplotlib 保存图像 /
本章总结 /
作业与练习 /
第  章 OpenCV 图像处理（） /
. 图像模糊 /
.. 均值滤波 /
.. 中值滤波 /
.. 高斯滤波 /
.. 案例实现 /
. 图像锐化 /
.. 图像锐化简介 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 OpenCV 图像处理（） /
. OpenCV 绘图 /
.. 使用 OpenCV 绘制各种图形 /
.. 案例实现 /
. 图像的几何变换 /
.. 几何变换操作 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像特征检测 /
. 边缘编辑和增强 /
.. Canny 边缘检测简介 /
.. 案例实现 /
. 图像轮廓检测 /
.. 轮廓查找步骤 /
.. 查找轮廓函数 /
.. 绘制轮廓函数 /
.. 案例实现 /
. 图像角点和线条检测 /
.. 角点的定义 /
.. Harris 角点简介 /
.. Harris 角点检测函数 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像特征匹配 /
. ORB 关键点检测与匹配 /
.. FAST 算法 /
.. BRIEF 算法 /
.. 特征匹配 /
.. 代码流程 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像对齐与拼接 /
. 全景图像拼接 /
.. 全景图像的拼接原理 /
.. 算法步骤 /
.. Ransac 算法介绍 /
.. 全景图像剪裁 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 相机运动估计 /
. 双目相机运动估计 /
.. 相机测距流程 /
.. 双目相机成像模型 /
.. 极限约束 /
.. 双目测距的优势 /
.. 双目测距的难点 /
. 案例实现 /
本章总结 /
作业与练习 /
第  部分 基于机器学习和深度学习的视觉应用
第  章 基于 SVM 模型的手写数字识别/
. 手写数字识别 /
.. 手写数字图像 /
.. 图像处理 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 基于 HOG+SVM 的行人检测 /
. 行人检测 /
.. HOG+SVM /
.. 检测流程 /
.. 滑动窗口 /
.. 非极大值抑制 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 数据标注 /
. 目标检测数据标注 /
.. 数据收集与数据标注 /
.. 数据标注的通用规则 /
.. 案例实现 /
. 视频目标跟踪数据标注 /
.. 视频与图像数据标注的差异 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 水果识别 /
. LeNet- 模型的训练与评估 /
.. 卷积层 /
.. 池化层 /
.. ReLU 层 /
.. LeNet- 模型 /
.. Keras /
.. 案例实现 /
. LeNet- 模型的应用 /
.. 使用 OpenCV 操作摄像头 /
.. OpenCV 的绘图功能 /
.. OpenCV 绘图函数的常见参数 /
.. Keras 模型的保存和加载 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 病虫害识别 /
. 植物叶子病虫害识别 /
.. PlantVillage 数据集 /
.. 性能评估 /
.. 感受野 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 相似图像搜索 /
. 以图搜图 /
.. VGG 模型 /
.. H 模型文件 /
.. 案例实现 /
. 人脸识别 /
.. 人脸检测 /
.. 分析面部特征 /
.. 人脸识别特征提取 /
.. 人脸相似性比较 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 多目标检测 /
. 人脸口罩佩戴检测 /
.. 目标检测 /
.. YOLO 模型 /
.. YOLOv 模型 /
.. YOLOv-Tiny 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 可采摘作物检测 /
. 番茄成熟度检测 /
.. 数据集 /
.. RCNN 模型 /
.. SPP-Net 模型 /
.. Fast-RCNN 模型 /
.. Faster-RCNN 模型 /
.. Mask-RCNN 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 智能照片编辑 /
. 图像自动着色 /
.. GAN 模型的基本结构与原理 /
.. 构建 GAN 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 超分辨率 /
. 图像超分辨率 /
.. SRGAN 模型的结构 /
.. SRGAN 模型的损失函数 /
.. SRGAN 模型的评价指标 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 医学图像分割 /
. 眼底血管图像分割 /
.. 图像分割 /
.. 语义分割 /
.. 全卷积神经网络 /
.. 反卷积 /
.. U-Net 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 医学图像配准 /
. 头颈部 CT 图像配准 /
.. 图像配准方法 /
.. VoxelMorph 配准框架 /
.. TensorFlow-pixpix /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 视频内容分析 /
. 人体动作识别 /
.. 视频动作识别模型 /
.. UCF- 数据集 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像语义理解 /
. 视觉问答 /
.. 编码器-解码器模型 /
.. 光束搜索 /
. 案例实现 /
本章总结 /
作业与练习 /
第  部分 基于深度学习的新兴视觉应用
第  章 三维空间重建 /
. D-RN 算法 /
.. 算法简介 /
.. 算法的优势 /
.. 算法的结构 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 视频稳定 /
. 人脸视频稳定 /
.. MobileNet 模型 /
.. SSD 模型 /
.. MobileNet-SSD 模型 /
.. 模型评估 /
.. 实时影响 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 目标检测与跟踪 /
. 车辆检测与跟踪 /
.. UA-DETRAC 数据集 /
.. 目标跟踪 /
.. DeepSORT 目标跟踪 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 风格迁移 /
. 图像与视频风格迁移 /
.. 理解图像内容和图像风格 /
.. 图像重建 /
.. 风格重建 /
. 案例实现 /
本章总结 /
作业与练习 /
附录 A 企业级综合教学项目介绍 /
. 智慧停车场管理系统 /
.. 项目概述 /
.. 技能目标 /
. 智慧景区管理系统 /
.. 项目概述 /
.. 技能目标 /
. 智能考勤打卡系统 /
.. 项目概述 /
.. 技能目标 /
・ ・ ・ ・ ・ ・ (收起)出版者的话
译者序
前言
作者简介
第一部分预备知识
第章数据
.可视化
.离散化
..采样
..量化
.表示
.噪声
.本章小结
参考文献
习题
第章技术
.插值
..线性插值
..双线性插值
.几何相交
.本章小结
参考文献
习题
第二部分基于图像的视觉计算
第章卷积
.线性系统
..线性系统的响应
..卷积的性质
.线性滤波器
..全通、低通、带通和高通滤波器
..设计新滤波器
..二维滤波器的可分性
..相关和模式匹配
.实现细节
.本章小结
参考文献
习题
第章谱分析
.离散傅里叶变换
.极坐标
..性质
..信号分析示例
.频域的周期性
.混叠
.推广到二维插值
..周期性的影响
..陷波器
..混叠效应示例
.对偶性
.本章小结
参考文献
习题
第章特征检测
.边缘检测
..边缘子检测器
..多分辨率边缘检测
..边缘子聚合
.特征检测
.其他非线性滤波器
.本章小结
参考文献
习题
第三部分基于几何的视觉计算
第章几何变换
.齐次坐标
.线性变换
.欧氏和仿射变换
..平移
..旋转
..缩放
..剪切
..一些现象
.变换的串联
..相对于中心点的缩放
..相对于任意轴的旋转
.坐标系
.串联的性质
.透视变换
.自由度
.非线性变换
.本章小结
参考文献
习题
第章针孔相机
.针孔相机模型
..相机标定
..三维深度估计
..单应性
.实际相机的一些考虑
.本章小结
参考文献
习题
第章对极几何
.背景
.多视几何中的匹配
.基础矩阵
..性质
..基础矩阵的估计
..仿前置双眼的相机设置
.本质矩阵
.整流
.应用对极几何
..根据视差恢复深度
..根据光流恢复深度
.本章小结
参考文献
习题
第四部分基于辐射度的视觉计算
第章光照
.辐射度学
..双向反射分布函数
..光传播方程
.光度学与色彩
..CIE XYZ色彩空间
..CIE XYZ空间的认知结构
..认知一致色彩空间
.本章小结
参考文献
习题
第章色彩还原
.加性色彩混合的建模
..设备的色域
..色调映射算子
..强度分辨率
..显示器示例
.色彩管理
..色域变换
..色域匹配
.减性色彩混合的建模
.局限性
..高动态范围成像
..多光谱成像
.本章小结
参考文献
习题
第章光度处理
.直方图处理
.图像融合
..图像混合
..图像割
.光度立体视觉
..阴影处理
..光照方向计算
..色彩处理
.本章小结
参考文献
习题
第五部分视觉内容合成
第章多样化域
.建模
.处理
.渲染
.应用
.本章小结
参考文献
第章交互式图形流程
.顶点的几何变换
..模型变换
..视图变换
..透视投影变换
..遮挡处理
..窗口坐标变换
..最终变换
.裁剪和属性的顶点插值
.光栅化和属性的像素插值
.本章小结
参考文献
习题
第章真实感与性能
.光照
.着色
.阴影
.纹理贴图
..纹理至对象空间映射
..对象至屏幕空间映射
..分级细化贴图
.凹凸贴图
.环境贴图
.透明度
.累积缓存
.背面剔除
.可见性剔除
..包围体
..空间细分
..其他用途
.本章小结
参考文献
习题
第章图形编程
.图形处理单元的发展
.图形API和程序库的发展
.现代GPU和CUDA
..GPU架构
..CUDA编程模型
..CUDA存储模型
.本章小结
参考文献
・ ・ ・ ・ ・ ・ (收起)第 章 图像的获取和表示
． 图像传感器技术 
．． 传感器材料 
．． 传感器光电二极管元件 
．． 传感器配置：马赛克、Foveon和BSI 
．． 动态范围、噪声和超分辨率 
．． 传感器处理 
．． 去马赛克 
．． 坏像素校正 
．． 色彩和光照校正 
．． 几何校正 
． 照相机和计算成像 
．． 计算成像概述 
．． 单像素可计算相机 
．． 二维可计算照相机 
．． 三维深度的照相机系统 
． 三维深度处理 
．． 方法概述 
．． 深度感知和处理中存在的问题 
．． 单目深度处理 
． 三维表示：体元、深度图、网格和点云 
． 总结 
． 习题 
第 章 图像预处理 
． 图像处理概述 
． 图像预处理要解决的问题 
．． 计算机视觉的流程和图像预处理 
．． 图像校正 
．． 图像增强 
．． 为特征提取准备图像 
． 图像处理方法分类 
．． 点运算 
．． 直线运算 
．． 区域运算 
．． 算法 
．． 数据转换 
． 色彩学 
．． 色彩管理系统概述 
．． 光源、白点、黑点和中性轴 
．． 设备颜色模型 
．． 色彩空间与色彩感知 
．． 色域映射与渲染的目标 
．． 色彩增强的实际考虑 
．． 色彩的准确度与精度 
． 空间滤波 
．． 卷积滤波与检测 
．． 核滤波与形状选择 
．． 点滤波 
．． 噪声与伪像滤波 
．． 积分图与方框滤波器 
． 边缘检测器 
．． 核集合 
．． Canny检测器 
． 变换滤波、Fourier变换及其他 
．． Fourier变换 
．． 其他变换 
． 形态学与分割 
．． 二值形态学 
．． 灰度和彩色形态学 
．． 形态学优化和改进 
．． 欧氏距离映射 
．． 超像素分割 
．． 深度图分割 
．． 色彩分割 
． 阈值化 
．． 全局阈值化 
．． 局部阈值化 
． 总结 
． 习题 
第章 全局特征和区域特征 
． 视觉特征的历史概述 
．． 全局度量、区域度量和局部度量的核心思想 
．． 纹理分析 
．． 统计方法 
． 纹理区域度量 
．． 边缘度量 
．． 互相关性和自相关性 
．． Fourier谱、小波和基签名 
．． 共生矩阵、Haralick特征 
．． Laws纹理度量 
．． LBP局部二值模式 
．． 动态纹理 
． 统计区域度量 
．． 图像矩特征 
．． 点度量特征 
．． 全局直方图 
．． 局部区域直方图 
．． 散点图、D直方图 
．． 多分辨率、多尺度直方图 
．． 径向直方图 
．． 轮廓或边缘直方图 
． 基空间度量 
．． Fourier描述 
．． Walsh-Hadamard变换 
．． HAAR变换 
．． 斜变换 
．． Zernike多项式 
．． 导向滤波器 
．． Karhunen-Loeve变换与Hotelling变换 
．． 小波变换和Gabor滤波器 
．． Hough变换与Radon变换 
． 总结 
． 习题 
第章 局部特征设计 
． 局部特征 
．． 检测器、兴趣点、关键点、锚点和特征点 
．． 描述子、特征描述和特征提取 
．． 稀疏局部模式方法 
． 局部特征属性 
．． 选择特征描述子和兴趣点 
．． 特征描述子和特征匹配 
．． 好特征的标准 
．． 可重复性，困难和容易的查找 
．． 判别性与非判别性 
．． 相对位置和绝对位置 
．． 匹配代价和一致性 
． 距离函数 
．． 距离函数的早期工作 
．． 欧氏或笛卡儿距离度量 
．． 网格距离度量 
．． 基于统计学的差异性度量 
．． 二值或布尔距离度量 
． 描述子的表示 
．． 坐标空间和复合空间 
．． 笛卡儿坐标 
．． 极坐标和对数极坐标 
．． 径向坐标 
．． 球面坐标 
．． Gauge坐标 
．． 多元空间和多模数据 
．． 特征金字塔 
． 描述子的密度 
．． 丢弃兴趣点和描述子 
．． 稠密与稀疏特征描述 
． 描述子形状 
．． 关联性模板 
．． 块和形状 
．． 对象多边形 
． 局部二值描述子与点对模式 
．． FREAK视网膜模式 
．． BRISK模式 
．． ORB和BRIEF模式 
． 描述子的判别性 
．． 谱的判别性 
．． 区域、形状和模式的判别性 
．． 几何判别因素 
．． 通过特征可视化来评价判别性 
．． 精度与可跟踪性 
．． 精度优化、子区域重叠、Gaussian加权和池化 
．． 亚像素精度 
． 搜索策略与优化 
．． 密集搜索 
．． 网格搜索 
．． 多尺度金字塔搜索 
．． 尺度空间和图像金字塔 
．． 特征金字塔 
．． 稀疏预测搜索与跟踪 
．． 跟踪区域限制搜寻 
．． 分割限制搜索 
．． 深度或Z限制搜索 
． 计算机视觉、模型和结构 
．． 特征空间 
．． 对象模型 
．． 约束 
．． 选择检测器和特征 
．． 训练概述 
．． 特征和对象的分类 
．． 特征学习、稀疏编码和卷积网络 
． 总结 
． 习题 
第章 特征描述属性的分类 
． 一般的鲁棒性分类 
． 一般的视觉度量分类 
． 特征度量评估 
．． SIFT的示例 
．． LBP的示例 
．． 形状因子的示例 
． 总结 
． 习题 
第章 兴趣点检测与特征描述子 
． 兴趣点调整 
． 兴趣点的概念 
． 兴趣点方法概述 
．． Laplacian和LoG 
．． Moravac角点检测器 
．． Harris方法、Harris-Stephens、Shi-Tomasi和Hessian类型的检测器 
．． Hessian矩阵检测器和Hessian-Laplace 
．． Gaussian差 
．． 显著性区域 
．． SUSAN、Trajkovic-Hedly 
．． FAST 
．． 局部曲率方法 
．． 形态兴趣区域 
． 特征描述简介 
．． 局部二值描述子 
．． Census 
．． 改进的Census变换 
．． BRIEF 
．． ORB 
．． BRISK 
．． FREAK 
． 谱描述子 
．． SIFT 
．． SIFT-PCA 
．． SIFT-GLOH 
．． SIFT-SIFER 
．． SIFT CS-LBP 
．． ROOTSIFT 
．． CenSurE和STAR 
．． 相关模板 
．． HAAR特征 
．． 使用类HAAR特征的Viola和Jones算法 
．． SURF 
．． 改进的SURF算法 
．． 梯度直方图（HOG）及改进方法 
．． PHOG和相关方法 
．． Daisy和O-Daisy 
．． CARD 
．． 具有鲁棒性的快速特征匹配 
．． RIFF和CHOG 
．． 链码直方图 
．． D-NETS 
．． 局部梯度模式 
．． 局部相位量化 
． 基空间描述子 
．． Fourier描述子 
．． 用其他基函数来构建描述子 
．． 稀疏编码方法 
． 多边形形状描述 
．． MSER方法 
．． 针对斑点和多边形的目标形状度量 
．． 形状上下文 
． D和D描述子 
．． D HOG 
．． HON D 
．． D SIFT 
． 总结 
． 习题 
第章 基准数据、内容、度量和分析 
． 基准数据 
． 先前关于基准数据方面的工作：艺术与科学 
．． 质量的一般度量 
．． 算法性能的度量 
．． Rosin关于角点方面的工作 
． 构造基准数据的关键问题 
．． 内容：采用、修改或创建 
．． 可用的基准数据集 
．． 拟合基准数据的算法 
．． 场景构成和标注 
． 定义目标和预期 
．． Mikolajczyk和Schmid的方法 
．． 开放式评价系统 
．． 极端情况和限制 
．． 兴趣点和特征 
． 基准数据的鲁棒性准则 
．． 举例说明鲁棒性标准 
．． 将鲁棒性标准用于实际应用 
． 度量与基准数据配对 
．． 兴趣点、特征和基准数据的配对和优化 
．． 一般的视觉分类例子 
． 合成的特征字母表 
．． 合成数据集的目标 
．． 合成兴趣点字母表 
．． 将合成字母表叠加到真实图像上 
． 总结 
． 习题 
第章 可视流程及优化 
． 阶段、操作和资源 
． 计算资源预算 
．． 计算单元、ALU和加速器 
．． 能耗的使用 
．． 内存的利用 
．． I O性能 
． 计算机视觉流程的实例 
．． 汽车识别 
．． 人脸检测、情感识别和年龄识别 
．． 图像分类 
．． 增强现实 
． 可选的加速方案 
．． 内存优化 
．． 粗粒度并行 
．． 细粒度数据并行 
．． 高级指令集和加速器 
． 视觉算法的优化与调整 
．． 编译器优化与手工优化 
．． 特征描述子改进、检测器和距离函数 
．． Boxlets与卷积加速 
．． 数据类型优化（整数与浮点） 
． 优化资源 
． 总结 
第章 特征学习的架构分类和神经科学背景 
． 计算机视觉中的神经科学思想 
． 特征生成与特征学习 
． 计算机视觉中所使用的神经科学术语 
． 特征学习的分类 
．． 卷积特征权重学习 
．． 局部特征描述子学习 
．． 基本特征的组合和字典学习 
．． 特征学习方法总结 
． 计算机视觉中的机器学习模型 
．． 专家系统 
．． 统计和数学分析方法 
．． 受神经科学启发的方法 
．． 深度学习 
． 机器学习和特征学习的历史 
．． 历史回顾：世纪年代至世纪初 
．． 人工神经网络（ANN）分类 
． 特征学习概述 
．． 通过学习得到的各类描述子 
．． 层次特征学习 
．． 要学习多少特征 
．． 深度神经网络的优势 
．． 特征编码的有效性 
．． 手工设计的特征与深度学习 
．． 特征学习的不变性和鲁棒性 
．． 最好的特征和学习架构 
．． 大数据、分析和计算机视觉的统一 
．． 关键技术的推动因素 
． 神经科学的概念 
．． 生物学及其整体结构 
．． 难以找到统一的学习理论 
．． 人类视觉系统的架构 
． 特征学习的结构分类 
．． 架构拓扑 
．． 架构组件和层 
． 总结 
． 习题 
第 章 特征学习和深度学习架构概述 
． 架构概述 
．． FNN架构简介 
．． RNN的结构简介 
．． BFN的结构简介 
． 集成方法 
． 深度神经网络的未来 
．． 增加最大深度―深度残差学习 
．． 使用更简单的MLP来近似复杂模型（模型压缩） 
．． 分类器的分解与重组 
． 总结 
． 习题 
附录A 合成特征分析 
附录B 基准数据集概述 
附录C 成像和计算机视觉资源 
附录D 扩展SDM准则 
附录E 视觉基因组模型（VGM） 
参考文献 
译后记 
・ ・ ・ ・ ・ ・ (收起)目　录
第章　人工智能的发展概况　
．　人工智能的诞生与初兴　
．　人工智能的复兴与计算机视觉的初露端倪　
．　数据被重视，人工智能崛起　
第　章 数据标注行业的国内现状与未来展望　
．　国内数据标注行业的现状　
．　数据标注工程师简介　
．　数据标注行业的发展前景　
第　章 人工智能治理　
．　人工智能的可持续发展　
．　数据是AI治理的第一道防火墙　
．　数据服务产业是AI治理落地的试验田　
．．　数据来源的合法合规问题　
．．　技术的安全性　
．．　问责机制　
．　旷视，AI发展与治理双轮驱动　
第章　数据标注服务产品及旷视Data++数据标注平台　
．　数据标注服务产品　
．　数据服务标注平台流程　
．．　创建项目　
．．　数据上传　
．．　项目发布　
．．　项目交付　
．　旷视Data++数据标注平台　
．．　用户注册　
．．　标注操作流程　
第章　通用标注工具　
．　行人属性筛选　
．．　行人属性筛选定义　
．．　行人属性筛选工具介绍　
．．　行人属性筛选分类　
．．　标注注意事项　
．．　标注难点　
．．　实际中的应用　
．．　思考与讨论　
．．　行人属性筛选工具现状及展望　
．．　小结　
．　属性标注　
．．　属性标注工具介绍　
．．　标注内容　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　属性标注在Objects中的应用　
．．　小结　
．　框+属性　
．．　“框+属性”工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　小实验　
．．　小结　
．　多边形+属性　
．．　多边形+属性工具介绍　
．．　标注标准　
．．　标注难点　
．．　“多边形+属性”工具在生活中的应用　
．．　小结　
第章　检测标注工具　
．　人脸点　
．．　人脸关键点检测定义　
．．　人脸点工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　小实验　
．．　人脸点工具现状及展望　
．．　小结　
．　人体骨骼点　
．．　人体骨骼点点定义　
．．　人体骨骼点工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　人体骨骼点工具现状及未来展望　
．．　小结　
．　手部关键点　
．．　手部关键点点定义　
．．　手部关键点标注工具介绍　
．．　标注方法　
．．　标注难点　
．．　手部关键点标注提升方法　
．．　生活中的应用　
．．　手部关键点工具现状及展望　
．．　小结　
第章　识别标注工具　
．　一人所属照片清洗　
．．　一人所属照片清洗工具介绍　
．．　标注方法　
．．　标注难点　
．．　一人所属照片清洗工具在生活中的应用　
．．　照片清洗工具现状　
．．　小实验　
．．　小结　
．　行人重识别　
．．　行人重识别合并标注工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　行人重识别技术现状与发展　
．．　小结　
第章　其他标注工具　
．　视频人脸点　
．．　视频人脸点工具介绍　
．．　标注方法　
．．　生活中的应用　
．．　视频人脸点工具的现状与发展　
．．　小结　
．　人脸D朝向　
．．　人脸D朝向工具　
．．　人脸D朝向工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　人脸D朝向工具现状与展望　
．．　小结　
．　精细分割　
．．　人像抠图工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　精细分割标注工具的现状与发展　
．．　小结　
声明　
・ ・ ・ ・ ・ ・ (收起)第部分 基础知识导读篇
第章 数字图像基础 
. 图像表示基础 
.. 艺术与生活 
.. 数字图像 
.. 二值图像的处理 
.. 像素值的范围 
.. 图像索引 
. 彩色图像的表示 
. 应用基础 
.. 量化 
.. 特征 
.. 距离 
.. 图像识别 
.. 信息隐藏 
. 智能图像处理基础 
. 抽象 
第章 Python基础 
. 如何开始 
. 基础语法 
.. 变量的概念 
.. 变量的使用 
. 数据类型 
.. 基础类型 
.. 列表 
.. 元组 
.. 字典 
. 选择结构 
. 循环结构 
. 函数 
.. 什么是函数 
.. 内置函数 
.. 自定义函数 
. 模块 
.. 标准模块 
.. 第三方模块 
.. 自定义模块 
第章 OpenCV基础 
. 基础 
.. 安装OpenCV 
.. 读取图像 
.. 显示图像 
.. 保存图像 
. 图像处理 
.. 像素处理 
.. 通道处理 
.. 调整图像大小 
. 感兴趣区域 
. 掩模 
.. 掩模基础及构造 
.. 乘法运算 
.. 逻辑运算 
.. 掩模作为函数参数 
. 色彩处理 
.. 色彩空间基础 
.. 色彩空间转换 
.. 获取皮肤范围 
. 滤波处理 
.. 均值滤波 
.. 高斯滤波 
.. 中值滤波 
. 形态学 
.. 腐蚀 
.. 膨胀 
.. 通用形态学函数 
第部分 基础案例篇
第章 图像加密与解密 
. 加密与解密原理 
. 图像整体加密与解密 
. 脸部打码及解码 
.. 掩模方式实现 
.. ROI方式实现 
第章 数字水印 
. 位平面 
. 数字水印原理 
. 实现方法 
. 具体实现 
. 可视化水印 
.. ROI 
.. 加法运算 
. 扩展学习 
.. 算术运算实现数字水印 
.. 艺术字 
第章 物体计数 
. 理论基础 
.. 如何计算图像的中心点 
.. 获取图像的中心点 
.. 按照面积筛选前景对象 
. 核心程序 
.. 核函数 
.. zip函数 
.. 阈值处理函数threshold 
. 程序设计 
. 实现程序 
第章 缺陷检测 
. 理论基础 
.. 开运算 
.. 距离变换函数distanceTransform 
.. 最小包围圆形 
.. 筛选标准 
. 程序设计 
. 实现程序 
第章 手势识别 
. 理论基础 
.. 获取凸包 
.. 凸缺陷 
.. 凸缺陷占凸包面积比 
. 识别过程 
.. 识别流程 
.. 实现程序 
. 扩展学习：石头、剪刀、布的识别 
.. 形状匹配 
.. 实现程序 
第章 答题卡识别 
. 单道题目的识别 
.. 基本流程及原理 
.. 实现程序 
. 整张答题卡识别原理 
.. 图像预处理 
.. 答题卡处理 
.. 筛选出所有选项 
.. 将选项按照题目分组 
.. 处理每一道题目的选项 
.. 显示结果 
. 整张答题卡识别程序 
第章 隐身术 
. 图像的隐身术 
.. 基本原理与实现 
.. 实现程序 
.. 问题及优化方向 
. 视频隐身术 
第章 以图搜图 
. 原理与实现 
.. 算法原理 
.. 感知哈希值计算方法 
.. 感知哈希值计算函数 
.. 计算距离 
.. 计算图像库内所有图像的哈希值 
.. 结果显示 
. 实现程序 
. 扩展学习 
第章 手写数字识别 
. 基本原理 
. 实现细节 
. 实现程序 
. 扩展阅读 
第章 车牌识别 
. 基本原理 
.. 提取车牌 
.. 分割车牌 
.. 识别车牌 
. 实现程序 
. 下一步学习 
第章 指纹识别 
. 指纹识别基本原理 
. 指纹识别算法概述 
.. 描述关键点特征 
.. 特征提取 
.. MCC匹配方法 
.. 参考资料 
. 尺度不变特征变换 
.. 尺度空间变换 
.. 关键点定位 
.. 通过方向描述关键点 
.. 显示关键点 
. 基于SIFT的指纹识别 
.. 距离计算 
.. 特征匹配 
.. 算法及实现程序 
第部分 机器学习篇
第章 机器学习导读 
. 机器学习是什么 
. 机器学习基础概念 
.. 机器学习的类型 
.. 泛化能力 
.. 数据集的划分 
.. 模型的拟合 
.. 性能度量 
.. 偏差与方差 
. OpenCV中的机器学习模块 
.. 人工神经网络 
.. 决策树 
.. EM模块 
.. K近邻模块 
.. logistic回归 
.. 贝叶斯分类器 
.. 支持向量机 
.. 随机梯度下降 SVM 分类器 
. OpenCV机器学习模块的使用 
.. 使用KNN模块分类 
.. 使用SVM模块分类 
第章 KNN实现字符识别 
. 手写数字识别 
. 英文字母识别 
第章 求解数独图像 
. 基本过程 
. 定位数独图像内的单元格 
. 构造KNN模型 
. 识别数独图像内的数字 
. 求解数独 
. 绘制数独求解结果 
. 实现程序 
. 扩展学习 
第章 SVM数字识别 
. 基本流程 
. 倾斜校正 
. HOG特征提取 
. 数据处理 
. 构造及使用SVM分类器 
. 实现程序 
. 参考学习 
第章 行人检测 
. 方向梯度直方图特征 
. 基础实现 
.. 基本流程 
.. 实现程序 
. 函数detectMultiScale参数及优化 
.. 参数winStride 
.. 参数padding 
.. 参数scale 
.. 参数useMeanshiftGrouping 
. 完整程序 
. 参考学习 
第章 K均值聚类实现艺术画 
. 理论基础 
.. 案例 
.. K均值聚类的基本步骤 
. K均值聚类模块 
. 艺术画 
第部分 深度学习篇
第章 深度学习导读 
. 从感知机到人工神经网络 
.. 感知机 
.. 激活函数 
.. 人工神经网络 
.. 完成分类 
. 人工神经网络如何学习 
. 深度学习是什么 
.. 深度的含义 
.. 表示学习 
.. 端到端 
.. 深度学习可视化 
. 激活函数的分类 
.. sigmoid函数 
.. tanh函数 
.. ReLU函数 
.. Leaky ReLU函数 
.. ELU函数 
. 损失函数 
.. 为什么要用损失值 
.. 损失值如何起作用 
.. 均方误差 
.. 交叉熵误差 
. 学习的技能与方法 
.. 全连接 
.. 随机失活 
.. One-hot编码 
.. 学习率 
.. 正则化 
.. mini-batch方法 
.. 超参数 
. 深度学习游乐场 
第章 卷积神经网络基础 
. 卷积基础 
. 卷积原理 
.. 数值卷积 
.. 图像卷积 
.. 如何获取卷积核 
. 填充和步长 
. 池化操作 
. 感受野 
. 预处理与初始化 
.. 扩充数据集 
.. 标准化与归一化 
.. 网络参数初始化 
. CNN 
.. LeNet 
.. AlexNet 
.. VGG网络 
.. NiN 
.. GooLeNet 
.. 残差网络 
第章 DNN模块 
. 工作流程 
. 模型导入 
. 图像预处理 
. 推理相关函数 
第章 深度学习应用实践 
. 图像分类 
.. 图像分类模型 
.. 实现程序 
. 目标检测 
.. YOLO 
.. SSD 
. 图像分割 
.. 语义分割 
.. 实例分割 
. 风格迁移 
. 姿势识别 
. 说明 
第部分 人脸识别篇
第章 人脸检测 
. 基本原理 
. 级联分类器的使用 
. 函数介绍 
. 人脸检测实现 
. 表情检测 
第章 人脸识别 
. 人脸识别基础 
.. 人脸识别基本流程 
.. OpenCV人脸识别基础 
. LBPH人脸识别 
.. 基本原理 
.. 函数介绍 
.. 案例介绍 
. EigenFaces人脸识别 
.. 基本原理 
.. 函数介绍 
.. 案例介绍 
. FisherFaces人脸识别 
.. 基本原理 
.. 函数介绍 
.. 案例介绍 
. 人脸数据库 
第章 dlib库 
. 定位人脸 
. 绘制关键点 
. 勾勒五官轮廓 
. 人脸对齐 
. 调用CNN实现人脸检测 
第章 人脸识别应用案例 
. 表情识别 
. 驾驶员疲劳检测 
. 易容术 
.. 仿射 
.. 算法流程 
.. 实现程序 
. 年龄和性别识别 
・ ・ ・ ・ ・ ・ (收起)第章 基于直方图优化的图像去雾技术 
. 案例背景 
. 理论基础 
.. 空域图像增强 
.. 直方图均衡化 
. 程序实现 
.. 设计GUI界面 
.. 全局直方图处理 
.. 局部直方图处理 
.. Retinex增强处理 
. 延伸阅读 
第章 基于形态学的权重自适应图像去噪 
. 案例背景 
. 理论基础 
.. 图像去噪的方法 
.. 数学形态学的原理 
.. 权重自适应的多结构形态学去噪 
. 程序实现 
. 延伸阅读 
第章 基于多尺度形态学提取眼前节组织 
. 案例背景 
. 理论基础 
. 程序实现 
.. 多尺度结构设计 
.. 多尺度边缘提取 
.. 多尺度边缘融合 
. 延伸阅读 
第章 基于Hough变化的答题卡识别 
. 案例背景 
. 理论基础 
.. 图像二值化 
.. 倾斜校正 
.. 图像分割 
. 程序实现 
.. 图像灰度化 
.. 灰度图像二值化 
.. 图像平滑滤波 
.. 图像矫正 
.. 完整性核查 
. 延伸阅读 
第章 基于阈值分割的车牌定位识别 
. 案例背景 
. 理论基础 
.. 车牌图像处理 
.. 车牌定位原理 
.. 车牌字符处理 
.. 车牌字符识别 
. 程序实现 
. 延伸阅读 
第章 基于分水岭分割进行肺癌诊断 
. 案例背景 
. 理论基础 
.. 模拟浸水的过程 
.. 模拟降水的过程 
.. 过度分割问题 
.. 标记分水岭分割算法 
. 程序实现 
. 延伸阅读 
第章 基于主成分分析的人脸二维码识别 
. 案例背景 
. 理论基础 
.. QR二维码简介 
.. QR二维码的编码和译码流程 
.. 主成分分析方法 
. 程序实现 
.. 人脸建库 
.. 人脸识别 
.. 人脸二维码 
. 延伸阅读 
第章 基于知识库的手写体数字识别 
. 案例背景 
. 理论基础 
.. 算法流程 
.. 特征提取 
.. 模式识别 
. 程序实现 
.. 图像处理 
.. 特征提取 
.. 模式识别 
. 延伸阅读 
.. 识别器选择 
.. 特征库改善 
第章 基于特征匹配的英文印刷字符识别 
. 案例背景 
. 理论基础 
.. 图像预处理 
.. 图像识别技术 
. 程序实现 
.. 界面设计 
.. 回调识别 
. 延伸阅读 
第章 基于不变矩的数字验证码识别 
. 案例背景 
. 理论基础 
. 程序实现 
.. 设计GUI界面 
.. 载入验证码图像 
.. 验证码图像去噪 
.. 验证码数字定位 
.. 验证码归一化 
.. 验证码数字识别 
.. 手动确认并入库 
.. 重新生成模板库 
. 延伸阅读 
第章 基于小波技术进行图像融合 
. 案例背景 
. 理论基础 
. 程序实现 
.. 设计GUI界面 
.. 图像载入 
.. 小波融合 
. 延伸阅读 
第章 基于块匹配的全景图像拼接 
. 案例背景 
. 理论基础 
.. 图像匹配 
.. 图像融合 
. 程序实现 
.. 设计GUI界面 
.. 载入图片 
.. 图像匹配 
.. 图像拼接 
. 延伸阅读 
第章 基于霍夫曼图像编码的图像压缩和重建 
. 案例背景 
. 理论基础 
.. 霍夫曼编码的步骤 
.. 霍夫曼编码的特点 
. 程序实现 
.. 设计GUI界面 
.. 压缩和重建 
.. 效果对比 
. 延伸阅读 
第章 基于主成分分析的图像压缩和重建 
. 案例背景 
. 理论基础 
.. 主成分降维分析原理 
.. 由得分矩阵重建样本 
.. 主成分分析数据压缩比 
.. 基于主成分分析的图像压缩 
. 程序实现 
.. 主成分分析的源代码 
.. 图像数组和样本矩阵之间的转换 
.. 基于主成分分析的图像压缩 
. 延伸阅读 
第章 基于小波的图像压缩技术 
. 案例背景 
. 理论基础 
. 程序实现 
. 延伸阅读 
第章 基于融合特征的以图搜图技术 
. 案例背景 
. 理论基础 
. 程序实现 
.. 图像预处理 
.. 计算特征 
.. 图像检索 
.. 结果分析 
. 延伸阅读 
第章 基于Harris的角点特征检测 
. 案例背景 
. 理论基础 
.. Harris的基本原理 
.. Harris算法的流程 
.. Harris角点的性质 
. 程序实现 
.. Harris算法的代码 
.. 角点检测实例 
. 延伸阅读 
第章 基于GUI搭建通用视频处理工具 
. 案例背景 
. 理论基础 
. 程序实现 
.. 设计GUI界面 
.. 实现GUI界面 
. 延伸阅读 
第章 基于语音识别的信号灯图像
模拟控制技术 
. 案例背景 
. 理论基础 
. 程序实现 
. 延伸阅读 
第章 基于帧间差法进行视频目标检测 
. 案例背景 
. 理论基础 
.. 帧间差分法 
.. 背景差分法 
.. 光流法 
. 程序实现 
. 延伸阅读 
第章 路面裂缝检测系统设计 
. 案例背景 
. 理论基础 
.. 图像灰度化 
.. 图像滤波 
.. 图像增强 
.. 图像二值化 
. 程序实现 
. 延伸阅读 
第章 基于K-means聚类算法的图像分割 
. 案例背景 
. 理论基础 
.. K-means聚类算法的原理 
.. K-means聚类算法的要点 
.. K-means聚类算法的缺点 
.. 基于K-means聚类算法进行图像分割 
. 程序实现 
.. 样本间的距离 
.. 提取特征向量 
.. 图像聚类分割 
. 延伸阅读 
第章 基于光流场的车流量计数应用 
. 案例背景 
. 理论基础 
.. 基于光流法检测运动的原理 
.. 光流场的主要计算方法 
.. 梯度光流场约束方程 
.. Horn-Schunck光流算法 
. 程序实现 
.. 计算视觉系统工具箱简介 
.. 基于光流法检测汽车运动 
. 延伸阅读 
第章 基于Simulink进行图像和视频处理 
. 案例背景 
. 模块介绍 
.. 分析和增强模块库（Analysis和Enhancement） 
.. 转化模块库（Conversions） 
.. 滤波模块库（Filtering） 
.. 几何变换模块库（Geometric Transformations） 
.. 形态学操作模块库（Morphological Operations） 
.. 输入模块库（Sources） 
.. 输出模块库（Sinks） 
.. 统计模块库（Statistics） 
.. 文本和图形模块库（Text 和 Graphic） 
.. 变换模块库（Transforms） 
.. 其他工具模块库（Utilities） 
. 仿真案例 
.. 搭建组织模型 
.. 仿真执行模型 
.. 自动生成报告 
. 延伸阅读 
第章 基于小波变换的数字水印技术 
. 案例背景 
. 理论基础 
.. 数字水印技术的原理 
.. 典型的数字水印算法 
.. 数字水印攻击和评价 
.. 基于小波的水印技术 
. 程序实现 
.. 准备载体和水印图像 
.. 小波数字水印的嵌入 
.. 小波数字水印的提取 
.. 小波水印的攻击试验 
. 延伸阅读 
第章 基于最小误差法的胸片分割技术 
. 案例背景 
. 理论基础 
.. 图像增强 
.. 区域选择 
.. 形态学滤波 
.. 基于最小误差法进行胸片分割 
. 程序实现 
.. 设计GUI界面 
.. 图像预处理 
.. 基于最小误差法进行图像分割 
.. 形态学后处理 
. 延伸阅读 
第章 基于区域生长的肝脏影像分割系统 
. 案例背景 
. 理论基础 
.. 阈值分割 
.. 区域生长 
.. 基于阈值预分割的区域生长 
. 程序实现 
. 延伸阅读 
第章 基于计算机视觉的自动驾驶应用 
. 案例背景 
. 理论基础 
.. 环境感知 
.. 行为决策 
.. 路径规划 
.. 运动控制 
. 程序实现 
.. 传感器数据载入 
.. 追踪器创建 
.. 碰撞预警 
. 延伸阅读 
第章 基于深度学习的汽车目标检测 
. 案例背景 
. 理论基础 
.. 基本架构 
.. 卷积层 
.. 池化层 
. 程序实现 
.. 加载数据 
.. 构建CNN 
.. 训练CNN 
.. 评估训练效果 
. 延伸阅读 
第章 基于深度学习的视觉场景
识别 
. 案例背景 
. 理论基础 
. 程序实现 
.. 环境配置 
.. 数据集制作 
.. 网络训练 
.. 网络测试 
. 延伸阅读 
第章 深度学习综合应用 
. 应用背景 
. 理论基础 
.. 分类识别 
.. 目标检测 
. 案例实现：基于CNN的数字识别 
.. 自定义CNN 
.. AlexNet 
.. 基于MATLAB进行实验设计 
.. 基于TensorFlow进行实验设计 
.. 实验小结 
. 案例实现：基于CNN的物体识别 
.. CIFAR-数据集 
.. VggNet 
.. ResNet 
.. 实验设计 
.. 实验小结 
. 案例实现：基于CNN的图像矫正 
.. 倾斜数据集 
.. 自定义CNN回归网络 
.. AlexNet回归网络 
.. 实验设计 
.. 实验小结 
. 案例实现：基于LSTM的时间序列分析 
.. 厄尔尼诺南方涛动指数数据 
.. 样条拟合分析 
.. 基于MATLAB进行LSTM分析 
.. 基于Keras进行LSTM分析 
.. 实验小结 
. 案例实现：基于深度学习的以图搜图技术 
.. 人脸的深度特征 
.. AlexNet的特征 
.. GoogleNet的特征 
.. 深度特征融合计算 
.. 实验设计 
.. 实验小结 . 案例实现：基于YOLO的交通目标检测应用 
.. 车辆目标的YOLO检测 
.. 交通标志的YOLO检测 
. 延伸阅读 
・ ・ ・ ・ ・ ・ (收起)Summary of Contents
Foreword 
Preface 
About the Authors 
 Introduction 
I Words
 Regular Expressions and Automata 
 Words and Transducers 　　 
 N-Grams 
 Part-of-Speech Tagging 　　 
 Hidden Markov and Maximum Entropy Models 
 Phonetics 
 Speech Synthesis 
 Automatic Speech Recognition 
 Speech Recognition: Advanced Topics 
 Computational Phonology 　　 
 Formal Grammars of English 　 
 Syntactic Parsing 
 Statistical Parsing 
 Features and Uni?cation 　　 
 Language and Complexity 　　 
IV Semantics and Pragmatics
 The Representation ofMeaning　 
 Computational Semantics 　　 
 Lexical Semantics　 
 Computational Lexical Semantics　 
 Computational Discourse 　　 
V Applications
 Information Extraction 　　 
 Question Answering and Summarization 
 Dialogue and Conversational Agents 
 Machine Translation 　　 
Bibliography 
Author Index 
Subject Index 
Contents
Foreword 
Preface 
About the Authors 
 Introduction 
. Knowledge in Speech and Language Processing 　 
. Ambiguity 
. Models andAlgorithms 
. Language, Thought, and Understanding 　　 
. TheState of theArt 
. SomeBriefHistory 
.. Foundational Insights: s and s 　 
.. The Two Camps: C 　　 
.. Four Paradigms: C 　　 
.. Empiricism and Finite-State Models Redux: C 　 
.. The Field Comes Together: C　 
.. The Rise of Machine Learning: C 　 
.. On Multiple Discoveries 　 
.. A Final Brief Note on Psychology 　　 
. Summary 　 
Bibliographical and Historical Notes 　 
I Words
 Regular Expressions and Automata　 
. RegularExpressions 　 
.. Basic Regular Expression Patterns 　　 
.. Disjunction, Grouping, and Precedence　 
.. ASimpleExample　 
.. A More Complex Example　 
.. AdvancedOperators 　 
.. Regular Expression Substitution, Memory, and ELIZA 　 
. Finite-StateAutomata 　 
.. Use of an FSA to Recognize Sheeptalk 　 
.. Formal Languages　 
.. Another Example 　 
.. Non-Deterministic FSAs . 
.. Use of an NFSA to Accept Strings 　 
.. Recognition as Search 
.. Relation of Deterministic and Non-Deterministic Automata 　 
Foreword 　 
Preface 　 
About the Authors　 
 Introduction 　 
. Knowledge in Speech and Language Processing　 
. Ambiguity 　 
. Models andAlgorithms 　 
. Language, Thought, and Understanding 　　　
. TheState of theArt . 
. SomeBriefHistory . 
.. Foundational Insights: s and s 
.. The Two Camps: C 　　 
.. Four Paradigms: C 　　 
.. Empiricism and Finite-State Models Redux: C 
.. The Field Comes Together: C 
.. The Rise of Machine Learning: C 
.. On Multiple Discoveries 
.. A Final Brief Note on Psychology 　　 
. Summary 　 
Bibliographical and Historical Notes 
I Words
 Regular Expressions and Automata 
. RegularExpressions 
.. Basic Regular Expression Patterns 　　 
.. Disjunction, Grouping, and Precedence　 
.. ASimpleExample　 
.. A More Complex Example 　 
.. AdvancedOperators 　 
.. Regular Expression Substitution, Memory, and ELIZA　 
. Finite-StateAutomata　 
.. Use of an FSA to Recognize Sheeptalk　 
.. Formal Languages　 
.. Another Example 　 
.. Non-Deterministic FSAs 　 
.. Use of an NFSA to Accept Strings 　　 
.. Recognition as Search　 
.. Relation of Deterministic and Non-Deterministic Automata　 
. Regular Languages and FSAs　 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
 Words and Transducers 
. Survey of (Mostly) English Morphology 　 
.. In?ectional Morphology 　 
.. Derivational Morphology　 
.. Cliticization 　 
.. Non-Concatenative Morphology 　　 
.. Agreement 　 
. Finite-State Morphological Parsing　 
. Construction of a Finite-State Lexicon 　　 
. Finite-StateTransducers 　 
.. Sequential Transducers and Determinism 　 
. FSTs for Morphological Parsing 　 
. Transducers and Orthographic Rules 　　 
. The Combination of an FST Lexicon and Rules 　 
. Lexicon-Free FSTs: The Porter Stemmer 　　 
. Word and Sentence Tokenization　 
.. Segmentation in Chinese　 
. Detection and Correction of Spelling Errors 　 
. MinimumEditDistance 　 
. Human Morphological Processing 　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 
 N-Grams 　 
. WordCounting inCorpora　 
. Simple (Unsmoothed) N-Grams　 
. Training andTestSets 　 
.. N-Gram Sensitivity to the Training Corpus　 
.. Unknown Words: Open Versus Closed Vocabulary Tasks 　 
. Evaluating N-Grams: Perplexity 　 
. Smoothing 　 
.. LaplaceSmoothing 　 
.. Good-Turing Discounting　 
.. Some Advanced Issues in Good-Turing Estimation 　 
. Interpolation 　 
. Backoff 　 
.. Advanced: Details of Computing Katz Backoff α and P 
. Practical Issues: Toolkits and Data Formats 　　 
. Advanced Issues in Language Modeling 　　 
.. Advanced Smoothing Methods: Kneser-Ney Smoothing 　 
.. Class-Based N-Grams　 
.. Language Model Adaptation and Web Use　 
.. Using Longer-Distance Information: A Brief Summary 　 
. Advanced: Information Theory Background 　　
.. Cross-Entropy for Comparing Models 　　 
. Advanced: The Entropy of English and Entropy Rate Constancy 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
 Part-of-Speech Tagging 　 
. (Mostly) English Word Classes　 
. Tagsets forEnglish 　 
. Part-of-Speech Tagging 　 
. Rule-Based Part-of-Speech Tagging 　
. HMM Part-of-Speech Tagging　 
.. Computing the Most Likely Tag Sequence: An Example　 
.. Formalizing Hidden Markov Model Taggers　 
.. Using the Viterbi Algorithm for HMM Tagging 　 
.. Extending the HMM Algorithm to Trigrams 　 
. Transformation-Based Tagging 　 
.. How TBL Rules Are Applied 　　 
.. How TBL Rules Are Learned 　　 
. Evaluation and Error Analysis 　 
.. ErrorAnalysis　 
. Advanced Issues in Part-of-Speech Tagging 　　 
.. Practical Issues: Tag Indeterminacy and Tokenization 　 
.. Unknown Words . 
.. Part-of-Speech Tagging for Other Languages　 
.. Tagger Combination 
. Advanced: The Noisy Channel Model for Spelling 　 
.. Contextual Spelling Error Correction 　　 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
 Hidden Markov and Maximum Entropy Models 
. MarkovChains 　 
. TheHiddenMarkovModel 　 
. Likelihood Computation: The Forward Algorithm 　 
. Decoding: The Viterbi Algorithm　 
. HMM Training: The Forward-Backward Algorithm 　 
. Maximum Entropy Models: Background 　 
.. LinearRegression 　 
.. Logistic Regression 
.. Logistic Regression: Classi?cation 　　
.. Advanced: Learning in Logistic Regression 　 
. Maximum Entropy Modeling 　 
.. Why We Call It Maximum Entropy 　　 
. Maximum Entropy Markov Models 
.. Decoding and Learning in MEMMs 　　 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
II Speech
 Phonetics 　 
. Speech Sounds and Phonetic Transcription　 
. Articulatory Phonetics 　 
.. TheVocalOrgans 　 
.. Consonants: Place of Articulation 　　
.. Consonants: Manner of Articulation 　　 
.. Vowels 
.. Syllables 
. Phonological Categories and Pronunciation Variation 
.. Phonetic Features . 
.. Predicting Phonetic Variation 　　 . 
.. Factors In?uencing Phonetic Variation 　　 
. Acoustic Phonetics and Signals 
.. Waves 　 
.. Speech Sound Waves 　 
.. Frequency and Amplitude; Pitch and Loudness 　 
.. Interpretation of Phones from a Waveform　 
.. Spectra and the Frequency Domain 　 
.. The Source-Filter Model 　　
. Phonetic Resources 　 
. Advanced: Articulatory and Gestural Phonology 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 　 
 Speech Synthesis 　
. TextNormalization 　 
.. Sentence Tokenization 　 
.. Non-Standard Words 　 
.. Homograph Disambiguation 　　
. Phonetic Analysis 　 
.. Dictionary Lookup 　 
.. Names 　 
.. Grapheme-to-Phoneme Conversion 　　 
. ProsodicAnalysis 　 
.. ProsodicStructure　 
.. Prosodic Prominence 　 
.. Tune 　 
.. More Sophisticated Models: ToBI 　 
.. Computing Duration from Prosodic Labels 　
.. Computing F from Prosodic Labels 　　
.. Final Result of Text Analysis: Internal Representation　 
. Diphone Waveform Synthesis 　 
.. Steps for Building a Diphone Database 
.. Diphone Concatenation and TD-PSOLA for Prosody 　
. Unit Selection (Waveform) Synthesis　 
. Evaluation 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Automatic Speech Recognition 　　
. Speech Recognition Architecture 　 
. The Hidden Markov Model Applied to Speech 　 
. Feature Extraction: MFCC Vectors　 
.. Preemphasis　 
.. Windowing 　 
.. Discrete Fourier Transform 　 
.. Mel Filter Bank and Log 　 
.. The Cepstrum: Inverse Discrete Fourier Transform　 
.. Deltas andEnergy　 
.. Summary:MFCC 　 
. Acoustic Likelihood Computation　 
.. Vector Quantization 　 
.. GaussianPDFs 　 
.. Probabilities, Log-Probabilities, and Distance Functions　 
. The Lexicon and Language Model 　 
. Search andDecoding 　 
. EmbeddedTraining 　 
. Evaluation: Word Error Rate 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Speech Recognition: Advanced Topics　 
. Multipass Decoding: N-Best Lists and Lattices 　　 
. A? (“Stack”)Decoding　 
. Context-Dependent Acoustic Models: Triphones 　 
. DiscriminativeTraining　 
.. Maximum Mutual Information Estimation　 
.. Acoustic Models Based on Posterior Classi?ers 
. ModelingVariation 　 
.. Environmental Variation and Noise 　　
.. Speaker Variation and Speaker Adaptation 　 
.. Pronunciation Modeling: Variation Due to Genre 
. Metadata: Boundaries, Punctuation, and Dis?uencies 　 
. Speech Recognition by Humans　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Computational Phonology 　 
. Finite-State Phonology 　 
. Advanced Finite-State Phonology 　 
.. Harmony 　 
.. Templatic Morphology　 
. Computational Optimality Theory 　 
.. Finite-State Transducer Models of Optimality Theory 　 
.. Stochastic Models of Optimality Theory　 
. Syllabi?cation 　 
. Learning Phonology and Morphology 　 
.. Learning Phonological Rules 　 
.. Learning Morphology 
.. Learning in Optimality Theory 　　
. Summary 
Bibliographical and Historical Notes 　 
Exercises 
III Syntax
 Formal Grammars of English 
. Constituency 
. Context-FreeGrammars 
.. Formal De?nition of Context-Free Grammar 
. Some Grammar Rules for English 　 
.. Sentence-Level Constructions 　　
.. Clauses and Sentences 　 
.. The Noun Phrase　 
.. Agreement 　 
.. The Verb Phrase and Subcategorization　 
.. Auxiliaries 　 
.. Coordination　 
. Treebanks 
.. Example: The Penn Treebank Project 　　 
.. Treebanks as Grammars 　 
.. Treebank Searching　 
.. Heads and Head Finding 　
. Grammar Equivalence and Normal Form　 
. Finite-State and Context-Free Grammars 　 
. DependencyGrammars 
.. The Relationship Between Dependencies and Heads 
.. Categorial Grammar 
. Spoken Language Syntax 　 
.. Dis?uencies andRepair 　 
.. Treebanks for Spoken Language 　　
. Grammars and Human Processing 　 
. Summary 
Bibliographical and Historical Notes 　
Exercises 　 
 Syntactic Parsing 　 
. Parsing asSearch 　 
.. Top-DownParsing 　 
.. Bottom-UpParsing　 
.. Comparing Top-Down and Bottom-Up Parsing 
. Ambiguity 
. Search in the Face of Ambiguity . 
. Dynamic Programming Parsing Methods 　　 
.. CKYParsing 
.. The Earley Algorithm 
.. ChartParsing 
. PartialParsing . 
.. Finite-State Rule-Based Chunking 　　 
.. Machine Learning-Based Approaches to Chunking 
.. Chunking-System Evaluations 　　 . 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 　 
 Statistical Parsing 　　
. Probabilistic Context-Free Grammars 　 
.. PCFGs for Disambiguation 　 
.. PCFGs for Language Modeling 　 
. Probabilistic CKY Parsing of PCFGs 　 
. Ways to Learn PCFG Rule Probabilities 　 
. ProblemswithPCFGs 　
.. Independence Assumptions Miss Structural Dependencies BetweenRules　 
.. Lack of Sensitivity to Lexical Dependencies　 
. Improving PCFGs by Splitting Non-Terminals 　 
. Probabilistic Lexicalized CFGs 　
.. The Collins Parser 　
.. Advanced: Further Details of the Collins Parser 　 
. EvaluatingParsers 　
. Advanced: Discriminative Reranking 　 
. Advanced: Parser-Based Language Modeling 　　 
. HumanParsing 　
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 
 Features and Uni?cation　 
. FeatureStructures 　
. Uni?cation of Feature Structures 　 
. Feature Structures in the Grammar 　
.. Agreement 　
.. HeadFeatures 　
.. Subcategorization 　
.. Long-Distance Dependencies 　　 
. Implementation of Uni?cation　 
.. Uni?cation Data Structures 　 
.. The Uni?cationAlgorithm 　 
. Parsing with Uni?cation Constraints 　 
.. Integration of Uni?cation into an Earley Parser 　
.. Uni?cation-Based Parsing 　 
. Types and Inheritance 　 
.. Advanced: Extensions to Typing 　 
.. Other Extensions to Uni?cation 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 
 Language and Complexity 　 
. TheChomskyHierarchy 　 
. Ways to Tell if a Language Isn’t Regular 　　 
.. The Pumping Lemma 
.. Proofs that Various Natural Languages Are Not Regular　 
. Is Natural Language Context Free?　 
. Complexity and Human Processing 　 
. Summary 
Bibliographical and Historical Notes 
Exercises 
 The Representation of Meaning 
. Computational Desiderata for Representations 　 
.. Veri?ability 
.. Unambiguous Representations 　
.. Canonical Form 　 
.. Inference and Variables　 
.. Expressiveness 　
. Model-Theoretic Semantics　 
. First-OrderLogic 　 
.. Basic Elements of First-Order Logic 　　 
.. Variables and Quanti?ers . 
.. LambdaNotation . 
.. The Semantics of First-Order Logic 　
.. Inference 　 
. Event and State Representations　 
.. RepresentingTime　 
.. Aspect 　 
. DescriptionLogics 　 
. Embodied and Situated Approaches to Meaning 　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 
 Computational Semantics　 
. Syntax-Driven Semantic Analysis 　 
. Semantic Augmentations to Syntactic Rules 　 
. Quanti?er Scope Ambiguity and Underspeci?cation 　 
.. Store and Retrieve Approaches 　　 
.. Constraint-Based Approaches 　　 
. Uni?cation-Based Approaches to Semantic Analysis 　 
. Integration of Semantics into the Earley Parser 　 
. Idioms and Compositionality 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 　 
 Lexical Semantics 　
. WordSenses 　 
. Relations Between Senses 　 
.. Synonymy and Antonymy 　 
.. Hyponymy 　 
.. SemanticFields 　 
. WordNet: A Database of Lexical Relations 　　 
. EventParticipants　 
.. ThematicRoles 　 
.. Diathesis Alternations 　
.. Problems with Thematic Roles 　　 
.. The Proposition Bank　 
.. FrameNet 　 
.. Selectional Restrictions 　 
. Primitive Decomposition 　 
. Advanced: Metaphor 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Computational Lexical Semantics 　 
. Word Sense Disambiguation: Overview 　　 
. Supervised Word Sense Disambiguation 　　 
.. Feature Extraction for Supervised Learning　 
.. Naive Bayes and Decision List Classi?ers 　 
. WSD Evaluation, Baselines, and Ceilings 　 
. WSD: Dictionary and Thesaurus Methods 　　
.. The Lesk Algorithm 　 
.. Selectional Restrictions and Selectional Preferences 　 
. Minimally Supervised WSD: Bootstrapping 　　 
. Word Similarity: Thesaurus Methods 　　 
. Word Similarity: Distributional Methods 　　 
.. De?ning a Word’s Co-Occurrence Vectors 　 
.. Measuring Association with Context 　　
.. De?ning Similarity Between Two Vectors　 
.. Evaluating Distributional Word Similarity 　 
. Hyponymy and Other Word Relations 　 
. SemanticRoleLabeling 　 
. Advanced: Unsupervised Sense Disambiguation　 
. Summary 
Bibliographical and Historical Notes 
Exercises 
 Computational Discourse　 
. DiscourseSegmentation　 
.. Unsupervised Discourse Segmentation 　
.. Supervised Discourse Segmentation 　　
.. Discourse Segmentation Evaluation 　 
. TextCoherence　 
.. Rhetorical Structure Theory 　 
.. Automatic Coherence Assignment 　 
. ReferenceResolution 　 
. ReferencePhenomena 　 
.. Five Types of Referring Expressions 　　 
.. Information Status 　 
. Features for Pronominal Anaphora Resolution 　　 
.. Features for Filtering Potential Referents　 
.. Preferences in Pronoun Interpretation 　 
. Three Algorithms for Anaphora Resolution 　 
.. Pronominal Anaphora Baseline: The Hobbs Algorithm 　 
.. A Centering Algorithm for Anaphora Resolution 　 
.. A Log-Linear Model for Pronominal Anaphora Resolution 　 
.. Features for Pronominal Anaphora Resolution 　
. Coreference Resolution 　 
. Evaluation of Coreference Resolution 　 
. Advanced: Inference-Based Coherence Resolution 　 
. Psycholinguistic Studies of Reference 　 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises　 
V Applications
 Information Extraction 　 
. Named Entity Recognition 　 
.. Ambiguity in Named Entity Recognition 　 
.. NER as Sequence Labeling 　 
.. Evaluation of Named Entity Recognition　 
.. Practical NER Architectures 　　 
. Relation Detection and Classi?cation 　　 
.. Supervised Learning Approaches to Relation Analysis 
.. Lightly Supervised Approaches to Relation Analysis . 
.. Evaluation of Relation Analysis Systems . 
. Temporal and Event Processing 
.. Temporal Expression Recognition 　　 
.. Temporal Normalization 　 
.. Event Detection and Analysis 　　 
.. TimeBank 　
. Template Filling 　
.. Statistical Approaches to Template-Filling 　 
.. Finite-State Template-Filling Systems 　　 
. Advanced: Biomedical Information Extraction 　　 
.. Biological Named Entity Recognition 　　 
.. Gene Normalization　 
.. Biological Roles and Relations 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 　 
 Question Answering and Summarization　 
. InformationRetrieval 　 
.. The Vector Space Model 　 
.. TermWeighting 　 
.. Term Selection and Creation 　 
.. Evaluation of Information-Retrieval Systems 
.. Homonymy, Polysemy, and Synonymy 　 
.. Ways to Improve User Queries 　　
. Factoid Question Answering　 
.. Question Processing 　 
.. PassageRetrieval　 
.. AnswerProcessing　 
.. Evaluation of Factoid Answers 　　 
. Summarization 　 
. Single-Document Summarization 　 
.. Unsupervised Content Selection 　　 
.. Unsupervised Summarization Based on Rhetorical Parsing 　 
.. Supervised Content Selection 　　 
.. Sentence Simpli?cation 　 
. Multi-Document Summarization　 
.. Content Selection in Multi-Document Summarization　 
.. Information Ordering in Multi-Document Summarization 　 
. Focused Summarization and Question Answering 　 
. Summarization Evaluation 　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 
 Dialogue and Conversational Agents 　
. Properties of Human Conversations 　
.. Turns and Turn-Taking 　
.. Language as Action: Speech Acts 　　 
.. Language as Joint Action: Grounding 　 
.. Conversational Structure 　 
.. Conversational Implicature　 
. Basic Dialogue Systems 　 
.. ASR Component　 
.. NLU Component 　 
.. Generation and TTS Components 　 
.. Dialogue Manager 　 
.. Dealing with Errors: Con?rmation and Rejection 
. VoiceXML 
. Dialogue System Design and Evaluation 　　 
.. Designing Dialogue Systems 　　 
.. Evaluating Dialogue Systems 　 
. Information-State and Dialogue Acts 　 
.. Using Dialogue Acts 　 
.. Interpreting Dialogue Acts　 
.. Detecting Correction Acts　 
.. Generating Dialogue Acts: Con?rmation and Rejection 　
. Markov Decision Process Architecture 　　 
. Advanced: Plan-Based Dialogue Agents 　　 
.. Plan-Inferential Interpretation and Production　 
.. The Intentional Structure of Dialogue 　 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 　 
 Machine Translation　 
. Why Machine Translation Is Hard 　 
.. Typology 　 
.. Other Structural Divergences 　　 
.. LexicalDivergences 　 
. Classical MT and the Vauquois Triangle 
.. Direct Translation 　 
.. Transfer 　 
.. Combined Direct and Transfer Approaches in Classic MT　 
.. The Interlingua Idea: Using Meaning 　　 
. StatisticalMT 　 
. P(F|E): The Phrase-Based Translation Model　　 
. Alignment inMT 　 
.. IBMModel  　 
.. HMMAlignment 　　
. Training Alignment Models　 
.. EM for Training Alignment Models 　　
. Symmetrizing Alignments for Phrase-Based MT　 
. Decoding for Phrase-Based Statistical MT 　　 
. MTEvaluation 　 
.. Using Human Raters 　 
.. Automatic Evaluation: BLEU 　　 
. Advanced: Syntactic Models for MT 　　 
. Advanced: IBM Model  and Fertility 　　
.. Training forModel  　
. Advanced: Log-Linear Models for MT 　　 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 
Bibliography 　 
Author Index　 
Subject Index 　 
・ ・ ・ ・ ・ ・ (收起)推荐序III
推荐语IV
前言V
数学符号IX
第 章绪论
. 自然语言处理的概念 
. 自然语言处理的难点
.. 抽象性 
.. 组合性 
.. 歧义性 
.. 进化性
.. 非规范性
.. 主观性
.. 知识性
.. 难移植性
. 自然语言处理任务体系.
.. 任务层级
.. 任务类别
.. 研究对象与层次
. 自然语言处理技术发展历史
第 章自然语言处理基础
. 文本的表示.
.. 词的独热表示
.. 词的分布式表示
.. 词嵌入表示
.. 文本的词袋表示
. 自然语言处理任务
.. 语言模型
.. 自然语言处理基础任务
.. 自然语言处理应用任务
. 基本问题
.. 文本分类问题
.. 结构预测问题
.. 序列到序列问题
. 评价指标
. 小结
第 章基础工具集与常用数据集
. NLTK 工具集
.. 常用语料库和词典资源
.. 常用自然语言处理工具集.
. LTP 工具集
.. 中文分词
.. 其他中文自然语言处理功能.
. PyTorch 基础
.. 张量的基本概念
.. 张量的基本运算
.. 自动微分
.. 调整张量形状
.. 广播机制
.. 索引与切片
.. 降维与升维
. 大规模预训练数据
.. 维基百科数据
.. 原始数据的获取
.. 语料处理方法
.. Common Crawl 数据
. 更多数据集.
. 小结
第 章自然语言处理中的神经网络基础
. 多层感知器模型
.. 感知器
.. 线性回归
.. Logistic 回归
.. Softmax 回归
.. 多层感知器
.. 模型实现
. 卷积神经网络
.. 模型结构
.. 模型实现
. 循环神经网络
.. 模型结构
.. 长短时记忆网络
.. 模型实现
.. 基于循环神经网络的序列到序列模型
. 注意力模型.
.. 注意力机制
.. 自注意力模型
.. Transformer 
.. 基于Transformer 的序列到序列模型
.. Transformer 模型的优缺点
.. 模型实现
. 神经网络模型的训练
.. 损失函数
.. 梯度下降
. 情感分类实战
.. 词表映射
.. 词向量层
.. 融入词向量层的多层感知器
.. 数据处理
.. 多层感知器模型的训练与测试
.. 基于卷积神经网络的情感分类
.. 基于循环神经网络的情感分类
.. 基于Transformer 的情感分类
. 词性标注实战
.. 基于前馈神经网络的词性标注
.. 基于循环神经网络的词性标注
.. 基于Transformer 的词性标注
. 小结
第 章静态词向量预训练模型
. 神经网络语言模型
.. 预训练任务
.. 模型实现
. Wordvec 词向量
.. 概述
.. 负采样
.. 模型实现
. GloVe 词向量
.. 概述
.. 预训练任务
.. 参数估计
.. 模型实现
. 评价与应用.
.. 词义相关性
.. 类比性
.. 应用
. 小结
第 章动态词向量预训练模型
. 词向量――从静态到动态
. 基于语言模型的动态词向量预训练
.. 双向语言模型
.. ELMo 词向量
.. 模型实现
.. 应用与评价
. 小结
第 章预训练语言模型
. 概述
.. 大数据
.. 大模型
.. 大算力
. GPT 
.. 无监督预训练
.. 有监督下游任务精调
.. 适配不同的下游任务
. BERT 
.. 整体结构
.. 输入表示
.. 基本预训练任务
.. 更多预训练任务
.. 模型对比
. 预训练语言模型的应用
.. 概述
.. 单句文本分类
.. 句对文本分类
.. 阅读理解
.. 序列标注
. 深入理解BERT .
.. 概述
.. 自注意力可视化分析
.. 探针实验
. 小结.
第 章预训练语言模型进阶
. 模型优化.
.. XLNet 
.. RoBERTa .
.. ALBERT .
.. ELECTRA 
.. MacBERT 
.. 模型对比
. 长文本处理.
.. 概述
.. Transformer-XL 
.. Reformer .
.. Longformer 
.. BigBird .
.. 模型对比
. 模型蒸馏与压缩
.. 概述
.. DistilBERT 
.. TinyBERT 
.. MobileBERT 
.. TextBrewer 
. 生成模型
.. BART 
.. UniLM 
.. T .
.. GPT- 
.. 可控文本生成
. 小结.
第 章多模态融合的预训练模型
. 多语言融合.
.. 多语言BERT .
.. 跨语言预训练语言模型
.. 多语言预训练语言模型的应用
. 多媒体融合.
.. VideoBERT 
.. VL-BERT 
.. DALL・E 
.. ALIGN 
. 异构知识融合
.. 融入知识的预训练
.. 多任务学习
. 更多模态的预训练模型
. 小结.
参考文献
术语表
・ ・ ・ ・ ・ ・ (收起)第章 新手上路 
. 自然语言与编程语言 
.. 词汇量 
.. 结构化 
.. 歧义性 
.. 容错性 
.. 易变性 
.. 简略性 
. 自然语言处理的层次 
.. 语音、图像和文本 
.. 中文分词、词性标注和命名实体识别 
.. 信息抽取 
.. 文本分类与文本聚类 
.. 句法分析 
.. 语义分析与篇章分析 
.. 其他高级任务 
. 自然语言处理的流派 
.. 基于规则的专家系统 
.. 基于统计的学习方法 
.. 历史 
.. 规则与统计 
.. 传统方法与深度学习 
. 机器学习 
.. 什么是机器学习 
.. 模型 
.. 特征 
.. 数据集 
.. 监督学习 
.. 无监督学习 
.. 其他类型的机器学习算法 
. 语料库 
.. 中文分词语料库 
.. 词性标注语料库 
.. 命名实体识别语料库 
.. 句法分析语料库 
.. 文本分类语料库 
.. 语料库建设 
. 开源工具 
.. 主流NLP工具比较 
.. Python接口 
.. Java接口 
. 总结 
第章 词典分词 
. 什么是词 
.. 词的定义 
.. 词的性质--齐夫定律 
. 词典 
.. HanLP词典 
.. 词典的加载 
. 切分算法 
.. 完全切分 
.. 正向最长匹配 
.. 逆向最长匹配 
.. 双向最长匹配 
.. 速度评测 
. 字典树 
.. 什么是字典树 
.. 字典树的节点实现 
.. 字典树的增删改查实现 
.. 首字散列其余二分的字典树 
.. 前缀树的妙用 
. 双数组字典树 
.. 双数组的定义 
.. 状态转移 
.. 查询 
.. 构造* 
.. 全切分与最长匹配 
. AC自动机 
.. 从字典树到AC自动机 
.. goto表 
.. output表 
.. fail表 
.. 实现 
. 基于双数组字典树的AC自动机 
.. 原理 
.. 实现 
. HanLP的词典分词实现 
.. DoubleArrayTrieSegment 
.. AhoCorasickDoubleArrayTrie-Segment 
. 准确率评测 
.. 准确率 
.. 混淆矩阵与TP/FN/FP/TN 
.. 精确率 
.. 召回率 
.. F值 
.. 中文分词中的P、R、F计算 
.. 实现 
.. 第二届国际中文分词评测 
.. OOVRecallRate与IVRecallRate 
. 字典树的其他应用 
.. 停用词过滤 
.. 简繁转换 
.. 拼音转换 
. 总结 
第章 二元语法与中文分词 
. 语言模型 
.. 什么是语言模型 
.. 马尔可夫链与二元语法 
.. n元语法 
.. 数据稀疏与平滑策略 
. 中文分词语料库 
.. 年《人民日报》语料库PKU 
.. 微软亚洲研究院语料库MSR 
.. 繁体中文分词语料库 
.. 语料库统计 
. 训练 
.. 加载语料库 
.. 统计一元语法 
.. 统计二元语法 
. 预测 
.. 加载模型 
.. 构建词网 
.. 节点间的距离计算 
.. 词图上的维特比算法 
.. 与用户词典的集成 
. 评测 
.. 标准化评测 
.. 误差分析 
.. 调整模型 
. 日语分词 
.. 日语分词语料 
.. 训练日语分词器 
. 总结 
第章 隐马尔可夫模型与序列标注 
. 序列标注问题 
.. 序列标注与中文分词 
.. 序列标注与词性标注 
.. 序列标注与命名实体识别 
. 隐马尔可夫模型 
.. 从马尔可夫假设到隐马尔可夫模型 
.. 初始状态概率向量 
.. 状态转移概率矩阵 
.. 发射概率矩阵 
.. 隐马尔可夫模型的三个基本用法 
. 隐马尔可夫模型的样本生成 
.. 案例--医疗诊断 
.. 样本生成算法 
. 隐马尔可夫模型的训练 
.. 转移概率矩阵的估计 
.. 初始状态概率向量的估计 
.. 发射概率矩阵的估计 
.. 验证样本生成与模型训练 
. 隐马尔可夫模型的预测 
.. 概率计算的前向算法 
.. 搜索状态序列的维特比算法 
. 隐马尔可夫模型应用于中文分词 
.. 标注集 
.. 字符映射 
.. 语料转换 
.. 训练 
.. 预测 
.. 评测 
.. 误差分析 
. 二阶隐马尔可夫模型* 
.. 二阶转移概率张量的估计 
.. 二阶隐马尔可夫模型中的维特比算法 
.. 二阶隐马尔可夫模型应用于中文分词 
. 总结 
第章 感知机分类与序列标注 
. 分类问题 
.. 定义 
.. 应用 
. 线性分类模型与感知机算法 
.. 特征向量与样本空间 
.. 决策边界与分离超平面 
.. 感知机算法 
.. 损失函数与随机梯度下降* 
.. 投票感知机和平均感知机 
. 基于感知机的人名性别分类 
.. 人名性别语料库 
.. 特征提取 
.. 训练 
.. 预测 
.. 评测 
.. 模型调优 
. 结构化预测问题 
.. 定义 
.. 结构化预测与学习的流程 
. 线性模型的结构化感知机算法 
.. 结构化感知机算法 
.. 结构化感知机与序列标注 
.. 结构化感知机的维特比解码算法 
. 基于结构化感知机的中文分词 
.. 特征提取 
.. 多线程训练 
.. 特征裁剪与模型压缩* 
.. 创建感知机分词器 
.. 准确率与性能 
.. 模型调整与在线学习* 
.. 中文分词特征工程* 
. 总结 
第章 条件随机场与序列标注 
. 机器学习的模型谱系 
.. 生成式模型与判别式模型 
.. 有向与无向概率图模型 
. 条件随机场 
.. 线性链条件随机场 
.. 条件随机场的训练* 
.. 对比结构化感知机 
. 条件随机场工具包 
.. CRF++的安装 
.. CRF++语料格式 
.. CRF++特征模板 
.. CRF++命令行训练 
.. CRF++模型格式* 
.. CRF++命令行预测 
.. CRF++代码分析* 
. HanLP中的CRF++API 
.. 训练分词器 
.. 标准化评测 
. 总结 
第章 词性标注 
. 词性标注概述 
.. 什么是词性 
.. 词性的用处 
.. 词性标注 
.. 词性标注模型 
. 词性标注语料库与标注集 
.. 《人民日报》语料库与PKU标注集 
.. 国家语委语料库与标注集 
.. 《诛仙》语料库与CTB标注集 
. 序列标注模型应用于词性标注 
.. 基于隐马尔可夫模型的词性标注 
.. 基于感知机的词性标注 
.. 基于条件随机场的词性标注 
.. 词性标注评测 
. 自定义词性 
.. 朴素实现 
.. 标注语料 
. 总结 
第章 命名实体识别 
. 概述 
. 基于规则的命名实体识别 
. 命名实体识别语料库 
. 基于层叠隐马尔可夫模型的角色标注框架 
. 基于序列标注的命名实体识别 
. 自定义领域命名实体识别 
. 总结 
第章 信息抽取 
. 新词提取 
. 关键词提取 
. 短语提取 
. 关键句提取 
. 总结 
第章 文本聚类 
. 概述 
. 文档的特征提取 
. k均值算法 
. 重复二分聚类算法 
. 标准化评测 
. 总结 
第章 文本分类 
. 文本分类的概念 
. 文本分类语料库 
. 文本分类的特征提取 
. 朴素贝叶斯分类器 
. 支持向量机分类器 
. 标准化评测 
. 情感分析 
. 总结 
第章 依存句法分析 
. 短语结构树 
.. 宾州树库和中文树库 
. 依存句法树 
. 依存句法分析 
. 基于转移的依存句法分析 
. 依存句法分析API 
. 案例：基于依存句法树的意见抽取 
. 总结 
第章 深度学习与自然语言处理 
. 传统方法的局限 
. 深度学习与优势 
. wordvec 
. 基于神经网络的高性能依存句法分析器 
. 自然语言处理进阶 
自然语言处理学习资料推荐 
・ ・ ・ ・ ・ ・ (收起)扉页
版权声明
内容提要
译者简介
译者序
序
前言
致谢
关于本书
关于作者
关于封面插画
资源与支持
目录
第一部分 处理文本的机器
第章 NLP概述
. 自然语言与编程语言
. 神奇的魔法
.. 会交谈的机器
.. NLP中的数学
. 实际应用
. 计算机“眼”中的语言
.. 锁的语言（正则表达式）
.. 正则表达式
.. 一个简单的聊天机器人
.. 另一种方法
. 超空间简述
. 词序和语法
. 聊天机器人的自然语言流水线
. 深度处理
. 自然语言智商
. 小结
第章 构建自己的词汇表――分词
. 挑战（词干还原预览）
. 利用分词器构建词汇表
.. 点积
.. 度量词袋之间的重合度
.. 标点符号的处理
.. 将词汇表扩展到 n-gram
.. 词汇表归一化
. 情感
.. VADER：一个基于规则的情感分析器
.. 朴素贝叶斯
. 小结
第章 词中的数学
. 词袋
. 向量化
向量空间
. 齐普夫定律
. 主题建模
.. 回到齐普夫定律
.. 相关度排序
.. 工具
.. 其他工具
.. Okapi BM
.. 未来展望
. 小结
第章 词频背后的语义
. 从词频到主题得分
.. TF-IDF向量及词形归并
.. 主题向量
.. 思想实验
.. 一个主题评分算法
.. 一个 LDA分类器
. 潜在语义分析
思想实验的实际实现
. 奇异值分解
.. 左奇异向量 U
.. 奇异值向量 S
.. 右奇异向量 V
.. SVD矩阵的方向
.. 主题约简
. 主成分分析
.. 三维向量上的 PCA
.. 回归 NLP
.. 基于 PCA的短消息语义分析
.. 基于截断的 SVD的短消息语义分析
.. 基于 LSA的垃圾短消息分类的效果
. 潜在狄利克雷分布（LDiA）
.. LDiA思想
.. 基于 LDiA主题模型的短消息语义分析
.. LDiA+LDA=垃圾消息过滤器
.. 更公平的对比： 个 LDiA主题
. 距离和相似度
. 反馈及改进
线性判别分析
. 主题向量的威力
.. 语义搜索
.. 改进
. 小结
第二部分 深度学习（神经网络）
第章 神经网络初步（感知机与反向传播）
. 神经网络的组成
. 小结
第章 词向量推理（Wordvec）
. 语义查询与类比
类比问题
. 词向量
.. 面向向量的推理
.. 如何计算 Wordvec 表示
.. 如何使用 gensim.wordvec 模块
.. 生成定制化词向量表示
.. Wordvec 和 GloVe
.. fastText
.. Wordvec 和 LSA
.. 词关系可视化
.. 非自然词
.. 利用 Docvec 计算文档相似度
. 小结
第章 卷积神经网络（CNN）
. 语义理解
. 工具包
. 卷积神经网络
.. 构建块
.. 步长
.. 卷积核的组成
.. 填充
.. 学习
. 狭窄的窗口
.. Keras 实现：准备数据
.. 卷积神经网络架构
.. 池化
.. dropout
.. 输出层
.. 开始学习（训练）
.. 在流水线中使用模型
.. 前景展望
. 小结
第章 循环神经网络（RNN）
. 循环网络的记忆功能
. 整合各个部分
. 自我学习
. 超参数
. 预测
.. 有状态性
.. 双向 RNN
.. 编码向量
. 小结
第章 改进记忆力：长短期记忆网络（LSTM）
. 长短期记忆（LSTM）
.. 随时间反向传播
.. 模型的使用
.. 脏数据
.. “未知”词条的处理
.. 字符级建模
.. 生成聊天文字
.. 进一步生成文本
.. 文本生成的问题：内容不受控
.. 其他记忆机制
.. 更深的网络
. 小结
第章 序列到序列建模和注意力机制
. 编码-解码架构
.. 解码思想
.. 似曾相识？
.. 序列到序列对话
.. 回顾 LSTM
. 组装一个序列到序列的流水线
.. 为序列到序列训练准备数据集
.. Keras 中的序列到序列模型
.. 序列编码器
.. 思想解码器
.. 组装一个序列到序列网络
. 训练序列到序列网络
生成输出序列
. 使用序列到序列网络构建一个聊天机器人
.. 为训练准备语料库
.. 建立字符字典
.. 生成独热编码训练集
.. 训练序列到序列聊天机器人
.. 组装序列生成模型
.. 预测输出序列
.. 生成回复
.. 与聊天机器人交谈
. 增强
.. 使用装桶法降低训练复杂度
.. 注意力机制
. 实际应用
. 小结
第三部分 进入现实世界（现实中的 NLP 挑战）
第章 信息提取（命名实体识别与问答系统）
. 命名实体与关系
.. 知识库
.. 信息提取
. 正则模式
.. 正则表达式
.. 把信息提取当作机器学习里的特征提取任务
. 值得提取的信息
.. 提取 GPS位置
.. 提取日期
. 提取人物关系（事物关系）
.. 词性标注
.. 实体名称标准化
.. 实体关系标准化和提取
.. 单词模式
.. 文本分割
.. 为什么 split('.!?')函数不管用
.. 使用正则表达式进行断句
. 现实世界的信息提取
. 小结
第章 开始聊天（对话引擎）
. 语言技能
.. 现代方法
.. 混合方法
. 模式匹配方法
.. 基于 AIML 的模式匹配聊天机器人
.. 模式匹配的网络视图
. 知识方法
. 检索（搜索）方法
.. 上下文挑战
.. 基于示例检索的聊天机器人
.. 基于搜索的聊天机器人
. 生成式方法
.. 聊聊 NLPIA
.. 每种方法的利弊
. 四轮驱动
Will的成功
. 设计过程
. 技巧
.. 用带有可预测答案的问题提问
.. 要有趣
.. 当其他所有方法都失败时，搜索
.. 变得受欢迎
.. 成为连接器
.. 变得有情感
. 现实世界
. 小结
第章 可扩展性（优化、并行化和批处理）
. 太多（数据）未必是好事
. 优化NLP算法
.. 索引
.. 高级索引
.. 基于 Annoy 的高级索引
.. 究竟为什么要使用近似索引
.. 索引变通方法：离散化
. 常数级内存算法
.. gensim
.. 图计算
. 并行化NLP计算
.. 在 GPU上训练 NLP模型
.. 租与买
.. GPU租赁选择
.. 张量处理单元 TPU
. 减少模型训练期间的内存占用
. 使用TensorBoard 了解模型
如何可视化词嵌入
. 小结
附录A 本书配套的NLP工具
附录B 有趣的Python和正则表达式
附录C 向量和矩阵（线性代数基础）
附录D 机器学习常见工具与技术
附录E 设置亚马逊云服务（ AWS）上的GPU
附录F 局部敏感哈希
资源
词汇表
・ ・ ・ ・ ・ ・ (收起)第章导论
.语音与语言处理中的知识
.歧义
.模型和算法
.语言、思维和理解
.学科现状与近期发展
.语音和语言处理简史
..基础研究：世纪年代和世纪年代
..两个阵营：年至年
..四个范型：年至年
..经验主义和有限状态模型的复苏：年至年
..不同领域的合流：年至年
..机器学习的兴起：年至年
..关于多重发现
..心理学的简要注记
.小结
.文献和历史说明
第一部分词汇的计算机处理
第章正则表达式与自动机
.正则表达式
..基本正则表达式模式
..析取、组合与优先关系
..一个简单的例子
..一个比较复杂的例子
..高级算符
..正则表达式中的替换、存储器与ELIZA
.有限状态自动机
..用FSA来识别羊的语言
..形式语言
..其他例子
..非确定FSA
..使用NFSA接收符号串
..识别就是搜索
..确定自动机与非确定自动机的关系
.正则语言与FSA
.小结
.文献和历史说明
第章词与转录机
.英语形态学概观
..屈折形态学
..派生形态学
..附着
..非毗连形态学
..一致关系
.有限状态形态剖析
.有限状态词表的建造
.有限状态转录机
..定序转录机和确定性
.用于形态剖析的FST
.转录机和正词法规则
.把FST词表与规则相结合
.与词表无关的FST：Porter词干处理器
.单词和句子的词例还原
..中文的自动切词
.拼写错误的检查与更正
.最小编辑距离
.人是怎样进行形态处理的
.小结
.文献和历史说明
第章N元语法
.语料库中单词数目的计算
.简单的（非平滑的）N元语法
.训练集和测试集
..N元语法及其对训练语料库的敏感性
..未知词：开放词汇与封闭词汇
.N元语法的评测：困惑度
.平滑
..Laplace平滑
..GoodTuring打折法
..GoodTuring估计的一些高级专题
.插值法
.回退法
..高级专题：计算Katz回退的α和P*
.实际问题：工具包和数据格式
.语言模型建模中的高级专题
..高级的平滑方法：KneserNey平滑法
..基于类别的N元语法
..语言模型的自适应和网络（Web）应用
..长距离信息的使用：简要的综述
.信息论背景
..用于比较模型的交叉熵
.高级问题：英语的熵和熵率均衡性
.小结
.文献和历史说明
第章词类标注
.（大多数）英语词的分类
.英语的标记集
.词类标注
.基于规则的词类标注
.基于隐马尔可夫模型的词类标注
..计算最可能的标记序列：一个实例
..隐马尔可夫标注算法的形式化
..使用Viterbi算法来进行HMM标注
..把HMM扩充到三元语法
.基于转换的标注
..怎样应用TBL规则
..怎样学习TBL规则
.评测和错误分析
..错误分析
.词类标注中的高级专题
..实际问题：标记的不确定性与词例还原
..未知词
..其他语言中的词类标注
..标注算法的结合
.高级专题：拼写中的噪声信道模型
..上下文错拼更正
.小结
.文献和历史说明
第章隐马尔可夫模型与最大熵模型
.马尔可夫链
.隐马尔可夫模型
.似然度的计算：向前算法
.解码：Viterbi算法
.HMM的训练：向前向后算法
.最大熵模型：背景
..线性回归
..逻辑回归
..逻辑回归：分类
..高级专题：逻辑回归的训练
.最大熵模型
..为什么称为最大熵
.最大熵马尔可夫模型
..MEMM的解码和训练
.小结
.文献和历史说明
第二部分语音的计算机处理
第章语音学
.言语语音与语音标音法
.发音语音学
..发音器官
..辅音：发音部位
..辅音：发音方法
..元音
..音节
.音位范畴与发音变异
..语音特征
..语音变异的预测
..影响语音变异的因素
.声学语音学和信号
..波
..语音的声波
..频率与振幅：音高和响度
..从波形来解释音子
..声谱和频域
..声源滤波器模型
.语音资源
.高级问题：发音音系学与姿态音系学
.小结
.文献和历史说明
第章语音合成
.文本归一化
..句子的词例还原
..非标准词
..同形异义词的排歧
.语音分析
..查词典
..名称
..字位―音位转换
.韵律分析
..韵律的结构
..韵律的突显度
..音调
..更精巧的模型：ToBI
..从韵律标记计算音延
..从韵律标记计算F
..文本分析的最后结果：内部表示
.双音子波形合成
..建立双音子数据库的步骤
..双音子毗连和用于韵律的TD―PSOLA
.单元选择（波形）合成
.评测
.文献和历史说明
第章语音自动识别
.语音识别的总体结构
.隐马尔可夫模型应用于语音识别
.特征抽取：MFCC矢量
..预加重
..加窗
..离散傅里叶变换
..Mel滤波器组和对数
..倒谱：逆向傅里叶变换
..Delta特征与能量
..总结：MFCC
.声学似然度的计算
..矢量量化
..高斯概率密度函数
..概率、对数概率和距离函数
.词典和语言模型
.搜索与解码
.嵌入式训练
.评测：词错误率
.小结
.文献和历史说明
第章语音识别：高级专题
.多遍解码：N最佳表和格
.A*解码算法（“栈”解码算法）
.依赖于上下文的声学模型：三音子
.分辨训练
..最大互信息估计
..基于后验分类器的声学模型
.语音变异的建模
..环境语音变异和噪声
..说话人变异和说话人适应
..发音建模：由于语类的差别而产生的变异
.元数据：边界、标点符号和不流利现象
.人的语音识别
.小结
.文献和历史说明
第章计算音系学
.有限状态音系学
.高级有限状态音系学
..元音和谐
..模板式形态学
.计算优选理论
..优选理论中的有限状态转录机模型
..优选理论的随机模型
.音节切分
.音位规则和形态规则的机器学习
..音位规则的机器学习
..形态规则的机器学习
..优选理论中的机器学习
.小结
.文献和历史说明
第三部分句法的计算机处理
第章英语的形式语法
.组成性
.上下文无关语法
..上下文无关语法的形式定义
.英语的一些语法规则
..句子一级的结构
..子句与句子
..名词短语
..一致关系
..动词短语和次范畴化
..助动词
..并列关系
.树库
..树库的例子：宾州树库课题
..作为语法的树库
..树库搜索
..中心词与中心词的发现
.语法等价与范式
.有限状态语法和上下文无关语法
.依存语法
..依存和中心词之间的关系
..范畴语法
.口语的句法
..不流畅现象与口语修正
..口语树库
.语法和人的语言处理
.小结
.文献和历史说明
第章句法剖析
.剖析就是搜索
..自顶向下剖析
..自底向上剖析
..自顶向下剖析与自底向上剖析比较
.歧义
.面对歧义的搜索
.动态规划剖析方法
..CKY剖析
..Earley算法
..线图剖析
.局部剖析
..基于规则的有限状态组块分析
..基于机器学习的组块分析方法
..组块分析系统的评测
.小结
.文献和历史说明
第章统计剖析
.概率上下文无关语法
..PCFG用于排歧
..PCFG用于语言建模
.PCFG的概率CKY剖析
.PCFG规则概率的学习途径
.PCFG的问题
..独立性假设忽略了规则之间的结构依存关系
..缺乏对词汇依存关系的敏感性
.使用分离非终极符号的办法来改进PCFG
.概率词汇化的CFG
..Collins剖析器
..高级问题：Collins剖析器更多的细节
.剖析器的评测
.高级问题：分辨再排序
.高级问题：基于剖析器的语言模型
.人的剖析
.小结
.文献和历史说明
第章特征与合一
.特征结构
.特征结构的合一
.语法中的特征结构
..一致关系
..中心语特征
..次范畴化
..长距离依存关系
.合一的实现
..合一的数据结构
..合一算法
.带有合一约束的剖析
..把合一结合到Earley剖析器中
..基于合一的剖析
.类型与继承
..高级问题：类型的扩充
..合一的其他扩充
.小结
.文献和历史说明
第章语言和复杂性
.Chomsky层级
.怎么判断一种语言不是正则的
..抽吸引理
..证明各种自然语言不是正则语言
.自然语言是上下文无关的吗
.计算复杂性和人的语言处理
.小结
.文献和历史说明
第四部分语义和语用的计算机处理
第章意义的表示
.意义表示的计算要求
..可验证性
..无歧义性
..规范形式
..推理与变量
..表达能力
.模型论语义学
.一阶逻辑
..一阶逻辑基础
..变量和量词
..λ表示法
..一阶逻辑的语义
..推理
.事件与状态的表示
..时间表示
..体
.描述逻辑
.意义的具体化与情境表示方法
.小结
.文献和历史说明
第章计算语义学
.句法驱动的语义分析
.句法规则的语义扩充
.量词辖域歧义及非确定性
..存储与检索方法
..基于约束的方法
.基于合一的语义分析方法
.语义与Earley分析器的集成
.成语和组成性
.小结
.文献和历史说明
第章词汇语义学
.词义
.含义间的关系
..同义关系和反义关系
..上下位关系
..语义场
.WordNet：词汇关系信息库
.事件参与者
..题旨角色
..因素交替（DiathesisAlternations）
..题旨角色的问题
..命题库
..FrameNet
..选择限制
.基元分解
.高级问题：隐喻
.小结
.文献和历史说明
第章计算词汇语义学
.词义排歧：综述
.有监督词义排歧
..监督学习的特征抽取
..朴素贝叶斯分类器和决策表分类器
.WSD评价方法、基准线和上限
.WSD：字典方法和同义词库方法
..Lesk算法
..选择限制和选择优先度
.最低限度的监督WSD：自举法
.词语相似度：语义字典方法
.词语相似度：分布方法
..定义词语的共现向量
..度量与上下文的联系
..定义两个向量之间的相似度
..评价分布式词语相似度
.下位关系和其他词语关系
.语义角色标注
.高级主题：无监督语义排歧
.小结
.文献和历史说明
第章计算话语学
.话语分割
..无监督话语分割
..有监督话语分割
..话语分割的评价
.文本连贯性
..修辞结构理论
..自动连贯指派
.指代消解
.指代现象
..指示语的五种类型
..信息状态
.代词指代消解所使用的特征
..用来过滤潜在指代对象的特征
..代词解释中的优先关系
.指代消解的三种算法
..代词指代基准系统：Hobbs算法
..指代消解的中心算法
..代词指代消解的对数线性模型
..代词指代消解的特征
.共指消解
.共指消解的评价
.高级问题：基于推理的连贯判定
.所指的心理语言学研究
.小结
.文献和历史说明
第五部分应用
第章信息抽取
.命名实体识别
..命名实体识别中的歧义
..基于序列标注的命名实体识别
..命名实体识别的评价
..实用NER架构
.关系识别和分类
..用于关系分析的有监督学习方法
..用于关系分析的弱监督学习方法
..关系分析系统的评价
.时间和事件处理
..时间表达式的识别
..时间的归一化
..事件检测和分析
..TimeBank
.模板填充
..模板填充的统计方法
..有限状态机模板填充系统
.高级话题：生物医学信息的抽取
..生物学命名实体识别
..基因归一化
..生物学角色和关系
.小结
.文献和历史说明
第章问答和摘要
.信息检索
..向量空间模型
..词语权重计算
..词语选择和建立
..信息检索系统的评测
..同形关系、多义关系和同义关系
..改进用户查询的方法
.事实性问答
..问题处理
..段落检索
..答案处理
..事实性答案的评价
.摘要
.单文档摘要
..无监督的内容选择
..基于修辞分析的无监督摘要
..有监督的内容选择
..句子简化
.多文档摘要
..多文档摘要的内容选择
..多文档摘要的信息排序
.主题摘要和问答
.摘要的评价
.小结
.文献和历史说明
第章对话与会话智能代理
.人类会话的属性
..话轮和话轮转换
..语言作为行动：言语行为
..语言作为共同行动：对话的共同基础
..会话结构
..会话隐含
.基本的对话系统
..ASR组件
..NLU组件
..生成和TTS组件
..对话管理器
..错误处理：确认和拒绝
.VoiceXML
.对话系统的设计和评价
..设计对话系统
..评价对话系统
.信息状态和对话行为
..使用对话行为
..解释对话行为
..检测纠正行为
..生成对话行为：确认和拒绝
.马尔可夫决策过程架构
.高级问题：基于规划的对话行为
..规划推理解释和生成
..对话的意图结构
.小结
.文献和历史说明
第章机器翻译
.为什么机器翻译如此困难
..类型学
..其他的结构差异
..词汇的差异
.经典的机器翻译方法与Vauquois三角形
..直接翻译
..转换方法
..传统机器翻译系统中的直接和转换相融合的方法
..中间语言的思想：使用意义
.统计机器翻译
.P（F|E）：基于短语的翻译模型
.翻译中的对齐
..IBM模型
..HMM对齐
.对齐模型的训练
..训练对齐模型的EM算法
.用于基于短语机器翻译的对称对齐
.基于短语统计机器翻译的解码
.机器翻译评价
..使用人工评价者
..自动评价：BLEU
.高级问题：机器翻译的句法模型
.高级问题：IBM模型和繁衍度
..模型的训练
.高级问题：机器翻译的对数线性模型
.小结
.文献和历史说明
参考文献
・ ・ ・ ・ ・ ・ (收起)Preface
.Language Processing and Python
. Computing with Language： Texts and Words
. A Closer Look at Python： Texts as Lists of Words
. Computing with Language： Simple Statistics
. Back to Python： Making Decisions and Taking Control
. Automatic Natural Language Understanding
. Summary
. Further Reading
. Exercises
.Accessing Text Corpora and Lexical Resources
. Accessing Text Corpora
. Conditional Frequency Distributions
. More Python： Reusing Code
. Lexical Resources
. WordNet
. Summary
. Further Reading
. Exercises
.Processing Raw Text
. Accessing Text from the Web and from Disk
. Strings： Text Processing at the Lowest Level
. Text Processing with Unicode
. Regular Expressions for Detecting Word Patterns
. Useful Applications of Regular Expressions
. Normalizing Text
. Regular Expressions for Tokenizing Text
. Segmentation
. Formatting： From Lists to Strings
. Summary
. Further Reading
. Exercises
.Writing Structured Programs
. Back to the Basics
. Sequences
. Questions of Style
. Functions： The Foundation of Structured Programming
. Doing More with Functions
. Program Development
. Algorithm Design
. A Sample of Python Libraries
. Summary
. Further Reading
. Exercises
.Categorizing andTagging Words
. Using a Tagger
. Tagged Corpora
. Mapping Words to Properties Using Python Dictionaries
. Automatic Tagging
. N-Gram Tagging
. Transformation-Based Tagging
. How to Determine the Category of a Word
. Summary
. Further Reading
. Exercises
.Learning to Classify Text
. Supervised Classification
. Further Examples of Supervised Classification
. Evaluation
. Decision Trees
. Naive Bayes Classifiers
. Maximum Entropy Classifiers
. Modeling Linguistic Patterns
. Summary
. Further Reading
. Exercises
.Extracting Information from Text
. Information Extraction
. Chunking
. Developing and Evaluating Chunkers
. Recursion in Linguistic Structure
. Named Entity Recognition
. Relation Extraction
. Summary
. Further Reading
. Exercises
.Analyzing Sentence Structure
. Some Grammatical Dilemmas
. Whats the Use of Syntax?
. Context-Free Grammar
. Parsing with Context-Free Grammar
. Dependencies and Dependency Grammar
. Grammar Development
. Summary
. Further Reading
. Exercises
.Building Feature-Based Grammars
. Grammatical Features
. Processing Feature Structures
. Extending a Feature-Based Grammar
. Summary
. Further Reading
. Exercises
.Analyzing the Meaning of Sentences
. Natural Language Understanding
. Propositional Logic
. First-Order Logic
. The Semantics of English Sentences
. Discourse Semantics
. Summary
. Further Reading
. Exercises
.Managing Linguistic Data
. Corpus Structure： A Case Study
. The Life Cycle of a Corpus
. Acquiring Data
. Working with XML
. Working with Toolbox Data
. Describing Language Resources Using OLAC Metadata
. Summary
. Further Reading
. Exercises
Afterword： The Language Challenge
Bibliography
NLTK Index
General Index
・ ・ ・ ・ ・ ・ (收起)《python自然语言处理》
第章 语言处理与python 
. 语言计算：文本和词汇 
. 近观python：将文本当做词链表 
. 计算语言：简单的统计 
. 回到python:决策与控制 
. 自动理解自然语言 
. 小结 
. 深入阅读 
. 练习 
第章 获得文本语料和词汇资源 
. 获取文本语料库 
. 条件频率分布 
. 更多关于python：代码重用 
. 词典资源 
. wordnet 
. 小结 
. 深入阅读 
. 练习 
第章 处理原始文本 
. 从网络和硬盘访问文本 
. 字符串：最底层的文本处理 
. 使用unicode进行文字处理 
. 使用正则表达式检测词组搭配 
. 正则表达式的有益应用 
. 规范化文本 
. 用正则表达式为文本分词 
. 分割 
. 格式化：从链表到字符串 
. 小结 
. 深入阅读 
. 练习 
第章 编写结构化程序 
. 回到基础 
. 序列 
. 风格的问题 
. 函数：结构化编程的基础 
. 更多关于函数 
. 程序开发 
. 算法设计 
. python库的样例 
. 小结 
. 深入阅读 
. 练习 
第章 分类和标注词汇 
. 使用词性标注器 
. 标注语料库 
. 使用python字典映射词及其属性 
. 自动标注 
. n-gram标注 
. 基于转换的标注 
. 如何确定一个词的分类 
. 小结 
. 深入阅读 
. 练习 
第章 学习分类文本 
. 监督式分类 
. 监督式分类的举例 
. 评估 
. 决策树 
. 朴素贝叶斯分类器 
. 最大熵分类器 
. 为语言模式建模 
. 小结 
. 深入阅读 
. 练习 
第章 从文本提取信息 
. 信息提取 
. 分块 
. 开发和评估分块器 
. 语言结构中的递归 
. 命名实体识别 
. 关系抽取 
. 小结 
. 深入阅读 
. 练习 
第章 分析句子结构 
. 一些语法困境 
. 文法的用途 
. 上下文无关文法 
. 上下文无关文法分析 
. 依存关系和依存文法 
. 文法开发 
. 小结 
. 深入阅读 
. 练习 
第章 建立基于特征的文法 
. 文法特征 
. 处理特征结构 
. 扩展基于特征的文法 
. 小结 
. 深入阅读 
. 练习 
第章 分析语句的含义 
. 自然语言理解 
. 命题逻辑 
. 一阶逻辑 
. 英语语句的语义 
. 段落语义层 
. 小结 
. 深入阅读 
. 练习 
第章 语言数据管理 
. 语料库结构：案例研究 
. 语料库生命周期 
. 数据采集 
. 使用xml 
. 使用toolbox数据 
. 使用olac元数据描述语言资源 
. 小结 
. 深入阅读 
. 练习 
后记 
参考文献 
・ ・ ・ ・ ・ ・ (收起)译者序
推荐序
作者介绍
关于审校人员
前言
第章 引言 
. 自然语言处理 
. 基础应用 
. 高级应用 
. NLP和Python相结合的优势 
. nltk环境搭建 
. 读者提示 
. 总结 
第章 实践理解语料库和数据集 
. 语料库 
. 语料库的作用 
. 语料分析 
. 数据属性的类型 
.. 分类或定性数据属性 
.. 数值或定量数据属性 
. 不同文件格式的语料 
. 免费语料库资源 
. 为NLP应用准备数据集 
.. 挑选数据 
.. 预处理数据集 
. 网页爬取 
. 总结 
第章 理解句子的结构 
. 理解NLP的组成 
.. 自然语言理解 
.. 自然语言生成 
.. NLU和NLG的区别 
.. NLP的分支 
. 上下文无关文法 
. 形态分析 
.. 形态学 
.. 词素 
.. 词干 
.. 形态分析 
.. 词 
.. 词素的分类 
.. 词干和词根的区别 
. 词法分析 
.. 词条 
.. 词性标注 
.. 导出词条的过程 
.. 词干提取和词形还原的区别 
.. 应用 
. 句法分析 
. 语义分析 
.. 语义分析概念 
.. 词级别的语义 
.. 上下位关系和多义词 
.. 语义分析的应用 
. 消歧 
.. 词法歧义 
.. 句法歧义 
.. 语义歧义 
.. 语用歧义 
. 篇章整合 
. 语用分析 
. 总结 
第章 预处理 
. 处理原始语料库文本 
.. 获取原始文本 
.. 小写化转换 
.. 分句 
.. 原始文本词干提取 
.. 原始文本词形还原 
.. 停用词去除 
. 处理原始语料库句子 
.. 词条化 
.. 单词词形还原 
. 基础预处理 
. 实践和个性化预处理 
.. 由你自己决定 
.. 预处理流程 
.. 预处理的类型 
.. 理解预处理的案例 
. 总结 
第章 特征工程和NLP算法 
. 理解特征工程 
.. 特征工程的定义 
.. 特征工程的目的 
.. 一些挑战 
. NLP中的基础特征 
.. 句法分析和句法分析器 
.. 词性标注和词性标注器 
.. 命名实体识别 
.. n元语法 
.. 词袋 
.. 语义工具及资源 
. NLP中的基础统计特征 
.. 数学基础 
.. TF-IDF 
.. 向量化 
.. 规范化 
.. 概率模型 
.. 索引 
.. 排序 
. 特征工程的优点 
. 特征工程面临的挑战 
. 总结 
第章 高级特征工程和NLP算法 
. 词嵌入 
. wordvec基础 
.. 分布语义 
.. 定义wordvec 
.. 无监督分布语义模型中的必需品 
. wordvec模型从黑盒到白盒 
. 基于表示的分布相似度 
. wordvec模型的组成部分 
.. wordvec的输入 
.. wordvec的输出 
.. wordvec模型的构建模块 
. wordvec模型的逻辑 
.. 词汇表构建器 
.. 上下文环境构建器 
.. 两层的神经网络 
.. 算法的主要流程 
. wordvec模型背后的算法和数学理论 
.. wordvec算法中的基本数学理论 
.. 词汇表构建阶段用到的技术 
.. 上下文环境构建过程中使用的技术 
. 神经网络算法 
.. 基本神经元结构 
.. 训练一个简单的神经元 
.. 单个神经元的应用 
.. 多层神经网络 
.. 反向传播算法 
.. wordvec背后的数学理论 
. 生成最终词向量和概率预测结果的技术 
. wordvec相关的一些事情 
. wordvec的应用 
.. 实现一些简单例子 
.. wordvec的优势 
.. wordvec的挑战 
.. 在实际应用中使用wordvec 
.. 何时使用wordvec 
.. 开发一些有意思的东西 
.. 练习 
. wordvec概念的扩展 
.. paravec 
.. docvec 
.. docvec的应用 
.. GloVe 
.. 练习 
. 深度学习中向量化的重要性 
. 总结 
第章 规则式自然语言处理系统 
. 规则式系统 
. 规则式系统的目的 
.. 为何需要规则式系统 
.. 使用规则式系统的应用 
.. 练习 
.. 开发规则式系统需要的资源 
. 规则式系统的架构 
.. 从专家系统的角度来看规则式系统的通用架构 
.. NLP应用中的规则式系统的实用架构 
.. NLP应用中的规则式系统的定制架构 
.. 练习 
.. Apache UIMA架构 
. 规则式系统的开发周期 
. 规则式系统的应用 
.. 使用规则式系统的NLP应用 
.. 使用规则式系统的通用AI应用 
. 使用规则式系统来开发NLP应用 
.. 编写规则的思维过程 
.. 基于模板的聊天机器人应用 
. 规则式系统与其他方法的对比 
. 规则式系统的优点 
. 规则式系统的缺点 
. 规则式系统面临的挑战 
. 词义消歧的基础 
. 规则式系统近期发展的趋势 
. 总结 
第章 自然语言处理中的机器学习方法 
. 机器学习的基本概念 
. 自然语言处理应用的开发步骤 
.. 第一次迭代时的开发步骤 
.. 从第二次到第N次迭代的开发步骤 
. 机器学习算法和其他概念 
.. 有监督机器学习方法 
.. 无监督机器学习方法 
.. 半监督机器学习算法 
.. 一些重要概念 
.. 特征选择 
.. 维度约减 
. 自然语言处理中的混合方法 
. 总结 
第章 NLU和NLG问题中的深度学习 
. 人工智能概览 
.. 人工智能的基础 
.. 人工智能的阶段 
.. 人工智能的种类 
.. 人工智能的目标和应用 
. NLU和NLG之间的区别 
.. 自然语言理解 
.. 自然语言生成 
. 深度学习概览 
. 神经网络基础 
.. 神经元的第一个计算模型 
.. 感知机 
.. 理解人工神经网络中的数学概念 
. 实现神经网络 
.. 单层反向传播神经网络 
.. 练习 
. 深度学习和深度神经网络 
.. 回顾深度学习 
.. 深度神经网络的基本架构 
.. NLP中的深度学习 
.. 传统NLP和深度学习NLP技术的区别 
. 深度学习技术和NLU 
. 深度学习技术和NLG 
.. 练习 
.. 菜谱摘要和标题生成 
. 基于梯度下降的优化 
. 人工智能与人类智能 
. 总结 
第章 高级工具 
. 使用Apache Hadoop作为存储框架 
. 使用Apache Spark作为数据处理框架 
. 使用Apache Flink作为数据实时处理框架 
. Python中的可视化类库 
. 总结 
第章 如何提高你的NLP技能 
. 开始新的NLP职业生涯 
. 备忘列表 
. 确定你的领域 
. 通过敏捷的工作来实现成功 
. NLP和数据科学方面一些有用的博客 
. 使用公开的数据集 
. 数据科学领域需要的数学知识 
. 总结 
第章 安装指导 
. 安装Python、pip和NLTK 
. 安装PyCharm开发环境 
. 安装依赖库 
. 框架安装指导 
. 解决你的疑问 
. 总结 
・ ・ ・ ・ ・ ・ (收起)译者序
作者简介
审校者简介
前言
第章 NLP简介 
. 什么是NLP 
. 为何使用NLP 
. NLP的难点 
. NLP工具汇总 
.. Apache OpenNLP 
.. Stanford NLP 
.. LingPipe 
.. GATE 
.. UIMA 
. 文本处理概览 
.. 文本分词 
.. 文本断句 
.. 人物识别 
.. 词性判断 
.. 文本分类 
.. 关系提取 
.. 方法组合 
. 理解NLP模型 
.. 明确目标 
.. 选择模型 
.. 构建、训练模型 
.. 验证模型 
.. 使用模型 
. 准备数据 
. 本章小结 
第章 文本分词 
. 理解文本分词 
. 什么是分词 
. 一些简单的Java分词器 
.. 使用Scanner类 
.. 使用split方法 
.. 使用BreakIterator类 
.. 使用StreamTokenizer类 
.. 使用StringTokenizer类 
.. 使用Java核心分词法的性能考虑 
. NLP分词器的API 
.. 使用OpenNLPTokenizer类分词器 
.. 使用Stanford分词器 
.. 训练分词器进行文本分词 
.. 分词器的比较 
. 理解标准化处理 
.. 转换为小写字母 
.. 去除停用词 
.. 词干化 
.. 词形还原 
.. 使用流水线进行标准化处理 
. 本章小结 
第章 文本断句 
. SBD方法 
. SBD难在何处 
. 理解LingPipe的HeuristicSen-tenceModel类的SBD规则 
. 简单的Java SBD 
.. 使用正则表达式 
.. 使用BreakIterator类 
. 使用NLP API 
.. 使用OpenNLP 
.. 使用Stanford API 
.. 使用LingPipe 
. 训练文本断句模型 
.. 使用训练好的模型 
.. 使用SentenceDetector-Evaluator类评估模型 
. 本章小结 
第章 人物识别 
. NER难在何处 
. NER的方法 
.. 列表和正则表达式 
.. 统计分类器 
. 使用正则表达式进行NER 
.. 使用Java的正则表达式来寻找实体 
.. 使用LingPipe的RegEx-Chunker类 
. 使用NLP API 
.. 使用OpenNLP进行NER 
.. 使用Stanford API进行NER 
.. 使用LingPipe进行NER 
. 训练模型 
. 本章小结 
第章 词性判断 
. 词性标注 
.. 词性标注器的重要性 
.. 词性标注难在何处 
. 使用NLP API 
.. 使用OpenNLP词性标注器 
.. 使用Stanford词性标注器 
.. 使用LingPipe词性标注器 
.. 训练OpenNLP词性标注模型 
. 本章小结 
第章 文本分类 
. 文本分类问题 
. 情感分析介绍 
. 文本分类技术 
. 使用API进行文本分类 
.. OpenNLP的使用 
.. Stanford API的使用 
.. 使用LingPipe进行文本分类 
. 本章小结 
第章 关系提取 
. 关系类型 
. 理解解析树 
. 关系提取的应用 
. 关系提取 
. 使用NLP API 
.. OpenNLP的使用 
.. 使用Stanford API 
.. 判断共指消解的实体 
. 问答系统的关系提取 
.. 判断单词依赖关系 
.. 判断问题类型 
.. 搜索答案 
. 本章小结 
第章 方法组合 
. 准备数据 
.. 使用Boilerpipe从HTML中提取文本 
.. 使用POI从Word文档中提取文本 
.. 使用PDFBox从PDF文档中提取文本 
. 流水线 
.. 使用Stanford流水线 
.. 在Standford流水线中使用多核处理器 
. 创建一个文本搜索的流水线 
. 本章小结 
・ ・ ・ ・ ・ ・ (收起)第 章基础入门 
. 什么是自然语言处理 
.. 自然语言处理概述 
.. 自然语言处理的发展历史 
.. 自然语言处理的工作原理 
.. 自然语言处理的应用前景 
. 开发工具与环境 
.. Sublime Text 和Anaconda 介绍 
.. 开发环境的安装与配置 
. 实战：第一个小程序的诞生 
.. 实例介绍 
.. 源码实现 
第 章快速上手Python 
. 初识Python 编程语言 
.. Python 概述 
.. Python 能做什么 
.. Python 的语法和特点 
. Python 进阶 
.. Hello World 
.. 语句和控制流 
.. 函数 
.. List 列表 
.. 元组 
.. set 集合 
.. 字典 
.. 面向对象编程：类 
.. 标准库 
. Python 深入――第三方库 
.. Web 框架 
.. 科学计算 
.. GUI 
.. 其他库 
第 章线性代数 
. 线性代数介绍 
. 向量 
.. 向量定义 
.. 向量表示 
.. 向量定理 
.. 向量运算 
. 矩阵 
.. 矩阵定义 
.. 矩阵表示 
.. 矩阵运算 
.. 线性方程组 
.. 行列式 
.. 特征值和特征向量 
. 距离计算 
.. 余弦距离 
.. 欧氏距离 
.. 曼哈顿距离 
.. 明可夫斯基距离 
.. 切比雪夫距离 
.. 杰卡德距离 
.. 汉明距离 
.. 标准化欧式距离 
.. 皮尔逊相关系数 
第 章概率论 
. 概率论介绍 
. 事件 
.. 随机试验 
.. 随机事件和样本空间 
.. 事件的计算 
. 概率 
. 概率公理 
. 条件概率和全概率 
.. 条件概率 
.. 全概率 
. 贝叶斯定理 
. 信息论 
.. 信息论的基本概念 
.. 信息度量 
第 章统计学 
. 图形可视化 
.. 饼图 
.. 条形图 
.. 热力图 
.. 折线图 
.. 箱线图 
.. 散点图 
.. 雷达图 
.. 仪表盘 
.. 可视化图表用法 
. 数据度量标准 
.. 平均值 
.. 中位数 
.. 众数 
.. 期望 
.. 方差 
.. 标准差 
.. 标准分 
. 概率分布 
.. 几何分布 
.. 二项分布 
.. 正态分布 
.. 泊松分布 
. 统计假设检验 
. 相关和回归 
.. 相关 
.. 回归 
.. 相关和回归的联系 
第 章语言学 
. 语音 
.. 什么是语音 
.. 语音的三大属性 
.. 语音单位 
.. 记音符号 
.. 共时语流音变 
. 词汇 
.. 什么是词汇 
.. 词汇单位 
.. 词的构造 
.. 词义及其分类 
.. 义项与义素 
.. 语义场 
.. 词汇的构成 
. 语法 
.. 什么是语法 
.. 词类 
.. 短语 
.. 单句 
.. 复句 
第 章自然语言处理 
. 自然语言处理的任务和限制 
. 自然语言处理的主要技术范畴 
.. 语音合成 
.. 语音识别 
.. 中文自动分词 
.. 词性标注 
.. 句法分析 
.. 文本分类 
.. 文本挖掘 
.. 信息抽取 
.. 问答系统 
.. 机器翻译 
.. 文本情感分析 
.. 自动摘要 
.. 文字蕴涵 
. 自然语言处理的难点 
.. 语言环境复杂 
.. 文本结构形式多样 
.. 边界识别限制 
.. 词义消歧 
.. 指代消解 
. 自然语言处理展望 
第 章语料库 
. 语料库浅谈 
. 语料库深入 
. 自然语言处理工具包：NLTK 
.. NLTK 简介 
.. 安装NLTK 
.. 使用NLTK 
.. 在Python NLTK 下使用Stanford NLP 
. 获取语料库 
.. 国内外著名语料库 
.. 网络数据获取 
.. NLTK 获取语料库 
. 综合案例：走进大秦帝国 
.. 数据采集和预处理 
.. 构建本地语料库 
.. 大秦帝国语料操作 
第 章中文自动分词 
. 中文分词简介 
. 中文分词的特点和难点 
. 常见中文分词方法 
. 典型中文分词工具 
.. HanLP 中文分词 
.. 其他中文分词工具 
. 结巴中文分词 
.. 基于Python 的结巴中文分词 
.. 结巴分词工具详解 
.. 结巴分词核心内容 
.. 结巴分词基本用法 
第 章数据预处理 
. 数据清洗 
. 分词处理 
. 特征构造 
. 特征降维与选择 
.. 特征降维 
.. 特征选择 
. 简单实例 
. 本章小结 
第 章马尔可夫模型 
. 马尔可夫链 
.. 马尔可夫简介 
.. 马尔可夫链的基本概念 
. 隐马尔可夫模型 
.. 形式化描述 
.. 数学形式描述 
. 向前算法解决HMM 似然度 
.. 向前算法定义 
.. 向前算法原理 
.. 现实应用：预测成都天气的冷热 
. 文本序列标注案例：Viterbi 算法 
第 章条件随机场 
. 条件随机场介绍 
. 简单易懂的条件随机场 
.. CRF 的形式化表示 
.. CRF 的公式化表示 
.. 深度理解条件随机场 
第 章模型评估 
. 从统计角度介绍模型概念 
.. 算法模型 
.. 模型评估和模型选择 
.. 过拟合与欠拟合的模型选择 
. 模型评估与选择 
.. 模型评估的概念 
.. 模型评估的评测指标 
.. 以词性标注为例分析模型评估 
.. 模型评估的几种方法 
. ROC 曲线比较学习器模型 
第 章命名实体识别 
. 命名实体识别概述 
. 命名实体识别的特点与难点 
. 命名实体识别方法 
. 中文命名实体识别的核心技术 
. 展望 
第 章自然语言处理实战 
. GitHub 数据提取与可视化分析 
.. 了解GitHub 的API 
.. 使用NetworkX 作图 
.. 使用NetworkX 构建兴趣图 
.. NetWorkX 部分统计指标 
.. 构建GitHub 的兴趣图 
.. 可视化 
. 微博话题爬取与存储分析 
.. 数据采集 
.. 数据提取 
.. 数据存储 
.. 项目运行与分析 
附录A Python 与其他语言调用 
附录B Git 项目上传简易教程 
参考文献 
・ ・ ・ ・ ・ ・ (收起)模块　NLTK基础知识
第　章 自然语言处理简介　
.　为什么要学习NLP　
.　从Python的基本知识开始　
..　列表　
..　自助　
..　正则表达式　
..　词典　
..　编写函数　
.　NLTK　
.　试一试　
.　本章小结　
第　章 文本的整理和清洗　
.　文本整理　
.　文本清洗　
.　句子拆分器　
.　标记解析　
.　词干提取　
.　词形还原　
.　停用词删除　
.　生僻字删除　
.　拼写校正　
.　试一试　
.　本章小结　
第章　词性标注　
.　什么是词性标注　
..　斯坦福标注器　
..　深入了解标注器　
..　序列标注器　
..　布里尔标注器　
..　基于标注器的机器学习　
.　命名实体识别　
.　试一试　
.　本章小结　
第章　对文本的结构进行语法分析　
.　浅层语法分析与深层语法
分析　
.　语法分析的两种方法　
.　为什么需要语法分析　
.　不同类型的语法分析器　
..　递归下降的语法分析器　
..　移位归约语法分析器　
..　图表语法分析器　
..　正则表达式语法
分析器　
.　依存分析　
.　组块化　
.　信息抽取　
..　命名实体识别　
..　关系抽取　
.　本章小结　
第章　NLP应用　
.　构建第 一个NLP应用　
.　其他的NLP应用　
..　机器翻译　
..　统计机器翻译　
..　信息检索　
..　语音识别　
..　文本分类　
..　信息提取　
..　问答系统　
..　对话系统　
..　词义消歧　
..　主题建模　
..　语言检测　
..　光学字符识别　
.　本章小结　
第章　文本分类　
.　机器学习　
.　文本分类　
.　采样　
..　朴素贝叶斯　
..　决策树　
..　随机梯度下降　
..　逻辑回归　
..　支持向量机　
.　随机森林算法　
.　文本聚类　
.　文本的主题建模　
.　参考资料　
.　本章小结　
第章　网络爬取　
.　网络爬虫　
.　编写第 一个爬虫程序　
.　Scrapy中的数据流　
..　Scrapy命令行界面　
..　项　
.　站点地图蜘蛛　
.　项管道　
.　外部参考　
.　本章小结　
第章　与其他Python库一同
使用NLTK　
.　NumPy　
..　ndarray　
..　基本操作　
..　从数组中提取数据　
..　复杂的矩阵运算　
.　SciPy　
..　线性代数　
..　特征值和特征向量　
..　稀疏矩阵　
..　优化　
.　Pandas　
..　读取数据　
..　时序数据　
..　列转换　
..　噪声数据　
.　Matplotlib　
..　subplot　
..　添加轴　
..　散点图　
..　柱状图　
..　D图　
.　外部参考　
.　本章小结　
第章　使用Python进行社交媒体
挖掘　
.　数据收集　
.　数据提取　
.　地理可视化　
..　影响者检测　
..　Facebook　
..　影响者的朋友　
.　本章小结　
第　章 大规模的文本挖掘　
.　在Hadoop上使用Python的
不同方法　
..　Python的流　
..　Hive/Pig UDF　
..　流包装器　
.　在Hadoop上运行NLTK　
..　UDF　
..　Python流　
.　在Hadoop上运行
Scikit-learn　
.　PySpark　
.　本章小结　
模块　使用Python 的NLTK 进行文本处理
第　章 标记文本和WordNet的基础　
.　引言　
.　将文本标记成句子　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　将句子标记成单词　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式标记语句　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练语句标记生成器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　在已标记的语句中过滤
停用词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　查找WordNet中单词的
Synset　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　在WordNet中查找词元和
同义词　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　计算WordNet和Synset的
相似度　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　发现单词搭配　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第　章 替换和校正单词　
.　引言　
.　词干提取　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用WordNet进行词形还原　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　基于匹配的正则表达式替换
单词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　移除重复字符　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用Enchant进行拼写校正　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　替换同义词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用反义词替换否定形式　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　创建自定义语料库　
.　引言　
.　建立自定义语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建词汇表语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已标记词性单词的
语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已组块短语的语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已分类文本的语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已分类组块语料库
读取器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　懒惰语料库加载　
..　工作方式　
..　工作原理　
..　更多信息　
.　创建自定义语料库视图　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建基于MongoDB的
语料库读取器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　在加锁文件的情况下编辑
语料库　
..　准备工作　
..　工作方式　
..　工作原理　
第章　词性标注　
.　引言　
.　默认标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练一元组词性标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　回退标注的组合标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练和组合N元标注器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建似然单词标签的
模型　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　词缀标签　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练布里尔标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练TnT标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用WordNet进行
标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
.　标注专有名词　
..　工作方式　
..　工作原理　
..　请参阅　
.　基于分类器的标注　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用NLTK训练器训练
标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　提取组块　
.　引言　
.　使用正则表达式组块和
隔断　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式合并和拆分
组块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式扩展和删除
组块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式进行部分
解析　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练基于标注器的组块器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　基于分类的分块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　提取命名实体　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　提取专有名词组块　
..　工作方式　
..　工作原理　
..　更多信息　
.　提取部位组块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练命名实体组块器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用NLTK训练器训练
组块器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　转换组块与树　
.　引言　
.　过滤句子中无意义的
单词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　纠正动词形式　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
.　交换动词短语　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　交换名词基数　
..　工作方式　
..　工作原理　
..　请参阅　
.　交换不定式短语　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　单数化复数名词　
..　工作方式　
..　工作原理　
..　请参阅　
.　链接组块变换　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　将组块树转换为文本　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　平展深度树　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建浅树　
..　工作方式　
..　工作原理　
..　请参阅　
.　转换树标签　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
第章　文本分类　
.　引言　
.　词袋特征提取　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练朴素贝叶斯
分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练决策树分类器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练最大熵分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练scikit-learn
分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　衡量分类器的精准率和
召回率　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　计算高信息量单词　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用投票组合分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
.　使用多个二元分类器
分类　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用NLTK训练器训练
分类器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　分布式进程和大型数据集的
处理　
.　引言　
.　使用execnet进行分布式
标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　使用execnet进行分布式
组块　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　使用execnet并行处理
列表　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　在Redis中存储频率分布　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　在Redis中存储条件频率
分布　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　在Redis中存储有序
字典　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　使用Redis和execnet进行
分布式单词评分　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
第章　解析特定的数据类型　
.　引言　
.　使用dateutil解析日期和
时间　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　时区的查找和转换　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用lxml从HTML中提取
URL　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　清理和剥离HTML　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用BeautifulSoup转换
HTML实体　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　检测和转换字符编码　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
附录A　宾州treebank词性标签　
模块　使用Python掌握自然语言处理
第　章 使用字符串　
.　标记化　
..　将文本标记为句子　
..　其他语言文字的标记化　
..　将句子标记为单词　
..　使用TreebankWordTokenizer
进行标记化　
..　使用正则表达式进行
标记化　
.　规范化　
..　消除标点符号　
..　转化为小写和大写　
..　处理停用词　
..　计算英语中的停用词　
.　替代和纠正标记　
..　使用正则表达式替换
单词　
..　使用一个文本替换另一个
文本的示例　
..　在标记化之前进行
替代　
..　处理重复的字符　
..　删除重复字符的示例　
..　使用单词的同义词替换
单词　
.　在文本上应用齐夫定律　
.　相似性量度　
..　使用编辑距离算法应用
相似性量度　
..　使用杰卡德系数应用
相似性量度　
..　使用史密斯-沃特曼算法
应用相似性量度　
..　其他字符串相似性指标　
.　本章小结　
第　章 统计语言模型　
.　单词频率　
..　对给定文本进行最大
似然估计　
..　隐马尔可夫模型估计　
.　在MLE模型上应用平滑　
..　加一平滑法　
..　古德-图灵算法　
..　聂氏估计　
..　威滕 贝尔估计　
.　为MLE指定回退机制　
.　应用数据插值获得混合和
匹配　
.　应用困惑度评估语言模型　
.　在建模语言中应用
梅特罗波利斯-黑斯廷斯算法　
.　在语言处理中应用
吉布斯采样　
.　本章小结　
第章　词语形态学―试一试　
.　词语形态学　
.　词根还原器　
.　词形还原　
.　开发用于非英语语言的词根
还原器　
.　词语形态分析器　
.　词语形态生成器　
.　搜索引擎　
.　本章小结　
第章　词性标注―识别单词　
.　词性标注　
.　创建POS标注的语料库　
.　选择某个机器学习算法　
.　涉及n元组方法的统计建模　
.　使用POS标注的语料库开发
组块器　
.　本章小结　
第章　解析―分析训练数据　
.　解析　
.　构建树库　
.　从树库中提取上下文无关文法的
规则　
.　从CFG中创建概率上下文无关的
文法　
.　CYK图解析算法　
.　厄雷图解析算法　
.　本章小结　
第章　语义分析―意义重大　
.　语义分析　
..　NER简介　
..　使用隐马尔可夫模型的
NER系统　
..　使用机器学习工具包训练
NER　
..　使用POS标注的
NER　
.　从Wordnet中生成同义词集
ID　
.　使用Wordnet消除歧义　
.　本章小结　
第章　情感分析―我很高兴　
.　情感分析　
.　使用机器学习的情感分析　
.　本章小结　
第章　信息检索―访问信息　
.　信息检索　
..　停用词删除　
..　利用向量空间模型进行
信息检索　
.　向量空间评分以及与查询
操作器交互　
.　利用隐含语义索引开发IR
系统　
.　文本摘要　
.　问答系统　
.　本章小结　
第章　话语分析―知识就是信仰　
.　话语分析　
..　使用定中心理论进行
话语分析　
..　回指解析　
.　本章小结　
第　章 NLP系统的评估―
性能分析　
.　对NLP系统进行评估的
需求　
..　NLP工具（POS标注器、
词干还原器和形态分析器）
的评估　
..　使用黄金数据评估
解析器　
.　IR系统的评估　
.　错误识别的指标　
.　基于词汇匹配的指标　
.　基于语法匹配的指标　
.　使用浅层语义匹配的
指标　
.　本章小结　
参考书目　
・ ・ ・ ・ ・ ・ (收起)第章 中文语言的机器处理 
. 历史回顾 
.. 从科幻到现实 
.. 早期的探索 
.. 规则派还是统计派 
.. 从机器学习到认知计算 
. 现代自然语言系统简介 
.. NLP流程与开源框架 
.. 哈工大NLP平台及其演示环境 
.. Stanford NLP团队及其演示环境 
.. NLTK开发环境 
. 整合中文分词模块 
.. 安装Ltp Python组件 
.. 使用Ltp .进行中文分词 
.. 使用结巴分词模块 
. 整合词性标注模块 
.. Ltp .词性标注 
.. 安装StanfordNLP并编写Python接口类 
.. 执行Stanford词性标注 
. 整合命名实体识别模块 
.. Ltp .命名实体识别 
.. Stanford命名实体识别 
. 整合句法解析模块 
.. Ltp .句法依存树 
.. Stanford Parser类 
.. Stanford短语结构树 
.. Stanford依存句法树 
. 整合语义角色标注模块 
. 结语 
第章 汉语语言学研究回顾 
. 文字符号的起源 
.. 从记事谈起 
.. 古文字的形成 
. 六书及其他 
.. 象形 
.. 指事 
.. 会意 
.. 形声 
.. 转注 
.. 假借 
. 字形的流变 
.. 笔与墨的形成与变革 
.. 隶变的方式 
.. 汉字的符号化与结构 
. 汉语的发展 
.. 完整语义的基本形式DD句子 
.. 语言的初始形态与文言文 
.. 白话文与复音词 
.. 白话文与句法研究 
. 三个平面中的语义研究 
.. 词汇与本体论 
.. 格语法及其框架 
. 结语 
第章 词汇与分词技术 
. 中文分词 
.. 什么是词与分词规范 
.. 两种分词标准 
.. 歧义、机械分词、语言模型 
.. 词汇的构成与未登录词 
. 系统总体流程与词典结构 
.. 概述 
.. 中文分词流程 
.. 分词词典结构 
.. 命名实体的词典结构 
.. 词典的存储结构 
. 算法部分源码解析 
.. 系统配置 
.. Main方法与例句 
.. 句子切分 
.. 分词流程 
.. 一元词网 
.. 二元词图 
.. NShort算法原理 
.. 后处理规则集 
.. 命名实体识别 
.. 细分阶段与最短路径 
. 结语 
第章 NLP中的概率图模型 
. 概率论回顾 
.. 多元概率论的几个基本概念 
.. 贝叶斯与朴素贝叶斯算法 
.. 文本分类 
.. 文本分类的实现 
. 信息熵 
.. 信息量与信息熵 
.. 互信息、联合熵、条件熵 
.. 交叉熵和KL散度 
.. 信息熵的NLP的意义 
. NLP与概率图模型 
.. 概率图模型的几个基本问题 
.. 产生式模型和判别式模型 
.. 统计语言模型与NLP算法设计 
.. 极大似然估计 
. 隐马尔科夫模型简介 
.. 马尔科夫链 
.. 隐马尔科夫模型 
.. HMMs的一个实例 
.. Viterbi算法的实现 
. 最大熵模型 
.. 从词性标注谈起 
.. 特征和约束 
.. 最大熵原理 
.. 公式推导 
.. 对偶问题的极大似然估计 
.. GIS实现 
. 条件随机场模型 
.. 随机场 
.. 无向图的团（Clique）与因子分解 
.. 线性链条件随机场 
.. CRF的概率计算 
.. CRF的参数学习 
.. CRF预测标签 
. 结语 
第章 词性、语块与命名实体识别 
. 汉语词性标注 
.. 汉语的词性 
.. 宾州树库的词性标注规范 
.. stanfordNLP标注词性 
.. 训练模型文件 
. 语义组块标注 
.. 语义组块的种类 
.. 细说NP 
.. 细说VP 
.. 其他语义块 
.. 语义块的抽取 
.. CRF的使用 
. 命名实体识别 
.. 命名实体 
.. 分词架构与专名词典 
.. 算法的策略DD词典与统计相结合 
.. 算法的策略DD层叠式架构 
. 结语 
第章 句法理论与自动分析 
. 转换生成语法 
.. 乔姆斯基的语言观 
.. 短语结构文法 
.. 汉语句类 
.. 谓词论元与空范畴 
.. 轻动词分析理论 
.. NLTK操作句法树 
. 依存句法理论 
.. 配价理论 
.. 配价词典 
.. 依存理论概述 
.. Ltp依存分析介绍 
.. Stanford依存转换、解析 
. PCFG短语结构句法分析 
.. PCFG短语结构 
.. 内向算法和外向算法 
.. Viterbi算法 
.. 参数估计 
.. Stanford 的PCFG算法训练 
. 结语 
第章 建设语言资源库 
. 语料库概述 
.. 语料库的简史 
.. 语言资源库的分类 
.. 语料库的设计实例：国家语委语料库 
.. 语料库的层次加工 
. 语法语料库 
.. 中文分词语料库 
.. 中文分词的测评 
.. 宾州大学CTB简介 
. 语义知识库 
.. 知识库与HowNet简介 
.. 发掘义原 
.. 语义角色 
.. 分类原则与事件分类 
.. 实体分类 
.. 属性与分类 
.. 相似度计算与实例 
. 语义网与百科知识库 
.. 语义网理论介绍 
.. 维基百科知识库 
.. DBpedia抽取原理 
. 结语 
第章 语义与认知 
. 回顾现代语义学 
.. 语义三角论 
.. 语义场论 
.. 基于逻辑的语义学 
. 认知语言学概述 
.. 象似性原理 
.. 顺序象似性 
.. 距离象似性 
.. 重叠象似性 
. 意象图式的构成 
.. 主观性与焦点 
.. 范畴化：概念的认知 
.. 主体与背景 
.. 意象图式 
.. 社交中的图式 
.. 完形：压缩与省略 
. 隐喻与转喻 
.. 隐喻的结构 
.. 隐喻的认知本质 
.. 隐喻计算的系统架构 
.. 隐喻计算的实现 
. 构式语法 
.. 构式的概念 
.. 句法与构式 
.. 构式知识库 
. 结语 
第章 NLP中的深度学习 
. 神经网络回顾 
.. 神经网络框架 
.. 梯度下降法推导 
.. 梯度下降法的实现 
.. BP神经网络介绍和推导 
. WordVec简介 
.. 词向量及其表达 
.. WordVec的算法原理 
.. 训练词向量 
.. 大规模上下位关系的自动识别 
. NLP与RNN 
.. Simple-RNN 
.. LSTM原理 
.. LSTM的Python实现 
. 深度学习框架与应用 
.. Keras框架介绍 
.. Keras序列标注 
.. 依存句法的算法原理 
.. Stanford依存解析的训练过程 
. 结语 
第章 语义计算的架构 
. 句子的语义和语法预处理 
.. 长句切分和融合 
.. 共指消解 
. 语义角色 
.. 谓词论元与语义角色 
.. PropBank简介 
.. CPB中的特殊句式 
.. 名词性谓词的语义角色 
.. PropBank展开 
. 句子的语义解析 
.. 语义依存 
.. 完整架构 
.. 实体关系抽取 
. 结语 
・ ・ ・ ・ ・ ・ (收起)第章 起步　　
. NLP中的基本概念和术语　　
.. 文本语料库　　
.. 段落　　
.. 句子　　
.. 短语和单词　　
.. n元语法　　
.. 词袋　　
. NLP技术的应用　　
.. 情感分析　　
.. 命名实体识别　　
.. 实体链接　　
.. 文本翻译　　
.. 自然语言推理　　
.. 语义角色标记　　
.. 关系提取　　
.. SQL查询生成或语义解析　　
.. 机器阅读理解　　
.. 文字蕴含　　
.. 指代消解　　
.. 搜索　　
.. 问答和聊天机器人　　
.. 文本转语音　　
.. 语音转文本　　
.. 说话人识别　　
.. 口语对话系统　　
.. 其他应用　　
. 小结　　
第章 使用NLTK进行文本分类和词性标注　　
. 安装NLTK 及其模块　　
. 文本预处理及探索性分析　　
.. 分词　　
.. 词干提取　　
.. 去除停用词　　
.. 探索性分析　　
. 词性标注　　
.. 词性标注定义　　
.. 词性标注的应用　　
.. 训练词性标注器　　
. 训练影评情感分类器　　
. 训练词袋分类器　　
. 小结　　
第章 深度学习和TensorFlow　　
. 深度学习　　
.. 感知器　　
.. 激活函数　　
.. 神经网络　　
.. 训练神经网络　　
.. 卷积神经网络　　
.. 递归神经网络　　
. TensorFlow　　
.. 通用图形处理单元　　
.. 安装　　
.. Hello world !　　
.. 两数相加　　
.. TensorBoard　　
.. Keras库　　
. 小结　　
第章 使用浅层模型进行语义嵌入　　
. 词向量　　
.. 经典方法　　
.. Wordvec　　
.. 连续词袋模型　　
.. 跳字模型　　
. 从单词到文档嵌入　　
. Sentencevec　　
. Docvec　　
. 小结　　
第章 使用LSTM进行文本分类　　
. 文本分类数据　　
. 主题建模　　
. 用于文本分类的深度学习元架构　　
.. 嵌入层　　
.. 深层表示　　
.. 全连接部分　　
. 使用RNN识别YouTube视频垃圾评论　　
. 使用CNN对新闻主题分类　　
. 使用GloVe嵌入进行迁移学习　　
. 多标签分类　　
.. 二元关联　　
.. 用于多标签分类的深度学习　　
.. 用于文档分类的attention网络　　
. 小结　　
第章 使用CNN进行搜索和去重　　
. 数据　　
. 模型训练　　
.. 文本编码　　
.. 建立CNN模型　　
.. 训练　　
.. 推理　　
. 小结　　
第章 使用字符级LSTM进行命名实体识别　　
. 使用深度学习实现NER　　
.. 数据　　
.. 模型　　
.. 代码详解　　
.. 不同预训练词嵌入的影响　　
.. 改进空间　　
. 小结　　
第章 使用GRU 进行文本生成和文本摘要　　
. 使用RNN进行文本生成　　
. 文本摘要　　
.. 提取式摘要　　
.. 抽象式摘要　　
.. 最新抽象式文本摘要　　
. 小结　　
第章 使用记忆网络完成问答任务和编写聊天机器人　　
. QA任务　　
. 用于QA任务的记忆网络　　
.. 记忆网络管道概述　　
.. 使用TensorFlow写一个记忆网络　　
. 拓展记忆网络以进行对话建模　　
.. 对话数据集　　
.. 使用TensorFlow编写一个聊天机器人　　
.. 记忆网络相关文献　　
. 小结　　
第章 使用基于attention的模型进行机器翻译　　
. 机器翻译概述　　
.. 统计机器翻译　　
.. 神经机器翻译　　
. 小结　　
第章 使用DeepSpeech进行语音识别　　
. 语音识别概述　　
. 建立用于语音识别的RNN模型　　
.. 语音信号表示　　
.. 用于语音数字识别的LSTM模型　　
.. TensorBoard可视化　　
.. 使用DeepSpeech架构的语音转文本模型　　
.. 语音识别最新技术　　
. 小结　　
第章 使用Tacotron进行文本转语音　　
. TTS领域概述　　
.. 自然性与可懂性　　
.. TTS系统表现的评估方式　　
.. 传统技术――级联模型和参数模型　　
.. 关于频谱图和梅尔标度的一些提醒　　
. 深度学习中的TTS　　
.. WaveNet简介　　
.. Tacotron　　
. 利用Keras的Tacotron实现　　
.. 数据集　　
.. 数据准备　　
.. 架构实现　　
.. 训练与测试　　
. 小结　　
第章 部署训练好的模型　　
. 性能提升　　
.. 量化权重　　
.. MobileNets　　
. TensorFlow Serving　　
.. 导出训练好的模型　　
.. 把导出模型投入服务　　
. 在云上部署　　
.. Amazon Web Services　　
.. Google Cloud Platform　　
. 在移动设备上部署　　
.. iPhone　　
.. Android　　
. 小结　　
・ ・ ・ ・ ・ ・ (收起)序一
序二
前言
第章 NLP基础 
. 什么是NLP 
.. NLP的概念 
.. NLP的研究任务 
. NLP的发展历程 
. NLP相关知识的构成 
.. 基本术语 
.. 知识结构 
. 语料库 
. 探讨NLP的几个层面 
. NLP与人工智能 
. 本章小结 
第章 NLP前置技术解析 
. 搭建Python开发环境 
.. Python的科学计算发行版――Anaconda 
.. Anaconda的下载与安装 
. 正则表达式在NLP的基本应用 
.. 匹配字符串 
.. 使用转义符 
.. 抽取文本中的数字 
. Numpy使用详解 
.. 创建数组 
.. 获取Numpy中数组的维度 
.. 获取本地数据 
.. 正确读取数据 
.. Numpy数组索引 
.. 切片 
.. 数组比较 
.. 替代值 
.. 数据类型转换 
.. Numpy的统计计算方法 
. 本章小结 
第章 中文分词技术 
. 中文分词简介 
. 规则分词 
.. 正向最大匹配法 
.. 逆向最大匹配法 
.. 双向最大匹配法 
. 统计分词 
.. 语言模型 
.. HMM模型 
.. 其他统计分词算法 
. 混合分词 
. 中文分词工具――Jieba 
.. Jieba的三种分词模式 
.. 实战之高频词提取 
. 本章小结 
第章 词性标注与命名实体识别 
. 词性标注 
.. 词性标注简介 
.. 词性标注规范 
.. Jieba分词中的词性标注 
. 命名实体识别 
.. 命名实体识别简介 
.. 基于条件随机场的命名实体识别 
.. 实战一：日期识别 
.. 实战二：地名识别 
. 总结 
第章 关键词提取算法 
. 关键词提取技术概述 
. 关键词提取算法TF/IDF算法 
. TextRank算法 
. LSA/LSI/LDA算法 
.. LSA/LSI算法 
.. LDA算法 
. 实战提取文本关键词 
. 本章小结 
第章 句法分析 
. 句法分析概述 
. 句法分析的数据集与评测方法 
.. 句法分析的数据集 
.. 句法分析的评测方法 
. 句法分析的常用方法 
.. 基于PCFG的句法分析 
.. 基于最大间隔马尔可夫网络的句法分析 
.. 基于CRF的句法分析 
.. 基于移进C归约的句法分析模型 
. 使用Stanford Parser的PCFG算法进行句法分析 
.. Stanford Parser 
.. 基于PCFG的中文句法分析实战 
. 本章小结 
第章 文本向量化 
. 文本向量化概述 
. 向量化算法wordvec 
.. 神经网络语言模型 
.. C&W模型 
.. CBOW模型和Skip-gram模型 
. 向量化算法docvec/strvec 
. 案例：将网页文本向量化 
.. 词向量的训练 
.. 段落向量的训练 
.. 利用wordvec和docvec计算网页相似度 
. 本章小结 
第章 情感分析技术 
. 情感分析的应用 
. 情感分析的基本方法 
.. 词法分析 
.. 机器学习方法 
.. 混合分析 
. 实战电影评论情感分析 
.. 卷积神经网络 
.. 循环神经网络 
.. 长短时记忆网络 
.. 载入数据 
.. 辅助函数 
.. 模型设置 
.. 调参配置 
.. 训练过程 
. 本章小结 
第章 NLP中用到的机器学习算法 
. 简介 
.. 机器学习训练的要素 
.. 机器学习的组成部分 
. 几种常用的机器学习方法 
.. 文本分类 
.. 特征提取 
.. 标注 
.. 搜索与排序 
.. 推荐系统 
.. 序列学习 
. 分类器方法 
.. 朴素贝叶斯Naive Bayesian 
.. 逻辑回归 
.. 支持向量机 
. 无监督学习的文本聚类 
. 文本分类实战：中文垃圾邮件分类 
.. 实现代码 
.. 评价指标 
. 文本聚类实战：用K-means对豆瓣读书数据聚类 
. 本章小结 
第章 基于深度学习的NLP算法 
. 深度学习概述 
.. 神经元模型 
.. 激活函数 
.. 感知机与多层网络 
. 神经网络模型 
. 多输出层模型 
. 反向传播算法 
. 最优化算法 
.. 梯度下降 
.. 随机梯度下降 
.. 批量梯度下降 
. 丢弃法 
. 激活函数 
.. tanh函数 
.. ReLU函数 
. 实现BP算法 
. 词嵌入算法 
.. 词向量 
.. wordvec简介 
.. 词向量模型 
.. CBOW和Skip-gram模型 
. 训练词向量实践 
. 朴素Vanilla-RNN 
. LSTM网络 
.. LSTM基本结构 
.. 其他LSTM变种形式 
. Attention机制 
.. 文本翻译 
.. 图说模型 
.. 语音识别 
.. 文本摘要 
. SeqSeq模型 
. 图说模型 
. 深度学习平台 
.. Tensorflow 
.. Mxnet 
.. PyTorch 
.. Caffe 
.. Theano 
. 实战SeqSeq问答机器人 
. 本章小结 
第章 Solr搜索引擎 
. 全文检索的原理 
. Solr简介与部署 
. Solr后台管理描述 
. 配置schema 
. Solr管理索引库 
.. 创建索引 
.. 查询索引 
.. 删除文档 
. 本章小结 
・ ・ ・ ・ ・ ・ (收起)第 章　什么是文本分析 
.　什么是文本分析　
.　搜集数据　
.　若输入错误数据，则输出亦为错误数据（garbage in，garbage out）　
.　为什么你需要文本分析　
.　总结　
第　章 Python文本分析技巧　
.　为什么用Python来做文本分析　
.　用Python进行文本操作　
.　总结　
第章　spaCy语言模型　
.　spaCy库　
.　spaCy的安装步骤　
.　故障排除　
.　语言模型　
.　安装语言模型　
.　安装语言模型的方式及原因　
.　语言模型的基本预处理操作　
.　分词　
.　词性标注　
.　命名实体识别　
.　规则匹配　
.　预处理　
.　总结　
第章　Gensim：文本向量化、向量变换和n-grams的工具　
.　Gensim库介绍　
.　向量以及为什么需要向量化　
.　词袋（bag-of-words）　
.　TF-IDF（词频-反向文档频率）　
.　其他表示方式　
.　Gensim中的向量变换　
.　n-grams及其预处理技术　
.　总结　
第章　词性标注及其应用　
.　什么是词性标注　
.　使用Python实现词性标注　
.　使用spaCy进行词性标注　
.　从头开始训练一个词性标注模型　
.　词性标注的代码示例　
.　总结　
第章　NER标注及其应用　
.　什么是NER标注　
.　用Python实现NER标注　
.　使用spaCy实现NER标注　
.　从头开始训练一个NER标注器　
.　NER标注应用实例和可视化　
.　总结　
第章　依存分析　
.　依存分析　
.　用Python实现依存分析　
.　用spaCy实现依存分析　
.　从头开始训练一个依存分析器　
.　总结　
第章　主题模型　
.　什么是主题模型　
.　使用Gensim构建主题模型　
.　隐狄利克雷分配（Latent Dirichlet Allocation）　
.　潜在语义索引（Latent Semantic Indexing）　
.　分层狄利特雷过程（Hierarchical Dirichlet Process）　
.　动态主题模型　
.　使用scikit-learn构建主题模型　
.　总结　
第章　高级主题建模　
.　高级训练技巧　
.　探索文档　
.　主题一致性和主题模型的评估　
.　主题模型的可视化　
.　总结　
第　章 文本聚类和文本分类　
.　文本聚类　
.　聚类前的准备工作　
.　K-means　
.　层次聚类　
.　文本分类　
.　总结　
第　章 查询词相似度计算和文本摘要　
.　文本距离的度量　
.　查询词相似度计算　
.　文本摘要　
.　总结　
第　章 WordVec、DocVec和Gensim　
.　WordVec　
.　用Gensim实现WordVec　
.　DocVec　
.　其他词嵌入技术　
.　总结　
第　章 使用深度学习处理文本　
.　深度学习　
.　深度学习在文本上的应用　
.　文本生成　
.　总结　
第　章 使用Keras和spaCy进行深度学习　
.　Keras和spaCy　
.　使用Keras进行文本分类　
.　使用spaCy进行文本分类　
.　总结　
第　章 情感分析与聊天机器人　
.　情感分析　
.　基于Reddit的新闻数据挖掘　
.　基于Twitter的微博数据挖掘　
.　聊天机器人　
.　总结　
・ ・ ・ ・ ・ ・ (收起)译者序
前言
作者名单
第章 延迟解释、浅层处理和构式：“尽可能解释”原则的基础 
. 引言 
. 延迟处理 
. 工作记忆 
. 如何识别语块：分词操作 
. 延迟架构 
.. 分段和存储 
.. 内聚聚集 
. 结论 
. 参考文献 
第章 人类关联规范能否评估机器制造的关联列表 
. 引言 
. 人类语义关联 
.. 单词关联测试 
.. 作者的实验 
.. 人类关联拓扑 
.. 人类关联具有可比性 
. 算法效率比较 
.. 语料库 
.. LSA源关联列表 
.. LDA源列表 
.. 基于关联比率的列表 
.. 列表比较 
. 结论 
. 参考文献 
第章 文本词如何在人类关联网络中选择相关词 
. 引言 
. 网络 
. 基于文本的激励驱动的网络提取 
.. 子图提取算法 
.. 控制流程 
.. 最短路径提取 
.. 基于语料库的子图 
. 网络提取流程的测试 
.. 进行测试的语料库 
.. 提取子图的评估 
.. 有向和无向子图提取：对比 
.. 每个激励产生的结果 
. 对结果和相关工作的简要讨论 
. 参考文献 
第章 反向关联任务 
. 引言 
. 计算前向关联 
.. 步骤 
.. 结果和评估 
. 计算反向关联 
.. 问题 
.. 步骤 
.. 结果和评估 
. 人类的表现 
.. 数据集 
.. 测试流程 
.. 评估 
. 机器性能 
. 讨论、结果和展望 
.. 人类的反向关联 
.. 机器的反向关联 
. 致谢 
. 参考文献 
第章 词汇的隐藏结构与功能 
. 引言 
. 方法 
.. 词典图 
.. 心理语言学变量 
.. 数据分析 
. 内核、卫星、核心、MinSet以及词典余下部分的心理语言学属性 
. 讨论 
. 未来工作 
. 参考文献 
第章 用于词义消歧的直推式学习博弈 
. 引言 
. 基于图的词义消歧 
. 半监督学习方法 
.. 基于图的半监督学习 
.. 博弈论和博弈动态 
. 词义消歧博弈 
.. 图构造 
.. 策略空间 
.. 收益矩阵 
.. 系统动力学 
. 评估 
.. 实验设置 
.. 评估结果 
.. 对比先进水平算法 
. 结论 
. 参考文献 
第章 用心学写：生成连贯文本的问题 
. 问题 
. 次优文本及其相关原因 
.. 缺乏连贯性或凝聚力 
.. 错误引用 
.. 无动机的主题转移 
. 如何解决任务的复杂性 
. 相关研究 
. 关于构建辅助写作过程的工具的假设 
. 方法论 
.. 句法结构的识别 
.. 语义种子词的识别 
.. 单词对齐 
.. 确定对齐单词的相似性值 
.. 确定句子之间的相似性 
.. 基于句子相似性值的聚类 
. 实验结果和评估 
. 展望和总结 
. 参考文献 
第章 面向著述属性的基于序贯规则挖掘的文体特征 
. 引言和研究动机 
. 著述属性过程 
. 著述属性的文体特征 
. 针对文体分析的时序数据挖掘 
. 实验设置 
.. 数据集 
.. 分类方案 
. 结果和讨论 
. 结论 
. 参考文献 
第章 一种并行的、面向认知的基频估计算法 
. 引言 
. 语音信号分割 
.. 语音和停顿段 
.. 浊音和清音区 
.. 稳定和不稳定区间 
. 稳定区间的F估计 
. F传播 
.. 控制流 
.. 峰值传播 
. 不稳定的浊音区域 
. 并行化 
. 实验和结果 
. 结论 
. 致谢 
. 参考文献 
第章 基于完形填充、脑电图和眼球运动数据对n元语言模型、主题模型和循环神经网络的基准测试 
. 引言 
. 相关工作 
. 方法 
.. 人类绩效评估 
.. 语言模型的三种风格 
. 实验设置 
. 结果 
.. 可预测性结果 
.. N振幅结果 
.. 单一注视时延结果 
. 讨论和结论 
. 致谢 
. 参考文献 
术语表 
・ ・ ・ ・ ・ ・ (收起)第章　应用自然语言处理技术 
.　付出与回报 
..　如何开始 
.. 招聘人员 
.. 学习 
. 开发环境 
. 技术基础 
.. Java 
.. 规则方法 
.. 统计方法 
.. 计算框架 
.. 文本挖掘 
.. 语义库 
. 本章小结 
. 专业术语 
第章　中文分词原理与实现 
. 接口 
.. 切分方案 
.. 词特征 
. 查找词典算法 
.. 标准Trie树 
.. 三叉Trie树 
.. 词典格式 
. 最长匹配中文分词 
.. 正向最大长度匹配法 
.. 逆向最大长度匹配法 
.. 处理未登录串 
.. 开发分词 
. 概率语言模型的分词方法 
.. 一元模型 
.. 整合基于规则的方法 
.. 表示切分词图 
.. 形成切分词图 
.. 数据基础 
.. 改进一元模型 
.. 二元词典 
.. 完全二叉树组 
.. 三元词典 
.. N元模型 
.. N元分词 
.. 生成语言模型 
.. 评估语言模型 
.. 概率分词的流程与结构 
.. 可变长N元分词 
.. 条件随机场 
. 新词发现 
.. 成词规则 
. 词性标注 
.. 数据基础 
.. 隐马尔可夫模型 
.. 存储数据 
.. 统计数据 
.. 整合切分与词性标注 
.. 大词表 
.. 词性序列 
.. 基于转换的错误学习方法 
.. 条件随机场 
. 词类模型 
. 未登录词识别 
.. 未登录人名 
.. 提取候选人名 
.. 最长人名切分 
.. 一元概率人名切分 
.. 二元概率人名切分 
.. 未登录地名 
.. 未登录企业名 
. 平滑算法 
. 机器学习的方法 
.. 最大熵 
.. 条件随机场 
. 有限状态机 
. 地名切分 
.. 识别未登录地名 
.. 整体流程 
. 企业名切分 
.. 识别未登录词 
.. 整体流程 
. 结果评测 
. 本章小结 
. 专业术语 
第章　英文分析 
. 分词 
.. 句子切分 
.. 识别未登录串 
.. 切分边界 
. 词性标注 
. 重点词汇 
. 句子时态 
. 本章小结 
第章　依存文法分析 
. 句法分析树 
. 依存文法 
.. 中文依存文法 
.. 英文依存文法 
.. 生成依存树 
.. 遍历 
.. 机器学习的方法 
. 小结 
. 专业术语 
第章　文档排重 
. 相似度计算 
.. 夹角余弦 
.. 最长公共子串 
.. 同义词替换 
.. 地名相似度 
.. 企业名相似度 
. 文档排重 
.. 关键词排重 
.. SimHash 
.. 分布式文档排重 
.. 使用文本排重 
. 在搜索引擎中使用文本排重 
. 本章小结 
. 专业术语 
第章　信息提取 
. 指代消解 
. 中文关键词提取 
.. 关键词提取的基本方法 
.. HITS算法应用于关键词提取 
.. 从网页中提取关键词 
. 信息提取 
.. 提取联系方式 
.. 从互联网提取信息 
.. 提取地名 
. 拼写纠错 
.. 模糊匹配问题 
.. 正确词表 
.. 英文拼写检查 
.. 中文拼写检查 
. 输入提示 
. 本章小结 
. 专业术语 
第章　自动摘要 
. 自动摘要技术 
.. 英文文本摘要 
.. 中文文本摘要 
.. 基于篇章结构的自动摘要 
.. 句子压缩 
. 指代消解 
. Lucene中的动态摘要 
. 本章小结 
. 专业术语 
第章　文本分类 
. 地名分类 
. 错误类型分类 
. 特征提取 
. 关键词加权法 
. 朴素贝叶斯 
. 贝叶斯文本分类 
. 支持向量机 
.. 多级分类 
.. 规则方法 
.. 网页分类 
. 最大熵 
. 信息审查 
. 文本聚类 
.. K均值聚类方法 
.. K均值实现 
.. 深入理解DBScan算法 
.. 使用DBScan算法聚类实例 
. 本章小结 
. 专业术语 
第章　文本倾向性分析 
. 确定词语的褒贬倾向 
. 实现情感识别 
. 本章小结 
. 专业术语 
第章　问答系统 
. 问答系统的结构 
.. 提取问答对 
.. 等价问题 
. 问句分析 
.. 问题类型 
.. 句型 
.. 业务类型 
.. 依存树 
.. 指代消解 
.. 二元关系 
.. 逻辑表示 
.. 问句模板 
.. 结构化问句模板 
.. 检索方式 
.. 问题重写 
.. 提取事实 
.. 验证答案 
.. 无答案的处理 
. 知识库 
. 聊天机器人 
.. 交互式问答 
.. 垂直领域问答系统 
.. 语料库 
.. 客户端 
. 自然语言生成 
. 依存句法 
. 提取同义词 
.. 流程 
. 本章小结 
. 术语表 
第章　语音识别 
. 总体结构 
.. 识别中文 
.. 自动问答 
. 语音库 
. 语音合成 
.. 归一化 
. 语音 
.. 标注 
.. 相似度 
. Sphinx 
.. 中文训练集 
. Julius 
. 本章小结 
. 术语表 
参考资源 
后记 
・ ・ ・ ・ ・ ・ (收起)出版者的话
译者序
前言
关于作者
第一部分 理论
第章 找出词的结构
. 词及其部件
.. 词元
.. 词形
.. 词素
.. 类型学
. 问题和挑战
.. 不规则性
.. 歧义性
.. 能产性
. 形态模型
.. 查词典
.. 有限状态形态
.. 基于合一的形态
.. 函数式形态
.. 形态归纳
. 总结
第章 找出文档的结构
. 概述
.. 句子边界检测
.. 主题边界检测
. 方法
.. 生成序列分类方法
.. 判别性局部分类方法
.. 判别性序列分类方法
.. 混合方法
.. 句子分割的全局建模扩展
. 方法的复杂度
. 方法的性能
. 特征
.. 同时用于文本与语音的特征
.. 只用于文本的特征
.. 语音特征
. 处理阶段
. 讨论
. 总结
第章 句法
. 自然语言分析
. 树库：句法分析的数据驱动方法
. 句法结构的表示
.. 使用依存图的句法分析
.. 使用短语结构树的句法分析
. 分析算法
.. 移进归约分析
.. 超图和线图分析
.. 最小生成树和依存分析
. 分析中的歧义消解模型
.. 概率上下文无关文法
.. 句法分析的生成模型
.. 句法分析的判别模型
. 多语言问题：什么是词元
.. 词元切分、实例和编码
.. 分词
.. 形态学
. 总结
第章 语义分析
. 概述
. 语义解释
.. 结构歧义
.. 词义
.. 实体与事件消解
.. 谓词　论元结构
.. 意义表示
. 系统范式
. 词义
.. 资源
.. 系统
.. 软件
. 谓词　论元结构
.. 资源
.. 系统
.. 软件
. 意义表示
.. 资源
.. 系统
.. 软件
. 总结
.. 词义消歧
.. 谓词　论元结构
.. 意义表示
第章 语言模型
. 概述
. n元模型
. 语言模型评价
. 参数估计
.. 最大似然估计和平滑
.. 贝叶斯参数估计
.. 大规模语言模型
. 语言模型适应
. 语言模型的类型
.. 基于类的语言模型
.. 变长语言模型
.. 判别式语言模型
.. 基于句法的语言模型
.. 最大熵语言模型
.. 因子化语言模型
.. 其他基于树的语言模型
.. 基于主题的贝叶斯语言模型
.. 神经网络语言模型
. 特定语言建模问题
.. 形态丰富语言的建模
.. 亚词单元的选择
.. 形态类别建模
.. 无分词语言
.. 口语与书面语言
. 多语言和跨语言建模
.. 多语言建模
.. 跨语言建模
. 总结
第章 文本蕴涵识别
. 概述
. 文本识别蕴涵任务
.. 问题定义
.. RTE的挑战
.. 评估文本蕴涵系统性能
.. 文本蕴涵解决方案的应用
.. 其他语言中的RTE研究
. 文本蕴涵识别的框架
.. 要求
.. 分析
.. 有用的组件
.. 通用模型
.. 实现
.. 对齐
.. 推理
.. 训练
. 案例分析
.. 抽取语篇约束
.. 基于编辑距离的RTE
.. 基于转换的方法
.. 逻辑表示及推理
.. 独立于蕴涵学习对齐
.. 在RTE中利用多对齐
.. 自然逻辑
.. 句法树核
.. 使用有限依存上下文的全局相似度
.. RTE的潜在对齐推理
. RTE的进一步研究
.. 改进分析器
.. 发明或解决新问题
.. 开发知识库
.. 更好的RTE评价
. 有用资源
.. 文献
.. 知识库
.. 自然语言处理包
. 总结
第章 多语情感与主观性分析
. 概述
. 定义
. 英语中的情感及主观性分析
.. 词典
.. 语料库
.. 工具
. 词级和短语级标注
.. 基于字典的方法
.. 基于语料库的方法
. 句子级标注
.. 基于字典
.. 基于语料库
. 文档级标注
.. 基于字典
.. 基于语料库
. 什么有效，什么无效
.. 最佳情况：已有人工标注的语料库
.. 次优情形：基于语料库的跨语言映射
.. 第三优情形：孳衍词典
.. 第四优情形：翻译词典
.. 各种可行方法的比较
. 总结
第二部分 实践
第章 实体检测和追踪
. 概述
. 提及检测
.. 数据驱动的分类
.. 搜索提及
.. 提及检测特征
.. 提及检测实验
. 共指消解
.. Bell树的构建
.. 共指模型：链接和引入模型
.. 最大熵链接模型
.. 共指消解实验
. 总结
第章 关系和事件
. 概述
. 关系与事件
. 关系类别
. 将关系抽取视为分类
.. 算法
.. 特征
.. 分类器
. 关系抽取的其他方法
.. 无监督和半监督方法
.. 核方法
.. 实体和关系检测的联合方法
. 事件
. 事件抽取方法
. 超句
. 事件匹配
. 事件抽取的未来方向
. 总结
第章 机器翻译
. 机器翻译现状
. 机器翻译评测
.. 人工评测
.. 自动评测
.. WER、BLEU、METEOR等
. 词对齐
.. 共现
.. IBM模型
.. 期望最大化
.. 对齐模型
.. 对称化
.. 作为机器学习问题的词对齐
. 基于短语的翻译模型
.. 模型
.. 训练
.. 解码
.. 立方剪枝
.. 对数线性模型和参数调节
.. 控制模型的大小
. 基于树的翻译模型
.. 层次短语翻译模型
.. 线图解码
.. 基于句法的模型
. 语言学挑战
.. 译词选择
.. 形态学
.. 词序
. 工具和数据资源
.. 基本工具
.. 机器翻译系统
.. 平行语料
. 未来的方向
. 总结
第章 跨语言信息检索
. 概述
. 文档预处理
.. 文档句法和编码
.. 词元化
.. 规范化
.. 预处理最佳实践
. 单语信息检索
.. 文档表示
.. 索引结构
.. 检索模型
.. 查询扩展
.. 文档先验模型
.. 模型选择的最佳实践
. CLIR
.. 基于翻译的方法
.. 机器翻译
.. 中间语言文档表示
.. 最佳实践
. 多语言信息检索
.. 语言识别
.. MLIR的索引建立
.. 翻译查询串
.. 聚合模型
.. 最佳实践
. 信息检索的评价
.. 建立实验环境
.. 相关性评估
.. 评价指标
.. 已有数据集
.. 最佳实践
. 工具、软件和资源
. 总结
第章 多语自动文摘
. 概述
. 自动文摘方法
.. 传统方法
.. 基于图的方法
.. 学习如何做摘要
.. 多语自动摘要
. 评测
.. 人工评价
.. 自动评价
.. 自动文摘评测系统的近期发展
.. 多语自动文摘的自动评测方法
. 如何搭建自动文摘系统
.. 材料
.. 工具
.. 说明
. 评测竞赛和数据集
.. 评测竞赛
.. 数据集
. 总结
第章 问答系统
. 概述和历史
. 架构
. 源获取和预处理
. 问题分析
. 搜索及候选抽取
.. 非结构化资源搜索
.. 非结构化源文本的候选抽取
.. 结构化源文本的候选抽取
. 回答评分
.. 方法概述
.. 证据结合
.. 扩展到列表型问题
. 跨语言问答
. 案例研究
. 评测
.. 评测任务
.. 判断答案正确性
.. 性能度量
. 当前和未来的挑战
. 总结和进一步阅读
第章 提炼
. 概述
. 示例
. 相关性和冗余性
. Rosetta Consortium 提炼系统
.. 文档和语料库准备
.. 索引
.. 查询回答
. 其他提炼方法
.. 系统架构
.. 相关度
.. 冗余
.. 多模态提炼
.. 跨语言提炼
. 评测和指标
. 总结
第章 口语对话系统
. 概述
. 口语对话系统
.. 语音识别和理解
.. 语音生成
.. 对话管理器
.. 语音用户接口
. 对话形式
. 自然语言呼叫路由选择
. 三代对话应用
. 持续的改进循环
. 口语句子的转录和标注
. 口语对话系统的本地化
.. 呼叫流程本地化
.. 提示本地化
.. 文法的本地化
.. 源端数据
.. 训练
.. 测试
. 总结
第章 聚合自然语言处理引擎
. 概述
. 聚合语音和NLP引擎架构的期望属性
.. 灵活的分布式组件化
.. 计算效率
.. 数据操作功能
.. 鲁棒性处理
. 聚合的架构
.. UIMA
.. GATE
.. InfoSphere Streams
. 案例研究
.. GALE 互操作性演示系统
.. 跨语言自动语言开发系统
.. 实时翻译服务
. 经验教训
.. 分割涉及延迟和精度之间的权衡
.. 联合优化与互操作性
.. 数据模型需要使用约定
.. 性能评估的挑战
.. 引擎的前向波训练
. 总结
. UIMA样本代码
索引
・ ・ ・ ・ ・ ・ (收起)★★第篇 入门――基础知识与编程框架
-
★第章 BERT模型很强大，你值得拥有 /
★. 全球欢腾，喜迎BERT模型 /
★. 为什么BERT模型这么强 /
★. 怎么学习BERT模型 /
.. BERT模型的技术体系 /
.. 学好自然语言处理的件套――神经网络的基础知识、NLP的基础知识、编程框架的使用、BERT模型的原理及应用 /
.. 学习本书的前提条件 /
★. 自然语言处理的技术趋势 /
.. 基于超大规模的高精度模型 /
.. 基于超小规模的高精度模型 /
.. 基于小样本训练的模型 /
-
★第章 神经网络的基础知识――可能你掌握得也没有那么牢 /
★. 什么是神经网络 /
.. 神经网络能解决哪些问题 /
.. 神经网络的发展 /
.. 什么是深度学习 /
.. 什么是图神经网络 /
.. 什么是图深度学习 /
★. 神经网络的工作原理 /
.. 了解单个神经元 /
.. 生物神经元与计算机神经元模型的结构相似性 /
.. 生物神经元与计算机神经元模型的工作流程相似性 /
.. 神经网络的形成 /
★. 深度学习中包含了哪些神经网络 /
.. 全连接神经网络 /
.. 卷积神经网络 /
.. 循环神经网络 /
.. 带有注意力机制的神经网络 /
.. 自编码神经网络 /
★. 图深度学习中包含哪些神经网络 /
.. 同构图神经网络 /
.. 异构图神经网络 /
★. 激活函数――加入非线性因素，以解决线性模型的缺陷 /
.. 常用的激活函数 /
.. 更好的激活函数――Swish()与Mish() /
.. 更适合NLP任务的激活函数――GELU() /
.. 激活函数总结 /
.. 分类任务与Softmax算法 /
★. 训练模型的原理 /
.. 反向传播与BP算法 /
.. 神经网络模块中的损失函数 /
.. 学习率 /
.. 优化器 /
.. 训练模型的相关算法，会用就行 /
★. 【实例】用循环神经网络实现退位减法 /
★. 训练模型中的常见问题及优化技巧 /
.. 过拟合与欠拟合问题 /
.. 改善模型过拟合的方法 /
.. 了解正则化技巧 /
.. 了解Dropout技巧 /
.. Targeted Dropout与Multi-sample Dropout /
.. 批量归一化（BN）算法 /
.. 多种BN算法的介绍与选取 /
.. 全连接网络的深浅与泛化能力的联系 /
-
★第章 NLP的基础知识――NLP没那么“玄” /
★. NLP的本质与原理 /
.. 情感分析、相似度分析等任务的本质 /
.. 完形填空、实体词识别等任务的本质 /
.. 文章摘要任务、问答任务、翻译任务的本质 /
★. NLP的常用工具 /
.. 自然语言处理工具包――SpaCy /
.. 中文分词工具――Jieba /
.. 中文转拼音工具――Pypinyin /
.. 评估翻译质量的算法库――SacreBLEU /
★. 计算机中的字符编码 /
.. 什么是ASCII编码 /
.. 为什么会出现乱码问题 /
.. 什么是Unicode /
.. 借助Unicode 处理中文字符的常用操作 /
★. 计算机中的词与句 /
.. 词表与词向量 /
.. 词向量的原理及意义 /
.. 多项式分布 /
.. 什么是依存关系分析 /
.. 什么是TF /
.. 什么是IDF /
.. 什么是TF-IDF /
.. 什么是BLEU /
★. 什么是语言模型 /
.. 统计语言模型 /
.. CBOW与Skip-Gram语言模型 /
.. 自编码（Auto Encoding，AE）语言模型 /
.. 自回归（Auto Regressive，AR）语言模型 /
★. 文本预处理的常用方法 /
.. NLP数据集的获取与清洗 /
.. 基于马尔可夫链的数据增强 /
-
★第章 搭建编程环境――从安装开始，更适合零基础入门 /
★. 编程框架介绍 /
.. PyTorch介绍 /
.. DGL库介绍 /
.. 支持BERT模型的常用工具库介绍 /
★. 搭建Python开发环境 /
★. 搭建PyTorch开发环境 /
★. 搭建DGL环境 /
★. 安装Transformers库 /
-
★★第篇 基础――神经网络与BERT模型
★第章 PyTorch编程基础 /
★. 神经网络中的基础数据类型 /
★. 矩阵运算的基础 /
.. 转置矩阵 /
.. 对称矩阵及其特性 /
.. 对角矩阵与单位矩阵 /
.. 阿达玛积（Hadamard Product） /
.. 点积（Dot Product） /
.. 对角矩阵的特性与操作方法 /
★. PyTorch中的张量 /
.. 定义张量的方法 /
.. 生成随机值张量 /
.. 张量的基本操作 /
.. 在CPU和GPU控制的内存中定义张量 /
.. 张量间的数据操作 /
★. Variable类型与自动微分模块 /
.. Variable对象与Tensor对象之间的转换 /
.. 控制梯度计算的方法 /
.. Variable对象的属性 /
★. 【实例】用PyTorch实现一个简单模型 /
.. 准备可复现的随机数据 /
.. 实现并训练模型 /
.. 可视化模型能力 /
★. 定义模型结构的常用方法 /
.. Module类的使用方法 /
.. 模型中的参数（Parameters变量） /
.. 为模型添加参数 /
.. 从模型中获取参数 /
.. 激活模型接口 /
.. L正则化接口 /
.. Dropout接口 /
.. 批量归一化接口 /
.. 【实例】手动实现BN的计算方法 /
★. 保存与载入模型的常用方法 /
★. 训练模型的接口与使用 /
.. 选取训练模型中的损失函数 /
.. 【实例】Softmax接口的使用 /
.. 优化器的使用与优化参数的查看 /
.. 用退化学习率训练模型 /
.. 为模型添加钩子函数 /
.. 多显卡的训练方法 /
.. 梯度累加的训练方法 /
★. 处理数据集的接口与使用 /
.. 用DataLoader类实现自定义数据集 /
.. DataLoader类中的多种采样器子类 /
.. Torchtext工具与内置数据集 /
★. 【实例】训练中文词向量 /
.. 用Jieba库进行中文样本预处理 /
.. 按照Skip-Gram规则制作数据集 /
.. 搭建模型并进行训练 /
.. 夹角余弦值介绍 /
★. 卷积神经网络的实现 /
.. 了解卷积接口 /
.. 卷积操作的类型 /
.. 卷积参数与卷积结果的计算规则 /
.. 【实例】卷积函数的使用 /
.. 了解池化接口 /
.. 【实例】池化函数的使用 /
★. 【实例】用卷积神经网络实现文本分类任务 /
.. 了解用于文本分类的卷积网络――TextCNN模型 /
.. 编写代码实现实例 /
.. 用多GPU并行训练模型 /
.. 在多GPU的训练过程中，保存/读取模型文件的注意事项 /
.. 处理显存残留问题 /
★. RNN的实现 /
.. LSTM与GRU接口的实现 /
.. 多项式分布采样接口 /
★. 【实例】用RNN训练语言模型 /
.. 实现语言模型的思路与步骤 /
.. 准备样本与代码实现 /
★. 【实例】手动实现一个带有自注意力机制的模型 /
★. 【实例】利用带注意力机制的循环神经网络对文本进行分类 /
.. 制作等长数据集并实现LSTM模型 /
.. 用梯度剪辑技巧优化训练过程 /
-
★第章 BERT模型的原理 /
★. BERT模型的起源――Transformer模型 /
.. Transformer模型出现之前的主流模型 /
.. Transformer模型的原理 /
.. Transformer模型的优缺点 /
★. 【实例】用Transformer模型进行中/英文翻译 /
★. BERT模型的原理 /
.. BERT模型的训练过程 /
.. BERT模型的预训练方法 /
.. BERT模型的掩码机制 /
.. BERT模型的训练参数 /
.. BERT模型的缺点 /
★. 高精度的BERTology系列模型 /
.. 适合生成文章的模型――GPT模型 /
.. 支持人机对话的模型――DialoGPT模型 /
.. 融合了BERT模型与GPT技术的模型――MASS模型 /
.. 支持长文本输入的模型――Transformer-XL模型 /
.. 支持更长文本的模型――XLNet模型 /
.. 弥补XLNet模型不足的模型――MPNet模型 /
.. 稳健性更好的模型――RoBERTa模型 /
.. 使用了稀疏注意力的模型――Longformer、BigBird模型 /
.. 基于词掩码的模型――BERT-WWM、Wo BERT等模型 /
.. 基于小段文字掩码的模型――SpanBERT模型 /
.. 适合翻译任务的模型――T模型 /
.. 支持多种语言的翻译模型――XLM、XLM-Roberta模型 /
.. 既能阅读又能写作的模型――UniLM .模型 /
.. 适用于语法纠错任务的模型――StructBERT、Bart模型 /
.. 可以进行定向写作的模型――CTRL模型 /
.. 适合摘要生成的模型――PEGASUS模型 /
.. 支持更多语言的模型――T-ULR v模型 /
★. 小规模的BERTology系列模型 /
.. 比RoBERTa模型训练速度更快的模型――ELECTRA模型 /
.. 适用于文本分类的超小模型――PRADO、pQRNN模型 /
.. 比BERT模型更适合于部署场景的模型――DistillBERT模型 /
.. 比BERT模型更快的模型――FastBERT模型 /
.. 带有通用蒸馏方案的模型――MiniLM模型 /
.. 精简版的BERT模型――ALBERT、ALBERT_tiny、ALBERT V模型 /
★. BERTology系列模型的预训练方法总结 /
.. AE式训练方法的常用策略 /
.. 更多的训练经验 /
-
★第章 BERT模型的快速应用――BERT模型虽然强大，使用却不复杂！ /
★. 了解Transformers库 /
★. Transformers库的层应用结构 /
★. 【实例】用Transformers库的管道方式完成多种NLP任务 /
.. 在管道方式中指定NLP任务 /
.. 代码实现：完成文本分类任务 /
.. 代码实现：完成特征提取任务 /
.. 代码实现：完成完形填空任务 /
.. 代码实现：完成阅读理解任务 /
.. 代码实现：完成摘要生成任务 /
.. 预训练模型文件的组成与其加载时的固定名称 /
.. 代码实现：完成实体词识别任务 /
.. 管道方式的工作原理 /
.. 在管道方式中应用指定模型 /
★. Transformers库中的自动模型（AutoModel）类 /
.. 各种AutoModel类 /
.. AutoModel类的模型加载机制 /
.. Transformers库中的其他语言模型 /
★. Transformers库中的BERTology系列模型 /
.. Transformers库的文件结构 /
.. 获取和加载预训练模型文件 /
.. 查找Transformers库中可以使用的模型 /
.. 【实例】用BERT模型实现完形填空任务 /
.. 【扩展实例】用自动模型类替换BertForMaskedLM类 /
★. Transformers库中的词表工具 /
.. PreTrainedTokenizer类中的特殊词 /
.. PreTrainedTokenizer类中的特殊词的使用 /
.. 向PreTrainedTokenizer类中添加词 /
.. 【实例】用手动加载GPT-模型权重的方式将句子补充完整 /
.. 子词拆分 /
★. 【实例】用迁移学习训练BERT模型来对中文分类 /
.. NLP中的迁移学习 /
.. 构建数据集 /
.. 构建并加载BERT模型的预训练模型 /
.. Transformers库中的底层类 /
.. 用退化学习率训练模型 /
.. 用数据增强方法训练模型 /
-
★第章 模型的可解释性――深入模型内部，探究其工作的根源
★. 模型的可解释库 /
.. 了解Captum库 /
.. Captum库的可视化工具――Captum Insights /
★. 什么是梯度积分方法 /
★. 【实例】对NLP模型的可解释性分析 /
.. 分析词嵌入模型 /
.. 拆解NLP模型的处理过程 /
.. 用Captum库提取NLP模型的词嵌入层 /
.. 用梯度积分的方法计算模型的可解释性 /
.. 可视化模型的可解释性 /
★. 【实例】BERT模型的可解释性分析 /
.. 了解BERT模型的可解释性工具――Bertviz /
.. 用Bertviz工具可视化BERT模型的权重 /
.. 分析BERT模型的权重参数 /
★. 用图神经网络解释BERT模型 /
.. 点积计算与聚合计算的关系 /
.. 从图的角度思考BERT模型 /
-
★★第篇 BERT模型实战★★
★第章 图神经网络与BERT模型的结合★
★. 图神经网络基础 /
.. 图的相关术语和操作 /
.. 图卷积神经网络 /
★. DGL库的使用方法 /
.. 创建图结构 /
.. DGL库与NetWorkx库的相互转换 /
.. 图的基本操作 /
.. 图的消息传播机制 /
.. DGL库中的多图处理 /
★. 【实例】用图节点的聚合方法实现BERT模型 /
.. 基于Transformers库的BERT模型修改方案 /
.. 实现图节点聚合的核心代码 /
.. 将原BERT模型的权重应用到基于图节点聚合方法实现的BERT模型上 /
★. 什么是关系图卷积网络（R-GCN）模型 /
.. R-GCN模型的原理 /
.. 基于R-GCN模型的优化 /
.. R-GCN模型的实现 /
★. 【实例】用R-GCN模型理解文本中的代词 /
.. 代词数据集（GAP）介绍 /
.. 将GAP数据集转换成“图”结构数据的思路 /
.. 用BERT模型提取代词特征 /
.. 用BERT模型提取其他词特征 /
.. 用SpaCy工具和批次图方法构建图数据集 /
.. 搭建多层R-GCN模型 /
.. 用折交叉验证方法训练模型 /
-
★第章 BERT模型的行业应用 ★
★. BERT模型在文本纠错领域的应用 /
.. 文本纠错中的常见任务及解决办法 /
.. 理解BERT模型的纠错能力 /
.. 改进BERT模型使其具有更强的纠错能力 /
.. 专用于文本纠错的模型――Soft-Masked BERT模型 /
.. 基于图神经网络的文本纠错模型――SpellGCN模型 /
.. 【实例】用Transformers和DGL库实现SpellGCN模型 /
★. BERT技术在聊天机器人领域的应用 /
.. 聊天机器人的种类与实现技术 /
.. 基于BERT模型完成聊天任务的思路 /
.. 【实例】用累加梯度训练支持中文的DialoGPT模型 /
.. 更强大的多轮聊天模型――Meena模型 /
★. BERT模型在服务器端部署的应用 /
.. 用transformers-cli工具快速部署BERT模型 /
.. 用torchserve库部署BERT模型 /
・ ・ ・ ・ ・ ・ (收起)第篇 自然语言处理基础篇
第章 自然语言处理概述 
. 什么是自然语言处理 
.. 定义 
.. 常用术语 
.. 自然语言处理的任务 
.. 自然语言处理的发展历程 
. 自然语言处理中的挑战 
.. 歧义问题 
.. 语言的多样性 
.. 未登录词 
.. 数据稀疏 
. 自然语言处理中的常用技术 
. 机器学习中的常见问题 
.. Batch和Epoch 
.. Batch Size的选择 
.. 数据集不平衡问题 
.. 预训练模型与数据安全 
.. 通过开源代码学习 
. 小结 
第章 Python自然语言处理基础 
. 搭建环境 
.. 选择Python版本 
.. 安装Python 
.. 使用pip包管理工具和Python虚拟环境 
.. 使用集成开发环境 
.. 安装Python自然语言处理常用的库 
. 用Python处理字符串 
.. 使用str类型 
.. 使用StringIO类 
. 用Python处理语料 
.. 从文件读取语料 
.. 去重 
.. 停用词 
.. 编辑距离 
.. 文本规范化 
.. 分词 
.. 词频-逆文本频率 
.. One-Hot 编码 
. Python的一些特性 
.. 动态的解释型语言 
.. 跨平台 
.. 性能问题 
.. 并行和并发 
. 在Python中调用其他语言 
.. 通过ctypes调用C/C++代码 
.. 通过网络接口调用其他语言 
. 小结 
第篇 PyTorch入门篇
第章 PyTorch介绍 
. 概述 
. 与其他框架的比较 
.. TensorFlow 
.. PaddlePaddle 
.. CNTK 
. PyTorch环境配置 
.. 通过pip安装 
.. 配置GPU环境 
.. 其他安装方法 
.. 在PyTorch中查看GPU是否可用 
. Transformers简介及安装 
. Apex简介及安装 
. 小结 
第章 PyTorch基本使用方法 
. 张量的使用 
.. 创建张量 
.. 张量的变换 
.. 张量的索引 
.. 张量的运算 
. 使用torch.nn 
. 激活函数 
.. Sigmoid函数 
.. Tanh函数 
.. ReLU函数 
.. Softmax函数 
.. Softmin函数 
.. LogSoftmax函数 
. 损失函数 
.. -损失函数 
.. 平方损失函数 
.. 绝对值损失函数 
.. 对数损失函数 
. 优化器 
.. SGD优化器 
.. Adam优化器 
.. AdamW优化器 
. 数据加载 
.. Dataset 
.. DataLoader 
. 使用PyTorch实现逻辑回归 
.. 生成随机数据 
.. 数据可视化 
.. 定义模型 
.. 训练模型 
. TorchText 
.. 安装TorchText 
.. Data类 
.. Datasets类 
.. Vocab 
.. utils 
. 使用TensorBoard 
.. 安装和启动TensorBoard 
.. 在PyTorch中使用TensorBoard 
. 小结 
第章 热身：使用字符级RNN分类帖子 
. 数据与目标 
.. 数据 
.. 目标 
. 输入与输出 
.. 统计数据集中出现的字符数量 
.. 使用One-Hot编码表示标题数据 
.. 使用词嵌入表示标题数据 
.. 输出 
. 字符级RNN 
.. 定义模型 
.. 运行模型 
. 数据预处理 
.. 合并数据并添加标签 
.. 划分训练集和数据集 
. 训练与评估 
.. 训练 
.. 评估 
.. 训练模型 
. 保存和加载模型 
.. 仅保存模型参数 
.. 保存模型与参数 
.. 保存词表 
. 开发应用 
.. 给出任意标题的建议分类 
.. 获取用户输入并返回结果 
.. 开发Web API和Web界面 
. 小结 
第篇 用PyTorch完成自然语言处理任务篇
第章 分词问题 
. 中文分词 
.. 中文的语言结构 
.. 未收录词 
.. 歧义 
. 分词原理 
.. 基于词典匹配的分词 
.. 基于概率进行分词 
.. 基于机器学习的分词 
. 使用第三方工具分词 
.. S-MSRSeg 
.. ICTCLAS 
.. 结巴分词 
.. pkuseg 
. 实践 
.. 对标题分词 
.. 统计词语数量与模型训练 
.. 处理用户输入 
. 小结 
第章 RNN 
. RNN的原理 
.. 原始RNN 
.. LSTM 
.. GRU 
. PyTorch中的RNN 
.. 使用RNN 
.. 使用LSTM和GRU 
.. 双向RNN和多层RNN 
. RNN可以完成的任务 
.. 输入不定长，输出与输入长度相同 
.. 输入不定长，输出定长 
.. 输入定长，输出不定长 
. 实践：使用PyTorch自带的RNN完成帖子分类 
.. 载入数据 
.. 定义模型 
.. 训练模型 
. 小结 
第章 词嵌入 
. 概述 
.. 词表示 
.. PyTorch中的词嵌入 
. Wordvec 
.. Wordvec简介 
.. CBOW 
.. SG 
.. 在PyTorch中使用Wordvec 
. GloVe 
.. GloVe的原理 
.. 在PyTorch中使用GloVe预训练词向量 
. 实践：使用预训练词向量完成帖子标题分类 
.. 获取预训练词向量 
.. 加载词向量 
.. 方法一：直接使用预训练词向量 
.. 方法二：在Embedding层中载入预训练词向量 
. 小结 
第章 Seqseq 
. 概述 
.. 背景 
.. 模型结构 
.. 训练技巧 
.. 预测技巧 
. 使用PyTorch实现Seqseq 
.. 编码器 
.. 解码器 
.. Seqseq 
.. Teacher Forcing 
.. Beam Search 
. 实践：使用Seqseq完成机器翻译任务 
.. 数据集 
.. 数据预处理 
.. 构建训练集和测试集 
.. 定义模型 
.. 初始化模型 
.. 定义优化器和损失函数 
.. 训练函数和评估函数 
.. 训练模型 
.. 测试模型 
. 小结 
第章 注意力机制 
. 注意力机制的起源 
.. 在计算机视觉中的应用 
.. 在自然语言处理中的应用 
. 使用注意力机制的视觉循环模型 
.. 背景 
.. 实现方法 
. Seqseq中的注意力机制 
.. 背景 
.. 实现方法 
.. 工作原理 
. 自注意力机制 
.. 背景 
.. 自注意力机制相关的工作 
.. 实现方法与应用 
. 其他注意力机制 
. 小结 
第章 Transformer 
. Transformer的背景 
.. 概述 
.. 主要技术 
.. 优势和缺点 
. 基于卷积网络的Seqseq 
. Transformer的结构 
.. 概述 
.. Transformer中的自注意力机制 
.. Multi-head Attention 
.. 使用Positional Encoding 
. Transformer的改进 
. 小结 
第章 预训练语言模型 
. 概述 
.. 为什么需要预训练 
.. 预训练模型的工作方式 
.. 自然语言处理预训练的发展 
. ELMo 
.. 特点 
.. 模型结构 
.. 预训练过程 
. GPT 
.. 特点 
.. 模型结构 
.. 下游任务 
.. 预训练过程 
.. GPT-和GPT- 
. BERT 
.. 背景 
.. 模型结构 
.. 预训练 
.. RoBERTa和ALBERT 
. Hugging Face Transformers 
.. 概述 
.. 使用Transformers 
.. 下载预训练模型 
.. Tokenizer 
.. BERT的参数 
.. BERT的使用 
.. GPT-的参数 
.. 常见错误及其解决方法 
. 其他开源中文预训练模型 
.. TAL-EduBERT 
.. Albert 
. 实践：使用Hugging Face Transformers中的BERT做帖子标题分类 
.. 读取数据 
.. 导入包和设置参数 
.. 定义Dataset和DataLoader 
.. 定义评估函数 
.. 定义模型 
.. 训练模型 
. 小结 
第篇 实战篇
第章 项目：中文地址解析 
. 数据集 
.. 实验目标与数据集介绍 
.. 载入数据集 
. 词向量 
.. 查看词向量文件 
.. 载入词向量 
. BERT 
.. 导入包和配置 
.. Dataset和DataLoader 
.. 定义模型 
.. 训练模型 
.. 获取预测结果 
. HTML演示程序开发 
.. 项目结构 
.. HTML界面 
.. 创建前端事件 
.. 服务器逻辑 
. 小结 
第章 项目：诗句补充 
. 了解chinese-poetry数据集 
.. 下载chinese-poetry数据集 
.. 探索chinese-poetry数据集 
. 准备训练数据 
.. 选择数据源 
.. 载入内存 
.. 切分句子 
.. 统计字频 
.. 删除低频字所在诗句 
.. 词到ID的转换 
. 实现基本的LSTM 
.. 把处理好的数据和词表存入文件 
.. 切分训练集和测试集 
.. Dataset 
.. DataLoader 
.. 创建Dataset和DataLoader对象 
.. 定义模型 
.. 测试模型 
.. 训练模型 
. 根据句子长度分组 
.. 按照句子长度分割数据集 
.. 不用考虑填充的DataLoader 
.. 创建多个DataLoader对象 
.. 处理等长句子的LSTM 
.. 评估模型效果 
.. 训练模型 
. 使用预训练词向量初始化Embedding层 
.. 根据词向量调整字表 
.. 载入预训练权重 
.. 训练模型 
. 使用Transformer完成诗句生成 
.. 位置编码 
.. 使用Transformer 
.. 训练和评估 
. 使用GPT-完成对诗模型 
.. 预训练模型 
.. 评估模型 
.. Fine-tuning 
. 开发HTML演示程序 
.. 目录结构 
.. HTML界面 
.. 创建前端事件 
.. 服务器逻辑 
.. 检验结果 
. 小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第 章 深度学习――机器大脑的结构 
. 概述 
.. 可以做酸奶的面包机――通用机器的概念 
.. 连接主义 
.. 用机器设计机器 
.. 深度网络 
.. 深度学习的用武之地 
. 从人脑神经元到人工神经元 
.. 生物神经元中的计算灵感 
.. 激活函数 
. 参数学习 
.. 模型的评价 
.. 有监督学习 
.. 梯度下降法 
. 多层前馈网络 
.. 多层前馈网络 
.. 后向传播算法计算梯度 
. 逐层预训练 
. 深度学习是终极神器吗 
.. 深度学习带来了什么 
.. 深度学习尚未做到什么 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 知识图谱――机器大脑中的知识库 
. 什么是知识图谱 
. 知识图谱的构建 
.. 大规模知识库 
.. 互联网链接数据 
.. 互联网网页文本数据 
.. 多数据源的知识融合 
. 知识图谱的典型应用 
.. 查询理解（Query Understanding） 
.. 自动问答（Question Answering） 
.. 文档表示（Document Representation） 
. 知识图谱的主要技术 
.. 实体链指（Entity Linking） 
.. 关系抽取（Relation Extraction） 
.. 知识推理（Knowledge Reasoning） 
.. 知识表示（Knowledge Representation） 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 大数据系统――大数据背后的支撑技术 
. 概述 
. 高性能计算技术 
.. 超级计算机的组成 
.. 并行计算的系统支持 
. 虚拟化和云计算技术 
.. 虚拟化技术 
.. 云计算服务 
. 基于分布式计算的大数据系统 
.. Hadoop 生态系统 
.. Spark 
.. 典型的大数据基础架构 
. 大规模图计算 
.. 分布式图计算框架 
.. 高效的单机图计算框架 
. NoSQL 
.. MongoDB 简介 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 智能问答――智能助手是如何炼成的 
. 概述 
. 问答系统的主要组成 
. 文本问答系统 
.. 问题理解 
.. 知识检索 
.. 答案生成 
. 社区问答系统 
.. 社区问答系统的结构 
.. 相似问题检索 
.. 答案过滤 
. 多媒体问答系统 
. 大型问答系统案例：IBM 沃森问答系统 
.. 沃森的总体结构 
.. 问题解析 
.. 知识储备 
.. 检索和候选答案生成 
.. 可信答案确定 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 主题模型――机器的智能摘要利器 
. 概述 
. 主题模型出现的背景 
. 第一个主题模型潜在语义分析 
. 第一个正式的概率主题模型 
. 第一个正式的贝叶斯主题模型 
. LDA 的概要介绍 
.. LDA 的延伸理解――主题模型广义理解 
.. 模型求解 
.. 模型评估 
.. 模型选择：主题数目的确定 
. 主题模型的变形与应用 
.. 基于LDA 的模型变种 
.. 基于LDA 的典型应用 
.. 一个基于主题模型的新浪名人话题排行榜应用 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 个性化推荐系统――如何了解电脑背后的TA 
. 概述 
.. 推荐系统的发展历史 
.. 推荐无处不在 
.. 从千人一面到千人千面 
. 个性化推荐的基本问题 
.. 推荐系统的输入 
.. 推荐系统的输出 
.. 个性化推荐的形式化 
.. 推荐系统的三大核心问题 
. 典型推荐算法浅析 
.. 推荐算法的分类 
.. 典型推荐算法介绍 
.. 基于矩阵分解的打分预测 
.. 推荐的可解释性 
.. 推荐算法的评价 
.. 我们走了多远 
. 参考文献 
第 章 情感分析与意见挖掘――计算机如何了解人类情感 
. 概述 
. 情感分析的主要研究问题 
. 情感分析的主要方法 
.. 构成情感和观点的基本元素 
.. 情感极性与情感词典 
.. 属性－观点对 
.. 情感分析 
. 主要的情感词典资源 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 面向社会媒体大数据的语言使用分析及应用 
. 概述 
. 面向社会媒体的自然语言使用分析 
.. 词汇的时空传播与演化 
.. 语言使用与个体差异 
.. 语言使用与社会地位 
.. 语言使用与群体分析 
. 面向社会媒体的自然语言分析应用 
.. 社会预测 
.. 霸凌现象定量分析 
. 未来研究的挑战与展望 
. 参考文献 
后 记 
国际学术组织、学术会议与学术论文 
国内学术组织、学术会议与学术论文 
如何快速了解某个领域的研究进展 
・ ・ ・ ・ ・ ・ (收起) 深度计算――机器大脑的结构 
. 惊人的深度学习 
.. 可以做酸奶的面包机：通用机器的概念 
.. 连接主义 
.. 用机器设计机器 
.. 深度网络 
.. 深度学习的用武之地 
. 从人脑神经元到人工神经元 
.. 生物神经元中的计算灵感 
.. 激活函数 
. 参数学习 
.. 模型的评价 
.. 有监督学习 
.. 梯度下降法 
. 多层前馈网络 
.. 多层前馈网络 
.. 后向传播算法计算梯度 
. 逐层预训练 
. 深度学习是终极神器吗 
.. 深度学习带来了什么 
.. 深度学习尚未做到什么 
. 内容回顾与推荐阅读 . 
. 参考文献 
 知识图谱――机器大脑中的知识库 
. 什么是知识图谱 
. 知识图谱的构建 
.. 大规模知识库 
.. 互联网链接数据 
.. 互联网网页文本数据 
.. 多数据源的知识融合 
. 知识图谱的典型应用 
.. 查询理解 
.. 自动问答 
.. 文档表示 
. 知识图谱的主要技术 
.. 实体链指 
.. 关系抽取 
.. 知识推理 
.. 知识表示 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 大数据系统――大数据背后的支撑技术 
. 大数据有多大 
. 高性能计算技术 
.. 超级计算机的组成 
.. 并行计算的系统支持 
. 虚拟化和云计算技术 
.. 虚拟化技术 
.. 云计算服务 
. 基于分布式计算的大数据系统 
.. Hadoop 生态系统 
.. Spark 
.. 典型的大数据基础架构 
. 大规模图计算 
.. 分布式图计算框架 
.. 高效的单机图计算框架 
. NoSQL 
.. NoSQL 数据库的类别 
.. MongoDB 简介 
. 内容回顾与推荐阅读 
. 参考文献 
 主题模型――机器的智能摘要利器 
. 由文档到主题 
. 主题模型出现的背景 
. 第一个主题模型：潜在语义分析 
. 第一个正式的概率主题模型 
. 第一个正式的贝叶斯主题模型 
. LDA 的概要介绍 
.. LDA 的延伸理解：主题模型广义理解 . 
.. 模型求解 
.. 模型评估 
.. 模型选择：主题数目的确定 
. 主题模型的变形与应用 
.. 基于 LDA 的变种模型 
.. 基于 LDA 的典型应用 
.. 基于主题模型的新浪名人话题排行榜应用 
. 内容回顾与推荐阅读 
. 参考文献 
 机器翻译――机器如何跨越语言障碍 
. 机器翻译的意义 
. 机器翻译的发展历史 
.. 基于规则的机器翻译 
.. 基于语料库的机器翻译 
.. 基于神经网络的机器翻译 
. 经典的神经网络机器翻译模型 
.. 基于循环神经网络的神经网络机器翻译 
.. 从卷积序列到序列模型 
.. 基于自注意力机制的 Transformer 模型 
. 机器翻译译文质量评价 
. 机器翻译面临的挑战 
. 参考文献 
 情感分析与意见挖掘――机器如何了解人类情感 
. 情感可以计算吗 
. 哪里需要文本情感分析 . 
.. 情感分析的宏观反映 
.. 情感分析的微观特征 
. 情感分析的主要研究问题 
. 情感分析的主要方法 
.. 构成情感和观点的基本元素 
.. 情感极性与情感词典 
.. 属性－观点对 
.. 情感极性分析 
. 主要的情感分析资源 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能问答与对话系统――智能助手是如何炼成的 
. 问答：图灵测试的基本形式 
. 从问答到对话 
.. 对话系统的基本过程 
.. 文本对话系统的常见场景 
. 问答系统的主要组成 
. 文本问答系统 
.. 问题理解 
.. 知识检索 
.. 答案生成 
. 端到端的阅读理解问答技术 
.. 什么是阅读理解任务 
.. 阅读理解任务的模型 
.. 阅读理解任务的其他工程技巧 
. 社区问答系统 
.. 社区问答系统的结构 
.. 相似问题检索 
.. 答案过滤 
.. 社区问答的应用 
. 多媒体问答系统 
. 大型问答系统案例：IBM 沃森问答系统 
.. 沃森的总体结构 
.. 问题解析 
.. 知识储备 
.. 检索和候选答案生成 
.. 可信答案确定 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 个性化推荐系统――如何了解计算机背后的他 
. 什么是推荐系统 
. 推荐系统的发展历史 
.. 推荐无处不在 
.. 从千人一面到千人千面 
. 个性化推荐的基本问题 
.. 推荐系统的输入 
.. 推荐系统的输出 
.. 个性化推荐的基本形式 
.. 推荐系统的三大核心问题 
. 典型推荐算法浅析 
.. 推荐算法的分类 
.. 典型推荐算法介绍 
.. 基于矩阵分解的打分预测 
.. 基于神经网络的推荐算法 
. 推荐的可解释性 
. 推荐算法的评价 
.. 评分预测的评价 
.. 推荐列表的评价 
.. 推荐理由的评价 
. 前景与挑战：我们走了多远 
.. 推荐系统面临的问题 
.. 推荐系统的新方向 
. 内容回顾与推荐阅读 
. 参考文献 
 机器写作――从分析到创造 
. 什么是机器写作 
. 艺术写作 
.. 机器写诗 
.. AI 对联 
. 当代写作 
.. 机器写稿 
.. 机器故事生成 
. 内容回顾 
. 参考文献 
 社交商业数据挖掘――从用户数据挖掘到商业智能应用 
. 社交媒体平台中的数据宝藏 . 
. 打通网络社区的束缚：用户网络社区身份的链指与融合 
. 揭开社交用户的面纱：用户画像的构建 
.. 基于显式社交属性的构建方法 
.. 基于网络表示学习的构建方法 
.. 产品受众画像的构建 
. 了解用户的需求：用户消费意图的识别 
.. 个体消费意图识别 
.. 群体消费意图识别 
. 精准的供需匹配：面向社交平台的产品推荐算法 
.. 候选产品列表生成 
.. 基于学习排序算法的推荐框架 
.. 基于用户属性的排序特征构建 
.. 推荐系统的整体设计概览 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧医疗――信息技术在医疗领域应用的结晶 
. 智慧医疗的起源 
. 智慧医疗的庐山真面目 
. 智慧医疗中的人工智能应用 
.. 医疗过程中的人工智能应用 
.. 医疗研究中的人工智能应用 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧司法――智能技术促进司法公正 
. 智能技术与法律的碰撞 . 
. 智慧司法相关研究 . 
.. 法律智能的早期研究 
.. 判决预测：虚拟法官的诞生与未来 
.. 文书生成：司法过程简化 
.. 要素提取：司法结构化 
.. 类案匹配：解决一案多判 
.. 司法问答：让机器理解法律 
. 智慧司法的期望偏差与应用挑战 
.. 智慧司法的期望偏差 
.. 智慧司法的应用挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能金融――机器金融大脑 
. 智能金融正当其时 
.. 什么是智能金融 
.. 智能金融与金融科技、互联网金融的异同 
.. 智能金融适时而生 
. 智能金融技术 
.. 大数据的机遇与挑战 
.. 智能金融中的自然语言处理 
.. 金融事理图谱 
.. 智能金融中的深度学习 
. 智能金融应用 
.. 智能投顾 
.. 智能研报 
.. 智能客服 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 计算社会学――透过大数据了解人类社会 
. 透过数据了解人类社会 
. 面向社会媒体的自然语言使用分析 
.. 词汇的时空传播与演化 
.. 语言使用与个体差异 
.. 语言使用与社会地位 
.. 语言使用与群体分析 
. 面向社会媒体的自然语言分析应用 
.. 社会预测 
.. 霸凌现象定量分析 
. 未来研究的挑战与展望 
. 参考文献 
后记 
・ ・ ・ ・ ・ ・ (收起) 深度计算――机器大脑的结构 
. 惊人的深度学习 
.. 可以做酸奶的面包机：通用机器的概念 
.. 连接主义 
.. 用机器设计机器 
.. 深度网络 
.. 深度学习的用武之地 
. 从人脑神经元到人工神经元 
.. 生物神经元中的计算灵感 
.. 激活函数 
. 参数学习 
.. 模型的评价 
.. 有监督学习 
.. 梯度下降法 
. 多层前馈网络 
.. 多层前馈网络 
.. 后向传播算法计算梯度 
. 逐层预训练 
. 深度学习是终极神器吗 
.. 深度学习带来了什么 
.. 深度学习尚未做到什么 
. 内容回顾与推荐阅读 . 
. 参考文献 
 知识图谱――机器大脑中的知识库 
. 什么是知识图谱 
. 知识图谱的构建 
.. 大规模知识库 
.. 互联网链接数据 
.. 互联网网页文本数据 
.. 多数据源的知识融合 
. 知识图谱的典型应用 
.. 查询理解 
.. 自动问答 
.. 文档表示 
. 知识图谱的主要技术 
.. 实体链指 
.. 关系抽取 
.. 知识推理 
.. 知识表示 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 大数据系统――大数据背后的支撑技术 
. 大数据有多大 
. 高性能计算技术 
.. 超级计算机的组成 
.. 并行计算的系统支持 
. 虚拟化和云计算技术 
.. 虚拟化技术 
.. 云计算服务 
. 基于分布式计算的大数据系统 
.. Hadoop 生态系统 
.. Spark 
.. 典型的大数据基础架构 
. 大规模图计算 
.. 分布式图计算框架 
.. 高效的单机图计算框架 
. NoSQL 
.. NoSQL 数据库的类别 
.. MongoDB 简介 
. 内容回顾与推荐阅读 
. 参考文献 
 主题模型――机器的智能摘要利器 
. 由文档到主题 
. 主题模型出现的背景 
. 第一个主题模型：潜在语义分析 
. 第一个正式的概率主题模型 
. 第一个正式的贝叶斯主题模型 
. LDA 的概要介绍 
.. LDA 的延伸理解：主题模型广义理解 . 
.. 模型求解 
.. 模型评估 
.. 模型选择：主题数目的确定 
. 主题模型的变形与应用 
.. 基于 LDA 的变种模型 
.. 基于 LDA 的典型应用 
.. 基于主题模型的新浪名人话题排行榜应用 
. 内容回顾与推荐阅读 
. 参考文献 
 机器翻译――机器如何跨越语言障碍 
. 机器翻译的意义 
. 机器翻译的发展历史 
.. 基于规则的机器翻译 
.. 基于语料库的机器翻译 
.. 基于神经网络的机器翻译 
. 经典的神经网络机器翻译模型 
.. 基于循环神经网络的神经网络机器翻译 
.. 从卷积序列到序列模型 
.. 基于自注意力机制的 Transformer 模型 
. 机器翻译译文质量评价 
. 机器翻译面临的挑战 
. 参考文献 
 情感分析与意见挖掘――机器如何了解人类情感 
. 情感可以计算吗 
. 哪里需要文本情感分析 . 
.. 情感分析的宏观反映 
.. 情感分析的微观特征 
. 情感分析的主要研究问题 
. 情感分析的主要方法 
.. 构成情感和观点的基本元素 
.. 情感极性与情感词典 
.. 属性－观点对 
.. 情感极性分析 
. 主要的情感分析资源 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能问答与对话系统――智能助手是如何炼成的 
. 问答：图灵测试的基本形式 
. 从问答到对话 
.. 对话系统的基本过程 
.. 文本对话系统的常见场景 
. 问答系统的主要组成 
. 文本问答系统 
.. 问题理解 
.. 知识检索 
.. 答案生成 
. 端到端的阅读理解问答技术 
.. 什么是阅读理解任务 
.. 阅读理解任务的模型 
.. 阅读理解任务的其他工程技巧 
. 社区问答系统 
.. 社区问答系统的结构 
.. 相似问题检索 
.. 答案过滤 
.. 社区问答的应用 
. 多媒体问答系统 
. 大型问答系统案例：IBM 沃森问答系统 
.. 沃森的总体结构 
.. 问题解析 
.. 知识储备 
.. 检索和候选答案生成 
.. 可信答案确定 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 个性化推荐系统――如何了解计算机背后的他 
. 什么是推荐系统 
. 推荐系统的发展历史 
.. 推荐无处不在 
.. 从千人一面到千人千面 
. 个性化推荐的基本问题 
.. 推荐系统的输入 
.. 推荐系统的输出 
.. 个性化推荐的基本形式 
.. 推荐系统的三大核心问题 
. 典型推荐算法浅析 
.. 推荐算法的分类 
.. 典型推荐算法介绍 
.. 基于矩阵分解的打分预测 
.. 基于神经网络的推荐算法 
. 推荐的可解释性 
. 推荐算法的评价 
.. 评分预测的评价 
.. 推荐列表的评价 
.. 推荐理由的评价 
. 前景与挑战：我们走了多远 
.. 推荐系统面临的问题 
.. 推荐系统的新方向 
. 内容回顾与推荐阅读 
. 参考文献 
 机器写作――从分析到创造 
. 什么是机器写作 
. 艺术写作 
.. 机器写诗 
.. AI 对联 
. 当代写作 
.. 机器写稿 
.. 机器故事生成 
. 内容回顾 
. 参考文献 
 社交商业数据挖掘――从用户数据挖掘到商业智能应用 
. 社交媒体平台中的数据宝藏 . 
. 打通网络社区的束缚：用户网络社区身份的链指与融合 
. 揭开社交用户的面纱：用户画像的构建 
.. 基于显式社交属性的构建方法 
.. 基于网络表示学习的构建方法 
.. 产品受众画像的构建 
. 了解用户的需求：用户消费意图的识别 
.. 个体消费意图识别 
.. 群体消费意图识别 
. 精准的供需匹配：面向社交平台的产品推荐算法 
.. 候选产品列表生成 
.. 基于学习排序算法的推荐框架 
.. 基于用户属性的排序特征构建 
.. 推荐系统的整体设计概览 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧医疗――信息技术在医疗领域应用的结晶 
. 智慧医疗的起源 
. 智慧医疗的庐山真面目 
. 智慧医疗中的人工智能应用 
.. 医疗过程中的人工智能应用 
.. 医疗研究中的人工智能应用 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧司法――智能技术促进司法公正 
. 智能技术与法律的碰撞 . 
. 智慧司法相关研究 . 
.. 法律智能的早期研究 
.. 判决预测：虚拟法官的诞生与未来 
.. 文书生成：司法过程简化 
.. 要素提取：司法结构化 
.. 类案匹配：解决一案多判 
.. 司法问答：让机器理解法律 
. 智慧司法的期望偏差与应用挑战 
.. 智慧司法的期望偏差 
.. 智慧司法的应用挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能金融――机器金融大脑 
. 智能金融正当其时 
.. 什么是智能金融 
.. 智能金融与金融科技、互联网金融的异同 
.. 智能金融适时而生 
. 智能金融技术 
.. 大数据的机遇与挑战 
.. 智能金融中的自然语言处理 
.. 金融事理图谱 
.. 智能金融中的深度学习 
. 智能金融应用 
.. 智能投顾 
.. 智能研报 
.. 智能客服 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 计算社会学――透过大数据了解人类社会 
. 透过数据了解人类社会 
. 面向社会媒体的自然语言使用分析 
.. 词汇的时空传播与演化 
.. 语言使用与个体差异 
.. 语言使用与社会地位 
.. 语言使用与群体分析 
. 面向社会媒体的自然语言分析应用 
.. 社会预测 
.. 霸凌现象定量分析 
. 未来研究的挑战与展望 
. 参考文献 
后记 
・ ・ ・ ・ ・ ・ (收起)目 录
第章 数据革命 
. 数据生成 
. Spark 
.. Spark Core 
.. Spark组件 
. 设置环境 
.. Windows 
.. iOS 
. 小结 
第章 机器学习简介 
. 有监督机器学习 
. 无监督机器学习 
. 半监督机器学习 
. 强化学习 
. 小结 
第章 数据处理 
. 加载和读取数据 
. 添加一个新列 
. 筛选数据 
.. 条件 
.. 条件 
. 列中的非重复值 
. 数据分组 
. 聚合 
. 用户自定义函数(UDF) 
.. 传统的Python函数 
.. 使用lambda函数 
.. Pandas UDF(向量化的UDF) 
.. Pandas UDF(多列) 
. 去掉重复值 
. 删除列 
. 写入数据 
.. csv 
.. 嵌套结构 
. 小结 
第章 线性回归 
. 变量 
. 理论 
. 说明 
. 评估 
. 代码 
.. 数据信息 
.. 步骤：创建
SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程化 
.. 步骤：划分数据集 
.. 步骤：构建和训练线性回归模型 
.. 步骤：在测试数据上评估线性回归模型 
. 小结 
第章 逻辑回归 
. 概率 
.. 使用线性回归 
.. 使用Logit 
. 截距(回归系数) 
. 虚变量 
. 模型评估 
.. 正确的正面预测 
.. 正确的负面预测 
.. 错误的正面预测 
.. 错误的负面预测 
.. 准确率 
.. 召回率 
.. 精度 
.. F分数 
.. 截断/阈值概率 
.. ROC曲线 
. 逻辑回归代码 
.. 数据信息 
.. 步骤：创建Spark会话对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：划分数据集 
.. 步骤：构建和训练逻辑回归模型 
.. 训练结果 
.. 步骤：在测试数据上评估线性回归模型 
.. 混淆矩阵 
. 小结 
第章 随机森林 
. 决策树 
.. 熵 
.. 信息增益 
. 随机森林 
. 代码 
.. 数据信息 
.. 步骤：创建SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：划分数据集 
.. 步骤：构建和训练随机森林模型 
.. 步骤：基于测试数据进行评估 
.. 准确率 
.. 精度 
.. AUC曲线下的面积 
.. 步骤：保存模型 
. 小结 
第章 推荐系统 
. 推荐 
.. 基于流行度的RS 
.. 基于内容的RS 
.. 基于协同过滤的RS 
.. 混合推荐系统 
. 代码 
.. 数据信息 
.. 步骤：创建SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：划分数据集 
.. 步骤：构建和训练推荐系统模型 
.. 步骤：基于测试数据进行预测和评估 
.. 步骤：推荐活动用户可能会喜欢的排名靠前的电影 
. 小结 
第章 聚类 
. 初识聚类 
. 用途 
.. K-均值 
.. 层次聚类 
. 代码 
.. 数据信息 
.. 步骤：创建SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：构建K均值聚类模型 
.. 步骤：聚类的可视化 
. 小结 
第章 自然语言处理 
. 引言 
. NLP涉及的处理步骤 
. 语料 
. 标记化 
. 移除停用词 
. 词袋 
. 计数向量器 
. TF-IDF 
. 使用机器学习进行文本分类 
. 序列嵌入 
. 嵌入 
. 小结 
・ ・ ・ ・ ・ ・ (收起)导读 
Contributors 
Preface 
Part I Fundamental aspects 
 Ontology and the lexicon： a multidisciplinary perspective 
. Situating ontologies and lexical resources 
. The content of ontologies 
. Theoretical framework for the
ontologies／lexicons interface 
. From ontologies to the lexicon and back 
. Outline of chapters 
 Formal ontology as interlingua： the SUMO and
WordNet linking project and global WordNet 
. WordNet 
. Principles of construction of formal ontologies
and lexicons 
. Mappings 
. Interpreting language 
. Global WordNet 
. SUMO translation templates 
 Interfacing WordNet with DOLCE： towards OntoWordNet 
. Introduction 
. WordNet’s preliminary analysis 
. The DOLCE upper ontology 
. Mapping WordNet into DOLCE 
. Conclusion 
 Reasoning over natural language text by means of FrameNet and ontologies 
. Introduction 
. An introduction to the FrameNet lexicon 
. Linking FrameNet to ontologies for reasoning 
. Formalizing FrameNet in OWL DL 
. Reasoning over FrameNet―annotated text 
. Linking FrameNet to SUMO 
. Discussion 
. Conclusion and outlook 
 Synergizing ontologies and the lexicon： a roadmap 
. Formal mappings between ontologies 
. Evaluation of ontolex resources 
. Bridging different lexical models and resources 
. Technological framework 
Part II Discovery and representation of conceptual systems 
 Experiments of ontology construction with Formal Concept Analysis 
. Introduction 
. Basic concepts and related work 
. Dataset selection and design of experiments 
. Evaluation and discussion 
. Conclusion and future work 
 Ontology， lexicon， and fact repository as leveraged to interpret events of change 
. Introduction 
. A snapshot of OntoSem 
. Motivation for pursuing deep analysis of events of change 
. Increase 
. Content divorced from its rendering 
. NLP with reasoning and for reasoning 
. Conclusion 
 Hantology： conceptual system discovery based on orthographic convention 
. Introduction： hanzi and conventionalized conceptualization 
. General framework 
. Conceptualization and classification of the radicals system 
. The ontology of a radical as a semantic symbol 
. The architecture of Hantology 
. OWL encoding of Hantology 
. Summary 
. Conclusion 
 What’s in a schema？ 
. Introduction 
. An ontology for cognitive linguistics 
. The c.DnS ontology 
. Schemata， mental spaces， and constructions 
. An embodied semiotic metamodel 
. Applying Semion to FrameNet and related resources 
. Conclusion 
Part III Interfacing ontologies and lexical resources 
 Interfacing ontologies and lexical resources 
. Introduction 
. Classifying experiments in ontologies and lexical resources 
. Ontologies and their construction 
. How actual resources fit the classification 
. Two practical examples 
. Available tools for the ontology lexical resource interface 
. Conclusion 
 Sinica BOW （Bilingual Ontological WordNet）：integration of bilingual WordNet and SUMO 
. Background and motivation 
. Resources and structure required in the BOW approach 
. Interfacing multiple resources： a lexicon―driven approach 
. Integration of multiple knowledge sources 
. Updating and future improvements 
. Conclusion 
 Ontology―based semantic lexicons：mapping between terms and object descriptions 
. Introduction 
. Why we need semantic lexicons 
. More semantics than we need 
. The semantics we need is in ontologies 
. Conclusion 
 Merging global and specialized linguistic ontologies 
. Introduction 
. Linguistic ontologies versus formal ontologies 
. Specialized linguistic ontologies 
. The plug―in approach 
. Experiments 
. Applications and extensions 
. Conclusion 
Part IV Learning and using ontological knowledge 
 The life cycle of knowledge 
. Introduction 
. Using ontolexical knowledge in NLP 
. Creating ontolexical knowledge with NLP 
. Conclusion 
 The Omega ontology 
. Introduction 
. Constituents of Omega 
. Structure of Omega 
. Construction of Omega via merging 
. Omega’s auxiliary knowledge sources 
. Applications 
. Omega  and the OntoNotes project 
. Discussion and future work 
. Conclusion 
 Automatic acquisition of lexico―semantic knowledge for question answering 
. Introduction 
. Lexico―semantic knowledge for QA 
. Related work 
. Extracting semantically similar words 
. Using automatically acquired role and function words 
. Using automatically acquired categorized NEs 
. Evaluation 
. Conclusion and future work 
 Agricultural ontology construction and maintenance in Thai 
. Introduction 
. A framework of ontology construction and maintenance 
. Ontology acquisition from texts 
. Ontology acquisitions from a dictionary and a thesaurus 
. Integration into an ontological tree 
. Conclusion 
References 
Index 
・ ・ ・ ・ ・ ・ (收起)第  章 心爱的聊天机器人 .................................................................................................. 
聊天机器人的受欢迎程度 .......................................................................................... 
Python 之禅以及为什么它适用于聊天机器人 .......................................................... 
对聊天机器人的需求 .................................................................................................. 
商业视角 ............................................................................................................ 
开发者视角 ........................................................................................................ 
受聊天机器人影响的行业 ........................................................................................ 
聊天机器人的发展历程 ............................................................................................ 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
我可以用聊天机器人解决什么样的问题 ................................................................ 
这个问题能通过简单的问答或来回交流解决吗 ........................................... 
这个工作是否有高度重复性，需要进行数据收集和分析 ........................... 
你的机器人的任务可以自动化和固定化吗 ................................................... 
一个 QnA 机器人 ...................................................................................................... 
从聊天机器人开始 .................................................................................................... 
聊天机器人中的决策树 ............................................................................................ 
在聊天机器人中使用决策树 ........................................................................... 
决策树如何起到作用 ....................................................................................... 
最好的聊天机器人/机器人框架 ............................................................................... 
聊天机器人组件和使用的相关术语 ........................................................................ 
意图（Intent） ................................................................................................. 
实体（Entities） .............................................................................................. 
话术（Utterances） ......................................................................................... 
训练机器人 ...................................................................................................... 
置信度得分 ...................................................................................................... 
第  章 聊天机器人中的自然语言处理 ............................................................................ 
为什么我需要自然语言处理知识来搭建聊天机器人 ............................................ 
spaCy 是什么 ............................................................................................................. 
spaCy 的基准测试结果 .................................................................................... 
spaCy 提供了什么能力 .................................................................................... 
spaCy 的特性 ............................................................................................................. 
安装和前置条件 .............................................................................................. 
spaCy 模型是什么............................................................................................ 
搭建聊天机器人所使用的自然语言处理基本方法 ................................................ 
词性标注 .......................................................................................................... 
词干提取和词性还原 ....................................................................................... 
命名实体识别 .................................................................................................. 
停用词 .............................................................................................................. 
依存句法分析 .................................................................................................. 
名词块 .............................................................................................................. 
计算相似度 ...................................................................................................... 
搭建聊天机器人时自然语言处理的一些好方法 .................................................... 
分词 .................................................................................................................. 
正则表达式 ...................................................................................................... 
总结 ........................................................................................................................... 
第  章 轻松搭建聊天机器人 ............................................................................................ 
Dialogflow 简介 ........................................................................................................ 
开始 ........................................................................................................................... 
搭建一个点餐机器人 ....................................................................................... 
确定范围 .......................................................................................................... 
列举意图 .......................................................................................................... 
列举实体 .......................................................................................................... 
搭建点餐机器人 ........................................................................................................ 
Dialogflow 入门 ............................................................................................... 
创建意图的几大要点 ....................................................................................... 
创建意图并添加自定义话术 ........................................................................... 
为意图添加默认回复 ....................................................................................... 
菜品描述意图及附属实体 ............................................................................... 
理解用户需求并回复 ....................................................................................... 
将 Dialogflow 聊天机器人发布到互联网上 ............................................................ 
在 Facebook Messenger 上集成 Dialogflow 聊天机器人 ........................................ 
设置 Facebook .................................................................................................. 
创建一个 Facebook 应用程序 ......................................................................... 
设置 Dialogflow 控制台 .................................................................................. 
配置 Webhook .................................................................................................. 
测试信使机器人 .............................................................................................. 
Fulfillment .................................................................................................................. 
启用 Webhook .................................................................................................. 
检查响应数据 .................................................................................................. 
总结 ........................................................................................................................... 
第  章 从零开始搭建聊天机器人 .................................................................................... 
Rasa NLU 是什么 ...................................................................................................... 
我们为什么要使用 Rasa NLU ......................................................................... 
深入了解 Rasa NLU ......................................................................................... 
从零开始训练和搭建聊天机器人 ............................................................................ 
搭建一个星座聊天机器人 ............................................................................... 
星座机器人和用户之间的对话脚本 ............................................................... 
为聊天机器人准备数据 ................................................................................... 
训练聊天机器人模型 ..................................................................................... 
从模型进行预测 ............................................................................................ 
使用 Rasa Core 进行对话管理 ............................................................................... 
深入了解 Rasa Core 及对话系统 .................................................................. 
理解 Rasa 概念 ............................................................................................... 
为聊天机器人创建域文件 ............................................................................. 
为聊天机器人编写自定义动作 .............................................................................. 
训练机器人的数据准备 .......................................................................................... 
构造故事数据 ................................................................................................ 
交互学习 ........................................................................................................ 
将对话导出成故事......................................................................................... 
测试机器人 .............................................................................................................. 
测试用例一 .................................................................................................... 
测试用例二 .................................................................................................... 
总结 ......................................................................................................................... 
第  章 部署自己的聊天机器人 ...................................................................................... 
前提条件.................................................................................................................. 
Rasa 的凭据管理 ..................................................................................................... 
在 Facebook 上部署聊天机器人 ............................................................................ 
在 Heroku 上创建一个应用 ........................................................................... 
在本地系统中安装 Heroku ............................................................................ 
在 Facebook 上创建和设置应用程序 ........................................................... 
在 Heroku 上创建和部署 Rasa 动作服务器应用程序 ................................. 
创建 Rasa 聊天机器人 API 应用程序........................................................... 
创建一个用于 Facebook Messenger 聊天机器人的独立脚本 ..................... 
验证对话管理应用程序在 Heroku 上的部署情况 ....................................... 
集成 Facebook Webhook ................................................................................ 
部署后验证：Facebook 聊天机器人 ............................................................ 
在 Slack 上部署聊天机器人 ................................................................................... 
为 Slack 创建独立脚本 .................................................................................. 
编辑 Procfile ................................................................................................... 
将 Slack 机器人最终部署到 Heroku 上 ........................................................ 
订阅 Slack 事件 .............................................................................................. 
订阅机器人事件 ............................................................................................ 
部署后验证：Slack 机器人 ........................................................................... 
独立部署聊天机器人 .............................................................................................. 
编写脚本实现自己的聊天机器人通道 ......................................................... 
编写 Procfile 并部署到 Web 上 ..................................................................... 
验证你的聊天机器人 API ............................................................................. 
绘制聊天机器人的图形界面 ......................................................................... 
总结 ......................................................................................................................... 
・ ・ ・ ・ ・ ・ (收起)自然语言处理Java实现 
第章 自然语言处理实践基础 -  -
. 准备开发环境 -  -
.. Windows命令行Cmd -  -
.. 在Windows下使用Java -  -
.. Linux终端 -  -
.. 在Linux下使用Java -  -
.. Eclipse集成开发环境 -  -
. 技术基础 -  -
.. 机器学习 -  -
.. Java基础 -  -
.. 信息采集 -  -
.. 文本挖掘 -  -
.. SWIG扩展Java性能 -  -
.. 代码移植 -  -
.. 语义 -  -
.. Hadoop分布式计算框架 -  -
. 本章小结 -  -
. 专业术语 -  -
第章 中文分词原理与实现 
. 接口 
.. 切分方案 
.. 词典格式 
. 散列表最长匹配中文分词 
.. 算法实现 
.. 使用Ant构建分词jar包 
.. 使用Maven构建分词jar包 
.. 使用Gradle构建分词jar包 
.. 生成JavaDoc 
. 查找词典算法 
.. 标准Trie树 
.. 三叉Trie树 
. Trie树正向最大长度匹配法 
.. 逆向最大长度匹配法 
.. 有限状态机识别未登录串 
. 概率语言模型的分词方法 
.. 一元模型 
.. 整合基于规则的方法 
.. 表示切分词图 
.. 形成切分词图 
.. 数据基础 
.. 改进一元模型 
.. 二元词典 
.. 完全二叉树组 
.. 三元词典 
.. N元模型 
.. N元分词 
.. 生成语言模型 
.. 评估语言模型 
.. 概率分词的流程与结构 
.. 可变长n元分词 
.. 条件随机场 
. 新词发现 
. 安卓中文输入法 
. 词性标注 
.. 数据基础 
.. 隐马尔可夫模型 
.. 存储数据 
.. 统计数据 
.. 整合切分与词性标注 
.. 大词表 
.. 词性序列 
.. 基于转换的错误学习方法 
.. 条件随机场 
. 词类模型 
. 未登录词识别 
.. 未登录人名 
.. 提取候选人名 
.. 最长人名切分 
.. 一元概率人名切分 
.. 二元概率人名切分 
.. 未登录地名 
.. 未登录企业名 
. 中文分词总体结构 
. 平滑算法 
.. 最大熵 
.. 条件随机场 
. 地名切分 
.. 识别未登录地名 
.. 整体流程 
. 企业名切分 
.. 识别未登录词 
.. 整体流程 
. 结果评测 
. 本章小结 
. 专业术语 
第章 语义分析 
. 句法分析树 
. 依存文法 
.. 中文依存文法 
.. 英文依存文法 
.. 生成依存树 
.. 机器学习的方法 
. 依存语言模型 
. 使用Java计算机语言的语义分析 
. 小结 
. 专业术语 
第章 文章分析与生成 
. 分词 
.. 句子切分 
.. 识别未登录串 
.. 切分边界 
. 词性标注 
. 重点词汇 
. 句子时态 
. 自动写作 
. 本章小结 
第章 文档排重 
. 相似度计算 
.. 夹角余弦 
.. 最长公共子串 
.. 同义词替换 
.. 地名相似度 
.. 企业名相似度 
. 文档排重 
.. 关键词排重 
.. SimHash 
.. 分布式文档排重 
.. 使用文本排重 
. 在搜索引擎中使用文本排重 
. 本章小结 
. 专业术语 
第章 信息提取 
. 指代消解 
. 中文关键词提取 
.. 关键词提取的基本方法 
.. HITS算法应用于关键词提取 
.. 从网页中提取关键词 
. 信息提取 
.. 提取联系方式 
.. 从互联网提取信息 
.. 提取地名 
. 拼写纠错 
.. 模糊匹配问题 
.. 正确词表 
.. 英文拼写检查 
.. 中文拼写检查 
. 输入提示 
. 本章小结 
.专业术语 
第章 自动摘要 
. 自动摘要技术 
.. 英文文本摘要 
.. 中文文本摘要 
.. 基于篇章结构的自动摘要 
.. 句子压缩 
. 指代消解 
. 多文档摘要 
. 分布式部署 
. 本章小结 
.专业术语 
第章 文本分类 
. 地名分类 
. 文本模板分类 
. 特征提取 
. 线性分类器 
.. 关键词加权法 
.. 朴素贝叶斯 
.. 贝叶斯文本分类 
.. 支持向量机 
.. 多级分类 
.. 使用sklearn实现文本分类 
.. 规则方法 
.. 网页分类 
. FastText文本分类 
.. 词向量 
.. JavaCPP包装Java接口 
.. 使用JFastText 
. 最大熵分类器 
. 文本聚类 
.. K均值聚类方法 
.. K均值实现 
.. 深入理解DBScan算法 
.. 使用DBScan算法聚类实例 
. 持续集成 
. 本章小结 
.专业术语 
第章 文本倾向性分析 
. 确定词语的褒贬倾向 
. 实现情感识别 
. 本章小结 
.专业术语 
第章 语音识别 
. 总体结构 
.. 识别中文 
.. 自动问答 
. 语音库 
. 语音 
.. 标注语音 
.. 动态时间规整计算相似度 
. Sphinx语音识别 
.. 中文训练集 
.. 使用Sphinx 
.. ARPA文件格式 
.. 运行于Android的PocketSphinx 
. 说话人识别 
. 本章小结 
. 术语表 
第章 问答系统 
. 问答系统的结构 
.. 提取问答对 
.. 等价问题 
. 问句分析 
.. 问题类型 
.. 句型 
.. 用户意图识别 
.. 业务类型 
.. 依存树 
.. 指代消解 
.. 二元关系 
.. 问句模板 
.. 结构化问句模板 
.. 检索方式 
.. 问题重写 
.. 提取事实 
.. 验证答案 
. 知识库 
.. 语义库 
. AIML聊天机器人 
.. 交互式问答 
.. 垂直领域问答系统 
.. 语料库 
.. 客户端 
. 自然语言生成 
. JavaFX开发界面 
. 本章小结 
. 术语表 
第章 机器翻译 
. 使用机器翻译API 
. 翻译日期 
. 神经网络机器翻译 
. 辅助机器翻译 
. 机器翻译的评价 
. 本章小结 
参考资源 
书籍 
网址 
后记 
・ ・ ・ ・ ・ ・ (收起)译者序
第版前言
第版前言
第版致谢
第章　基础知识 
.　概率测度 
.　随机变量 
..　连续随机变量和离散随机变量 
..　多元随机变量的联合分布 
.　条件分布 
..　贝叶斯法则 
..　独立随机变量与条件独立随机变量 
..　可交换的随机变量 
.　随机变量的期望 
.　模型 
..　参数模型与非参数模型 
..　模型推断 
..　生成模型 
..　模型中的独立性假定 
..　有向图模型 
.　从数据场景中学习 
.　贝叶斯学派和频率学派的哲学（冰山一角） 
.　本章小结 
.　习题 
第章　绪论 
.　贝叶斯统计与自然语言处理的结合点概述 
.　第一个例子：隐狄利克雷分配模型 
..　狄利克雷分布 
..　推断 
..　总结 
.　第二个例子：贝叶斯文本回归 
.　本章小结 
.　习题 
第章　先验 
.　共轭先验 
..　共轭先验和归一化常数 
..　共轭先验在隐变量模型中的应用 
..　混合共轭先验 
..　重新归一化共轭分布 
..　是否共轭的讨论 
..　总结 
.　多项式分布和类别分布的先验 
..　再谈狄利克雷分布 
..　Logistic正态分布 
..　讨论 
..　总结 
.　非信息先验 
..　均匀不正常先验 
..　Jeffreys先验 
..　讨论 
.　共轭指数模型 
.　模型中的多参数抽取 
.　结构先验 
.　本章小结 
.　习题 
第章　贝叶斯估计 
.　隐变量学习：两种观点 
.　贝叶斯点估计 
..　最大后验估计 
..　基于最大后验解的后验近似 
..　决策-理论点估计 
..　总结 
.　经验贝叶斯 
.　后验的渐近行为 
.　本章小结 
.　习题 
第章　采样算法 
.　MCMC算法：概述 
.　MCMC推断的自然语言处理模型结构 
.　吉布斯采样 
..　坍塌吉布斯采样 
..　运算符视图 
..　并行化的吉布斯采样器 
..　总结 
.　Metropolis-Hastings算法 
.　切片采样 
..　辅助变量采样 
..　切片采样和辅助变量采样在自然语言处理中的应用 
.　模拟退火 
.　MCMC算法的收敛性 
.　马尔可夫链：基本理论 
.　MCMC领域外的采样算法 
.　蒙特卡罗积分 
.　讨论 
..　分布的可计算性与采样 
..　嵌套的MCMC采样 
..　MCMC方法的运行时间 
..　粒子滤波 
.　本章小结 
.　习题 
第章　变分推断 
.　边缘对数似然的变分界 
.　平均场近似 
.　平均场变分推断算法 
..　狄利克雷-多项式变分推断 
..　与期望最大化算法的联系 
.　基于变分推断的经验贝叶斯 
.　讨论 
..　推断算法的初始化 
..　收敛性诊断 
..　变分推断在解码中的应用 
..　变分推断最小化KL散度 
..　在线的变分推断 
.　本章小结 
.　习题 
第章　非参数先验 
.　狄利克雷过程：三种视角 
..　折棍子过程 
..　中餐馆过程 
.　狄利克雷过程混合模型 
..　基于狄利克雷过程混合模型的推断 
..　狄利克雷过程混合是混合模型的极限 
.　层次狄利克雷过程 
.　Pitman?Yor过程 
..　Pitman-Yor过程用于语言建模 
..　Pitman-Yor过程的幂律行为 
.　讨论 
..　高斯过程 
..　印度自助餐过程 
..　嵌套的中餐馆过程 
..　距离依赖的中餐馆过程 
..　序列记忆器 
.　本章小结 
.　习题 
第章　贝叶斯语法模型 
.　贝叶斯隐马尔可夫模型 
.　概率上下文无关语法 
..　作为多项式分布集的PCFG 
..　PCFG的基本推断算法 
..　作为隐马尔可夫模型的PCFG 
.　贝叶斯概率上下文无关语法 
..　PCFG的先验 
..　贝叶斯PCFG的蒙特卡罗推断 
..　贝叶斯PCFG的变分推断 
.　适配器语法 
..　Pitman-Yor适配器语法 
..　PYAG的折棍子视角 
..　基于PYAG的推断 
.　层次狄利克雷过程PCFG 
.　依存语法 
.　同步语法 
.　多语言学习 
..　词性标注 
..　语法归纳 
.　延伸阅读 
.　本章小结 
.　习题 
第章　表征学习与神经网络 
.　神经网络与表征学习：为什么是现在 
.　词嵌入 
..　词嵌入的skip-gram模型 
..　贝叶斯skip-gram词嵌入 
..　讨论 
.　神经网络 
..　频率论估计和反向传播算法 
..　神经网络权值的先验 
.　神经网络在自然语言处理中的现代应用 
..　循环神经网络和递归神经网络 
..　梯度消失与梯度爆炸问题 
..　神经编码器-解码器模型 
..　卷积神经网络 
.　调整神经网络 
..　正则化 
..　超参数调整 
.　神经网络生成建模 
..　变分自编码器 
..　生成对抗网络 
.　本章小结 
.　习题 
结束语 
附录A　基本概念 
附录B　概率分布清单 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第一部分 人工智能基础
第  章 绪论 
. 什么是人工智能 
.. 类人行为：图灵测试方法 
.. 类人思考：认知建模方法 
.. 理性思考：“思维法则”方法 
.. 理性行为：理性智能体方法 
.. 益机 
. 人工智能的基础 
.. 哲学 
.. 数学 
.. 经济学 
.. 神经科学 
.. 心理学 
.. 计算机工程 
.. 控制理论与控制论 
.. 语言学 
. 人工智能的历史 
.. 人工智能的诞生（―） 
.. 早期热情高涨，期望无限（―） 
.. 一些现实（―） 
.. 专家系统（―） 
.. 神经网络的回归（―现在） 
.. 概率推理和机器学习（―现在） 
.. 大数据（―现在） 
.. 深度学习（―现在） 
. 目前的先进技术 
. 人工智能的风险和收益 
小结 
参考文献与历史注释 
第  章 智能体 
. 智能体和环境 
. 良好行为：理性的概念 
.. 性能度量 
.. 理性 
.. 全知、学习和自主 
. 环境的本质 
.. 指定任务环境 
.. 任务环境的属性 
. 智能体的结构 
.. 智能体程序 
.. 简单反射型智能体 
.. 基于模型的反射型智能体 
.. 基于目标的智能体 
.. 基于效用的智能体 
.. 学习型智能体 
.. 智能体程序的组件如何工作 
小结 
参考文献与历史注释 
第二部分 问题求解
第  章 通过搜索进行问题求解 
. 问题求解智能体 
.. 搜索问题和解 
.. 问题形式化 
. 问题示例 
.. 标准化问题 
.. 真实世界问题 
. 搜索算法 
.. 最佳优先搜索 
.. 搜索数据结构 
.. 冗余路径 
.. 问题求解性能评估 
. 无信息搜索策略 
.. 广度优先搜索 
.. Dijkstra 算法或一致代价搜索 
.. 深度优先搜索与内存问题 
.. 深度受限和迭代加深搜索 
.. 双向搜索 
.. 无信息搜索算法对比 
. 有信息（启发式）搜索策略 
.. 贪心最佳优先搜索 
.. A* 搜索 
.. 搜索等值线 
.. 满意搜索：不可容许的启发式
函数与加权 A* 搜索 
.. 内存受限搜索 
.. 双向启发式搜索 
. 启发式函数 
.. 启发式函数的准确性对性能的影响 
.. 从松弛问题出发生成启发式函数 
.. 从子问题出发生成启发式函数：模式数据库 
.. 使用地标生成启发式函数 
.. 学习以更好地搜索 
.. 从经验中学习启发式函数 
小结 
参考文献与历史注释 
第  章 复杂环境中的搜索 
. 局部搜索和最优化问题 
.. 爬山搜索 
.. 模拟退火 
.. 局部束搜索 
.. 进化算法 
. 连续空间中的局部搜索 
. 使用非确定性动作的搜索 
.. 不稳定的真空吸尘器世界 
.. 与或搜索树 
.. 反复尝试 
. 部分可观测环境中的搜索 
.. 无观测信息的搜索 
.. 部分可观测环境中的搜索 
.. 求解部分可观测问题 
.. 部分可观测环境中的智能体 
. 在线搜索智能体和未知环境 
.. 在线搜索问题 
.. 在线搜索智能体 
.. 在线局部搜索 
.. 在线搜索中的学习 
小结 
参考文献与历史注释 
第  章 对抗搜索和博弈 
. 博弈论 
. 博弈中的优化决策 
.. 极小化极大搜索算法 
.. 多人博弈中的最优决策 
.. α-β 剪枝 
.. 移动顺序 
. 启发式 α-β 树搜索 
.. 评价函数 
.. 截断搜索 
.. 前向剪枝 
.. 搜索和查表 
. 蒙特卡罗树搜索 
. 随机博弈 
. 部分可观测博弈 
.. 四国军棋：部分可观测的国际象棋 
.. 纸牌游戏 
. 博弈搜索算法的局限性 
小结 
参考文献与历史注释 
第  章 约束满足问题 
. 定义约束满足问题 
.. 问题示例：地图着色 
.. 问题示例：车间作业调度 
.. CSP 形式体系的变体 
. 约束传播：CSP 中的推断 
.. 节点一致性 
.. 弧一致性 
.. 路径一致性 
.. k 一致性 
.. 全局约束 
.. 数独 
. CSP 的回溯搜索 
.. 变量排序和值排序 
.. 交替进行搜索和推理 
.. 智能回溯：向后看 
.. 约束学习 
. CSP 的局部搜索 
. 问题的结构 
.. 割集调整 
.. 树分解 
.. 值对称 
小结 
参考文献与历史注释 
第三部分 知识、推理和规划
第  章 逻辑智能体 
. 基于知识的智能体 
. wumpus 世界 
. 逻辑 
. 命题逻辑：一种非常简单的逻辑 
.. 语法 
.. 语义 
.. 一个简单的知识库 
.. 一个简单的推断过程 
. 命题定理证明 
.. 推断与证明 
.. 通过归结证明 
.. 霍恩子句与确定子句 
.. 前向链接与反向链接 
. 高效命题模型检验 
.. 完备的回溯算法 
.. 局部搜索算法 
.. 随机 SAT 问题概览 
. 基于命题逻辑的智能体 
.. 世界的当前状态 
.. 混合智能体 
.. 逻辑状态估计 
.. 用命题推断进行规划 
小结 
参考文献与历史注释 
第  章 一阶逻辑 
. 回顾表示 
.. 思想的语言 
.. 结合形式语言和自然语言的优点 
. 一阶逻辑的语法和语义 
.. 一阶逻辑模型 
.. 符号与解释 
.. 项 
.. 原子语句 
.. 复合语句 
.. 量词 
.. 等词 
.. 数据库语义 
. 使用一阶逻辑 
.. 一阶逻辑的断言与查询 
.. 亲属关系论域 
.. 数、集合与列表 
.. wumpus 世界 
. 一阶逻辑中的知识工程 
.. 知识工程的过程 
.. 电子电路论域 
小结 
参考文献与历史注释 
第  章 一阶逻辑中的推断 
. 命题推断与一阶推断 
. 合一与一阶推断 
.. 合一 
.. 存储与检索 
. 前向链接 
.. 一阶确定子句 
.. 简单的前向链接算法 
.. 高效前向链接 
. 反向链接 
.. 反向链接算法 
.. 逻辑编程 
.. 冗余推断和无限循环 
.. Prolog 的数据库语义 
.. 约束逻辑编程 
. 归结 
.. 一阶逻辑的合取范式 
.. 归结推断规则 
.. 证明范例 
.. 归结的完备性 
.. 等词 
.. 归结策略 
小结 
参考文献与历史注释 
第  章 知识表示 
. 本体论工程 
. 类别与对象 
.. 物理组成 
.. 量度 
.. 对象：事物和物质 
. 事件 
.. 时间 
.. 流和对象 
. 精神对象和模态逻辑 
. 类别的推理系统 
.. 语义网络 
.. 描述逻辑 
. 用缺省信息推理 
.. 限定与缺省逻辑 
.. 真值维护系统 
小结 
参考文献与历史注释 
第  章 自动规划 
. 经典规划的定义 
.. 范例领域：航空货物运输 
.. 范例领域：备用轮胎问题 
.. 范例领域：积木世界 
. 经典规划的算法 
.. 规划的前向状态空间搜索 
.. 规划的反向状态空间搜索 
.. 使用布尔可满足性规划 
.. 其他经典规划方法 
. 规划的启发式方法 
.. 领域无关剪枝 
.. 规划中的状态抽象 
. 分层规划 
.. 高层动作 
.. 搜索基元解 
.. 搜索抽象解 
. 非确定性域的规划和行动 
.. 无传感器规划 
.. 应变规划 
.. 在线规划 
. 时间、调度和资源 
.. 时间约束和资源约束的表示 
.. 解决调度问题 
. 规划方法分析 
小结 
参考文献与历史注释 
第四部分 不确定知识和不确定推理
第  章 不确定性的量化 
. 不确定性下的动作 
.. 不确定性概述 
.. 不确定性与理性决策 
. 基本概率记号 
.. 概率是关于什么的 
.. 概率断言中的命题语言 
.. 概率公理及其合理性 
. 使用完全联合分布进行推断 
. 独立性 
. 贝叶斯法则及其应用 
.. 应用贝叶斯法则：简单实例 
.. 应用贝叶斯法则：合并证据 
. 朴素贝叶斯模型 
. 重游 wumpus 世界 
小结 
参考文献与历史注释 
第  章 概率推理 
. 不确定域的知识表示 
. 贝叶斯网络的语义 
.. 贝叶斯网络中的条件独立性关系 
.. 条件分布的高效表示 
.. 连续变量的贝叶斯网络 
.. 案例研究：汽车保险 
. 贝叶斯网络中的精确推断 
.. 通过枚举进行推断 
.. 变量消元算法 
.. 精确推断的复杂性 
.. 聚类算法 
. 贝叶斯网络中的近似推理 
.. 直接采样方法 
.. 通过马尔可夫链模拟进行推断 
.. 编译近似推断 
. 因果网络 
.. 表示动作：do 操作 
.. 后门准则 
小结 
参考文献与历史注释 
第  章 时间上的概率推理 
. 时间与不确定性 
.. 状态与观测 
.. 转移模型与传感器模型 
. 时序模型中的推断 
.. 滤波与预测 
.. 平滑 
.. 寻找最可能序列 
. 隐马尔可夫模型 
.. 简化矩阵算法 
.. 隐马尔可夫模型示例：定位 
. 卡尔曼滤波器 
.. 更新高斯分布 
.. 简单的一维示例 
.. 一般情况 
.. 卡尔曼滤波的适用范围 
. 动态贝叶斯网络 
.. 构建动态贝叶斯网络 
.. 动态贝叶斯网络中的精确推断 
.. 动态贝叶斯网络中的近似推断 
小结 
参考文献与历史注释 
第  章 概率编程 
. 关系概率模型 
.. 语法与语义 
.. 实例：评定玩家的技能等级 
.. 关系概率模型中的推断 
. 开宇宙概率模型 
.. 语义与语法 
.. 开宇宙概率模型的推断 
.. 示例 
. 追踪复杂世界 
.. 示例：多目标跟踪 
.. 示例：交通监控 
. 作为概率模型的程序 
.. 示例：文本阅读 
.. 语法与语义 
.. 推断结果 
.. 结合马尔可夫模型改进生成程序 
.. 生成程序的推断 
小结 
参考文献与历史注释 
第  章 做简单决策 
. 在不确定性下结合信念与愿望 
. 效用理论基础 
.. 理性偏好的约束 
.. 理性偏好导致效用 
. 效用函数 
.. 效用评估和效用尺度 
.. 金钱的效用 
.. 期望效用与决策后失望 
.. 人类判断与非理性 
. 多属性效用函数 
.. 占优 
.. 偏好结构与多属性效用 
. 决策网络 
.. 使用决策网络表示决策问题 
.. 评估决策网络 
. 信息价值 
.. 简单示例 
.. 完美信息的一般公式 
.. 价值信息的性质 
.. 信息收集智能体的实现 
.. 非短视信息收集 
.. 敏感性分析与健壮决策 
. 未知偏好 
.. 个人偏好的不确定性 
.. 顺从人类 
小结 
参考文献与历史注释 
第  章 做复杂决策 
. 序贯决策问题 
.. 时间上的效用 
.. 最优策略与状态效用 
.. 奖励规模 
.. 表示 MDP 
. MDP 的算法 
.. 价值迭代 
.. 策略迭代 
.. 线性规划 
.. MDP 的在线算法 
. 老虎机问题 
.. 计算基廷斯指数 
.. 伯努利老虎机 
.. 近似最优老虎机策略 
.. 不可索引变体 
. 部分可观测MDP 
. 求解POMDP 的算法 
.. POMDP的价值迭代 
.. POMDP的在线算法 
小结 
参考文献与历史注释 
第  章 多智能体决策 
. 多智能体环境的特性 
.. 单个决策者 
.. 多决策者 
.. 多智能体规划 
.. 多智能体规划：合作与协调 
. 非合作博弈论 
.. 单步博弈：正则形式博弈 
.. 社会福利 
.. 重复博弈 
.. 序贯博弈：扩展形式 
.. 不确定收益与辅助博弈 
. 合作博弈论 
.. 联盟结构与结果 
.. 合作博弈中的策略 
.. 合作博弈中的计算 
. 制定集体决策 
.. 在合同网中分配任务 
.. 通过拍卖分配稀缺资源 
.. 投票 
.. 议价 
小结 
参考文献与历史注释 
第五部分 机器学习
第  章 样例学习 
. 学习的形式 
. 监督学习 
. 决策树学习 
.. 决策树的表达能力 
.. 从样例中学习决策树 
.. 选择测试属性 
.. 泛化与过拟合 
.. 拓展决策树的适用范围 
. 模型选择与模型优化 
.. 模型选择 
.. 从错误率到损失函数 
.. 正则化 
.. 超参数调整 
. 学习理论 
. 线性回归与分类 
.. 单变量线性回归 
.. 梯度下降 
.. 多变量线性回归 
.. 带有硬阈值的线性分类器 
.. 基于逻辑斯谛回归的线性分类器 
. 非参数模型 
.. 最近邻模型 
.. 使用 k-d 树寻找最近邻 
.. 局部敏感哈希 
.. 非参数回归 
.. 支持向量机 
.. 核技巧 
. 集成学习 
.. 自助聚合法 
.. 随机森林法 
.. 堆叠法 
.. 自适应提升法 
.. 梯度提升法 
.. 在线学习 
. 开发机器学习系统 
.. 问题形式化 
.. 数据收集、评估和管理 
.. 模型选择与训练 
.. 信任、可解释性、可说明性 
.. 操作、监控和维护 
小结 
参考文献与历史注释 
第  章 概率模型学习 
. 统计学习 
. 完全数据学习 
.. 最大似然参数学习：离散模型 
.. 朴素贝叶斯模型 
.. 生成模型和判别模型 
.. 最大似然参数学习：连续模型 
.. 贝叶斯参数学习 
.. 贝叶斯线性回归 
.. 贝叶斯网络结构学习 
.. 非参数模型密度估计 
. 隐变量学习：EM 算法 
.. 无监督聚类：学习混合高斯 
.. 学习带隐变量的贝叶斯网络参数值 
.. 学习隐马尔可夫模型 
.. EM 算法的一般形式 
.. 学习带隐变量的贝叶斯网络结构 
小结 
参考文献与历史注释 
第  章 深度学习 
. 简单前馈网络 
.. 网络作为复杂函数 
.. 梯度与学习 
. 深度学习的计算图 
.. 输入编码 
.. 输出层与损失函数 
.. 隐藏层 
. 卷积网络 
.. 池化与下采样 
.. 卷积神经网络的张量运算 
.. 残差网络 
. 学习算法 
.. 计算图中的梯度计算 
.. 批量归一化 
. 泛化 
.. 选择正确的网络架构 
.. 神经架构搜索 
.. 权重衰减 
.. 暂退法 
. 循环神经网络 
.. 训练基本的循环神经网络 
.. 长短期记忆 RNN 
. 无监督学习与迁移学习 
.. 无监督学习 
.. 迁移学习和多任务学习 
. 应用 
.. 视觉 
.. 自然语言处理 
.. 强化学习 
小结 
参考文献与历史注释 
第  章 强化学习 
. 从奖励中学习 
. 被动强化学习 
.. 直接效用估计 
.. 自适应动态规划 
.. 时序差分学习 
. 主动强化学习 
.. 探索 
.. 安全探索 
.. 时序差分 Q 学习 
. 强化学习中的泛化 
.. 近似直接效用估计 
.. 近似时序差分学习 
.. 深度强化学习 
.. 奖励函数设计 
.. 分层强化学习 
. 策略搜索 
. 学徒学习与逆强化学习 
. 强化学习的应用 
.. 在电子游戏中的应用 
.. 在机器人控制中的应用 
小结 
参考文献与历史注释 
第六部分 沟通、感知和行动
第  章 自然语言处理 
. 语言模型 
.. 词袋模型 
.. n 元单词模型 
.. 其他 n 元模型 
.. n 元模型的平滑 
.. 单词表示 
.. 词性标注 
.. 语言模型的比较 
. 文法 
. 句法分析 
.. 依存分析 
.. 从样例中学习句法分析器 
. 扩展文法 
.. 语义解释 
.. 学习语义文法 
. 真实自然语言的复杂性 
. 自然语言任务 
小结 
参考文献与历史注释 
第  章 自然语言处理中的深度学习 
. 词嵌入 
. 自然语言处理中的循环神经网络 
.. 使用循环神经网络的语言模型 
.. 用循环神经网络进行分类 
.. 自然语言处理任务中的 LSTM模型 
. 序列到序列模型 
.. 注意力 
.. 解码 
. Transformer 架构 
.. 自注意力 
.. 从自注意力到 Transformer 
. 预训练和迁移学习 
.. 预训练词嵌入 
.. 预训练上下文表示 
.. 掩码语言模型 
. 最高水平（SOTA） 
小结 
参考文献与历史注释 
第  章 计算机视觉 
. 引言 
. 图像形成 
.. 无透镜成像：针孔照相机 
.. 透镜系统 
.. 缩放正交投影 
.. 光线与明暗 
.. 颜色 
. 简单图像特征 
.. 边缘 
.. 纹理 
.. 光流 
.. 自然图像分割 
. 图像分类 
.. 基于卷积神经网络的图像分类 
.. 卷积神经网络对图像分类问题
有效的原因 
. 物体检测 
. 三维世界 
.. 多个视图下的三维线索 
.. 双目立体视觉 
.. 移动摄像机给出的三维线索 
.. 单个视图的三维线索 
. 计算机视觉的应用 
.. 理解人类行为 
.. 匹配图片与文字 
.. 多视图重建 
.. 单视图中的几何 
.. 生成图片 
.. 利用视觉控制运动 
小结 
参考文献与历史注释 
第  章 机器人学 
. 机器人 
. 机器人硬件 
.. 机器人的硬件层面分类 
.. 感知世界 
.. 产生运动 
. 机器人学解决哪些问题 
. 机器人感知 
.. 定位与地图构建 
.. 其他感知类型 
.. 机器人感知中的监督学习与无监督学习 
. 规划与控制 
.. 构形空间 
.. 运动规划 
.. 轨迹跟踪控制 
.. 最优控制 
. 规划不确定的运动 
. 机器人学中的强化学习 
.. 利用模型 
.. 利用其他信息 
. 人类与机器人 
.. 协调 
.. 学习做人类期望的事情 
. 其他机器人框架 
.. 反应式控制器 
.. 包容架构 
. 应用领域 
小结 
参考文献与历史注释 
第七部分 总结
第  章 人工智能的哲学、伦理和安全性 
. 人工智能的极限 
.. 由非形式化得出的论据 
.. 由能力缺陷得出的论据 
.. 数学异议 
.. 衡量人工智能 
. 机器能真正地思考吗 
.. 中文房间 
.. 意识与感质 
. 人工智能的伦理 
.. 致命性自主武器 
.. 监控、安全与隐私 
.. 公平与偏见 
.. 信任与透明度 
.. 工作前景 
.. 机器人权利 
.. 人工智能安全性 
小结 
参考文献与历史注释 
第  章 人工智能的未来 
. 人工智能组件 
. 人工智能架构 
附录 A 数学背景知识 
附录 B 关于语言与算法的说明 
参考文献 Ⅰ artificial intelligence
 introduction
.what is al?
.the foundations of artificial intelligence
.the history of artificial intelligence
.the state of the art
.summary, bibliographical and historical notes, exercises
 intelligent agents
.agents and environments
.good behavior: the concept of rationality
.the nature of environments
.the structure of agents
.summary, bibliographical and historical notes, exercises
Ⅱ problem-solving
 solving problems by searching
.problem-solving agents
.example problems
.searching for solutions
.uninformed search strategies
.informed (heuristic) search strategies
.heuristic functions
.summary, bibliographical and historical notes, exercises
 beyond classical search
.local search algorithms and optimization problems
.local search in continuous spaces
.searching with nondeterministic actions
.searching with partial observations
.online search agents and unknown environments
.summary, bibliographical and historical notes, exercises
 adversarial search
.games
.optimal decisions in games
.alpha-beta pruning
.imperfect real-time decisions
.stochastic games
.partially observable games
.state-of-the-art game programs
.alternative approaches
.summary, bibliographical and historical notes, exercises
 constraint satisfaction problems
.defining constraint satisfaction problems
.constraint propagation: inference in csps
.backtracking search for csps
.local search for csps
.the structure of problems
.summary, bibliographical and historical notes, exercises
Ⅲ knowledge, reasoning, and planning
 logical agents
.knowledge-based agents
.the wumpus world
.logic
.propositional logic: a very simple logic
.propositional theorem proving
.effective propositional model checking
.agents based on propositional logic
.summary, bibliographical and historical notes, exercises
 first-order logic
.representation revisited
.syntax and semantics of first-order logic
.using first-order logic
.knowledge engineering in first-order logic
.summary, bibliographical and historical notes, exercises
 inference in first-order logic
.propositional vs. first-order inference
.unification and lifting
.forward chaining
.backward chaining
.resolution
.summary, bibliographical and historical notes, exercises
 classical planning
. definition of classical planning
. algorithms for planning as state-space search
. planning graphs
. other classical planning approaches
. analysis of planning approaches
. summary, bibliographical and historical notes, exercises
 planning and acting in the real world
. time, schedules, and resources
. hierarchical planning
. planning and acting in nondeterministic domains
. multiagent planning
. summary, bibliographical and historical notes, exercises
 knowledge representation
. ontological engineering
. categories and objects
. events
. mental events and mental objects
. reasoning systems for categories
. reasoning with default information
. the intemet shopping world
. summary, bibliographical and historical notes, exercises
Ⅳ uncertain knowledge and reasoning
 quantifying uncertainty
. acting under uncertainty
. basic probability notation
. inference using full joint distributions
. independence
. bayes' rule and its use
. the wumpus world revisited
. summary, bibliographical and historical notes, exercises
 probabilistic reasoning
. representing knowledge in an uncertain domain
. the semantics of bayesian networks
. efficient representation of conditional distributions
. exact inference in bayesian networks
. approximate inference in bayesian networks
. relational and first-order probability models
. other approaches to uncertain reasoning
. summary, bibliographical and historical notes, exercises
 probabilistic reasoning over time
. time and uncertainty
. inference in temporal models
. hidden markov models
. kalman filters
. dynamic bayesian networks
. keeping track of many objects
. summary, bibliographical and historical notes, exercises
 making simple decisions
. combining beliefs and desires under uncertainty
. the basis of utility theory
. utility functions
. multiattribute utility functions
. decision networks
. the value of information
. decision-theoretic expert systems
. summary, bibliographical and historical notes, exercises
 making complex decisions
. sequential decision problems
. value iteration
. policy iteration
. partially observable mdps
. decisions with multiple agents: game theory
. mechanism design
. summary, bibliographical and historical notes, exercises
V learning
 learning from examples
. forms of learning
. supervised learning
. leaming decision trees
. evaluating and choosing the best hypothesis
. the theory of learning
. regression and classification with linear models
. artificial neural networks
. nonparametric models
. support vector machines
. ensemble learning
. practical machine learning
. summary, bibliographical and historical notes, exercises
 knowledge in learning
. a logical formulation of learning
. knowledge in learning
. explanation-based learning
. learning using relevance information
. inductive logic programming
. summary, bibliographical and historical notes, exercis
 learning probabilistic models
. statistical learning
. learning with complete data
. learning with hidden variables: the em algorithm.
. summary, bibliographical and historical notes, exercis
 reinforcement learning
. l introduction
. passive reinforcement learning
. active reinforcement learning
. generalization in reinforcement learning
. policy search
. applications of reinforcement learning
. summary, bibliographical and historical notes, exercis
VI communicating, perceiving, and acting
 natural language processing
. language models
. text classification
. information retrieval
. information extraction
. summary, bibliographical and historical notes, exercis
 natural language for communication
. phrase structure grammars
. syntactic analysis (parsing)
. augmented grammars and semantic interpretation
. machine translation
. speech recognition
. summary, bibliographical and historical notes, exercis
 perception
. image formation
. early image-processing operations
. object recognition by appearance
. reconstructing the d world
. object recognition from structural information
. using vision
. summary, bibliographical and historical notes, exercises
 robotics
. introduction
. robot hardware
. robotic perception
. planning to move
. planning uncertain movements
. moving
. robotic software architectures
. application domains
. summary, bibliographical and historical notes, exercises
VII conclusions
 philosophical foundations
. weak ai: can machines act intelligently?
. strong ai: can machines really think?
. the ethics and risks of developing artificial intelligence
. summary, bibliographical and historical notes, exercises
 al: the present and future
. agent components
. agent architectures
. are we going in the right direction?
. what if ai does succeed?
a mathematical background
a. complexity analysis and o notation
a. vectors, matrices, and linear algebra
a. probability distributions
b notes on languages and algorithms
b.defining languages with backus-naur form (bnf)
b.describing algorithms with pseudocode
b.online help
bibliography
index
・ ・ ・ ・ ・ ・ (收起)第章 AIGC为何引发关注
.　《太空歌剧院》带来的冲击和影响　
.　“生成”所引发的创意性工作革新　
.　内容生成方式进入新阶段　
.　AIGC在绘画领域率先破圈　
.　典型的AIGC模型　
海外模型　
国内模型　
第章 模型即服务时代的到来
.　模型即服务的历史进程　
早期人工智能在曲折中探索　
深度学习引发关注　
.　典型的深度学习网络　
生成对抗网络　
Transformer　
.　大公司探索之路　
DeepMind　
OpenAI　
.　基础模型普及的关键节点　
基础模型的能力与服务　
曾经热议的云，今后的基础模型　
基础模型的通用性　
.　人工智能的未来何在　
人工智能逐步接近人类的思考模式　
未来人工智能的发展特点　
第章 ChatGPT引发的潮流与思考
.　ChatGPT会成为人工智能的拐点吗　
引发全球关注的ChatGPT　
ChatGPT潜在的应用领域　
.　ChatGPT能力大揭秘　
.　ChatGPT是OpenAI对大模型的坚定实践　
.　ChatGPT的局限性及其引发的思考　
技术创新性与工程创新性　
知识局限性　
盈利与成本之间的平衡　
应用落地所面临的困境　
法律合规与应用抵制　
网络安全风险　
能耗挑战　
.　ChatGPT引发的思考　
如何看待人类创新与机器创新　
ChatGPT在哪些方面值得我们学习　
.?GPT-未来已来，奇点时刻该如何面对　
多模态　
提示工程的价值　
安全隐忧　
第章 大模型驱动的人工智能绘画“创作”
.　AI绘画的先驱――AARON　
.　人工智能绘画的原理　
神经网络是如何模仿人类思考的　
如何让神经网络画一幅画　
.　人工智能学习如何画一只猫　
教会你的神经网络认识“猫咪”　
人工智能真的画出了猫咪　
.　DALL-E的初次尝试与突破　
.　人工智能绘画的技术创新点　
CLIP实现跨模态创新，打造图文匹配　
用Diffusion加速AIGC落地普及　
Diffusion模型为AIGC写下的注脚　
Stable Diffusion岂止于开源　
AIGC进一步降低模型的使用门槛　
.　使AIGC绘画技术成熟的重要因素　
提示词的重要性　
算力资源的关键支撑　
第章 人类的创新能力会被AIGC替代吗
.　艺术创作会被AIGC取代吗　
用户的猎奇与创作者的抵触　
AIGC不会取代艺术创作工作　
使用AIGC，需要具备什么能力　
AIGC是直接消费品还是工具　
.　创作者如何通过AIGC获得更大的收益　
如何将AIGC应用于创作　
创意工作者的收益探索　
未来人工智能创作艺术的个层次　
.　AIGC――你的“达・芬奇”　
内容输出的“平民化”　
大众与艺术家“直连”　
实时互动和精准化构建的“即时满足”　
社区与共创的“想象力”　
基于生成全新内容的平台　
.　抓住AIGC的机遇　
AIGC时代，做“短信”还是“微信”　
AIGC的发展仍无法脱离技术周期　
第章 开源成就行业发展的未来
.　开源让我们站在巨人的肩膀上　
.　开源成为引爆AIGC的导火索　
.　大模型的开源之路　
第章 AIGC与商业化
.　AIGC商业化的个阶段　
感知冲击――尝鲜阶段　
认知领悟――协助阶段　
新生态链――原创阶段　
.　AI领域的企业发展　
平台型企业　
应用型企业　
现有产品的智能化　
.　当下典型的AIGC变现手段　
按照计算量收费　
按照输出图像数量收费　
软件按月付费　
模型训练费　
.　AIGC商业模式的困境　
AIGC Inside的商业化并不容易　
难以建立技术壁垒　
探索自主的大模型及应用　
第章 AIGC的典型应用
.　文字创作　
主要特点　
典型应用　
.　音频生成　
主要特点　
典型应用　
.　视频生成　
主要特点　
典型应用　
.　D模型生成　
主要特点　
典型应用　
.　编写代码　
主要特点　
典型应用　
.　游戏创作开发　
主要特点　
典型应用　
.　绘画产品　
典型绘画产品的AIGC应用　
AIGC绘画与NFT结合　
.　建筑设计　
将AIGC融入建筑设计　
用AIGC实现装修设计　
.　其他应用　
DIY设计　
儿童创意实现　
内容营销　
诊疗与心灵慰藉　
第章 AIGC的不足与挑战
.　技术与产业方面的不足与挑战　
细节仍需打磨　
成本问题　
输出结果不一致　
大模型到大应用的挑战　
通用性较差　
.　在确权方面面临的挑战　
AIGC作品的著作权归属　
著作权争议的潜在解决方案　
法律监管出现争议　
企业态度不统一　
伦理与安全风险　
第章 业界和学界的专家洞察
.　AIGC可扩展潜力巨大，可能掀起新一波创新创业浪潮　
从AIGC到AIGS，“服务规模化的个性化”时代到来　
从科技圈体验到全民使用，AI首次成功破圈　
OpenAI已经成功探索出AI领域科技创新落地的新模式　
中国需要自主大模型，也有可能探索出自己的创新　
.　AIGC火热的背后，需要深度思考治理难题　
破解“克林格里奇困境”，要靠更敏捷的治理思路　
加强对弱势群体的保护，平台应该做好“守门人”　
AIGC内容知识产权还没有定论，但业界已有基本共识　
探索人工智能领域“数据合作”新范式　
.　AIGC火热背后的业界冷思考：中国AI行业的未来发展，需要有自己的思路　
ChatGPT的流畅对话来源于预训练大模型　
“AI幻觉”仍是阻碍产业发展的难题　
大规模预训练技术仍处于早期探索阶段，人工智能公司还需耐心打磨　
在AIGC技术浪潮中，一些行业将迎来全新挑战　
中国AI行业的未来发展，需要有自己的思考和思路　
・ ・ ・ ・ ・ ・ (收起)第 章　从数学建模到人工智能 
.　数学建模　
..　数学建模与人工智能　
..　数学建模中的常见问题　
.　人工智能下的数学　
..　统计量　
..　矩阵概念及运算　
..　概率论与数理统计　
..　高等数学――导数、微分、不定积分、定积分　
第　章 Python快速入门　
.　安装Python　
..　Python安装步骤　
..　IDE的选择　
.　Python基本操作　
..　第 一个小程序　
..　注释与格式化输出　
..　列表、元组、字典　
..　条件语句与循环语句　
..　break、continue、pass　
.　Python高级操作　
..　lambda　
..　map　
..　filter　
第章　Python科学计算库NumPy　
.　NumPy简介与安装　
..　NumPy简介　
..　NumPy安装　
.　基本操作　
..　初识NumPy　
..　NumPy数组类型　
..　NumPy创建数组　
..　索引与切片　
..　矩阵合并与分割　
..　矩阵运算与线性代数　
..　NumPy的广播机制　
..　NumPy统计函数　
..　NumPy排序、搜索　
..　NumPy数据的保存　
第章　常用科学计算模块快速入门　
.　Pandas科学计算库　
..　初识Pandas　
..　Pandas基本操作　
.　Matplotlib可视化图库　
..　初识Matplotlib　
..　Matplotlib基本操作　
..　Matplotlib绘图案例　
.　SciPy科学计算库　
..　初识SciPy　
..　SciPy基本操作　
..　SciPy图像处理案例　
第章　Python网络爬虫　
.　爬虫基础　
..　初识爬虫　
..　网络爬虫的算法　
.　爬虫入门实战　
..　调用API　
..　爬虫实战　
.　爬虫进阶―高效率爬虫　
..　多进程　
..　多线程　
..　协程　
..　小结　
第章　Python数据存储　
.　关系型数据库MySQL　
..　初识MySQL　
..　Python操作MySQL　
.　NoSQL之MongoDB　
..　初识NoSQL　
..　Python操作MongoDB　
.　本章小结　
..　数据库基本理论　
..　数据库结合　
..　结束语　
第章　Python数据分析　
.　数据获取　
..　从键盘获取数据　
..　文件的读取与写入　
..　Pandas读写操作　
.　数据分析案例　
..　普查数据统计分析案例　
..　小结　
第章　自然语言处理　
.　Jieba分词基础　
..　Jieba中文分词　
..　Jieba分词的种模式　
..　标注词性与添加定义词　
.　关键词提取　
..　TF-IDF关键词提取　
..　TextRank关键词提取　
.　wordvec介绍　
..　wordvec基础原理简介　
..　wordvec训练模型　
..　基于gensim的wordvec实战　
第章　从回归分析到算法基础　
.　回归分析简介　
..　“回归”一词的来源　
..　回归与相关　
..　回归模型的划分与应用　
.　线性回归分析实战　
..　线性回归的建立与求解　
..　Python求解回归模型案例　
..　检验、预测与控制　
第　章 从K-Means聚类看算法调参　
.　K-Means基本概述　
..　K-Means简介　
..　目标函数　
..　算法流程　
..　算法优缺点分析　
.　K-Means实战　
第　章 从决策树看算法升级　
.　决策树基本简介　
.　经典算法介绍　
..　信息熵　
..　信息增益　
..　信息增益率
..　基尼系数　
..　小结　
.　决策树实战　
..　决策树回归　
..　决策树的分类　
第　章 从朴素贝叶斯看算法多变　
.　朴素贝叶斯简介　
..　认识朴素贝叶斯　
..　朴素贝叶斯分类的工作过程　
..　朴素贝叶斯算法的优缺点　
.　种朴素贝叶斯实战　
第　章 从推荐系统看算法场景　
.　推荐系统简介　
..　推荐系统的发展　
..　协同过滤　
.　基于文本的推荐　
..　标签与知识图谱推荐案例　
..　小结　
第　章 从TensorFlow开启深度学习之旅　
.　初识TensorFlow　
..　什么是TensorFlow　
..　安装TensorFlow　
..　TensorFlow基本概念与原理　
.　TensorFlow数据结构　
..　阶　
..　形状　
..　数据类型　
.　生成数据十二法　
..　生成Tensor　
..　生成序列　
..　生成随机数　
.　TensorFlow实战　
参考文献　
・ ・ ・ ・ ・ ・ (收起)目 录

第章 人工智能初印象 
. 什么是人工智能？ 
.. 定义AI 
.. 理解数据是智能算法的核心 
.. 把算法看作“菜谱” 
. 人工智能简史 
. 问题类型与问题解决范式 
. 人工智能概念的直观印象 
. 人工智能算法的用途 
.. 农业：植物种植优化 
.. 银行业：欺诈检测 
.. 网络安全：攻击检测与处理 
.. 医疗：智能诊断 
.. 物流：路径规划与优化 
.. 通信：网络优化 
.. 游戏：主体创造 
.. 艺术：创造杰出作品 
. 本章小结 
第章 搜索算法基础 
. 什么是规划与搜索？ 
. 计算成本：需要智能算法的原因 
. 适合用搜索算法的问题 
. 表示状态：创建一个表示问题空间与解的框架 
.. 图：表示搜索问题与解 
.. 用具体的数据结构表示图 
.. 树：表示搜索结果的具体结构 
. 无知搜索：盲目地找寻解 
. 广度优先搜索：先看广度，再看深度 
. 深度优先搜索：先看深度，再看广度 
. 盲目搜索算法的用例 
. 可选：关于图的类别 
. 可选：其他表示图的方法 
.. 关联矩阵 
.. 邻接表 
. 本章小结 
第章 智能搜索 
. 定义启发式方法：设计有根据的猜测 
. 知情搜索：在指导下寻求解决方案 
.. A*搜索 
.. 知情搜索算法的用例 
. 对抗性搜索：在不断变化的环境中寻找解决方案 
.. 一个简单的对抗性问题 
.. 最小-最大搜索：模拟行动并选择最好的未来 
.. 启发式 
.. 阿尔法-贝塔剪枝：仅探索合理的路径 
.. 对抗搜索算法的典型案例 
. 本章小结 
第章 进化算法 
. 什么是进化？ 
. 适合用进化算法的问题 
. 遗传算法的生命周期 
. 对解空间进行编码 
. 创建解决方案种群 
. 衡量种群中个体的适应度 
. 根据适应度得分筛选亲本 
. 由亲本繁殖个体 
.. 单点交叉：从每个亲本继承一部分 
.. 两点交叉：从每个亲本继承多个部分 
.. 均匀交叉：从每个亲本继承多个部分 
.. 二进制编码的位串突变 
.. 二进制编码的翻转位突变 
. 繁衍下一代 
.. 探索与挖掘 
.. 停止条件 
. 遗传算法的参数配置 
. 进化算法的用例 
. 本章小结 
第章 进化算法(高级篇) 
. 进化算法的生命周期 
. 其他筛选策略 
.. 排序筛选法：均分赛场 
.. 联赛筛选法：分组对抗 
.. 精英筛选法：只选最好的 
. 实值编码：处理真实数值 
.. 实值编码的核心概念 
.. 算术交叉：数学化繁殖 
.. 边界突变 
.. 算术突变 
. 顺序编码：处理序列 
.. 适应度函数的重要性 
.. 顺序编码的核心概念 
.. 顺序突变：适用于顺序编码 
. 树编码：处理层次结构 
.. 树编码的核心概念 
.. 树交叉：继承树的分支 
.. 节点突变：更改节点的值 
. 常见进化算法 
.. 遗传编程 
.. 进化编程 
. 进化算法术语表 
. 进化算法的其他用例 
. 本章小结 
第章 群体智能：蚁群优化 
. 什么是群体智能？ 
. 适合用蚁群优化算法的问题 
. 状态表达：如何表达蚂蚁和路径？ 
. 蚁群优化算法的生命周期 
.. 初始化信息素印迹 
.. 建立蚂蚁种群 
.. 为蚂蚁选择下一个访问项目 
.. 更新信息素印迹 
.. 更新最佳解决方案 
.. 确定终止条件 
. 蚁群优化算法的用例 
. 本章小结 
第章 群体智能：粒子群优化 
. 什么是粒子群优化？ 
. 优化问题：略偏技术性的观点 
. 适合用粒子群优化算法的问题 
. 状态表达：粒子是什么样的？ 
. 粒子群优化的生命周期 
.. 初始化粒子群 
.. 计算粒子的适应度 
.. 更新粒子的位置 
.. 确定终止条件 
. 粒子群优化算法的用例 
. 本章小结 
第章 机器学习 
. 什么是机器学习？ 
. 适合用机器学习的问题 
.. 监督学习 
.. 非监督学习 
.. 强化学习 
. 机器学习的工作流程 
.. 收集和理解数据：掌握数据背景 
.. 准备数据：清洗和整理 
.. 训练模型：用线性回归预测 
.. 测试模型：验证模型精度 
.. 提高准确性 
. 分类问题：决策树 
.. 分类问题：非此即彼 
.. 决策树的基础知识 
.. 训练决策树 
.. 用决策树对实例进行分类 
. 其他常见的机器学习算法 
. 机器学习算法的用例 
. 本章小结 
第章 人工神经网络 
. 什么是人工神经网络？ 
. 感知器：表征神经元 
. 定义人工神经网络 
. 前向传播：使用训练好的人工神经网络 
. 反向传播：训练人工神经网络 
. 激活函数一览 
. 设计人工神经网络 
. 人工神经网络的类型和用例 
.. 卷积神经网络 
.. 递归神经网络 
.. 生成对抗网络 
. 本章小结 
第章 基于Q-learning的强化学习 
. 什么是强化学习？ 
. 适合用强化学习的问题 
. 强化学习的生命周期 
.. 模拟与数据：环境重现 
.. 使用Q-learning模拟训练 
.. 模拟并测试Q表 
.. 衡量训练的性能 
.. 无模型和基于模型的学习 
. 强化学习的深度学习方法 
. 强化学习的用例 
.. 机器人技术 
.. 推荐引擎 
.. 金融贸易 
.. 电子游戏 
. 本章小结 
・ ・ ・ ・ ・ ・ (收起)第一部分引言
第　章人工智能概述　
.　引言　
..　人工智能的定义　
..　思维是什么？智能是什么？　
.　图灵测试　
..　图灵测试的定义　
..　图灵测试的争议和批评　
.　强人工智能与弱人工智能　
.　启发法　
..　长方体的对角线：解决一个相对简单但相关的
问题　
..　水壶问题：向后倒推　
.　识别适用人工智能来求解的问题　
.　应用和方法　
..　搜索算法和拼图　
..　二人博弈　
..　自动推理　
..　产生式规则和专家系统　
..　细胞自动机　
..　神经计算　
..　遗传算法　
..　知识表示　
..　不确定性推理　
.　人工智能的早期历史　
.　人工智能的近期历史到现在　
..　博弈　
..　专家系统　
..　神经计算　
..　进化计算　
..　自然语言处理　
..　生物信息学　
.　新千年人工智能的发展　
.　本章小结　
第二部分　基础知识
第　章盲目搜索　
.　简介：智能系统中的搜索　
.　状态空间图　
.　生成与测试范式　
..　回溯　
..　贪婪算法　
..　旅行销售员问题　
.　盲目搜索算法　
..　深度优先搜索　
..　广度优先搜索　
.　盲目搜索算法的实现和比较　
..　实现深度优先搜索　
..　实现广度优先搜索　
..　问题求解性能的测量指标　
..　DFS和BFS的比较　
.　本章小结　
第章　知情搜索　
.　引言　
.　启发法　
.　知情搜索（第一部分）――找到任何解　
..　爬山法　
..　最陡爬坡法　
.　最佳优先搜索　
.　集束搜索　
.　搜索算法的其他指标　
.　知情搜索（第二部分）――找到最佳解　
..　分支定界法　
..　使用低估值的分支定界法　
..　采用动态规划的分支定界法　
..　A*搜索　
.　知情搜索（第三部分）―高级搜索算法　
..　约束满足搜索　
..　与或树　
..　双向搜索　
.　本章小结　
第章　博弈中的搜索　
.　引言　
.　博弈树和极小化极大评估　
..　启发式评估　
..　博弈树的极小化极大评估　
.　具有α-剪枝的极小化极大算法　
.　极小化极大算法的变体和改进　
..　负极大值算法　
..　渐进深化法　
..　启发式续篇和地平线效应　
.　概率游戏和预期极小化极大值算法　
.　博弈理论　
迭代的囚徒困境　
.　本章小结　
第章　人工智能中的逻辑　
.　引言　
.　逻辑和表示　
.　命题逻辑　
..　命题逻辑―基础　
..　命题逻辑中的论证　
..　证明命题逻辑论证有效的第二种方法　
.　谓词逻辑――简要介绍　
..　谓词逻辑中的合一　
..　谓词逻辑中的反演　
..　将谓词表达式转换为子句形式　
.　其他一些逻辑　
..　二阶逻辑　
..　非单调逻辑　
..　模糊逻辑　
..　模态逻辑　
.　本章小结　
第章　知识表示　
.　引言　
.　图形草图和人类视窗　
.　图和哥尼斯堡桥问题　
.　搜索树　
.　表示方法的选择　
.　产生式系统　
.　面向对象　
.　框架法　
.　脚本和概念依赖系统　
.　语义网络　
.　关联　
.　新近的方法　
..　概念地图　
..　概念图　
..　Baecker的工作　
.　智能体：智能或其他　
..　智能体的一些历史　
..　当代智能体　
..　语义网　
..　IBM眼中的未来世界　
..　作者的观点　
.　本章小结　
第章　产生式系统　
.　引言　
.　背景　
.　基本示例　
.　CARBUYER系统　
.　产生式系统和推导方法　
..　冲突消解　
..　正向链接　
..　反向链接　
.　产生式系统和细胞自动机　
.　随机过程与马尔可夫链　
.　本章小结　
第三部分　基于知识的系统
第章　人工智能中的不确定性　
.　引言　
.　模糊集　
.　模糊逻辑　
.　模糊推理　
.　概率理论和不确定性　
.　本章小结　
第章　专家系统　
.　引言　
.　背景　
.　专家系统的特点　
.　知识工程　
.　知识获取　
.　经典的专家系统　
..　DENDRAL　
..　MYCIN　
..　EMYCIN　
..　PROSPECTOR　
..　模糊知识和贝叶斯规则　
.　提高效率的方法　
..　守护规则　
..　Rete算法　
.　基于案例的推理　
.　更多最新的专家系统　
..　改善就业匹配系统　
..　振动故障诊断的专家系统　
..　自动牙科识别　
..　更多采用案例推理的专家系统　
.　本章小结　
第　章机器学习第一部分　
.　引言　
.　机器学习：简要概述　
.　机器学习系统中反馈的作用　
.　归纳学习　
.　利用决策树进行学习　
.　适用于决策树的问题　
.　熵　
.　使用ID构建决策树　
.　其余问题　
.　本章小结　
第　章机器学习第二部分：神经网络　
.　引言　
.　人工神经网络的研究　
.　麦卡洛克-皮茨网络　
.　感知器学习规则　
.　增量规则　
.　反向传播　
.　实现关注点　
..　模式分析　
..　训练方法　
.　离散型霍普菲尔德网络　
.　应用领域　
.　本章小结　
第　章受到自然启发的搜索　
.　引言　
.　模拟退火　
.　遗传算法　
.　遗传规划　
.　禁忌搜索　
.　蚂蚁聚居地优化　
.　本章小结　
第四部分　高级专题
第　章自然语言处理　
.　引言　
.　概述：语言的问题和可能性　
.　自然语言处理的历史　
..　基础期（世纪年代和年代）　
..　符号与随机方法（―）　
..　种范式（―）　
..　经验主义和有限状态模型（―）　
..　大融合（―）　
..　机器学习的兴起（―）　
.　句法和形式语法　
..　语法类型　
..　句法解析：CYK算法　
.　语义分析和扩展语法　
..　转换语法　
..　系统语法　
..　格语法　
..　语义语法　
..　Schank系统　
.　NLP中的统计方法　
..　统计解析　
..　机器翻译（回顾）和IBM的Candide系统　
..　词义消歧　
.　统计NLP的概率模型　
..　隐马尔可夫模型　
..　维特比算法　
.　统计NLP语言数据集　
..　宾夕法尼亚州树库项目　
..　WordNet　
..　NLP中的隐喻模型　
.　应用：信息提取和问答系统　
..　问答系统　
..　信息提取　
.　现在和未来的研究（基于CHARNIAK的工作）　
.　语音理解　
.　语音理解技术的应用　
.　本章小结　
第　章自动规划　
.　引言　
.　规划问题　
..　规划术语　
..　规划应用示例　
.　一段简短的历史和一个著名的问题　
.　规划方法　
..　规划即搜索　
..　部分有序规划　
..　分级规划　
..　基于案例的规划　
..　规划方法集锦　
.　早期规划系统　
..　STRIPS　
..　NOAH　
..　NONLIN　
.　更多现代规划系统　
..　O-PLAN　
..　Graphplan　
..　规划系统集锦　
..　学习系统的规划方法　
..　SCIBox自动规划器　
.　本章小结　
第五部分　现在和未来
第　章机器人技术　
.　引言　
.　历史：服务人类、仿效人类、增强人类和替代人类　
..　早期机械机器人　
..　电影与文学中的机器人　
..　世纪早期的机器人　
.　技术问题　
..　机器人的组件　
..　运动　
..　点机器人的路径规划　
..　移动机器人运动学　
.　应用：世纪的机器人　
.　本章小结　
第　章高级计算机博弈　
.　引言　
.　跳棋：从塞缪尔到舍弗尔　
..　在跳棋博弈中用于机器学习的启发式方法　
..　填鸭式学习与概括　
..　签名表评估和棋谱学习　
..　含有奇诺克程序的世界跳棋锦标赛　
..　彻底解决跳棋游戏　
.　国际象棋：人工智能的“果蝇”　
..　计算机国际象棋的历史背景　
..　编程方法　
..　超越地平线效应　
..　DeepThought和DeepBlue与特级大师的比赛（―年）　
.　计算机国际象棋对人工智能的贡献　
..　在机器中的搜索　
..　在搜索方面，人与机器的对比　
..　启发式、知识和问题求解　
..　蛮力：知识vs.搜索；表现vs.能力　
..　残局数据库和并行计算　
..　本书第一作者的贡献　
.　其他博弈　
..　奥赛罗　
..　西洋双陆棋　
..　桥牌　
..　扑克　
.　围棋：人工智能的“新果蝇”？　
.　本章小结　
第　章大事记　
.　引言　
.　提纲挈领――概述　
.　普罗米修斯归来　
.　提纲挈领――介绍人工智能的成果　
.　IBM的沃森-危险边缘挑战赛　
.　世纪的人工智能　
.　本章小结　
附录A　CLIPS示例：专家系统外壳　
附录B　用于隐马尔可夫链的维特比算法的实现（由HarunIftikhar提供）　
附录C　对计算机国际象棋的贡献：令人惊叹的WalterShawnBrowne　
附录D　应用程序和数据　
附录E　部分练习的答案　
・ ・ ・ ・ ・ ・ (收起)第章 绪论
第章 数学基础
. 导数
. 概率论基础
. 矩阵基础
习题
第章 搜索
引言
. 搜索问题的定义
. 搜索算法基础
. 盲目搜索
. 启发式搜索
. 局部搜索
. 对抗搜索
本章总结
历史回顾
习题
第章 机器学习
引言
. 监督学习的概念
. 数据集与损失函数
. 泛化
. 过拟合与欠拟合
. 创建数据集
. 无监督学习与半监督学习
本章总结
历史回顾
习题
参考文献
第章 线性回归
引言
. 线性回归
. 优化方法
. 二分类问题
. 多分类问题
. 岭回归
. 套索回归
. 支持向量机算法
本章总结
习题
第章 决策树模型
引言
. 决策树的例子
. 决策树的定义
. 决策树的训练算法
本章总结
历史回顾
习题
参考文献
第章 集成学习
引言
. 集成学习
. 随机森林
. 梯度提升
本章总结
历史回顾
习题
参考文献
第章 神经网络初步
引言
. 深度线性网络
. 非线性神经网络
. 反向传播计算导数
. 优化器
. 权值初始化
. 权值衰减
. 权值共享与卷积
. 循环神经网络
本章总结
历史回顾
习题
第章 计算机视觉
引言
. 什么是计算机视觉
. 图像的形成
. 线性滤波器
. 边缘检测
. 立体视觉
. 卷积神经网络
. 物体检测
. 语义分割
本章总结
历史回顾
习题
参考文献
第章 自然语言处理
引言
. 语言模型
. 向量语义
. 基于神经网络的语言模型处理
. 基于神经网络的机器翻译
. 语言模型预训练
本章总结
历史回顾
习题
第章 马尔可夫决策过程与强化学习
引言
. 马尔可夫链
. 马尔可夫决策过程
. 马尔可夫决策过程的求解算法及分析
. 强化学习
本章总结
历史回顾
参考文献
习题
附录A 数学基础
A. 导数
A. 概率
A. 矩阵
・ ・ ・ ・ ・ ・ (收起)第 章 人工智能与数学基础..........
. 什么是人工智能............................ 
. 人工智能的发展 ............................ 
. 人工智能的应用 ............................ 
. 学习人工智能需要哪些知识 ............. 
. 为什么要学习数学 ......................... 
. 本书包括的数学知识 ...................... 
第  篇
基础篇................................................................. 
第  章 高等数学基础 ................. 
. 函数.......................................... 
. 极限..........................................
. 无穷小与无穷大...........................
. 连续性与导数..............................
. 偏导数...................................... 
. 方向导数................................... 
. 梯度......................................... 
. 综合实例―梯度下降法求函数的最小值.......................................
. 高手点拨................................... 
. 习题....................................... 
第  章 微积分..............................
. 微积分的基本思想 ....................... 
. 微积分的解释..............................
. 定积分...................................... 
. 定积分的性质............................. 
. 牛顿―莱布尼茨公式.................... 
. 综合实例―Python 中常用的定积分求解方法................................... 
. 高手点拨....................................
. 习题 ........................................ 
第  章 泰勒公式与拉格朗日乘子法..............................
. 泰勒公式出发点.......................... 
. 一点一世界................................ 
. 阶数和阶乘的作用....................... 
. 麦克劳林展开式的应用..................
. 拉格朗日乘子法.......................... 
. 求解拉格朗日乘子法.................... 
. 综合实例―编程模拟实现 sinx 的n 阶泰勒多项式并验证结果.................. 
. 高手点拨 ................................... 
. 习题 ......................................... 
第 篇
核心篇............................................................... 
第  章 将研究对象形式化―线性代数基础 ..........................
. 向量..........................................
. 矩阵......................................... 
. 矩阵和向量的创建....................... 
. 特殊的矩阵................................ 
. 矩阵基本操作..............................
. 转置矩阵和逆矩阵....................... 
. 行列式..................................... 
. 矩阵的秩..................................
. 内积与正交...............................
. 综合实例―线性代数在实际问题中的应用 ....................................... 
. 高手点拨 ................................ 
. 习题......................................
第  章 从数据中提取重要信息―特征值与矩阵分解..........
. 特征值与特征向量 .....................
. 特征空间..................................
. 特征值分解...............................
. SVD 解决的问题.......................
. 奇异值分解（SVD）..................
. 综合实例 ―利用 SVD 对图像进行压缩 .......................................
. 综合实例 ―利用 SVD 推荐商品 .......................................
. 高手点拨..................................
. 习题 .......................................
第  章 描述统计规律 ―概率论基础................................
. 随机事件及其概率 ......................
. 条件概率.................................. 
. 独立性.....................................
. 随机变量..................................
. 二维随机变量............................
. 边缘分布..................................
. 综合实例―概率的应用.............
. 高手点拨.................................. 
. 习题........................................
第  章 描述统计规律 ―随机变量与概率估计........................
. 随机变量的数字特征 ..................
. 大数定律和中心极限定理.............
. 数理统计基本概念......................
. 最大似然估计........................... 
. 最大后验估计........................... 
. 综合实例 ―贝叶斯用户满意度预测 ...................................... 
. 综合实例 ―最大似然法求解模型参数 .......................................
. 高手点拨 ................................ 
. 习题 ....................................... 
第  篇
提高篇............................................................. 
第  章 随机变量的几种分布...... 
. 正态分布 ................................ 
. 二项分布................................. 
. 泊松分布................................. 
. 均匀分布..................................
. 卡方分布................................. 
. Beta 分布 .............................. 
. 综合实例―估算棒球运动员的击中率 ...................................... 
. 高手点拨 ................................ 
. 习题 ...................................... 
第  章 数据的空间变换―核函数变换............................. 
. 相关知识简介 ......................... 
. 核函数的引入 ......................... 
. 核函数实例............................ 
. 常用核函数.............................
. 核函数的选择......................... 
. SVM 原理 ............................ 
. 非线性 SVM 与核函数的引入.... 
. 综合实例―利用 SVM 构建分类
问题......................................
. 高手点拨................................
. 习题 ................................... 
第  章 熵与激活函数 .............. 
. 熵和信息熵............................ 
. 激活函数 ............................... 
. 综合案例―分类算法中信息熵的应用...................................... 
. 高手点拨 ................................
. 习题 ..................................... 
第 篇
应用篇............................................................. 
第  章 假设检验 ..................... 
. 假设检验的基本概念................. 
. Z 检验 ...................................
. t 检验 ................................... 
. 卡方检验............................... 
. 假设检验中的两类错误 ..............
. 综合实例 ―体检数据中的假设检验问题..................................... 
. 综合实例 ―种族对求职是否有影响..................................... 
. 高手点拨............................... 
. 习题..................................... 
 章 相关分析...................... 
. 相关分析概述.......................... 
. 皮尔森相关系数....................... 
. 相关系数的计算与假设检验........ 
. 斯皮尔曼等级相关.................... 
. 肯德尔系数............................. 
. 质量相关分析.......................... 
. 品质相关分析.......................... 
. 偏相关与复相关....................... 
. 综合实例―相关系数计算........ 
. 高手点拨.............................. 
. 习题..................................... 
第  章 回归分析......................
. 回归分析概述...........................
. 回归方程推导及应用..................
. 回归直线拟合优度.....................
. 线性回归的模型检验..................
. 利用回归直线进行估计和预测......
. 多元与曲线回归问题..................
. Python 工具包....................... 
. 综合实例―个人医疗保费预测任务...................................... 
. 高手点拨................................ 
. 习题..................................... 
第  章 方差分析......................
. 方差分析概述.......................... 
. 方差的比较............................. 
. 方差分析.................................
. 综合实例―连锁餐饮用户评级分析...................................... 
. 高手点拨................................ 
. 习题...................................... 
第  章 聚类分析......................
. 聚类分析概述.......................... 
. 层次聚类................................ 
. K-Means 聚类...................... 
. DBSCAN 聚类....................... 
. 综合实例―聚类分析.............. 
. 高手点拨.................................
. 习题.......................................
第  章 贝叶斯分析....................
. 贝叶斯分析概述........................
. MCMC 概述.......................... 
. MCMC 采样 ......................... 
. Gibbs 采样........................... 
. 综合实例―利用 PyMC 实现随机模拟样本分布......................... 
. 高手点拨............................... 
. 习题..................................... 
・ ・ ・ ・ ・ ・ (收起)出版者的话
专家指导委员会
译者序
序
第版序
致谢
第章 基于知识的智能系统概述
. 智能机器概述
. 人工智能发展历史
. 小结
复习题
参考文献
第章 基于规则的专家系统
. 知识概述
. 规则是一种知识表达技术
. 专家系统研发团队中的主要参与者
. 基于规则的专家系统的结构
. 专家系统的基本特征
. 前向链接和后向链接推理技术
. 实例
. 冲突的解决方案
. 基于规则的专家系统的优缺点
. 小结
复习题
参考文献
第章 基于规则的专家系统的不确定管理
. 不确定性简介
. 基本概率论
. 贝叶斯推理
. FORECAST：贝叶斯证据累积
. 贝叶斯方法的偏差
. 确定因子理论和证据推理
. FORECAST：确定因子的应用
. 贝叶斯推理和确定因子的比较
. 小结
复习题
参考文献
第章 模糊专家系统
. 概述
. 模糊集
. 语言变量和模糊限制语
. 模糊集的操作
. 模糊规则
. 模糊推理
. 建立模糊专家系统
. 小结
复习题
参考文献
参考书目
第章 基于框架的专家系统
. 框架简介
. 作为知识表达技术的框架
. 基于框架系统中的继承
. 方法和守护程序
. 框架和规则的交互
. 基于框架的专家系统实例：Buy Smart
. 小结
复习题
参考文献
参考书目
第章 人工神经网络
. 人脑工作机制简介
. 作为简单计算元素的神经元
. 感知器
. 多层神经网络
. 多层神经网络的加速学习
. Hopfield神经网络
. 双向相关记忆
. 自组织神经网络
. 小结
复习题
参考文献
第章 进化计算
. 进化是智能的吗
. 模拟自然进化
. 遗传算法
. 遗传算法如何工作
. 实例：用遗传算法来维护计划
. 进化策略
. 遗传编程
. 小结
复习题
参考文献
参考书目
第章 混合智能系统
. 概述
. 神经专家系统
. 神经模糊系统
. ANFIS：自适应性神经模糊推理系统
. 进化神经网络
. 模糊进化系统
. 小结
复习题
参考文献
第章 知识工程和数据挖掘
. 知识工程简介
. 专家系统可以解决的问题
. 模糊专家系统可以解决的问题
. 神经网络可以解决的问题
. 遗传算法可以解决的问题
. 混合智能系统可以解决的问题
. 数据挖掘和知识发现
. 小结
复习题
参考文献
术语表
附录 人工智能工具和厂商
・ ・ ・ ・ ・ ・ (收起)推荐序 情感机器离我们有多远
李德毅
中国人工智能学会理事长
中国工程院院士
引言 人类思维与人工智能的未来
第一部分 情感，另一种人类思维方式
 坠入爱河
我们的每一种主要的“情感状态”都是因为激活了一些资源,同时关闭了另外一些资源――大脑的运行方式由此改变了。如果每次这种改变都会激活更多其他资源,那么最终将导致资源的大规模“级联”。
“爱”的手提箱
精神奥秘之海
情绪与情感
本能机，让婴儿情感更好捉摸
云认知型思维
成人精神活动的大层级
情感“瀑布”
思维维度的多样性
 依恋与目标
人类的一些目标是天生的本能, 是由我们的基因决定的; 另一些目标则是通过“尝试和错误”学习，来实现已有目标的次级目标；而高层次目标, 则是由一种特殊的机器体系形成的。这种特殊的机器体系是指我们对身为依恋对象的父母、朋友或亲人的价值观的继承, 这些价值观积极地响应了我们的需要, 在我们体内产生了“自我意识”情感。
沙子游戏 ：从叉子到勺子
依恋与目标
印刻者
依恋性学习模式
学习、快乐和信用赋能
价值体系的塑造
幼儿和动物的依恋
谁是我们的印刻者
自律，构建目标一致的自我模型
公众印刻
 从疼痛到煎熬
任何疼痛都会激活“摆脱疼痛”这一目标, 而这个目标的实现将有助于目标本身的消失。然而, 如果疼痛强烈而又持久, 就会激发其他大脑资源, 进而压制其他目标。如果这种情况级联式地爆发下去, 那么大脑
的大部分区域都会被痛苦占据 。可见，在处于某种精神状态中时, 我们也就失去了“选择的自由”。
疼痛之中
煎熬，大脑失去自由选择权
苦难机器
致命性的痛苦
心智“批评家”：纠正性警告、外显抑制和内隐束缚
弗洛伊德的思维“三明治”
控制我们的情绪和性情
情感利用
第二部分 洞悉思维本质，创建情感机器的大维度
 意识
“意识”是一个“手提箱”式词汇, 它被我们用来表示许多不同的精神活动。而这些精神活动并没有单一的原因或起源, 当然, 这也正是为何人们发现很难“理解意识是什么”的原因所在。心灵的每个阶段都
是一个同时存在多种可能性的剧场，而意识则将这些可能性相互比较, 通过注意力的强化和抑制作用, 选择一些可能性、抑制其他可能性。
什么是意识
打开意识的手提箱
A 脑、B 脑和C 脑
对意识的高估
如何开启意识
主观体验，心理学中的无解难题
自我模型与自我意识
笛卡儿剧场
不间断的意识流
 精神活动层级
我们的大脑是如何产生如此多新事物和新想法的? 资源可以分为  种不同的层级――本能反应、后天反应、沉思、反思、自我反思、自我意识，以对想法和思维机制进行衡量。每一个层级模式都建立在下一个
层级模式的基础之上, 最上层的模式表现的是人们的最高理想和个人目标。
本能反应
后天反应
沉思
反思
自我反思
自我意识
想象
想象场景
预测机器
 常识
我们所做的许多常识性事情和常识性推理，要比吸引更多关注、获得令人敬仰的专业技能复杂得多。你所“看到”的并不完全来自视觉, 还来自这些视觉引发的其他知识。常识性知识的主体, 即人类需要在文明
世界中相处下去会涉及的许多问题, 如我们所说的常识性问题, 目标是什么以及它们是如何实现的，我们平常是如何通过类比来推理, 以及我们如何猜测哪一项知识等，可能与我们的决策方式相关联。
什么是常识
常识性知识和推理
意图和目标
差异的“幻想”世界
在不确定性中，作出最优决策
相似推理
正面经验和负面经验的博弈
 思维
我们几乎从未认识到常识性思考所创造的奇迹。人人都有不同的思维方式。在众多的兴趣爱好当中, 是什么选择了我们下一步将要思考的内容？每一种兴趣又会持续多久? 批评家又是如何选择所使用思维方式
的？事实上，工作被隐藏在“脑后”, 仍在继续运行。
是什么选择了我们思考的主题
批评家-选择器模型，思维跳跃之源
情感化思维
人类的大思维方式
 大批评家，选择最合适的思维方式
先有情感，还是先有行为
庞加莱无意识过程的 大阶段
认知语境下的批评家选择
人类心理学的核心问题
 智能
每个物种的个体智力都会从愚笨逐渐发展到优秀, 即使最高级的人类思维也本应从这个过程发展而来。我们可以通过多种视角来观察事物，我们拥有快速进行视角转换的方法、拥有高效学习的特殊方式、拥有获
得相关知识的有效方式并可以不断扩大思维方式的范围、拥有表征事物的多种方式。正是这种多样性造就了人类思维的多功能。
预估距离
平行类比
高效率学习的奥秘
信用赋能
创造力和天才
记忆与表征结构
表征等级
 自我
是什么让人类变得独一无二? 任何其他动物都无法像人类这样拥有各种各样的人格。其中一些性格是与生俱来的, 而另一些性格则来自个人经验, 但在每一种情况中, 我们都具有各异
的特征。每当想尝试理解自己时, 我们都可能需要采取多种角度来看待自己。
多样的“自我”
人格特质
“自我”观念的魅力
为什么我们喜欢快乐
情感描述难题
发现感觉中独特的“质”
人类思维的组织方式
复杂的尊严
人类智能的大时间跨度
致 谢
注 释
译者后记
・ ・ ・ ・ ・ ・ (收起)第  章 引言 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 本书面向的读者 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 深度学习的历史趋势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 神经网络的众多名称和命运变迁 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 与日俱增的数据量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 与日俱增的模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 与日俱增的精度、复杂度和对现实世界的冲击 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  部分 应用数学与机器学习基础
第  章 线性代数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 标量、向量、矩阵和张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 矩阵和向量相乘. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 单位矩阵和逆矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 线性相关和生成子空间 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 范数. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 特殊类型的矩阵和向量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 特征分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 奇异值分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Moore-Penrose 伪逆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 迹运算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 行列式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实例：主成分分析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 概率与信息论. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 为什么要使用概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 离散型变量和概率质量函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 连续型变量和概率密度函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 边缘概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 条件概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 条件概率的链式法则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 独立性和条件独立性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 期望、方差和协方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 常用概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Bernoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Multinoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高斯分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 指数分布和 Laplace 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Dirac 分布和经验分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 分布的混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 常用函数的有用性质. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 贝叶斯规则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 连续型变量的技术细节 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 信息论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 数值计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 上溢和下溢 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 病态条件 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于梯度的优化方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 梯度之上：Jacobian 和 Hessian 矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 约束优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实例：线性最小二乘 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 机器学习基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 任务 T . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 性能度量 P . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 经验 E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 示例：线性回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 容量、过拟合和欠拟合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 没有免费午餐定理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 超参数和验证集. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 交叉验证 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 估计、偏差和方差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 点估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 偏差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 方差和标准差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 权衡偏差和方差以最小化均方误差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 一致性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 最大似然估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 条件对数似然和均方误差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 最大似然的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 贝叶斯统计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最大后验 (MAP) 估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 监督学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 概率监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 支持向量机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他简单的监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 无监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 主成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. k-均值聚类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 构建机器学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 促使深度学习发展的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 维数灾难 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 局部不变性和平滑正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 流形学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  部分 深度网络：现代实践
第  章 深度前馈网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实例：学习 XOR. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于梯度的学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 代价函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 输出单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 隐藏单元. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 整流线性单元及其扩展 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. logistic sigmoid 与双曲正切函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他隐藏单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 架构设计. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 万能近似性质和深度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 其他架构上的考虑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 反向传播和其他的微分算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 微积分中的链式法则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 递归地使用链式法则来实现反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 全连接 MLP 中的反向传播计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 符号到符号的导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 一般化的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 实例：用于 MLP 训练的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 复杂化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 深度学习界以外的微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高阶微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 历史小记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 深度学习中的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 参数范数惩罚 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. L 参数正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. L 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 作为约束的范数惩罚. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 正则化和欠约束问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 噪声鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 向输出目标注入噪声. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 半监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 提前终止. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 参数绑定和参数共享. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 稀疏表示. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. Bagging 和其他集成方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 对抗训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 切面距离、正切传播和流形正切分类器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度模型中的优化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 学习和纯优化有什么不同 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 经验风险最小化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 代理损失函数和提前终止 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 批量算法和小批量算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 神经网络优化中的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 病态 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 局部极小值 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高原、鞍点和其他平坦区域 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 悬崖和梯度爆炸 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 长期依赖 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 非精确梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 局部和全局结构间的弱对应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 优化的理论限制 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基本算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 动量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Nesterov 动量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 参数初始化策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 自适应学习率算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. AdaGrad . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. RMSProp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 选择正确的优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 二阶近似方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 牛顿法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 共轭梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. BFGS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 优化策略和元算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 批标准化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 坐标下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Polyak 平均 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 设计有助于优化的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 延拓法和课程学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 卷积网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积运算. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 动机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 池化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积与池化作为一种无限强的先验 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基本卷积函数的变体. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 结构化输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 数据类型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 高效的卷积算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 随机或无监督的特征. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 卷积网络的神经科学基础 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积网络与深度学习的历史 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 序列建模：循环和递归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 展开计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 导师驱动过程和输出循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 计算循环神经网络的梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 作为有向图模型的循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于上下文的 RNN 序列建模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 双向 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于编码 - 解码的序列到序列架构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 深度循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 递归神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 长期依赖的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 回声状态网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 渗漏单元和其他多时间尺度的策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 时间维度的跳跃连接. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 渗漏单元和一系列不同时间尺度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 删除连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 长短期记忆和其他门控 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他门控 RNN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 优化长期依赖. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 截断梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 引导信息流的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 外显记忆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 实践方法论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 性能度量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 默认的基准模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 决定是否收集更多数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 选择超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 手动调整超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 自动超参数优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 网格搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 随机搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于模型的超参数优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 调试策略. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 示例：多位数字识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 大规模深度学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 快速的 CPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. GPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 大规模的分布式实现. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 模型压缩 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 动态结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 深度网络的专用硬件实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 计算机视觉 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 语音识别. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 自然语言处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. n-gram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 高维输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 结合 n-gram 和神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 神经机器翻译 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 其他应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 推荐系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 知识表示、推理和回答 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  部分 深度学习研究
第  章 线性因子模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 概率 PCA 和因子分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 独立成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 慢特征分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 稀疏编码. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. PCA 的流形解释 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 欠完备自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 正则自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 稀疏自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 去噪自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 惩罚导数作为正则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 表示能力、层的大小和深度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 随机编码器和解码器. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 去噪自编码器详解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 得分估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 使用自编码器学习流形 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 收缩自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 预测稀疏分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 自编码器的应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 表示学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 贪心逐层无监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 何时以及为何无监督预训练有效有效 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 迁移学习和领域自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 半监督解释因果关系. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 分布式表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 得益于深度的指数增益 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 提供发现潜在原因的线索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度学习中的结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 非结构化建模的挑战. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 使用图描述模型结构. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 有向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于能量的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 分离和 d-分离 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 在有向模型和无向模型中转换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 因子图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 从图模型中采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 结构化建模的优势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 学习依赖关系 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 推断和近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 结构化概率模型的深度学习方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 实例：受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 采样和蒙特卡罗方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 为什么需要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 蒙特卡罗采样的基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 重要采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 马尔可夫链蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Gibbs 采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 不同的峰值之间的混合挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 不同峰值之间通过回火来混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 深度也许会有助于混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 直面配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 对数似然梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 随机最大似然和对比散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 伪似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 得分匹配和比率匹配. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 去噪得分匹配 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 估计配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 退火重要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 桥式采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 把推断视作优化问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 期望最大化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 最大后验推断和稀疏编码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 变分推断和变分学习. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 离散型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 变分法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 连续型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学习和推断之间的相互作用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 学成近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 醒眠算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学成推断的其他形式. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
第  章 深度生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 条件分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练受限玻尔兹曼机. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 深度信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 有趣的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. DBM 均匀场推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. DBM 的参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 逐层预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 联合训练深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实值数据上的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Gaussian-Bernoulli RBM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 条件协方差的无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 卷积玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 用于结构化或序列输出的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 其他玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 通过随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 通过离散随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 有向生成网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. sigmoid 信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 可微生成器网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 变分自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 生成式对抗网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 生成矩匹配网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 卷积生成网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 线性自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 神经自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. NADE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 从自编码器采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 与任意去噪自编码器相关的马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 夹合与条件采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 回退训练过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 生成随机网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
.. 判别性 GSN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 其他生成方案. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 评估生成模型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. 结论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
参考文献. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
索引 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
・ ・ ・ ・ ・ ・ (收起)译者序　　xiii
前言　　xv
第章　Python入门　　
. Python是什么　　
. Python的安装　　
..　Python版本　　
..　使用的外部库　　
..　Anaconda发行版　　
. Python解释器　　
..　算术计算　　
..　数据类型　　
..　变量　　
..　列表　　
..　字典　　
..　布尔型　　
..　if 语句　　
..　for 语句　　
..　函数　　
. Python脚本文件　　
..　保存为文件　　
..　类　　
. NumPy　　
..　导入NumPy　　
..　生成NumPy数组　　
..　NumPy 的算术运算　　
..　NumPy的N维数组　　
..　广播　　
..　访问元素　　
. Matplotlib　　
..　绘制简单图形　　
..　pyplot 的功能　　
..　显示图像　　
. 小结　　
第章　感知机　　
. 感知机是什么　　
. 简单逻辑电路　　
..　与门　　
..　与非门和或门　　
. 感知机的实现　　
..　简单的实现　　
..　导入权重和偏置　　
..　使用权重和偏置的实现　　
. 感知机的局限性　　
..　异或门　　
..　线性和非线性　　
. 多层感知机　　
..　已有门电路的组合　　
..　异或门的实现　　
. 从与非门到计算机　　
. 小结　　
第章　神经网络　　
. 从感知机到神经网络　　
..　神经网络的例子　　
..　复习感知机　　
..　激活函数登场　　
. 激活函数　　
..　sigmoid 函数　　
..　阶跃函数的实现　　
..　阶跃函数的图形　　
..　sigmoid 函数的实现　　
..　sigmoid 函数和阶跃函数的比较　　
..　非线性函数　　
..　ReLU函数　　
. 多维数组的运算　　
..　多维数组　　
..　矩阵乘法　　
..　神经网络的内积　　
.　　 层神经网络的实现　　
..　符号确认　　
..　各层间信号传递的实现　　
..　代码实现小结　　
. 输出层的设计　　
..　恒等函数和softmax 函数　　
..　实现softmax 函数时的注意事项　　
..　softmax 函数的特征　　
..　输出层的神经元数量　　
. 手写数字识别　　
..　MNIST数据集　　
..　神经网络的推理处理　　
..　批处理　　
. 小结　　
第章　神经网络的学习　　
. 从数据中学习　　
..　数据驱动　　
..　训练数据和测试数据　　
. 损失函数　　
..　均方误差　　
..　交叉熵误差　　
..　mini-batch 学习　　
..　mini-batch 版交叉熵误差的实现　　
..　为何要设定损失函数　　
. 数值微分　　
..　导数　　
..　数值微分的例子　　
..　偏导数　　
. 梯度　　
..　梯度法　　
..　神经网络的梯度　　
. 学习算法的实现　　
..　 层神经网络的类　　
..　mini-batch 的实现　　
..　基于测试数据的评价　　
. 小结　　
第章　误差反向传播法　　
. 计算图　　
..　用计算图求解　　
..　局部计算　　
..　为何用计算图解题　　
. 链式法则　　
..　计算图的反向传播　　
..　什么是链式法则　　
..　链式法则和计算图　　
. 反向传播　　
..　加法节点的反向传播　　
..　乘法节点的反向传播　　
..　苹果的例子　　
. 简单层的实现　　
..　乘法层的实现　　
..　加法层的实现　　
. 激活函数层的实现　　
..　ReLU层　　
..　Sigmoid 层　　
. AffineSoftmax层的实现　　
..　Affine层　　
..　批版本的Affine层　　
..　Softmax-with-Loss 层　　
. 误差反向传播法的实现　　
..　神经网络学习的全貌图　　
..　对应误差反向传播法的神经网络的实现　　
..　误差反向传播法的梯度确认　　
..　使用误差反向传播法的学习　　
. 小结　　
第章　与学习相关的技巧　　
. 参数的更新　　
..　探险家的故事　　
..　SGD　　
..　SGD的缺点　　
..　Momentum　　
..　AdaGrad　　
..　Adam　　
..　使用哪种更新方法呢　　
..　基于MNIST数据集的更新方法的比较　　
. 权重的初始值　　
..　可以将权重初始值设为 吗　　
..　隐藏层的激活值的分布　　
..　ReLU的权重初始值　　
..　基于MNIST数据集的权重初始值的比较　　
. Batch Normalization　　
..　Batch Normalization 的算法　　
..　Batch Normalization 的评估　　
. 正则化　　
..　过拟合　　
..　权值衰减　　
..　Dropout　　
. 超参数的验证　　
..　验证数据　　
..　超参数的最优化　　
..　超参数最优化的实现　　
. 小结　　
第章　卷积神经网络　　
. 整体结构　　
. 卷积层　　
..　全连接层存在的问题　　
..　卷积运算　　
..　填充　　
..　步幅　　
..　 维数据的卷积运算　　
..　结合方块思考　　
..　批处理　　
. 池化层　　
. 卷积层和池化层的实现　　
..　 维数组　　
..　基于imcol 的展开　　
..　卷积层的实现　　
..　池化层的实现　　
. CNN的实现　　
. CNN的可视化　　
..　第 层权重的可视化　　
..　基于分层结构的信息提取　　
. 具有代表性的CNN　　
..　LeNet　　
..　AlexNet　　
. 小结　　
第章　深度学习　　
. 加深网络　　
..　向更深的网络出发　　
..　进一步提高识别精度　　
..　加深层的动机　　
. 深度学习的小历史　　
..　ImageNet　　
..　VGG　　
..　GoogLeNet　　
..　ResNet　　
. 深度学习的高速化　　
..　需要努力解决的问题　　
..　基于GPU的高速化　　
..　分布式学习　　
..　运算精度的位数缩减　　
. 深度学习的应用案例　　
..　物体检测　　
..　图像分割　　
..　图像标题的生成　　
. 深度学习的未来　　
..　图像风格变换　　
..　图像的生成　　
..　自动驾驶　　
..　Deep Q-Network（强化学习）　　
. 小结　　
附录A　Softmax-with-Loss 层的计算图　　
A. 正向传播　　
A. 反向传播　　
A. 小结　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
前言
译者简介
学习环境配置
资源与支持
主要符号表
第 章　引言　
.　日常生活中的机器学习　
.　机器学习中的关键组件　
..　数据　
..　模型　
..　目标函数　
..　优化算法　
.　各种机器学习问题　
..　监督学习　
..　无监督学习　
..　与环境互动　
..　强化学习　
.　起源　
.　深度学习的发展　
.　深度学习的成功案例　
.　特点　
第 章　预备知识　
.　数据操作　
..　入门　
..　运算符　
..　广播机制　
..　索引和切片　
..　节省内存　
..　转换为其他Python对象　
.　数据预处理　
..　读取数据集　
..　处理缺失值　
..　转换为张量格式　
.　线性代数　
..　标量　
..　向量　
..　矩阵　
..　张量　
..　张量算法的基本性质　
..　降维　
..　点积　
..　矩阵-向量积　
..　矩阵-矩阵乘法　
..　范数　
..　关于线性代数的更多信息　
.　微积分　
..　导数和微分　
..　偏导数　
..　梯度　
..　链式法则　
.　自动微分　
..　一个简单的例子　
..　非标量变量的反向传播　
..　分离计算　
..　Python控制流的梯度计算　
.　概率　
..　基本概率论　
..　处理多个随机变量　
..　期望和方差　
.　查阅文档　
..　查找模块中的所有函数和类　
..　查找特定函数和类的用法　
第章　线性神经网络　
.　线性回归　
..　线性回归的基本元素　
..　向量化加速　
..　正态分布与平方损失　
..　从线性回归到深度网络　
.　线性回归的从零开始实现　
..　生成数据集　
..　读取数据集　
..　初始化模型参数　
..　定义模型　
..　定义损失函数　
..　定义优化算法　
..　训练　
.　线性回归的简洁实现　
..　生成数据集　
..　读取数据集　
..　定义模型　
..　初始化模型参数　
..　定义损失函数　
..　定义优化算法　
..　训练　
.　softmax回归　
..　分类问题　
..　网络架构　
..　全连接层的参数开销　
..　softmax运算　
..　小批量样本的向量化　
..　损失函数　
..　信息论基础　
..　模型预测和评估　
.　图像分类数据集　
..　读取数据集　
..　读取小批量　
..　整合所有组件　
.　softmax回归的从零开始实现　
..　初始化模型参数　
..　定义softmax操作　
..　定义模型　
..　定义损失函数　
..　分类精度　
..　训练　
..　预测　
.　softmax回归的简洁实现　
..　初始化模型参数　
..　重新审视softmax的实现　
..　优化算法　
..　训练　
第章　多层感知机　
.　多层感知机　
..　隐藏层　
..　激活函数　
.　多层感知机的从零开始实现　
..　初始化模型参数　
..　激活函数　
..　模型　
..　损失函数　
..　训练　
.　多层感知机的简洁实现　
模型　
.　模型选择、欠拟合和过拟合　
..　训练误差和泛化误差　
..　模型选择　
..　欠拟合还是过拟合　
..　多项式回归　
.　权重衰减　
..　范数与权重衰减　
..　高维线性回归　
..　从零开始实现　
..　简洁实现　
.　暂退法　
..　重新审视过拟合　
..　扰动的稳健性　
..　实践中的暂退法　
..　从零开始实现　
..　简洁实现　
.　前向传播、反向传播和计算图　
..　前向传播　
..　前向传播计算图　
..　反向传播　
..　训练神经网络　
.　数值稳定性和模型初始化　
..　梯度消失和梯度爆炸　
..　参数初始化　
.　环境和分布偏移　
..　分布偏移的类型　
..　分布偏移示例　
..　分布偏移纠正　
..　学习问题的分类法　
..　机器学习中的公平、责任和透明度　
.　实战Kaggle比赛：预测房价　
..　下载和缓存数据集　
..　Kaggle　
..　访问和读取数据集　
..　数据预处理　
..　训练　
..　K折交叉验证　
..　模型选择　
..　提交Kaggle预测　
第章　深度学习计算　
.　层和块　
..　自定义块　
..　顺序块　
..　在前向传播函数中执行代码　
..　效率　
.　参数管理　
..　参数访问　
..　参数初始化　
..　参数绑定　
.　延后初始化　
实例化网络　
.　自定义层　
..　不带参数的层　
..　带参数的层　
.　读写文件　
..　加载和保存张量　
..　加载和保存模型参数　
.　GPU　
..　计算设备　
..　张量与GPU　
..　神经网络与GPU　
第章　卷积神经网络　
.　从全连接层到卷积　
..　不变性　
..　多层感知机的限制　
..　卷积　
..　“沃尔多在哪里”回顾　
.　图像卷积　
..　互相关运算　
..　卷积层　
..　图像中目标的边缘检测　
..　学习卷积核　
..　互相关和卷积　
..　特征映射和感受野　
.　填充和步幅　
..　填充　
..　步幅　
.　多输入多输出通道　
..　多输入通道　
..　多输出通道　
..　×卷积层　
.　汇聚层　
..　最大汇聚和平均汇聚　
..　填充和步幅　
..　多个通道　
.　卷积神经网络（LeNet）　
..　LeNet　
..　模型训练　
第章　现代卷积神经网络　
.　深度卷积神经网络（AlexNet）　
..　学习表征　
..　AlexNet　
..　读取数据集　
..　训练AlexNet　
.　使用块的网络（VGG）　
..　VGG块　
..　VGG网络　
..　训练模型　
.　网络中的网络（NiN）　
..　NiN块　
..　NiN模型　
..　训练模型　
.　含并行连接的网络（GoogLeNet）　
..　Inception块　
..　GoogLeNet模型　
..　训练模型　
.　批量规范化　
..　训练深层网络　
..　批量规范化层　
..　从零实现　
..　使用批量规范化层的 LeNet　
..　简明实现　
..　争议　
.　残差网络（ResNet）　
..　函数类　
..　残差块　
..　ResNet模型　
..　训练模型　
.　稠密连接网络（DenseNet）　
..　从ResNet到DenseNet　
..　稠密块体　
..　过渡层　
..　DenseNet模型　
..　训练模型　
第章　循环神经网络　
.　序列模型　
..　统计工具　
..　训练　
..　预测　
.　文本预处理　
..　读取数据集　
..　词元化　
..　词表　
..　整合所有功能　
.　语言模型和数据集　
..　学习语言模型　
..　马尔可夫模型与n元语法　
..　自然语言统计　
..　读取长序列数据　
.　循环神经网络　
..　无隐状态的神经网络　
..　有隐状态的循环神经网络　
..　基于循环神经网络的字符级语言模型　
..　困惑度　
.　循环神经网络的从零开始实现　
..　独热编码　
..　初始化模型参数　
..　循环神经网络模型　
..　预测　
..　梯度截断　
..　训练　
.　循环神经网络的简洁实现　
..　定义模型　
..　训练与预测　
.　通过时间反向传播　
..　循环神经网络的梯度分析　
..　通过时间反向传播的细节　
第章　现代循环神经网络　
.　门控循环单元（GRU）　
..　门控隐状态　
..　从零开始实现　
..　简洁实现　
.　长短期记忆网络（LSTM）　
..　门控记忆元　
..　从零开始实现　
..　简洁实现　
.　深度循环神经网络　
..　函数依赖关系　
..　简洁实现　
..　训练与预测　
.　双向循环神经网络　
..　隐马尔可夫模型中的动态规划　
..　双向模型　
..　双向循环神经网络的错误应用　
.　机器翻译与数据集　
..　下载和预处理数据集　
..　词元化　
..　词表　
..　加载数据集　
..　训练模型　
.　编码器-解码器架构　
..　编码器　
..　解码器　
..　合并编码器和解码器　
.　序列到序列学习（seqseq）　
..　编码器　
..　解码器　
..　损失函数　
..　训练　
..　预测　
..　预测序列的评估　
.　束搜索　
..　贪心搜索　
..　穷举搜索　
..　束搜索　
第 章　注意力机制　
.　注意力提示　
..　生物学中的注意力提示　
..　查询、键和值　
..　注意力的可视化　
.　注意力汇聚：Nadaraya-Watson 核回归　
..　生成数据集　
..　平均汇聚　
..　非参数注意力汇聚　
..　带参数注意力汇聚　
.　注意力评分函数　
..　掩蔽softmax操作　
..　加性注意力　
..　缩放点积注意力　
.　Bahdanau 注意力　
..　模型　
..　定义注意力解码器　
..　训练　
.　多头注意力　
..　模型　
..　实现　
.　自注意力和位置编码　
..　自注意力　
..　比较卷积神经网络、循环神经网络和自注意力　
..　位置编码　
.　Transformer　
..　模型　
..　基于位置的前馈网络　
..　残差连接和层规范化　
..　编码器　
..　解码器　
..　训练　
第 章　优化算法　
.　优化和深度学习　
..　优化的目标　
..　深度学习中的优化挑战　
.　凸性　
..　定义　
..　性质　
..　约束　
.　梯度下降　
..　一维梯度下降　
..　多元梯度下降　
..　自适应方法　
.　随机梯度下降　
..　随机梯度更新　
..　动态学习率　
..　凸目标的收敛性分析　
..　随机梯度和有限样本　
.　小批量随机梯度下降　
..　向量化和缓存　
..　小批量　
..　读取数据集　
..　从零开始实现　
..　简洁实现　
.　动量法　
..　基础　
..　实际实验　
..　理论分析　
.　AdaGrad算法　
..　稀疏特征和学习率　
..　预处理　
..　算法　
..　从零开始实现　
..　简洁实现　
.　RMSProp算法　
..　算法　
..　从零开始实现　
..　简洁实现　
.　Adadelta算法　
..　算法　
..　实现　
.　Adam算法　
..　算法　
..　实现　
..　Yogi　
.　学习率调度器　
..　一个简单的问题　
..　学习率调度器　
..　策略　
第 章　计算性能　
.　编译器和解释器　
..　符号式编程　
..　混合式编程　
..　Sequential的混合式编程　
.　异步计算　
通过后端异步处理　
.　自动并行　
..　基于GPU的并行计算　
..　并行计算与通信　
.　硬件　
..　计算机　
..　内存　
..　存储器　
..　CPU　
..　GPU和其他加速卡　
..　网络和总线　
..　更多延迟　
.　多GPU训练　
..　问题拆分　
..　数据并行性　
..　简单网络　
..　数据同步　
..　数据分发　
..　训练　
.　多GPU的简洁实现　
..　简单网络　
..　网络初始化　
..　训练　
.　参数服务器　
..　数据并行训练　
..　环同步（ring
synchronization）　
..　多机训练　
..　键-值存储　
第 章　计算机视觉　
.　图像增广　
..　常用的图像增广方法　
..　使用图像增广进行训练　
.　微调　
..　步骤　
..　热狗识别　
.　目标检测和边界框　
边界框　
.　锚框　
..　生成多个锚框　
..　交并比（IoU）　
..　在训练数据中标注锚框　
..　使用非极大值抑制预测
边界框　
.　多尺度目标检测　
..　多尺度锚框　
..　多尺度检测　
.　目标检测数据集　
..　下载数据集　
..　读取数据集　
..　演示　
.　单发多框检测（SSD）　
..　模型　
..　训练模型　
..　预测目标　
.　区域卷积神经网络（R-CNN）系列　
..　R-CNN　
..　Fast R-CNN　
..　Faster R-CNN　
..　Mask R-CNN　
.　语义分割和数据集　
..　图像分割和实例分割　
..　Pascal VOC 语义分割数据集　
.　转置卷积　
..　基本操作　
..　填充、步幅和多通道　
..　与矩阵变换的联系　
.　全卷积网络　
..　构建模型　
..　初始化转置卷积层　
..　读取数据集　
..　训练　
..　预测　
.　风格迁移　
..　方法　
..　阅读内容和风格图像　
..　预处理和后处理　
..　提取图像特征　
..　定义损失函数　
..　初始化合成图像　
..　训练模型　
.　实战 Kaggle竞赛：图像分类（CIFAR-）　
..　获取并组织数据集　
..　图像增广 　
..　读取数据集　
..　定义模型　
..　定义训练函数　
..　训练和验证模型　
..　在Kaggle上对测试集进行分类并提交结果　
.　实战Kaggle竞赛：狗的品种识别（ImageNet Dogs）　
..　获取和整理数据集　
..　图像增广　
..　读取数据集　
..　微调预训练模型　
..　定义训练函数　
..　训练和验证模型　
..　对测试集分类并在Kaggle提交结果　
第 章　自然语言处理：预训练　
.　词嵌入（wordvec）　
..　为何独热向量是一个糟糕的选择　
..　自监督的wordvec　
..　跳元模型　
..　连续词袋模型　
.　近似训练　
..　负采样　
..　层序softmax　
.　用于预训练词嵌入的数据集　
..　读取数据集　
..　下采样　
..　中心词和上下文词的提取　
..　负采样　
..　小批量加载训练实例　
..　整合代码　
.　预训练wordvec　
..　跳元模型　
..　训练　
..　应用词嵌入　
.　全局向量的词嵌入（GloVe）　
..　带全局语料库统计的跳元模型　
..　GloVe模型　
..　从共现概率比值理解GloVe模型　
.　子词嵌入　
..　fastText模型　
..　字节对编码　
.　词的相似度和类比任务　
..　加载预训练词向量　
..　应用预训练词向量　
.　来自Transformer的双向编码器表示（BERT）　
..　从上下文无关到上下文敏感　
..　从特定于任务到不可知任务　
..　BERT：将ELMo与GPT结合起来　
..　输入表示　
..　预训练任务　
..　整合代码　
.　用于预训练BERT的数据集　
..　为预训练任务定义辅助函数　
..　将文本转换为预训练数据集　
.　预训练BERT　
..　预训练BERT　
..　用BERT表示文本　
第 章　自然语言处理：应用　
.　情感分析及数据集　
..　读取数据集　
..　预处理数据集　
..　创建数据迭代器　
..　整合代码　
.　情感分析：使用循环神经网络　
..　使用循环神经网络表示单个文本　
..　加载预训练的词向量　
..　训练和评估模型　
.　情感分析：使用卷积神经网络　
..　一维卷积　
..　最大时间汇聚层　
..　textCNN模型　
.　自然语言推断与数据集　
..　自然语言推断　
..　斯坦福自然语言推断（SNLI）数据集　
.　自然语言推断：使用注意力　
..　模型　
..　训练和评估模型　
.　针对序列级和词元级应用微调BERT　
..　单文本分类　
..　文本对分类或回归　
..　文本标注　
..　问答　
.　自然语言推断：微调BERT　
..　加载预训练的BERT　
..　微调BERT的数据集　
..　微调BERT　
附录A　深度学习工具　
A.　使用Jupyter记事本　
A..　在本地编辑和运行代码　
A..　高级选项　
A.　使用Amazon SageMaker　
A..　注册　
A..　创建SageMaker实例　
A..　运行和停止实例　
A..　更新Notebook　
A.　使用Amazon EC实例　
A..　创建和运行EC实例　
A..　安装CUDA　
A..　安装库以运行代码　
A..　远程运行Jupyter记事本　
A..　关闭未使用的实例　
A.　选择服务器和GPU　
A..　选择服务器　
A..　选择GPU　
A.　为本书做贡献　
A..　提交微小更改　
A..　大量文本或代码修改　
A..　提交主要更改　
参考文献　
・ ・ ・ ・ ・ ・ (收起)第章　什么是深度学习 
.　人工智能、机器学习和深度学习 
..　人工智能 
..　机器学习 
..　从数据中学习规则与表示 
..　深度学习之“深度” 
..　用三张图理解深度学习的工作原理 
..　深度学习已取得的进展 
..　不要相信短期炒作 
..　人工智能的未来 
.　深度学习之前：机器学习简史 
..　概率建模 
..　早期神经网络 
..　核方法 
..　决策树、随机森林和梯度提升机 
..　回到神经网络 
..　深度学习有何不同 
..　机器学习现状 
.　为什么要用深度学习，为什么是现在 
..　硬件 
..　数据 
..　算法 
..　新一轮投资热潮 
..　深度学习的普及 
..　这种趋势会持续下去吗 
第章　神经网络的数学基础 
.　初识神经网络 
.　神经网络的数据表示 
..　标量（阶张量） 
..　向量（阶张量） 
..　矩阵（阶张量） 
..　阶张量与更高阶的张量 
..　关键属性 
..　在NumPy中操作张量 
..　数据批量的概念 
..　现实世界中的数据张量实例 
..　向量数据 
..　时间序列数据或序列数据 
..　图像数据 
..　视频数据 
.　神经网络的“齿轮”：张量运算 
..　逐元素运算 
..　广播 
..　张量积 
..　张量变形 
..　张量运算的几何解释 
..　深度学习的几何解释 
.　神经网络的“引擎”：基于梯度的优化 
..　什么是导数 
..　张量运算的导数：梯度 
..　随机梯度下降 
..　链式求导：反向传播算法 
.　回顾第一个例子 
..　用TensorFlow 从头开始重新实现第一个例子 
..　完成一次训练步骤 
..　完整的训练循环 
..　评估模型 
.　本章总结 
第章　Keras 和TensorFlow 入门 
.　TensorFlow 简介 
.　Keras 简介 
.　Keras 和TensorFlow 简史 
.　建立深度学习工作区 
..　Jupyter笔记本：运行深度学习实验的首选方法 
..　使用Colaboratory 
.　TensorFlow入门 
..　常数张量和变量 
..　张量运算：用TensorFlow进行数学运算 
..　重温GradientTape API 
..　一个端到端的例子：用TensorFlow编写线性分类器 
.　神经网络剖析：了解核心Keras API 
..　层：深度学习的基础模块 
..　从层到模型 
..　编译步骤：配置学习过程 
..　选择损失函数 
..　理解fit()方法 
..　监控验证数据上的损失和指标 
..　推断：在训练后使用模型 
.　本章总结 
第章　神经网络入门：分类与回归 
.　影评分类：二分类问题示例 
..　IMDB 数据集 
..　准备数据 
..　构建模型 
..　验证你的方法 
..　利用训练好的模型对新数据进行预测 
..　进一步实验 
..　小结 
.　新闻分类：多分类问题示例 
..　路透社数据集 
..　准备数据 
..　构建模型 
..　验证你的方法 
..　对新数据进行预测 
..　处理标签和损失的另一种方法 
..　拥有足够大的中间层的重要性 
..　进一步实验 
..　小结 
.　预测房价：标量回归问题示例 
..　波士顿房价数据集 
..　准备数据 
..　构建模型 
..　利用K折交叉验证来验证你的方法 
..　对新数据进行预测 
..　小结 
.　本章总结 
第章　机器学习基础 
.　泛化：机器学习的目标 
..　欠拟合与过拟合 
..　深度学习泛化的本质 
.　评估机器学习模型 
..　训练集、验证集和测试集 
..　超越基于常识的基准 
..　模型评估的注意事项 
.　改进模型拟合 
..　调节关键的梯度下降参数 
..　利用更好的架构预设 
..　提高模型容量 
.　提高泛化能力 
..　数据集管理 
..　特征工程 
..　提前终止 
..　模型正则化 
.　本章总结 
第章　机器学习的通用工作流程 
.　定义任务 
..　定义问题 
..　收集数据集 
..　理解数据 
..　选择衡量成功的指标 
.　开发模型 
..　准备数据 
..　选择评估方法 
..　超越基准 
..　扩大模型规模：开发一个过拟合的模型 
..　模型正则化与调节超参数 
.　部署模型 
..　向利益相关者解释你的工作并设定预期 
..　部署推断模型 
..　监控模型在真实环境中的性能 
..　维护模型 
.　本章总结 
第章　深入Keras 
.　Keras 工作流程 
.　构建Keras 模型的不同方法 
..　序贯模型 
..　函数式API 
..　模型子类化 
..　混合使用不同的组件 
..　用正确的工具完成工作 
.　使用内置的训练循环和评估循环 
..　编写自定义指标 
..　使用回调函数 
..　编写自定义回调函数 
..　利用TensorBoard进行监控和可视化 
.　编写自定义的训练循环和评估循环 
..　训练与推断 
..　指标的低阶用法 
..　完整的训练循环和评估循环 
..　利用tf.function加快运行速度 
..　在fit()中使用自定义训练循环 
.　本章总结 
第章　计算机视觉深度学习入门 
.　卷积神经网络入门 
..　卷积运算 
..　最大汇聚运算 
.　在小型数据集上从头开始训练一个卷积神经网络 
..　深度学习对数据量很小的问题的适用性 
..　下载数据 
..　构建模型 . 
..　数据预处理 
..　使用数据增强 
.　使用预训练模型 
..　使用预训练模型做特征提取 
..　微调预训练模型 
.　本章总结 
第章　计算机视觉深度学习进阶 
.　三项基本的计算机视觉任务 
.　图像分割示例 
.　现代卷积神经网络架构模式 
..　模块化、层次结构和复用 
..　残差连接 
..　批量规范化 
..　深度可分离卷积 
..　综合示例：一个类似Xception的迷你模型 
.　解释卷积神经网络学到的内容 
..　中间激活值的可视化 
..　卷积神经网络滤波器的可视化 
..　类激活热力图的可视化 
.　本章总结 
第章　深度学习处理时间序列 
.　不同类型的时间序列任务 
.　温度预测示例 
..　准备数据 
..　基于常识、不使用机器学习的基准 
..　基本的机器学习模型 
..　一维卷积模型 
..　第一个RNN 基准 
.　理解RNN 
.　RNN 的高级用法 
..　利用循环dropout 降低过拟合 
..　循环层堆叠 
..　使用双向RNN 
..　进一步实验 
.　本章总结 
第章　深度学习处理文本 
.　自然语言处理概述 
.　准备文本数据 
..　文本标准化 
..　文本拆分（词元化） 
..　建立词表索引 
..　使用TextVectorization层 
.　表示单词组的两种方法：集合和序列 
..　准备IMDB 影评数据 
..　将单词作为集合处理：词袋方法 
..　将单词作为序列处理：序列模型方法 
.　Transformer架构 
..　理解自注意力 
..　多头注意力 
..　Transformer编码器 
..　何时使用序列模型而不是词袋模型 
.　超越文本分类：序列到序列学习 
..　机器翻译示例 
..　RNN 的序列到序列学习 
..　使用Transformer 进行序列到序列学习 
.　本章总结 
第章　生成式深度学习 
.　文本生成 
..　生成式深度学习用于序列生成的简史 
..　如何生成序列数据 
..　采样策略的重要性 
..　用Keras 实现文本生成 
..　带有可变温度采样的文本生成回调函数 
..　小结 
.　DeepDream 
..　用Keras 实现DeepDream 
..　小结 
.　　神经风格迁移 
..　内容损失 
..　风格损失 
..　用Keras 实现神经风格迁移 
..　小结 
.　用变分自编码器生成图像 
..　从图像潜在空间中采样 
..　图像编辑的概念向量 
..　变分自编码器 
..　用Keras 实现变分自编码器 
..　小结 
.　生成式对抗网络入门 
..　简要实现流程 
..　诸多技巧 
..　CelebA 数据集 
..　判别器 
..　生成器 
..　对抗网络 
..　小结 
.　本章总结 
第章　适合现实世界的最佳实践 
.　将模型性能发挥到极致 
..　超参数优化 
..　模型集成 
.　加速模型训练 
..　使用混合精度加快GPU上的训练速度 
..　多GPU训练 
..　TPU训练 
.　本章总结 
第章　总结 
.　重点概念回顾 
..　人工智能的多种方法 
..　深度学习在机器学习领域中的特殊之处 
..　如何看待深度学习 
..　关键的推动技术 
..　机器学习的通用工作流程 
..　关键网络架构 
..　可能性空间 
.　深度学习的局限性 
..　将机器学习模型拟人化的风险 
..　自动机与智能体 
..　局部泛化与极端泛化 
..　智能的目的 
..　逐步提高泛化能力 
.　如何实现更加通用的人工智能 
..　设定正确目标的重要性：捷径法则 
..　新目标 
.　实现智能：缺失的内容 
..　智能是对抽象类比的敏感性 
..　两种抽象 
..　深度学习所缺失的那一半 
.　深度学习的未来 
..　模型即程序 
..　将深度学习与程序合成融合 
..　终身学习和模块化子程序复用 
..　长期愿景 
.　了解快速发展的领域的最新进展 
..　在Kaggle 上练习解决现实世界的问题 
..　在arXiv上了解最新进展 
..　探索Keras 生态系统 
.　结束语 
・ ・ ・ ・ ・ ・ (收起)第一部分　深度学习基础
第章　什么是深度学习　　
.　人工智能、机器学习与深度学习　　
..　人工智能　　
..　机器学习　　
..　从数据中学习表示　　
..　深度学习之“深度”　　
..　用三张图理解深度学习的工作原理　　
..　深度学习已经取得的进展　　
..　不要相信短期炒作　　
..　人工智能的未来　　
.　深度学习之前：机器学习简史　　
..　概率建模　　
..　早期神经网络　　
..　核方法　　
..　决策树、随机森林与梯度提升机　　
..　回到神经网络　　
..　深度学习有何不同　　
..　机器学习现状　　
.　为什么是深度学习，为什么是现在　　
..　硬件　　
..　数据　　
..　算法　　
..　新的投资热潮　　
..　深度学习的大众化　　
..　这种趋势会持续吗　　
第章　神经网络的数学基础　　
.　初识神经网络　　
.　神经网络的数据表示　　
..　标量（D张量）　　
..　向量（D张量）　　
..　矩阵（D张量）　　
..　D张量与更高维张量　　
..　关键属性　　
..　在Numpy中操作张量　　
..　数据批量的概念　　
..　现实世界中的数据张量　　
..　向量数据　　
..　时间序列数据或序列数据　　
..　图像数据　　
..　视频数据　　
.　神经网络的“齿轮”：张量运算　　
..　逐元素运算　　
..　广播　　
..　张量点积　　
..　张量变形　　
..　张量运算的几何解释　　
..　深度学习的几何解释　　
.　神经网络的“引擎”：基于梯度的优化　　
..　什么是导数　　
..　张量运算的导数：梯度　　
..　随机梯度下降　　
..　链式求导：反向传播算法　　
.　回顾第一个例子　　
本章小结　　
第章　神经网络入门　　
.　神经网络剖析　　
..　层：深度学习的基础组件　　
..　模型：层构成的网络　　
..　损失函数与优化器：配置学习过程的关键　　
.　Keras简介　　
..　Keras、TensorFlow、Theano 和CNTK　　
..　使用Keras 开发：概述　　
.　建立深度学习工作站　　
..　Jupyter笔记本：运行深度学习实验的首选方法　　
..　运行Keras：两种选择　　
..　在云端运行深度学习任务：优点和缺点　　
..　深度学习的最佳GPU　　
.　电影评论分类：二分类问题　　
..　IMDB 数据集　　
..　准备数据　　
..　构建网络　　
..　验证你的方法　　
..　使用训练好的网络在新数据上生成预测结果　　
..　进一步的实验　　
..　小结　　
.　新闻分类：多分类问题　　
..　路透社数据集　　
..　准备数据　　
..　构建网络　　
..　验证你的方法　　
..　在新数据上生成预测结果　　
..　处理标签和损失的另一种方法　　
..　中间层维度足够大的重要性　　
..　进一步的实验　　
..　小结　　
.　预测房价：回归问题　　
..　波士顿房价数据集　　
..　准备数据　　
..　构建网络　　
..　利用K折验证来验证你的方法　　
..　小结　　
本章小结　　
第章　机器学习基础　　
.　机器学习的四个分支　　
..　监督学习　　
..　无监督学习　　
..　自监督学习　　
..　强化学习　　
.　评估机器学习模型　　
..　训练集、验证集和测试集　　
..　评估模型的注意事项　　
.　数据预处理、特征工程和特征学习　　
..　神经网络的数据预处理　　
..　特征工程　　
.　过拟合与欠拟合　　
..　减小网络大小　　
..　添加权重正则化　　
..　添加dropout正则化　　
.　机器学习的通用工作流程　　
..　定义问题，收集数据集　　
..　选择衡量成功的指标　　
..　确定评估方法　　
..　准备数据　　
..　开发比基准更好的模型　　
..　扩大模型规模：开发过拟合的模型　　
..　模型正则化与调节超参数　　
本章小结　　
第二部分　深度学习实践
第章　深度学习用于计算机视觉　　
.　卷积神经网络简介　　
..　卷积运算　　
..　最大池化运算　　
.　在小型数据集上从头开始训练一个卷积神经网络　　
..　深度学习与小数据问题的相关性　　
..　下载数据　　
..　构建网络　　
..　数据预处理　　
..　使用数据增强　　
.　使用预训练的卷积神经网络　　
..　特征提取　　
..　微调模型　　
..　小结　　
.　卷积神经网络的可视化　　
..　可视化中间激活　　
..　可视化卷积神经网络的过滤器　　
..　可视化类激活的热力图　　
本章小结　　
第章　深度学习用于文本和序列　　
.　处理文本数据　　
..　单词和字符的one-hot编码　　
..　使用词嵌入　　
..　整合在一起：从原始文本到词嵌入　　
..　小结　　
.　理解循环神经网络　　
..　Keras中的循环层　　
..　理解LSTM层和GRU层　　
..　Keras中一个LSTM的具体例子　　
..　小结　　
.　循环神经网络的高级用法　　
..　温度预测问题　　
..　准备数据　　
..　一种基于常识的、非机器学习的基准方法　　
..　一种基本的机器学习方法　　
..　第一个循环网络基准　　
..　使用循环dropout来降低过拟合　　
..　循环层堆叠　　
..　使用双向RNN　　
..　更多尝试　　
..　小结　　
.　用卷积神经网络处理序列　　
..　理解序列数据的一维卷积　　
..　序列数据的一维池化　　
..　实现一维卷积神经网络　　
..　结合CNN和RNN来处理长序列　　
..　小结　　
本章总结　　
第章　高级的深度学习最佳实践　　
.　不用Sequential模型的解决方案：Keras 函数式API　　
..　函数式API简介　　
..　多输入模型　　
..　多输出模型　　
..　层组成的有向无环图　　
..　共享层权重　　
..　将模型作为层　　
..　小结　　
.　使用Keras回调函数和TensorBoard来检查并监控深度学习模型　　
..　训练过程中将回调函数作用于模型　　
..　TensorBoard简介：TensorFlow的可视化框架　　
..　小结　　
.　让模型性能发挥到极致　　
..　高级架构模式　　
..　超参数优化　　
..　模型集成　　
..　小结　　
本章总结　　
第章　生成式深度学习　　
.　使用LSTM生成文本　　
..　生成式循环网络简史　　
..　如何生成序列数据　　
..　采样策略的重要性　　
..　实现字符级的LSTM文本生成　　
..　小结　　
.　DeepDream　　
..　用Keras实现DeepDream　　
..　小结　　
.　神经风格迁移　　
..　内容损失　　
..　风格损失　　
..　用Keras实现神经风格迁移　　
..　小结　　
.　用变分自编码器生成图像　　
..　从图像的潜在空间中采样　　
..　图像编辑的概念向量　　
..　变分自编码器　　
..　小结　　
.　生成式对抗网络简介　　
..　GAN 的简要实现流程　　
..　大量技巧　　
..　生成器　　
..　判别器　　
..　对抗网络　　
..　如何训练DCGAN　　
..　小结　　
本章总结　　
第章　总结　　
.　重点内容回顾　　
..　人工智能的各种方法　　
..　深度学习在机器学习领域中的特殊之处　　
..　如何看待深度学习　　
..　关键的推动技术　　
..　机器学习的通用工作流程　　
..　关键网络架构　　
..　可能性空间　　
.　深度学习的局限性　　
..　将机器学习模型拟人化的风险　　
..　局部泛化与极端泛化　　
..　小结　　
.　深度学习的未来　　
..　模型即程序　　
..　超越反向传播和可微层　　
..　自动化机器学习　　
..　终身学习与模块化子程序复用　　
..　长期愿景　　
.　了解一个快速发展领域的最新进展　　
..　使用Kaggle练习解决现实世界的问题　　
..　在arXiv阅读最新进展　　
..　探索Keras生态系统　　
.　结束语　　
附录A　在Ubuntu上安装Keras及其依赖　　
附录B　在EC GPU实例上运行Jupyter笔记本　　
・ ・ ・ ・ ・ ・ (收起)序
前言
常用符号表
第一部分 机器学习基础
第章 绪论
.人工智能...............................
..人工智能的发展历史....................
..人工智能的流派.......................
.机器学习...............................
.表示学习...............................
..局部表示和分布式表示...................
..表示学习...........................
.深度学习...............................
..端到端学习..........................
.神经网络...............................
..人脑神经网络........................
..人工神经网络........................
..神经网络的发展历史....................
.本书的知识体系...........................
.常用的深度学习框架.........................
.总结和深入阅读...........................
第章 机器学习概述
.基本概念...............................
.机器学习的三个基本要素......................
..模型..............................
..学习准则...........................
..优化算法...........................
.机器学习的简单示例――线性回归.................
..参数学习...........................
.偏差-方差分解............................
.机器学习算法的类型.........................
.数据的特征表示...........................
..传统的特征学习.......................
..深度学习方法........................
.评价指标...............................
.理论和定理..............................
..PAC学习理论........................
..没有免费午餐定理......................
..奥卡姆剃刀原理.......................
..丑小鸭定理..........................
..归纳偏置...........................
.总结和深入阅读...........................
第章 线性模型
.线性判别函数和决策边界......................
..二分类............................
..多分类............................
.Logistic回归.............................
..参数学习...........................
.Softmax回归.............................
..参数学习...........................
.感知器.................................
..参数学习...........................
..感知器的收敛性.......................
..参数平均感知器.......................
..扩展到多分类........................
.支持向量机..............................
..参数学习...........................
..核函数............................
..软间隔............................
.损失函数对比.............................
.总结和深入阅读...........................
第二部分 基础模型
第章 前馈神经网络
.神经元.................................
..Sigmoid型函数.......................
..ReLU函数..........................
..Swish函数..........................
..GELU函数..........................
..Maxout单元.........................
.网络结构...............................
..前馈网络...........................
..记忆网络...........................
..图网络............................
.前馈神经网络.............................
..通用近似定理........................
..应用到机器学习.......................
..参数学习...........................
.反向传播算法.............................
.自动梯度计算.............................
..数值微分...........................
..符号微分...........................
..自动微分...........................
.优化问题...............................
..非凸优化问题........................
..梯度消失问题........................
.总结和深入阅读...........................
第章 卷积神经网络
.卷积..................................
..卷积的定义..........................
..互相关............................
..卷积的变种..........................
..卷积的数学性质.......................
.卷积神经网络.............................
..用卷积来代替全连接....................
..卷积层............................
..汇聚层............................
..卷积网络的整体结构....................
.参数学习...............................
..卷积神经网络的反向传播算法...............
.几种典型的卷积神经网络......................
..LeNet-............................
..AlexNet...........................
..Inception网络........................
..残差网络...........................
.其他卷积方式.............................
..转置卷积...........................
..空洞卷积...........................
.总结和深入阅读...........................
第章 循环神经网络
.给网络增加记忆能力.........................
..延时神经网络........................
..有外部输入的非线性自回归模型..............
..循环神经网络........................
.简单循环网络.............................
..循环神经网络的计算能力..................
.应用到机器学习...........................
..序列到类别模式.......................
..同步的序列到序列模式...................
..异步的序列到序列模式...................
.参数学习...............................
..随时间反向传播算法....................
..实时循环学习算法......................
.长程依赖问题.............................
..改进方案...........................
.基于门控的循环神经网络......................
..长短期记忆网络.......................
..LSTM网络的各种变体...................
..门控循环单元网络......................
.深层循环神经网络..........................
..堆叠循环神经网络......................
..双向循环神经网络......................
.扩展到图结构.............................
..递归神经网络........................
..图神经网络..........................
.总结和深入阅读...........................
第章 网络优化与正则化
.网络优化...............................
..网络结构多样性.......................
..高维变量的非凸优化....................
..神经网络优化的改善方法..................
.优化算法...............................
..小批量梯度下降.......................
..批量大小选择........................
..学习率调整..........................
..梯度估计修正........................
..优化算法小结........................
.参数初始化..............................
..基于固定方差的参数初始化.................
..基于方差缩放的参数初始化.................
..正交初始化..........................
.数据预处理..............................
.逐层归一化..............................
..批量归一化..........................
..层归一化...........................
..权重归一化..........................
..局部响应归一化.......................
.超参数优化..............................
..网格搜索...........................
..随机搜索...........................
..贝叶斯优化..........................
..动态资源分配........................
..神经架构搜索........................
.网络正则化..............................
..?和?正则化........................
..权重衰减...........................
..提前停止...........................
..丢弃法............................
..数据增强...........................
..标签平滑...........................
.总结和深入阅读...........................
第章 注意力机制与外部记忆
.认知神经学中的注意力.......................
.注意力机制..............................
..注意力机制的变体......................
.自注意力模型.............................
.人脑中的记忆.............................
.记忆增强神经网络..........................
..端到端记忆网络.......................
..神经图灵机..........................
.基于神经动力学的联想记忆.....................
..Hopfiel网络........................
..使用联想记忆增加网络容量.................
.总结和深入阅读...........................
第章 无监督学习
.无监督特征学习...........................
..主成分分析..........................
..稀疏编码...........................
..自编码器...........................
..稀疏自编码器........................
..堆叠自编码器........................
..降噪自编码器........................
.概率密度估计.............................
..参数密度估计........................
..非参数密度估计.......................
.总结和深入阅读...........................
第章 模型独立的学习方式
.集成学习...............................
..AdaBoost算法........................
.自训练和协同训练..........................
..自训练............................
..协同训练...........................
.多任务学习..............................
.迁移学习...............................
..归纳迁移学习........................
..转导迁移学习........................
.终身学习...............................
.元学习.................................
..基于优化器的元学习....................
..模型无关的元学习......................
.总结和深入阅读...........................
第三部分 进阶模型
第章 概率图模型
.模型表示...............................
..有向图模型..........................
..常见的有向图模型......................
..无向图模型..........................
..无向图模型的概率分解...................
..常见的无向图模型......................
..有向图和无向图之间的转换.................
.学习..................................
..不含隐变量的参数估计...................
..含隐变量的参数估计....................
.推断..................................
..精确推断...........................
..近似推断...........................
.变分推断...............................
.基于采样法的近似推断.......................
..采样法............................
..拒绝采样...........................
..重要性采样..........................
..马尔可夫链蒙特卡罗方法..................
.总结和深入阅读...........................
第章 深度信念网络
.玻尔兹曼机..............................
..生成模型...........................
..能量最小化与模拟退火...................
..参数学习...........................
.受限玻尔兹曼机...........................
..生成模型...........................
..参数学习...........................
..受限玻尔兹曼机的类型...................
.深度信念网络.............................
..生成模型...........................
..参数学习...........................
.总结和深入阅读...........................
第章 深度生成模型
.概率生成模型.............................
..密度估计...........................
..生成样本...........................
..应用于监督学习.......................
.变分自编码器.............................
..含隐变量的生成模型....................
..推断网络...........................
..生成网络...........................
..模型汇总...........................
..再参数化...........................
..训练..............................
.生成对抗网络.............................
..显式密度模型和隐式密度模型...............
..网络分解...........................
..训练..............................
..一个生成对抗网络的具体实现：DCGAN..........
..模型分析...........................
..改进模型...........................
.总结和深入阅读...........................
第章 深度强化学习
.强化学习问题.............................
..典型例子...........................
..强化学习定义........................
..马尔可夫决策过程......................
..强化学习的目标函数....................
..值函数............................
..深度强化学习........................
.基于值函数的学习方法.......................
..动态规划算法........................
..蒙特卡罗方法........................
..时序差分学习方法......................
..深度Q网络..........................
.基于策略函数的学习方法......................
..REINFORCE算法......................
..带基准线的REINFORCE算法...............
.演员-评论员算法...........................
.总结和深入阅读...........................
第章 序列生成模型
.序列概率模型.............................
..序列生成...........................
.N元统计模型.............................
.深度序列模型.............................
..模型结构...........................
..参数学习...........................
.评价方法...............................
..困惑度............................
..BLEU算法..........................
..ROUGE算法.........................
.序列生成模型中的学习问题.....................
..曝光偏差问题........................
..训练目标不一致问题....................
..计算效率问题........................
.序列到序列模型...........................
..基于循环神经网络的序列到序列模型...........
..基于注意力的序列到序列模型...............
..基于自注意力的序列到序列模型..............
.总结和深入阅读...........................
附录数学基础 
附录A 线性代数 
附录B 微积分 
附录C 数学优化 
附录D 概率论 
附录E 信息论 
索引 
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
前言
如何使用本书
资源与支持
主要符号表
第 章　深度学习简介… ………………… 
.　起源…………………………………………… 
.　发展…………………………………………… 
.　成功案例……………………………………… 
.　特点………………………………………… 
小结…………………………………………… 
练习…………………………………………… 
第 章　预备知识… ……………………… 
.　获取和运行本书的代码……………………… 
..　获取代码并安装运行环境 … ……… 
..　更新代码和运行环境 … …………… 
..　使用GPU版的MXNet … ………… 
小结……………………………………………
练习……………………………………………
.　数据操作… ……………………………… 
..　创建NDArray ………………………
..　运算 …………………………………
..　广播机制 ……………………………
..　索引 …………………………………
..　运算的内存开销 ……………………
..　NDArray和NumPy相互变换………
小结……………………………………………
练习……………………………………………
.　自动求梯度… …………………………… 
..　简单例子 … …………………………
..　训练模式和预测模式 …………… 
..　对Python控制流求梯度 … …… 
小结……………………………………………
练习……………………………………………
.　查阅文档… ……………………………… 
..　查找模块里的所有函数和类 … ……
..　查找特定函数和类的使用 ……… 
..　在MXNet网站上查阅 …………… 
小结………………………………………… 
练习………………………………………… 
第 章　深度学习基础… ……………… 
.　线性回归…………………………………… 
..　线性回归的基本要素 … ………… 
..　线性回归的表示方法 … ………… 
小结………………………………………… 
练习………………………………………… 
.　线性回归的从零开始实现… …………… 
..　生成数据集 … …………………… 
..　读取数据集 ……………………… 
..　初始化模型参数 ………………… 
..　定义模型 ………………………… 
..　定义损失函数 …………………… 
..　定义优化算法 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　线性回归的简洁实现… ………………… 
..　生成数据集 … …………………… 
..　读取数据集 ……………………… 
..　定义模型 ………………………… 
..　初始化模型参数 ………………… 
..　定义损失函数 …………………… 
..　定义优化算法 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　softmax回归… ………………………… 
..　分类问题 … ……………………… 
..　softmax回归模型… …………… 
..　单样本分类的矢量计算表达式…… 
..　小批量样本分类的矢量计算表达式 …………………………… 
..　交叉熵损失函数 ……………………
..　模型预测及评价 ………………… 
小结………………………………………… 
练习………………………………………… 
.　图像分类数据集（Fashion-MNIST）… ……………… 
..　获取数据集 … …………………… 
..　读取小批量 ……………………… 
小结………………………………………… 
练习………………………………………… 
.　softmax回归的从零开始实现… ……… 
..　读取数据集 … …………………… 
..　初始化模型参数 ………………… 
..　实现softmax运算 … …………… 
..　定义模型 ………………………… 
..　定义损失函数 …………………… 
..　计算分类准确率 ………………… 
..　训练模型 ………………………… 
..　预测… …………………………… 
小结………………………………………… 
练习………………………………………… 
.　softmax回归的简洁实现… …………… 
..　读取数据集 … …………………… 
..　定义和初始化模型 ……………… 
..　softmax和交叉熵损失函数 … … 
..　定义优化算法 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　多层感知机… …………………………… 
..　隐藏层 … ……………………………
..　激活函数 ………………………… 
..　多层感知机 ……………………… 
小结………………………………………… 
练习………………………………………… 
.　多层感知机的从零开始实现… ………… 
..　读取数据集 … …………………… 
..　定义模型参数 …………………… 
..　定义激活函数 …………………… 
..　定义模型 ………………………… 
..　定义损失函数 …………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　多层感知机的简洁实现………………… 
..　定义模型 ………………………… 
..　训练模型 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　模型选择、欠拟合和过拟合… ………… 
..　训练误差和泛化误差 …………… 
..　模型选择 ………………………… 
..　欠拟合和过拟合 ………………… 
..　多项式函数拟合实验 ……………
小结………………………………………… 
练习………………………………………… 
.　权重衰减………………………………… 
..　方法 ……………………………… 
..　高维线性回归实验 … ………… 
..　从零开始实现 … ……………… 
..　简洁实现 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　丢弃法…………………………………… 
..　方法 ……………………………… 
..　从零开始实现 … …………………
..　简洁实现 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　正向传播、反向传播和计算图………… 
..　正向传播 ……………………… 
..　正向传播的计算图 … ………… 
..　反向传播 … …………………… 
..　训练深度学习模型 … ………… 
小结………………………………………… 
练习………………………………………… 
.　数值稳定性和模型初始化……………… 
..　衰减和爆炸 ……………………… 
..　随机初始化模型参数 … ……… 
小结………………………………………… 
练习………………………………………… 
.　实战Kaggle比赛：房价预测… ……… 
..　Kaggle比赛 … ………………… 
..　读取数据集 … ………………… 
..　预处理数据集 … …………………
..　训练模型 … …………………… 
..　k 折交叉验证 …………………… 
..　模型选择 … …………………… 
..　预测并在Kaggle提交结果… … 
小结………………………………………… 
练习………………………………………… 
第 章　深度学习计算… ……………… 
.　模型构造………………………………… 
..　继承Block类来构造模型 … …… 
..　Sequential类继承自Block类…………………………… 
..　构造复杂的模型… ……………… 
小结………………………………………… 
练习………………………………………… 
.　模型参数的访问、初始化和共享… …… 
..　访问模型参数 … ………………… 
..　初始化模型参数 ………………… 
..　自定义初始化方法 ……………… 
..　共享模型参数 …………………… 
小结………………………………………… 
练习………………………………………… 
.　模型参数的延后初始化… ……………… 
..　延后初始化 … …………………… 
..　避免延后初始化 ………………… 
小结………………………………………… 
练习………………………………………… 
.　自定义层… ……………………………… 
..　不含模型参数的自定义层 … …… 
..　含模型参数的自定义层 ………… 
小结………………………………………… 
练习………………………………………… 
.　读取和存储… …………………………… 
..　读写NDArray… ………………… 
..　读写Gluon模型的参数… ……… 
小结………………………………………… 
练习………………………………………… 
.　GPU计算………………………………… 
..　计算设备 … ……………………… 
..　NDArray的GPU计算…………… 
..　Gluon的GPU计算 ……………… 
小结………………………………………… 
练习………………………………………… 
第 章　卷积神经网络… ……………… 
.　二维卷积层………………………………… 
..　二维互相关运算 … ……………… 
..　二维卷积层 … …………………… 
..　图像中物体边缘检测 … ………… 
..　通过数据学习核数组 … ………… 
..　互相关运算和卷积运算 … ……… 
..　特征图和感受野… ……………… 
小结………………………………………… 
练习………………………………………… 
.　填充和步幅… …………………………… 
..　填充 … …………………………… 
..　步幅 ……………………………… 
小结………………………………………… 
练习………………………………………… 
.　多输入通道和多输出通道… …………… 
..　多输入通道 … …………………… 
..　多输出通道… …………………… 
..　×卷积层 ……………………… 
小结………………………………………… 
练习………………………………………… 
.　池化层… ………………………………… 
..　二维最大池化层和平均池化层 … ………………………… 
..　填充和步幅 ……………………… 
..　多通道 …………………………… 
小结………………………………………… 
练习………………………………………… 
.　卷积神经网络（LeNet）… …………… 
..　LeNet模型 … …………………… 
..　训练模型… ……………………… 
小结………………………………………… 
练习………………………………………… 
.　深度卷积神经网络（AlexNet）… …… 
..　学习特征表示 … ………………… 
..　AlexNet… ……………………… 
..　读取数据集 ……………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　使用重复元素的网络（VGG）………… 
..　VGG块 …………………………… 
..　VGG网络 … …………………… 
..　训练模型… ……………………… 
小结………………………………………… 
练习………………………………………… 
.　网络中的网络（NiN）… ……………… 
..　NiN块 … ………………………… 
..　NiN模型 … ……………………… 
..　训练模型… ……………………… 
小结………………………………………… 
练习………………………………………… 
.　含并行连结的网络（GoogLeNet）…… 
..　Inception块 ……………………… 
..　GoogLeNet模型 … …………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　批量归一化……………………………… 
..　批量归一化层 ………………… 
..　从零开始实现 … ……………… 
..　使用批量归一化层的LeNet … … 
..　简洁实现 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　残差网络（ResNet） ……………… 
..　残差块 …………………………… 
..　ResNet模型… ………………… 
..　训练模型………………………… 
小结………………………………………… 
练习………………………………………… 
.　稠密连接网络（DenseNet）………… 
..　稠密块 …………………………… 
..　过渡层 … ……………………… 
..　DenseNet模型 ………………… 
..　训练模型 … …………………… 
小结………………………………………… 
练习………………………………………… 
第 章　循环神经网络… ……………… 
.　语言模型………………………………… 
..　语言模型的计算 … ……………… 
..　n 元语法 … ……………………… 
小结………………………………………… 
练习………………………………………… 
.　循环神经网络… ………………………… 
..　不含隐藏状态的神经网络 … …… 
..　含隐藏状态的循环神经网络… … 
..　应用：基于字符级循环神经网络的语言模型 … ……………………… 
小结………………………………………… 
练习………………………………………… 
.　语言模型数据集（歌词）…… 
..　读取数据集 … …………………… 
..　建立字符索引 …………………… 
..　时序数据的采样 ………………… 
小结………………………………………… 
练习………………………………………… 
.　循环神经网络的从零开始实现… ……… 
..　one-hot向量 … ………………… 
..　初始化模型参数 ………………… 
..　定义模型 ………………………… 
..　定义预测函数 …………………… 
..　裁剪梯度 ………………………… 
..　困惑度 …………………………… 
..　定义模型训练函数 ……………… 
..　训练模型并创作歌词 …………… 
小结………………………………………… 
练习………………………………………… 
.　循环神经网络的简洁实现… …………… 
..　定义模型 … ……………………… 
..　训练模型 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　通过时间反向传播… …………………… 
..　定义模型 … ……………………… 
..　模型计算图 ……………………… 
..　方法 ……………………………… 
小结………………………………………… 
练习………………………………………… 
.　门控循环单元（GRU）………………… 
..　门控循环单元 … ………………… 
..　读取数据集 ……………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　长短期记忆（LSTM）… ……………… 
..　长短期记忆 … …………………… 
..　读取数据集 ……………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　深度循环神经网络… …………………… 
小结………………………………………… 
练习………………………………………… 
.　双向循环神经网络……………………… 
小结………………………………………… 
练习………………………………………… 
第 章　优化算法… …………………… 
.　优化与深度学习…………………………… 
..　优化与深度学习的关系 … ……… 
..　优化在深度学习中的挑战 … …… 
小结………………………………………… 
练习………………………………………… 
.　梯度下降和随机梯度下降… …………… 
..　一维梯度下降 … ………………… 
..　学习率 …………………………… 
..　多维梯度下降 …………………… 
..　随机梯度下降 …………………… 
小结………………………………………… 
练习………………………………………… 
.　小批量随机梯度下降… ………………… 
..　读取数据集 … …………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　动量法… …………………………………
..　梯度下降的问题 … ……………… 
..　动量法 …………………………… 
・・　目　　录
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　AdaGrad算法……………………………
..　算法 … …………………………… 
..　特点 ……………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　RMSProp算法… ………………………
..　算法 … …………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　AdaDelta算法… ……………………… 
..　算法… …………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　Adam算法… …………………………… 
..　算法 … …………………………… 
..　从零开始实现 …………………… 
..　简洁实现 ………………………… 
小结………………………………………… 
练习………………………………………… 
第 章　计算性能… …………………… 
.　命令式和符号式混合编程… …………… 
..　混合式编程取两者之长 … ……… 
..　使用HybridSequential类构造模型 … …………………………… 
..　使用HybridBlock类构造模型… …………………………… 
小结………………………………………… 
练习………………………………………… 
.　异步计算… ………………………………
..　MXNet中的异步计算 …………… 
..　用同步函数让前端等待计算结果 … …………………………… 
..　使用异步计算提升计算性能 …… 
..　异步计算对内存的影响 ………… 
小结………………………………………… 
练习………………………………………… 
.　自动并行计算… …………………………
..　CPU和GPU的并行计算 … …… 
..　计算和通信的并行计算 ………… 
小结………………………………………… 
练习………………………………………… 
.　多GPU计算……………………………… 
..　数据并行 … ……………………… 
..　定义模型 ………………………… 
..　多GPU之间同步数据 … ……… 
..　单个小批量上的多GPU训练 … …………………………… 
..　定义训练函数 …………………… 
..　多GPU训练实验 … …………… 
小结………………………………………… 
练习………………………………………… 
.　多GPU计算的简洁实现………………… 
..　多GPU上初始化模型参数……… 
..　多GPU训练模型 … …………… 
小结………………………………………… 
练习………………………………………… 
第 章　计算机视觉… ………………… 
.　图像增广…………………………………
..　常用的图像增广方法 … ………… 
..　使用图像增广训练模型 … ……… 
小结………………………………………… 
练习………………………………………… 
.　微调… ……………………………………
热狗识别 … ……………………………… 
小结………………………………………… 
练习………………………………………… 
目　　录　・・
.　目标检测和边界框… ……………………
边界框 … ………………………………… 
小结………………………………………… 
练习………………………………………… 
.　锚框… …………………………………… 
..　生成多个锚框… ………………… 
..　交并比 …………………………… 
..　标注训练集的锚框 ……………… 
..　输出预测边界框… ……………… 
小结………………………………………… 
练习………………………………………… 
.　多尺度目标检测… ………………………
小结………………………………………… 
练习………………………………………… 
.　目标检测数据集（皮卡丘）… …………
..　获取数据集 … …………………… 
..　读取数据集… …………………… 
..　图示数据 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　单发多框检测（SSD）… ……………… 
..　定义模型… ……………………… 
..　训练模型 ………………………… 
..　预测目标 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　区域卷积神经网络（R-CNN）系列……
..　R-CNN … ……………………… 
..　Fast R-CNN …………………… 
..　Faster R-CNN ………………… 
..　Mask R-CNN … ……………… 
小结………………………………………… 
练习………………………………………… 
.　语义分割和数据集… ……………………
..　图像分割和实例分割 … ………… 
..　Pascal VOC语义分割数据集 … ………………………… 
小结………………………………………… 
练习………………………………………… 
.　全卷积网络（FCN）… ………………
..　转置卷积层 …………………… 
..　构造模型 … …………………… 
..　初始化转置卷积层……………… 
..　读取数据集 … ………………… 
..　训练模型………………………… 
..　预测像素类别…………………… 
小结………………………………………… 
练习………………………………………… 
.　样式迁移… ………………………………
..　方法 ……………………………… 
..　读取内容图像和样式图像……… 
..　预处理和后处理图像 ………… 
..　抽取特征 ……………………… 
..　定义损失函数 ………………… 
..　创建和初始化合成图像 ……… 
..　训练模型………………………… 
小结………………………………………… 
练习………………………………………… 
.　实战Kaggle比赛：图像
分类（CIFAR-）……………………
..　获取和整理数据集 ……………… 
..　图像增广 … …………………… 
..　读取数据集 … ………………… 
..　定义模型………………………… 
..　定义训练函数 … ……………… 
..　训练模型 … …………………… 
..　对测试集分类并在Kaggle
提交结果 … …………………… 
小结………………………………………… 
练习………………………………………… 
.　实战Kaggle比赛：狗的品种
识别（ImageNet Dogs）…………… 
..　获取和整理数据集 …………… 
..　图像增广 … …………………… 
..　读取数据集 … ………………… 
..　定义模型 … …………………… 
..　定义训练函数 … ……………… 
..　训练模型 … …………………… 
・・　目　　录
..　对测试集分类并在Kaggle提交结果 … …………………… 
小结………………………………………… 
练习………………………………………… 
第 章　自然语言处理………………… 
.　词嵌入（wordvec）………………… 
..　为何不采用one-hot向量… …… 
..　跳字模型 ………………………… 
..　连续词袋模型 …………………… 
小结………………………………………… 
练习………………………………………… 
.　近似训练…………………………………
..　负采样 …………………………… 
..　层序softmax …………………… 
小结………………………………………… 
练习………………………………………… 
.　wordvec的实现………………………
..　预处理数据集 …………………… 
..　负采样 … ……………………… 
..　读取数据集 … ………………… 
..　跳字模型 … …………………… 
..　训练模型 … …………………… 
..　应用词嵌入模型 … …………… 
小结………………………………………… 
练习………………………………………… 
.　子词嵌入（fastText）… ……………
小结………………………………………… 
练习………………………………………… 
.　全局向量的词嵌入（GloVe）…………
..　GloVe模型 …………………… 
..　从条件概率比值理解GloVe模型……………………… 
小结………………………………………… 
练习………………………………………… 
.　求近义词和类比词………………………
..　使用预训练的词向量 ………… 
..　应用预训练词向量 … ………… 
小结………………………………………… 
练习………………………………………… 
.　文本情感分类：使用循环神经网络…… 
..　文本情感分类数据集 ………… 
..　使用循环神经网络的模型……… 
小结………………………………………… 
练习………………………………………… 
.　文本情感分类：使用卷积神经网络（textCNN）… …………………
..　一维卷积层 … ………………… 
..　时序最大池化层 … …………… 
..　读取和预处理IMDb数据集 … ……………………… 
..　textCNN模型 … ……………… 
小结………………………………………… 
练习………………………………………… 
.　编码器-解码器（seqseq）…………
..　编码器 ………………………… 
..　解码器 … ……………………… 
..　训练模型………………………… 
小结………………………………………… 
练习………………………………………… 
.　 束搜索… ………………………………
..　贪婪搜索 … …………………… 
..　穷举搜索 ……………………… 
..　束搜索 ………………………… 
小结………………………………………… 
练习………………………………………… 
.　注意力机制… …………………………
..　计算背景变量 … ……………… 
..　更新隐藏状态 … ……………… 
..　发展… ………………………… 
小结………………………………………… 
练习………………………………………… 
.　机器翻译… …………………………… 
..　读取和预处理数据集… ……… 
..　含注意力机制的编码器-解码器 … …………… 
..　训练模型 ……………………… 
..　预测不定长的序列… ………… 
..　评价翻译结果 ………………… 
小结………………………………………… 
练习………………………………………… 
附录A　数学基础… …………………… 
附录B　使用 Jupyter 记事本… ……… 
附录C　使用 AWS 运行代码…………… 
附录D　GPU 购买指南………………… 
附录E　如何为本书做贡献… ………… 
附录F　dlzh 包索引…………………… 
附录G　中英文术语对照表… ………… 
参考文献………………………………… 
索引……………………………………… 
・ ・ ・ ・ ・ ・ (收起)前言
第阶段 自动微分 
步骤 作为“箱子”的变量 
. 什么是变量 
. 实现Variable类 
. （补充）NumPy的多维数组 
步骤 创建变量的函数 
. 什么是函数 
. Function类的实现 
. 使用Function类 
步骤 函数的连续调用 
. Exp函数的实现 
. 函数的连续调用 
步骤 数值微分 
. 什么是导数 
. 数值微分的实现 
. 复合函数的导数 
. 数值微分存在的问题 
步骤 反向传播的理论知识 
. 链式法则 
. 反向传播的推导 
. 用计算图表示 
步骤 手动进行反向传播 
. Variable类的功能扩展 
. Function类的功能扩展 
. Square类和Exp类的功能扩展 
. 反向传播的实现 
步骤 反向传播的自动化 
. 为反向传播的自动化创造条件 
. 尝试反向传播 
. 增加backward方法 
步骤 从递归到循环 
. 现在的Variable类 
. 使用循环实现 
. 代码验证 
步骤 让函数更易用 
. 作为Python函数使用 
. 简化backward方法 
. 只支持ndarray 
步骤 测试 
. Python的单元测试 
. square函数反向传播的测试 
. 通过梯度检验来自动测试 
. 测试小结 
第阶段 用自然的代码表达 
步骤 可变长参数（正向传播篇) 
. 修改Function类 
. Add类的实现 
步骤 可变长参数（改进篇) 
. 第项改进：使函数更容易使用 
. 第项改进：使函数更容易实现 
. add函数的实现 
步骤 可变长参数（反向传播篇) 
. 支持可变长参数的Add类的反向传播 
. 修改Variable类 
. Square类的实现 
步骤 重复使用同一个变量 
. 问题的原因 
. 解决方案 
. 重置导数 
步骤 复杂的计算图（理论篇）
. 反向传播的正确顺序 
. 当前的DeZero 
. 函数的优先级 
步骤 复杂的计算图（实现篇）
. 增加“辈分”变量 
. 按照“辈分”顺序取出元素 
. Variable类的backward 
. 代码验证 
步骤 内存管理和循环引用 
. 内存管理 
. 引用计数方式的内存管理 
. 循环引用 
. weakref模块 
. 代码验证 
步骤 减少内存使用量的模式 
. 不保留不必要的导数 
. 回顾Function类 
. 使用Confifig类进行切换 
. 模式的切换 
. 使用with语句切换 
步骤 让变量更易用 
. 命名变量 
. 实例变量ndarray 
. len函数和print函数 
步骤 运算符重载（）
. Mul类的实现 
. 运算符重载 
步骤 运算符重载（）
. 与ndarray一起使用 
. 与flfloat和int一起使用 
. 问题：左项为flfloat或int的情况 
. 问题：左项为ndarray实例的情况 
步骤 运算符重载（）
. 负数 
. 减法 
. 除法 
. 幂运算 
步骤 打包 
. 文件结构 
. 将代码移到核心类 
. 运算符重载 
. 实际的_ _init_ _.py文件 
. 导入dezero 
步骤 复杂函数的求导 
. Sphere函数 
. matyas函数 
. GoldsteinPrice函数 
第阶段 实现高阶导数 
步骤 计算图的可视化（） 
. 安装Graphviz 
. 使用DOT语言描述图形 
. 指定节点属性 
. 连接节点 
步骤 计算图的可视化（）
. 可视化代码的使用示例 
. 从计算图转换为DOT语言 
. 从DOT语言转换为图像 
. 代码验证 
步骤 泰勒展开的导数 
. sin函数的实现 
. 泰勒展开的理论知识 
. 泰勒展开的实现 
. 计算图的可视化 
步骤 函数优化 
. Rosenbrock函数 
. 求导 
. 梯度下降法的实现 
步骤 使用牛顿法进行优化（手动计算）
. 使用牛顿法进行优化的理论知识 
. 使用牛顿法实现优化 
步骤 高阶导数（准备篇） 
. 确认工作：Variable实例变量 
. 确认工作：Function类 
. 确认工作：Variable类的反向传播 
步骤 高阶导数（理论篇） 
. 在反向传播时进行的计算 
. 创建反向传播的计算图的方法 
步骤 高阶导数（实现篇） 
. 新的DeZero 
. 函数类的反向传播 
. 实现更有效的反向传播（增加模式控制代码）
. 修改_ _init_ _.py 
步骤 使用牛顿法进行优化（自动计算） 
. 求二阶导数 
. 使用牛顿法进行优化 
步骤 sin函数的高阶导数 
. sin函数的实现 
. cos函数的实现 
. sin函数的高阶导数 
步骤 高阶导数的计算图 
. tanh函数的导数 
. tanh函数的实现 
. 高阶导数的计算图可视化 
步骤 DeZero的其他用途 
. double backprop的用途 
. 深度学习研究中的应用示例 
第阶段 创建神经网络 
步骤 处理张量 
. 对各元素进行计算 
. 使用张量时的反向传播 
. 使用张量时的反向传播（补充内容）
步骤 改变形状的函数 
. reshape函数的实现 
. 从Variable对象调用reshape 
. 矩阵的转置 
. 实际的transpose函数（补充内容）
步骤 求和的函数 
. sum函数的反向传播 
. sum函数的实现 
. axis和keepdims 
步骤 进行广播的函数 
. broadcast_to函数和sum_to函数 
. DeZero的broadcast_to函数和sum_to函数 
. 支持广播 
步骤 矩阵的乘积 
. 向量的内积和矩阵的乘积 
. 检查矩阵的形状 
. 矩阵乘积的反向传播 
步骤 线性回归 
. 玩具数据集 
. 线性回归的理论知识 
. 线性回归的实现 
. DeZero的mean_squared_error函数（补充内容） 
步骤 神经网络 
. DeZero中的linear函数 
. 非线性数据集 
. 激活函数和神经网络 
. 神经网络的实现 
步骤 汇总参数的层 
. Parameter类的实现 
. Layer类的实现 
. Linear类的实现 
. 使用Layer实现神经网络 
步骤 汇总层的层 
. 扩展Layer类 
. Model类 
. 使用Model来解决问题 
. MLP类 
步骤 通过Optimizer更新参数 
. Optimizer类 
. SGD类的实现 
. 使用SGD类来解决问题 
. SGD以外的优化方法 
步骤 softmax函数和交叉熵误差 
. 用于切片操作的函数 
. softmax函数 
. 交叉熵误差 
步骤 多分类 
. 螺旋数据集 
. 用于训练的代码 
步骤 Dataset类和预处理 
. Dataset类的实现 
. 大型数据集的情况 
. 数据的连接 
. 用于训练的代码 
. 数据集的预处理 
步骤 用于取出小批量数据的DataLoader 
. 什么是迭代器 
. 使用DataLoader 
. accuracy函数的实现 
. 螺旋数据集的训练代码 
步骤 MINST的训练 
. MNIST数据集 
. 训练MNIST 
. 改进模型 
第阶段 DeZero高级挑战 
步骤 支持GPU 
. CuPy的安装和使用方法 
. cuda模块 
. 向Variable / Layer / DataLoader类添加代码 
. 函数的相应修改 
. 在GPU上训练MNIST 
步骤 模型的保存和加载 
. NumPy的save函数和load函数 
. Layer类参数的扁平化 
. Layer类的save函数和load函数 
步骤 Dropout和测试模式 
. 什么是Dropout 
. Inverted Dropout 
. 增加测试模式 
. Dropout的实现 
步骤 CNN的机制（） 
. CNN的网络结构 
. 卷积运算 
. 填充 
. 步幅 
. 输出大小的计算方法 
步骤 CNN的机制（）
. 三阶张量 
. 结合方块进行思考 
. 小批量处理 
. 池化层 
步骤 convd函数和pooling函数 
. 使用imcol展开 
. convd函数的实现 
. Convd层的实现 
. pooling函数的实现 
步骤 具有代表性的CNN（VGG）
. VGG的实现 
. 已训练的权重数据 
. 使用已训练的VGG 
步骤 使用RNN处理时间序列数据 
. RNN层的实现 
. RNN模型的实现 
. 切断连接的方法 
. 正弦波的预测 
步骤 LSTM与数据加载器 
. 用于时间序列数据的数据加载器 
. LSTM层的实现 
附录A inplace运算（步骤的补充内容）
A. 问题确认 
A. 关于复制和覆盖 
A. DeZero的反向传播 
附录B 实现get_item函数（步骤的补充内容）
附录C 在Google Colaboratory上运行 
后 记 
参考文献 
・ ・ ・ ・ ・ ・ (收起)推 荐 序 面对科技拐点，我们的判断与选择
中文版序 人工智能会放大认知能力
前 言 深度学习与智能的本质
第一部分 智能的新构想
 机器学习的崛起
汽车新生态：无人驾驶将全面走入人们生活
自然语言翻译：从语言到句子的飞跃
语音识别：实时跨文化交流不再遥远
AI医疗：医学诊断将更加准确
金融科技：利用数据和算法获取最佳回报
深度法律：效率的提高与费用的降低
德州扑克：当机器智能学会了虚张声势
AlphaGo奇迹：神经科学与人工智能的协同
弗林效应：深度学习让人类更加智能
新教育体系：每个人都需要终身学习
正面影响：新兴技术不是生存威胁
回到未来：当人类智能遇到人工智能
 人工智能的重生
看似简单的视觉识别
计算机视觉的进步
早期人工智能发展缓慢
从神经网络到人工智能
 神经网络的黎明
深度学习的起点
从样本中学习
利用感知器区分性别
被低估的神经网络
 大脑式的计算
网络模型能够模仿智能行为
神经网络先驱者
乔治・布尔与机器学习
利用神经科学理解大脑
大脑如何处理问题
计算神经科学的兴起
 洞察视觉系统
人眼是如何看到东西的
大脑皮层中的视觉
突触的可塑性
通过阴影脑补立体全貌
视觉区域的层级结构
认知神经科学的诞生
第二部分 深度学习的演进
 语音识别的突破
在嘈杂中找到你的声音
将独立分量分析应用于大脑
什么在操控我们的言行
 霍普菲尔德网络和玻尔兹曼机
约翰・霍普菲尔德的伟大之处
内容可寻址存储器
局部最小值与全局最小值
玻尔兹曼机
赫布理论
学习识别镜像对称
学习识别手写数字
无监督学习和皮层发育
 反向传播算法
算法的优化
语音合成的突破
神经网络的重生
理解真正的深度学习
神经网络的局限性
 卷积学习
机器学习的稳步发展
卷积网络的渐进式改进
当深度学习遇到视觉层级结构
有工作记忆的神经网络
生成式对抗网络
应对现实社会的复杂性
 奖励学习
机器如何学会下棋
大脑的奖励机制
用“感知-行动”框架提高绩效
学习如何翱翔
学习如何歌唱
人工智能的可塑性
更多需要被解决的问题
 火爆的NIPS
为什么NIPS如此受欢迎
谁拥有最多数据，谁就是赢家
为未来做准备
第三部分 人类，智能与未来
 智能时代
世纪的生活
未来的身份认证
社交机器人的崛起
机器已经会识别人类面部表情
新技术改变教育方式
成为更好的学习者
训练你的大脑
智能商业
 算法驱动
用算法把复杂问题简单化
理解、分析复杂系统
大脑的逻辑深度
尝试所有可能的策略
 芯片崛起
神经形态芯片
视网膜芯片
神经形态工程
摩尔定律的终结
 信息科学
用字节丈量世界
用数学思维解决通信难题
预测是如何产生的
深度理解大脑
大脑的操作系统
生物学与计算科学
人工智能能拥有媲美人类大脑的操作系统
 生命与意识
视觉意识
视觉感知的过程
视觉感知的时机
视觉感知的部位
视觉搜索的机理
创造意识比理解意识更容易
 进化的力量
大自然比我们聪明
认知科学的兴起
不能把语言问题只留给语言学家
难预测的行为规律
神经网络的寒冬
从深度学习到通用人工智能
 深度智能
遗传密码
每个物种都有智能
进化的起源
人类终将解决智能难题
・ ・ ・ ・ ・ ・ (收起)第 部分　PyTorch核心
第　章 深度学习和PyTorch库简介　
．　深度学习革命　
．　PyTorch深度学习　
．　为什么用PyTorch　
．　PyTorch如何支持深度学习概述　
．　硬件和软件要求　
．　练习题　
．　本章小结　
第　章 预训练网络　
．　一个识别图像主体的预训练网络　
．．　获取一个预先训练好的网络用于图像识别　
．．　AlexNet　
．．　ResNet　
．．　准备运行　
．．　运行模型　
．　一个足以以假乱真的预训练模型　
．．　GAN游戏　
．．　CycleGAN　
．．　一个把马变成斑马的网络　
．　一个描述场景的预训练网络　
．　Torch Hub　
．　总结　
．　练习题　
．　本章小结　
第章　从张量开始　
．　实际数据转为浮点数　
．　张量：多维数组　
．．　从Python列表到PyTorch张量　
．．　构造第 个张量　
．．　张量的本质　
．　索引张量　
．　命名张量　
．　张量的元素类型　
．．　使用dtype指定数字类型　
．．　适合任何场合的dtype　
．．　管理张量的dtype属性　
．　张量的API　
．　张量的存储视图　
．．　索引存储区　
．．　修改存储值：就地操作　
．　张量元数据：大小、偏移量和步长　
．．　另一个张量的存储视图　
．．　无复制转置　
．．　高维转置　
．．　连续张量　
．　将张量存储到GPU　
．　NumPy互操作性　
．　广义张量也是张量　
．　序列化张量　
．　总结　
．　练习题　
．　本章小结　
第章　使用张量表征真实数据　
．　处理图像　
．．　添加颜色通道　
．．　加载图像文件　
．．　改变布局　
．．　正规化数据　
．　三维图像：体数据　
．　表示表格数据　
．．　使用真实的数据集　
．．　加载葡萄酒数据张量　
．．　表示分数　
．．　独热编码　
．．　何时分类　
．．　寻找阈值　
．　处理时间序列　
．．　增加时间维度　
．．　按时间段调整数据　
．．　准备训练　
．　表示文本　
．．　将文本转化为数字　
．．　独热编码字符　
．．　独热编码整个词　
．．　文本嵌入　
．．　作为蓝图的文本嵌入　
．　总结　
．　练习题　
．　本章小结　
第章　学习的机制　
．　永恒的建模经验　
．　学习就是参数估计　
．．　一个热点问题　
．．　收集一些数据　
．．　可视化数据　
．．　选择线性模型首试　
．　减少损失是我们想要的　
．　沿着梯度下降　
．．　减小损失　
．．　进行分析　
．．　迭代以适应模型　
．．　归一化输入　
．．　再次可视化数据　
．　PyTorch自动求导：反向传播的一切　
．．　自动计算梯度　
．．　优化器　
．．　训练、验证和过拟合　
．．　自动求导更新及关闭　
．　总结　
．　练习题　
．　本章小结　
第章　使用神经网络拟合数据　
．　人工神经网络　
．．　组成一个多层网络　
．．　理解误差函数　
．．　我们需要的只是激活函数　
．．　更多激活函数　
．．　选择最佳激活函数　
．．　学习对于神经网络意味着什么　
．　PyTorch nn模块　
．．　使用__call__()而不是forward()　
．．　回到线性模型　
．　最终完成一个神经网络　
．．　替换线性模型　
．．　检查参数　
．．　与线性模型对比　
．　总结　
．　练习题　
．　本章小结　
第章　区分鸟和飞机：从图像学习　
．　微小图像数据集　
．．　下载CIFAR-　
．．　Dataset类　
．．　Dataset变换　
．．　数据归一化　
．　区分鸟和飞机　
．．　构建数据集　
．．　一个全连接模型　
．．　分类器的输出　
．．　用概率表示输出　
．．　分类的损失　
．．　训练分类器　
．．　全连接网络的局限　
．　总结　
．　练习题　
．　本章小结　
第章　使用卷积进行泛化　
．　卷积介绍　
．　卷积实战　
．．　填充边界　
．．　用卷积检测特征　
．．　使用深度和池化技术进一步研究　
．．　为我们的网络整合一切　
．　子类化nn．Module　
．．　将我们的网络作为一个nn．Module　
．．　PyTorch如何跟踪参数和子模块　
．．　函数式API　
．　训练我们的convnet　
．．　测量精度　
．．　保存并加载我们的模型　
．．　在GPU上训练　
．　模型设计　
．．　增加内存容量：宽度　
．．　帮助我们的模型收敛和泛化：正则化　
．．　深入学习更复杂的结构：深度　
．．　本节设计的比较　
．．　已经过时了　
．　总结　
．　练习题　
．　本章小结　
第　部分 从现实世界的图像中学习：肺癌的早期检测
第章　使用PyTorch来检测癌症　
．　用例简介　
．　为一个大型项目做准备　
．　到底什么是CT扫描　
．　项目：肺癌的端到端检测仪　
．．　为什么我们不把数据扔给神经网络直到它起作用呢　
．．　什么是结节　
．．　我们的数据来源：LUNA大挑战赛　
．．　下载LUNA数据集　
．　总结　
．　本章小结　
第　章 将数据源组合成统一的数据集　
．　原始CT数据文件　
．　解析LUNA的标注 数据　
．．　训练集和验证集　
．．　统一标注和候选 数据　
．　加载单个CT扫描　
．　使用病人坐标系定位结节　
．．　病人坐标系　
．．　CT扫描形状和体素大小　
．．　毫米和体素地址之间的转换　
．．　从CT扫描中取出一个结节　
．　一个简单的数据集实现　
．．　使用getCtRawCandidate()函数缓存候选数组　
．．　在LunaDataset．__init__()中构造我们的数据集　
．．　分隔训练集和验证集　
．．　呈现数据　
．　总结　
．　练习题　
．　本章小结　
第　章 训练分类模型以检测可疑肿瘤　
．　一个基本的模型和训练循环　
．　应用程序的主入口点　
．　预训练和初始化　
．．　初始化模型和优化器　
．．　数据加载器的维护和供给　
．　我们的首次神经网络设计　
．．　核心卷积　
．．　完整模型　
．　训练和验证模型　
．．　computeBatchLoss()函数　
．．　类似的验证循环　
．　输出性能指标　
．　运行训练脚本　
．．　训练所需的数据　
．．　插曲：enumerateWithEstimate()函数　
．　评估模型：得到．%的正确率是否意味着我们完成了任务　
．　用TensorBoard绘制训练指标　
．．　运行TensorBoard　
．．　增加TensorBoard对指标记录函数的支持　
．　为什么模型不学习检测结节　
．　总结　
．　练习题　
．　本章小结　
第　章 通过指标和数据增强来提升训练　
．　高级改进计划　
．　好狗与坏狗：假阳性与假阴性　
．　用图表表示阳性与阴性　
．．　召回率是Roxie的强项　
．．　精度是Preston的强项　
．．　在logMetrics()中实现精度和召回率　
．．　我们的终极性能指标：F分数　
．．　我们的模型在新指标下表现如何　
．　理想的数据集是什么样的　
．．　使数据看起来更理想化　
．．　使用平衡的LunaDataset与之前的数据集运行情况对比　
．．　认识过拟合　
．　重新审视过拟合的问题　
．　通过数据增强防止过拟合　
．．　具体的数据增强技术　
．．　看看数据增强带来的改进　
．　总结　
．　练习题　
．　本章小结　
第　章 利用分割法寻找可疑结节　
．　向我们的项目添加第 个模型　
．　各种类型的分割　
．　语义分割：逐像素分类　
．　更新分割模型　
．　更新数据集以进行分割　
．．　U-Net有非常具体的对输入大小的要求　
．．　U-Net对三维和二维数据的权衡　
．．　构建真实、有效的数据集　
．．　实现LunadSegmentationDataset　
．．　构建训练和验证数据　
．．　实现TrainingLunadSegmentationDataset　
．．　在GPU上增强数据　
．　更新用于分割的训练脚本　
．．　初始化分割和增强模型　
．．　使用Adam优化器　
．．　骰子损失　
．．　将图像导入TensorBoard　
．．　更新指标日志　
．．　保存模型　
．　结果　
．　总结　
．　练习题　
．　本章小结　
第　章 端到端的结节分析及下一步的方向　
．　接近终点线　
．　验证集的独立性　
．　连接CT分割和候选结节分类　
．．　分割　
．．　将体素分组为候选结节　
．．　我们发现结节了吗？分类以减少假阳性　
．　定量验证　
．　预测恶性肿瘤　
．．　获取恶性肿瘤信息　
．．　曲线基线下的区域：按直径分类　
．．　重用预先存在的权重：微调　
．．　TensorBoard中的输出　
．　在诊断时所见的内容　
．　接下来呢？其他灵感和数据的来源　
．．　防止过拟合：更好的正则化　
．．　精细化训练数据　
．．　竞赛结果及研究论文　
．　总结　
．　练习题　
．　本章小结　
第部分　部署
第　章 部署到生产环境　
．　PyTorch模型的服务　
．．　支持Flask服务的模型　
．．　我们想从部署中得到的东西　
．．　批处理请求　
．　导出模型　
．．　PyTorch与ONNX的互操作性　
．．　PyTorch自己的导出：跟踪　
．．　具有跟踪模型的服务器　
．　与PyTorch JIT编译器交互　
．．　超越经典Python/PyTorch的期望是什么　
．．　PyTorch作为接口和后端的双重特性　
．．　TorchScript　
．．　为可追溯的差异编写脚本　
．　LibTorch：C++中的PyTorch　
．．　从C++中运行JITed模型　
．．　从C++ API开始　
．　部署到移动设备　
．　新兴技术：PyTorch
模型的企业服务　
．　总结　
．　练习题　
．　本章小结　
・ ・ ・ ・ ・ ・ (收起)第章 互联网的增长引擎――推荐系统
. 为什么推荐系统是互联网的增长引擎
.. 推荐系统的作用和意义
.. 推荐系统与YouTube的观看时长增长
.. 推荐系统与电商网站的收入增长
. 推荐系统的架构
.. 推荐系统的逻辑框架
.. 推荐系统的技术架构
.. 推荐系统的数据部分
.. 推荐系统的模型部分
.. 深度学习对推荐系统的革命性贡献
.. 把握整体，补充细节
. 本书的整体结构
第章 前深度学习时代――推荐系统的进化之路
. 传统推荐模型的演化关系图
. 协同过滤――经典的推荐算法
.. 什么是协同过滤
.. 用户相似度计算
.. 终结果的排序
.. ItemCF
.. UserCF与ItemCF的应用场景
.. 协同过滤的下一步发展
. 矩阵分解算法――协同过滤的进化
.. 矩阵分解算法的原理
.. 矩阵分解的求解过程
.. 消除用户和物品打分的偏差
.. 矩阵分解的优点和局限性
. 逻辑回归――融合多种特征的推荐模型
.. 基于逻辑回归模型的推荐流程
.. 逻辑回归模型的数学形式
.. 逻辑回归模型的训练方法
.. 逻辑回归模型的优势
.. 逻辑回归模型的局限性
. 从FM到FFM――自动特征交叉的解决方案
.. POLY模型――特征交叉的开始
.. FM模型――隐向量特征交叉
.. FFM模型――引入特征域的概念
.. 从POLY到FFM的模型演化过程
. GBDT+LR――特征工程模型化的开端
.. GBDT+LR组合模型的结构
.. GBDT进行特征转换的过程
.. GBDT+LR 组合模型开启的特征工程新趋势
. LS-PLM――阿里巴巴曾经的主流推荐模型
.. LS-PLM 模型的主要结构
.. LS-PLM模型的优点
.. 从深度学习的角度重新审视LS-PLM模型
. 总结――深度学习推荐系统的前夜
第章 浪潮之巅――深度学习在推荐系统中的应用
. 深度学习推荐模型的演化关系图
. AutoRec――单隐层神经网络推荐模型
.. AutoRec模型的基本原理
.. AutoRec模型的结构
.. 基于AutoRec模型的推荐过程
.. AutoRec模型的特点和局限性
. Deep Crossing模型――经典的深度学习架构
.. Deep Crossing模型的应用场景
.. Deep Crossing模型的网络结构
.. Deep Crossing模型对特征交叉方法的革命
. NeuralCF模型――CF与深度学习的结合
.. 从深度学习的视角重新审视矩阵分解模型
.. NeuralCF模型的结构
.. NeuralCF模型的优势和局限性
. PNN模型――加强特征交叉能力
.. PNN模型的网络架构
.. Product层的多种特征交叉方式
.. PNN模型的优势和局限性
. Wide&Deep 模型――记忆能力和泛化能力的综合
.. 模型的记忆能力与泛化能力
.. Wide&Deep模型的结构
.. Wide&Deep模型的进化――Deep&Cross模型
.. Wide&Deep模型的影响力
. FM与深度学习模型的结合
.. FNN――用FM的隐向量完成Embedding层初始化
.. DeepFM――用FM代替Wide部分
.. NFM――FM的神经网络化尝试
.. 基于FM的深度学习模型的优点和局限性
. 注意力机制在推荐模型中的应用
.. AFM――引入注意力机制的FM
.. DIN――引入注意力机制的深度学习网络
.. 注意力机制对推荐系统的启发
. DIEN――序列模型与推荐系统的结合
.. DIEN的“进化”动机
.. DIEN模型的架构
.. 兴趣抽取层的结构
.. 兴趣进化层的结构
.. 序列模型对推荐系统的启发
. 强化学习与推荐系统的结合
.. 深度强化学习推荐系统框架
.. 深度强化学习推荐模型
.. DRN的学习过程
.. DRN的在线学习方法――竞争梯度下降算法
.. 强化学习对推荐系统的启发
. 总结――推荐系统的深度学习时代
第章 Embedding技术在推荐系统中的应用
. 什么是Embedding
.. 词向量的例子
.. Embedding 技术在其他领域的扩展
.. Embedding 技术对于深度学习推荐系统的重要性
. Wordvec――经典的Embedding方法
.. 什么是Wordvec
.. Wordvec模型的训练过程
.. Wordvec的“负采样”训练方法
.. Wordvec对Embedding技术的奠基性意义
. Itemvec――Wordvec 在推荐系统领域的推广
.. Itemvec的基本原理
.. “广义”的Itemvec
.. Itemvec方法的特点和局限性
. Graph Embedding――引入更多结构信息的图嵌入技术
.. DeepWalk――基础的Graph Embedding方法
.. Nodevec――同质性和结构性的权衡
.. EGES――阿里巴巴的综合性Graph Embedding方法
. Embedding与深度学习推荐系统的结合
.. 深度学习网络中的Embedding层
.. Embedding的预训练方法
.. Embedding作为推荐系统召回层的方法
. 局部敏感哈希――让Embedding插上翅膀的快速搜索方法
.. “快速”Embedding近邻搜索
.. 局部敏感哈希的基本原理
.. 局部敏感哈希多桶策略
. 总结――深度学习推荐系统的核心操作
第章 多角度审视推荐系统
. 推荐系统的特征工程
.. 构建推荐系统特征工程的原则
.. 推荐系统中的常用特征
.. 常用的特征处理方法
.. 特征工程与业务理解
. 推荐系统召回层的主要策略
.. 召回层和排序层的功能特点
.. 多路召回策略
.. 基于Embedding的召回方法
. 推荐系统的实时性
.. 为什么说推荐系统的实时性是重要的
.. 推荐系统“特征”的实时性
.. 推荐系统“模型”的实时性
.. 用“木桶理论”看待推荐系统的迭代升级
. 如何合理设定推荐系统中的优化目标
.. YouTube以观看时长为优化目标的合理性
.. 模型优化和应用场景的统一性
.. 优化目标是和其他团队的接口性工作
. 推荐系统中比模型结构更重要的是什么
.. 有解决推荐问题的“银弹”吗
.. Netflix对用户行为的观察
.. 观察用户行为，在模型中加入有价值的用户信息
.. DIN模型的改进动机
.. 算法工程师不能只是一个“炼金术士”
. 冷启动的解决办法
.. 基于规则的冷启动过程
.. 丰富冷启动过程中可获得的用户和物品特征
.. 利用主动学习、迁移学习和“探索与利用”机制
.. “巧妇难为无米之炊”的困境
. 探索与利用
.. 传统的探索与利用方法
.. 个性化的探索与利用方法
.. 基于模型的探索与利用方法
.. “探索与利用”机制在推荐系统中的应用
第章 深度学习推荐系统的工程实现
. 推荐系统的数据流
.. 批处理大数据架构
.. 流计算大数据架构
.. Lambda架构
.. Kappa架构
.. 大数据平台与推荐系统的整合
. 推荐模型离线训练之Spark MLlib
.. Spark的分布式计算原理
.. Spark MLlib的模型并行训练原理
.. Spark MLlib并行训练的局限性
. 推荐模型离线训练之Parameter Server
.. Parameter Server的分布式训练原理
.. 一致性与并行效率之间的取舍
.. 多server节点的协同和效率问题
.. Parameter Server技术要点总结
. 推荐模型离线训练之TensorFlow
.. TensorFlow的基本原理
.. TensorFlow基于任务关系图的并行训练过程
.. TensorFlow的单机训练与分布式训练模式
.. TensorFlow技术要点总结
. 深度学习推荐模型的上线部署
.. 预存推荐结果或Embedding结果
.. 自研模型线上服务平台
.. 预训练Embedding+轻量级线上模型
.. 利用PMML转换并部署模型
.. TensorFlow Serving
.. 灵活选择模型服务方法
. 工程与理论之间的权衡
.. 工程师职责的本质
.. Redis容量和模型上线方式之间的权衡
.. 研发周期限制和技术选型的权衡
.. 硬件平台环境和模型结构间的权衡
.. 处理好整体和局部的关系
第章 推荐系统的评估
. 离线评估方法与基本评价指标
.. 离线评估的主要方法
.. 离线评估的指标
. 直接评估推荐序列的离线指标
.. P-R曲线
.. ROC曲线
.. 平均精度均值
.. 合理选择评估指标
. 更接近线上环境的离线评估方法――Replay
.. 模型评估的逻辑闭环
.. 动态离线评估方法
.. Netflix的Replay评估方法实践
. A/B测试与线上评估指标
.. 什么是A/B测试
.. A/B测试的“分桶”原则
.. 线上A/B测试的评估指标
. 快速线上评估方法――Interleaving
.. 传统A/B测试存在的统计学问题
.. Interleaving方法的实现
.. Interleaving方法与传统A/B测试的灵敏度比较
.. Interleaving方法指标与A/B测试指标的相关性
.. Interleaving方法的优点与缺点
. 推荐系统的评估体系
第章 深度学习推荐系统的前沿实践
. Facebook的深度学习推荐系统
.. 推荐系统应用场景
.. 以GBDT+LR组合模型为基础的CTR预估模型
.. 实时数据流架构
.. 降采样和模型校正
.. Facebook GBDT+LR组合模型的工程实践
.. Facebook的深度学习模型DLRM
.. DLRM模型并行训练方法
.. DLRM模型的效果
.. Facebook深度学习推荐系统总结
. Airbnb基于Embedding的实时搜索推荐系统
.. 推荐系统应用场景
.. 基于短期兴趣的房源Embedding方法
.. 基于长期兴趣的用户Embedding和房源Embedding
.. Airbnb搜索词的Embedding
.. Airbnb的实时搜索排序模型及其特征工程
.. Airbnb实时搜索推荐系统总结
. YouTube深度学习视频推荐系统
.. 推荐系统应用场景
.. YouTube推荐系统架构
.. 候选集生成模型
.. 候选集生成模型独特的线上服务方法
.. 排序模型
.. 训练和测试样本的处理
.. 如何处理用户对新视频的偏好
.. YouTube深度学习视频推荐系统总结
. 阿里巴巴深度学习推荐系统的进化
.. 推荐系统应用场景
.. 阿里巴巴的推荐模型体系
.. 阿里巴巴深度学习推荐模型的进化过程
.. 模型服务模块的技术架构
.. 阿里巴巴推荐技术架构总结
第章 构建属于你的推荐系统知识框架
. 推荐系统的整体知识架构图
. 推荐模型发展的时间线
. 如何成为一名优秀的推荐工程师
.. 推荐工程师的项能力
.. 能力的深度和广度
.. 推荐工程师的能力总结
后记
・ ・ ・ ・ ・ ・ (收起)第 章绪论
. 简介
. 图深度学习的动机
. 本书内容
. 本书读者定位
. 图特征学习的简要发展史
.. 图特征选择
.. 图表示学习
. 小结
. 扩展阅读
第 篇基础理论
第 章图论基础
. 简介
. 图的表示
. 图的性质
.. 度
.. 连通度
.. 中心性
. 谱图论
.. 拉普拉斯矩阵
.. 拉普拉斯矩阵的特征值和特征向量
. 图信号处理
. 复杂图
.. 异质图
.. 二分图
.. 多维图
.. 符号图
.. 超图
.. 动态图
. 图的计算任务
.. 侧重于节点的任务
.. 侧重于图的任务
. 小结
. 扩展阅读
第 章深度学习基础
. 简介
. 深度前馈神经网络
.. 网络结构
.. 激活函数
.. 输出层和损失函数
. 卷积神经网络
.. 卷积操作和卷积层
.. 实际操作中的卷积层
.. 非线性激活层
.. 池化层
.. 卷积神经网络总体框架
. 循环神经网络
.. 传统循环神经网络的网络结构
.. 长短期记忆网络
.. 门控循环单元
. 自编码器
.. 欠完备自编码器
.. 正则化自编码器
. 深度神经网络的训练
.. 梯度下降
.. 反向传播
.. 预防过拟合
. 小结
. 扩展阅读
第 篇模型方法
第 章图嵌入
. 简介
. 简单图的图嵌入
.. 保留节点共现
.. 保留结构角色
.. 保留节点状态
.. 保留社区结构
. 复杂图的图嵌入
.. 异质图嵌入
.. 二分图嵌入
.. 多维图嵌入
.. 符号图嵌入
.. 超图嵌入
.. 动态图嵌入
. 小结
. 扩展阅读
第 章图神经网络
. 简介
. 图神经网络基本框架
.. 侧重于节点的任务的图神经网络框架
.. 侧重于图的任务的图神经网络框架
. 图滤波器
.. 基于谱的图滤波器
.. 基于空间的图滤波器
. 图池化
.. 平面图池化
.. 层次图池化
. 图卷积神经网络的参数学习
.. 节点分类中的参数学习
.. 图分类中的参数学习
. 小结
. 扩展阅读
第 章图神经网络的健壮性
. 简介
. 图对抗攻击
.. 图对抗攻击的分类
.. 白盒攻击
.. 灰盒攻击
.. 黑盒攻击
. 图对抗防御
.. 图对抗训练
.. 图净化
.. 图注意力机制
.. 图结构学习
. 小结
. 扩展阅读
第 章可扩展图神经网络
. 简介
. 逐点采样法
. 逐层采样法
. 子图采样法
. 小结
. 扩展阅读
第 章复杂图神经网络
. 简介
. 异质图神经网络
. 二分图神经网络
. 多维图神经网络
. 符号图神经网络
. 超图神经网络
. 动态图神经网络
. 小结
. 扩展阅读
第 章图上的其他深度模型
. 简介
. 图上的自编码器
. 图上的循环神经网络
. 图上的变分自编码器
.. 用于节点表示学习的变分自编码器
.. 用于图生成的变分自编码器
.. 编码器：推论模型
.. 解码器: 生成模型
.. 重建的损失函数
. 图上的生成对抗网络
.. 用于节点表示学习的生成对抗网络
.. 用于图生成的生成对抗网络
. 小结
. 扩展阅读
第 篇实际应用
第 章自然语言处理中的图神经网络
. 简介
. 语义角色标注
. 神经机器翻译
. 关系抽取
. 问答系统
.. 多跳问答任务
.. Entity-GCN 
. 图到序列学习
. 知识图谱中的图神经网络
.. 知识图谱中的图滤波
.. 知识图谱到简单图的转换
.. 知识图谱补全
. 小结
. 扩展阅读
第 章计算机视觉中的图神经网络
. 简介
. 视觉问答
.. 图像表示为图
.. 图像和问题表示为图
. 基于骨架的动作识别
. 图像分类
.. 零样本图像分类
.. 少样本图像分类
.. 多标签图像分类
. 点云学习
. 小结
. 扩展阅读
第 章数据挖掘中的图神经网络
. 简介
. 万维网数据挖掘
.. 社交网络分析
.. 推荐系统
. 城市数据挖掘
.. 交通预测
.. 空气质量预测
. 网络安全数据挖掘
.. 恶意账户检测
.. 虚假新闻检测
. 小结
. 扩展阅读
第 章生物化学和医疗健康中的
图神经网络
. 简介
. 药物开发与发现
.. 分子表示学习
.. 蛋白质相互作用界面预测
.. 药物C靶标结合亲和力预测
. 药物相似性整合
. 复方药物副作用预测
. 疾病预测
. 小结
. 扩展阅读
第 篇前沿进展
第 章图神经网络的高级方法
. 简介
. 深层图神经网络
.. Jumping Knowledge 
.. DropEdge 
.. PairNorm 
. 通过自监督学习探索未标记数据
.. 侧重于节点的任务
.. 侧重于图的任务
. 图神经网络的表达能力
.. WL 测试
.. 表达能力
. 小结
. 扩展阅读
第 章图神经网络的高级应用
. 简介
. 图的组合优化
. 学习程序表示
. 物理学中相互作用的动力系统推断
. 小结
. 扩展阅读
参考文献
索引
・ ・ ・ ・ ・ ・ (收起)Contents 目　　录
前言
第一部分　PyTorch基础
第章　Numpy基础
.　生成Numpy数组
..　从已有数据中创建数组
..　利用random模块生成数组
..　创建特定形状的多维数组
..　利用arange、linspace函数生成数组
.　获取元素
.　Numpy的算术运算
..　对应元素相乘
..　点积运算
.　数组变形
..　更改数组的形状
..　合并数组
.　批量处理
.　通用函数
.　广播机制
.　小结
第章　PyTorch基础
.　为何选择PyTorch？
.　安装配置
..　安装CPU版PyTorch
..　安装GPU版PyTorch
.　Jupyter Notebook环境配置
.　Numpy与Tensor
..　Tensor概述
..　创建Tensor
..　修改Tensor形状
..　索引操作
..　广播机制
..　逐元素操作
..　归并操作
..　比较操作
..　矩阵操作
..　PyTorch与Numpy比较
.　Tensor与Autograd
..　自动求导要点
..　计算图
..　标量反向传播
..　非标量反向传播
.　使用Numpy实现机器学习
.　使用Tensor及Antograd实现机器学习
.　使用TensorFlow架构
.　小结
第章　PyTorch神经网络工具箱
.　神经网络核心组件
.　实现神经网络实例
..　背景说明
..　准备数据
..　可视化源数据
..　构建模型
..　训练模型
.　如何构建神经网络？
..　构建网络层
..　前向传播
..　反向传播
..　训练模型
.　神经网络工具箱nn
..　nn.Module
..　nn.functional
.　优化器
.　动态修改学习率参数
.　优化器比较
.　小结
第章　PyTorch数据处理工具箱
.　数据处理工具箱概述
.　utils.data简介
.　torchvision简介
..　transforms
..　ImageFolder
.　可视化工具
..　tensorboardX简介
..　用tensorboardX可视化神经网络
..　用tensorboardX可视化损失值
..　用tensorboardX可视化特征图
.　本章小结
第二部分　深度学习基础
第章　机器学习基础
.　机器学习的基本任务
..　监督学习
..　无监督学习
..　半监督学习
..　强化学习
.　机器学习一般流程
..　明确目标
..　收集数据
..　数据探索与预处理
..　选择模型及损失函数
..　评估及优化模型
.　过拟合与欠拟合
..　权重正则化
..　Dropout正则化
..　批量正则化
..　权重初始化
.　选择合适激活函数
.　选择合适的损失函数
.　选择合适优化器
..　传统梯度优化的不足
..　动量算法
..　AdaGrad算法
..　RMSProp算法
..　Adam算法
.　GPU加速
..　单GPU加速
..　多GPU加速
..　使用GPU注意事项
.　本章小结
第章　视觉处理基础
.　卷积神经网络简介
.　卷积层
..　卷积核
..　步幅
..　填充
..　多通道上的卷积
..　激活函数
..　卷积函数
..　转置卷积
.　池化层
..　局部池化
..　全局池化
.　现代经典网络
..　LeNet-模型
..　AlexNet模型
..　VGG模型
..　GoogleNet模型
..　ResNet模型
..　胶囊网络简介
.　PyTorch实现CIFAR-多分类
..　数据集说明
..　加载数据
..　构建网络
..　训练模型
..　测试模型
..　采用全局平均池化
..　像Keras一样显示各层参数
.　模型集成提升性能
..　使用模型
..　集成方法
..　集成效果
.　使用现代经典模型提升性能
.　本章小结
第章　自然语言处理基础
.　循环神经网络基本结构
.　前向传播与随时间反向传播
.　循环神经网络变种
..　LSTM
..　GRU
..　Bi-RNN
.　循环神经网络的PyTorch实现
..　RNN实现
..　LSTM实现
..　GRU实现
.　文本数据处理
.　词嵌入
..　WordVec原理
..　CBOW模型
..　Skip-Gram模型
.　PyTorch实现词性判别
..　词性判别主要步骤
..　数据预处理
..　构建网络
..　训练网络
..　测试模型
.　用LSTM预测股票行情
..　 导入数据
..　数据概览
..　预处理数据
..　定义模型
..　训练模型
..　测试模型
.　循环神经网络应用场景
.　小结
第章　生成式深度学习
.　用变分自编码器生成图像
..　自编码器
..　变分自编码器
..　用变分自编码器生成图像
.　GAN简介
..　GAN架构
..　GAN的损失函数
.　用GAN生成图像
..　判别器
..　生成器
..　训练模型
..　可视化结果
.　VAE与GAN的优缺点
.　ConditionGAN
..　CGAN的架构
..　CGAN生成器
..　CGAN判别器
..　CGAN损失函数
..　CGAN可视化
..　查看指定标签的数据
..　可视化损失值
.　DCGAN
.　提升GAN训练效果的一些技巧
.　小结
第三部分　深度学习实践
第章　人脸检测与识别
.　人脸识别一般流程
.　人脸检测
..　目标检测
..　人脸定位
..　人脸对齐
..　MTCNN算法
.　特征提取
.　人脸识别
..　人脸识别主要原理
..　人脸识别发展
.　PyTorch实现人脸检测与识别
..　验证检测代码
..　检测图像
..　检测后进行预处理
..　查看经检测后的图像
..　人脸识别
.　小结
第章　迁移学习实例
.　迁移学习简介
.　特征提取
..　PyTorch提供的预处理模块
..　特征提取实例
.　数据增强
..　按比例缩放
..　裁剪
..　翻转
..　改变颜色
..　组合多种增强方法
.　微调实例
..　数据预处理
..　加载预训练模型
..　修改分类器
..　选择损失函数及优化器
..　训练及验证模型
.　清除图像中的雾霾
.　小结
第章　神经网络机器翻译实例
.　Encoder-Decoder模型原理
.　注意力框架
.　PyTorch实现注意力Decoder
..　构建Encoder
..　构建简单Decoder
..　构建注意力Decoder
.　用注意力机制实现中英文互译
..　导入需要的模块
..　数据预处理
..　构建模型
..　训练模型
..　随机采样，对模型进行测试
..　可视化注意力
.　小结
第章　实战生成式模型
.　DeepDream模型
..　Deep Dream原理
..　DeepDream算法流程
..　用PyTorch实现Deep Dream
.　风格迁移
..　内容损失
..　风格损失
..　用PyTorch实现神经网络风格迁移
.　PyTorch实现图像修复
..　网络结构
..　损失函数
..　图像修复实例
.　PyTorch实现DiscoGAN
..　DiscoGAN架构
..　损失函数
..　DiscoGAN实现
..　用PyTorch实现从边框生成鞋子
.　小结
第章　Caffe模型迁移实例
.　Caffe简介
.　Caffe如何升级到Caffe
.　PyTorch如何迁移到Caffe
.　小结
第章　AI新方向：对抗攻击
.　对抗攻击简介
..　白盒攻击与黑盒攻击
..　无目标攻击与有目标攻击
.　常见对抗样本生成方式
..　快速梯度符号法
..　快速梯度算法
.　PyTorch实现对抗攻击
..　实现无目标攻击
..　实现有目标攻击
.　对抗攻击和防御措施
..　对抗攻击
..　常见防御方法分类
.　总结
第章　强化学习
.　强化学习简介
.　Q-Learning原理
..　Q-Learning主要流程
..　Q函数
..　贪婪策略
.　用PyTorch实现Q-Learning
..　定义Q-Learing主函数
..　执行Q-Learing
.　SARSA算法
..　SARSA算法主要步骤
..　用PyTorch实现SARSA算法
.　小结
第章　深度强化学习
.　DQN算法原理
..　Q-Learning方法的局限性
..　用DL处理RL需要解决的问题
..　用DQN解决方法
..　定义损失函数
..　DQN的经验回放机制
..　目标网络
..　网络模型
..　DQN算法
.　用PyTorch实现DQN算法
.　小结
附录A　PyTorch.版本变更
附录B　AI在各行业的最新应用
・ ・ ・ ・ ・ ・ (收起)目录

第章 深度学习简介：为什么应该学习深度学习 
.　欢迎阅读《深度学习图解》 
.　为什么要学习深度学习 
.　这很难学吗? 
.　为什么要阅读本书 
.　准备工作 
.　你可能需要掌握一部分Python知识 
.　本章小结 
第章 基本概念：机器该如何学习？ 
.　什么是深度学习? 
.　什么是机器学习？ 
.　监督机器学习 
.　无监督机器学习 
.　参数学习和非参数学习 
.　监督参数学习 
.　无监督参数学习 
.　非参数学习 
.　本章小结 
第章 神经网络预测导论：前向传播 
.　什么是预测 
.　能够进行预测的简单神经网络 
.　什么是神经网络? 
.　这个神经网络做了什么? 
.　使用多个输入进行预测 
.　多个输入：这个神经网络做了什么? 
.　多个输入：完整的可运行代码 
.　预测多个输出 
.　使用多个输入和输出进行预测 
.　多输入多输出神经网络的工作原理 
.　用预测结果进一步预测 
.　NumPy快速入门 
.　本章小结 
第章 神经网络学习导论：梯度下降 
.　预测、比较和学习 
.　什么是比较 
.　学习 
.　比较：你的神经网络是否做出了好的预测？ 
.　为什么需要测量误差？ 
.　最简单的神经学习形式是什么？ 
.　冷热学习 
.　冷热学习的特点 
.　基于误差调节权重 
.　梯度下降的一次迭代 
.　学习就是减少误差 
.　回顾学习的步骤 
.　权重增量到底是什么? 
.　狭隘的观点 
.　插着小棍的盒子 
.　导数：两种方式 
.　你真正需要知道的 
.　你不需要知道的 
.　如何使用导数来学习 
.　看起来熟悉吗? 
.　破坏梯度下降 
.　过度修正的可视化 
.　发散 
.　引入α 
.　在代码中实现α 
.　记忆背诵 
第章 通用梯度下降：一次学习多个权重 
.　多输入梯度下降学习 
.　多输入梯度下降详解 
.　回顾学习的步骤 
.　单项权重冻结：它有什么作用? 
.　具有多个输出的梯度下降学习 
.　具有多个输入和输出的梯度下降 
.　这些权重学到了什么? 
.　权重可视化 
.　点积(加权和)可视化 
.　本章小结 
第章 建立你的第一个深度神经网络：反向传播 
.　交通信号灯问题 
.　准备数据 
.　矩阵和矩阵关系 
.　使用Python创建矩阵 
.　建立神经网络 
.　学习整个数据集 
.　完全、批量和随机梯度下降 
.　神经网络对相关性的学习 
.　向上与向下的压力 
.　边界情况：过拟合 
.　边界情况：压力冲突 
.　学习间接相关性 
.　创建关联 
.　堆叠神经网络：回顾 
.　反向传播：远程错误归因 
.　反向传播：为什么有效? 
.　线性与非线性 
.　为什么神经网络仍然不起作用 
.　选择性相关的秘密 
.　快速冲刺 
.　你的第一个深度神经网络 
.　反向传播的代码 
.　反向传播的一次迭代 
.　整合代码 
.　为什么深度网络这么重要? 
第章 如何描绘神经网络：在脑海里，在白纸上 
.　到了简化的时候了 
.　关联抽象 
.　旧的可视化方法过于复杂 
.　简化版可视化 
.　进一步简化 
.　观察神经网络是如何进行预测的 
.　用字母而不是图片来进行可视化 
.　连接变量 
.　信息整合 
.　可视化工具的重要性 
第章 学习信号，忽略噪声：正则化和批处理介绍 
.　用在MNIST上的三层网络 
.　好吧，这很简单 
.　记忆与泛化 
.　神经网络中的过拟合 
.　过拟合从何而来 
.　最简单的正则化：提前停止 
.　行业标准正则化：dropout 
.　为什么dropout有效：整合是有效的 
.　dropout的代码 
.　在MNIST数据集上对dropout进行测试 
.　批量梯度下降 
.　本章小结 
第章 概率和非线性建模：激活函数 
.　什么是激活函数? 
.　标准隐藏层激活函数 
.　标准输出层激活函数 
.　核心问题：输入具有
相似性 
.　计算softmax 
.　激活函数使用说明 
.　将增量与斜率相乘 
.　将输出转换为斜率(导数) 
.　升级MNIST网络 
第章 卷积神经网络概论：关于边与角的神经学习 
.　在多个位置复用权重 
.　卷积层 
.　基于NumPy的简单实现 
.　本章小结 
第章 能够理解自然语言的神经网络：国王-男人+女人=？ 
.　理解语言究竟是指什么? 
.　自然语言处理(NLP) 
.　监督NLP学习 
.　IMDB电影评论数据集 
.　在输入数据中提取单词相关性 
.　对影评进行预测 
.　引入嵌入层 
.　解释输出 
.　神经网络结构 
.　单词嵌入表达的对比 
.　神经元是什么意思? 
.　完形填空 
.　损失函数的意义 
.　国王-男人+女人~=女王 
.　单词类比 
.　本章小结 
第章 像莎士比亚一样写作的神经网络：变长数据的递归层 
.　任意长度的挑战 
.　做比较真的重要吗？ 
.　平均词向量的神奇力量 
.　信息是如何存储在这些向量嵌入中的？ 
.　神经网络是如何使用嵌入的？ 
.　词袋向量的局限 
.　用单位向量求词嵌入之和 
.　不改变任何东西的矩阵 
.　学习转移矩阵 
.　学习创建有用的句子向量 
.　Python下的前向传播 
.　如何反向传播？ 
.　让我们训练它！ 
.　进行设置 
.　任意长度的前向传播 
.　任意长度的反向传播 
.　任意长度的权重更新 
.　运行代码，并分析输出 
.　本章小结 
第章 介绍自动优化：搭建深度学习框架 
.　深度学习框架是什么？ 
.　张量介绍 
.　自动梯度计算(autograd)介绍 
.　快速检查 
.　多次使用的张量 
.　升级autograd以支持多次使用的张量 
.　加法的反向传播如何工作？ 
.　增加取负值操作的支持 
.　添加更多函数的支持 
.　使用autograd训练神经网络 
.　增加自动优化 
.　添加神经元层类型的支持 
.　包含神经元层的神经元层 
.　损失函数层 
.　如何学习一个框架 
.　非线性层 
.　嵌入层 
.　将下标操作添加到
autograd 
.　再看嵌入层 
.　交叉熵层 
.　递归神经网络层 
.　本章小结 
第章 像莎士比亚一样写作：长短期记忆网络 
.　字符语言建模 
.　截断式反向传播的必要性 
.　截断式反向传播 
.　输出样例 
.　梯度消失与梯度激增 
.　RNN反向传播的小例子 
.　长短期记忆(LSTM)元胞 
.　关于LSTM门限的直观理解 
.　长短期记忆层 
.　升级字符语言模型 
.　训练LSTM字符语言模型 
.　调优LSTM字符语言模型 
.　本章小结 
第章 在看不见的数据上做深度学习：联邦学习导论 
.　深度学习的隐私问题 
.　联邦学习 
.　学习检测垃圾邮件 
.　让我们把它联邦化 
.　深入联邦学习 
.　安全聚合 
.　同态加密 
.　同态加密联邦学习 
.　本章小结 
第章 往哪里去：简要指引 
・ ・ ・ ・ ・ ・ (收起)第　一部分 基础知识
第　章 走近深度学习：机器学习入门　
．　什么是机器学习　
．．　机器学习与AI的关系　
．．　机器学习能做什么，不能做什么　
．　机器学习示例　
．．　在软件应用中使用机器学习　
．．　监督学习　
．．　无监督学习　
．．　强化学习　
．　深度学习　
．　阅读本书能学到什么　
．　小结　
第　章 围棋与机器学习　
．　为什么选择游戏　
．　围棋快速入门　
．．　了解棋盘　
．．　落子与吃子　
．．　终盘与胜负计算　
．．　理解劫争　
．．　让子　
．　更多学习资源　
．　我们可以教会计算机什么　
．．　如何开局　
．．　搜索游戏状态　
．．　减少需要考虑的动作数量　
．．　评估游戏状态　
．　如何评估围棋AI的能力　
．．　传统围棋评级　
．．　对围棋AI进行基准测试　
．　小结　
第章　实现第 一个围棋机器人　
．　在Python中表达围棋游戏　
．．　实现围棋棋盘　
．．　在围棋中跟踪相连的棋组：棋链　
．．　在棋盘上落子和提子　
．　跟踪游戏状态并检查非法动作　
．．　自吃　
．．　劫争　
．　终盘　
．　创建自己的第 一个机器人：理论上最弱的围棋AI　
．　使用Zobrist哈希加速棋局　
．　人机对弈　
．　小结　
第二部分　机器学习和游戏AI
第章　使用树搜索下棋　
．　游戏分类　
．　利用极小化极大搜索预测对手　
．　井字棋推演：一个极小化极大算法的示例　
．　通过剪枝算法缩减搜索空间　
．．　通过棋局评估减少搜索深度　
．．　利用α-β剪枝缩减搜索宽度　
．　使用蒙特卡洛树搜索评估游戏状态　
．．　在Python中实现蒙特卡洛树搜索　
．．　如何选择继续探索的分支　
．．　将蒙特卡洛树搜索应用于围棋　
．　小结　
第章　神经网络入门　
．　一个简单的用例：手写数字分类　
．．　MNIST手写数字数据集　
．．　MNIST数据的预处理　
．　神经网络基础　
．．　将对率回归描述为简单的神经网络　
．．　具有多个输出维度的神经网络　
．　前馈网络　
．　我们的预测有多好？损失函数及优化　
．．　什么是损失函数　
．．　均方误差　
．．　在损失函数中找极小值　
．．　使用梯度下降法找极小值　
．．　损失函数的随机梯度下降算法　
．．　通过网络反向传播梯度　
．　在Python中逐步训练神经网络　
．．　Python中的神经网络层　
．．　神经网络中的激活层　
．．　在Python中实现稠密层　
．．　Python顺序神经网络　
．．　将网络集成到手写数字分类应用中　
．　小结　
第章　为围棋数据设计神经网络　
．　为神经网络编码围棋棋局　
．　生成树搜索游戏用作网络训练数据　
．　使用Keras深度学习库　
．．　了解Keras的设计原理　
．．　安装Keras深度学习库　
．．　热身运动：在Keras中运行一个熟悉的示例　
．．　使用Keras中的前馈神经网络进行动作预测　
．　使用卷积网络分析空间　
．．　卷积的直观解释　
．．　用Keras构建卷积神经网络　
．．　用池化层缩减空间　
．　预测围棋动作概率　
．．　在最后一层使用softmax激活函数　
．．　分类问题的交叉熵损失函数　
．　使用丢弃和线性整流单元构建更深的网络　
．．　通过丢弃神经元对网络进行正则化　
．．　线性整流单元激活函数　
．　构建更强大的围棋动作预测网络　
．　小结　
第章　从数据中学习：构建深度学习机器人　
．　导入围棋棋谱　
．．　SGF文件格式　
．．　从KGS下载围棋棋谱并复盘　
．　为深度学习准备围棋数据　
．．　从SGF棋谱中复盘围棋棋局　
．．　构建围棋数据处理器　
．．　构建可以高效地加载数据的围棋数据生成器　
．．　并行围棋数据处理和生成器　
．　基于真实棋局数据训练深度学习模型　
．　构建更逼真的围棋数据编码器　
．　使用自适应梯度进行高效的训练　
．．　在SGD中采用衰减和动量　
．．　使用Adagrad优化神经网络　
．．　使用Adadelta优化自适应梯度　
．　运行自己的实验并评估性能　
．．　测试架构与超参数的指南　
．．　评估训练与测试数据的性能指标　
．　小结　
第章　实地部署围棋机器人　
．　用深度神经网络创建动作预测代理　
．　为围棋机器人提供Web前端　
．　在云端训练与部署围棋机器人　
．　与其他机器人对话：围棋文本协议　
．　在本地与其他机器人对弈　
．．　机器人应该何时跳过回合或认输　
．．　让机器人与其他围棋程序进行对弈　
．　将围棋机器人部署到在线围棋服务器　
．　小结　
第章　通过实践学习：强化学习　
．　强化学习周期　
．　经验包括哪些内容　
．　建立一个有学习能力的代理　
．．　从某个概率分布中进行抽样　
．．　剪裁概率分布　
．．　初始化一个代理实例　
．．　在磁盘上加载并保存代理　
．．　实现动作选择　
．　自我对弈：计算机程序进行实践训练的方式　
．．　经验数据的表示　
．．　模拟棋局　
．　小结　
第　章 基于策略梯度的强化学习　
．　如何在随机棋局中识别更佳的决策　
．　使用梯度下降法修改神经网络的策略　
．　使用自我对弈进行训练的几个小技巧　
．．　评估学习的进展　
．．　衡量强度的细微差别　
．．　SGD优化器的微调　
．　小结　
第　章 基于价值评估方法的强化学习　
．　使用Q学习进行游戏　
．　在Keras中实现Q学习　
．．　在Keras中构建双输入网络　
．．　用Keras实现ε贪婪策略　
．．　训练一个行动-价值函数　
．　小结　
第　章 基于演员-评价方法的强化学习　
．　优势能够告诉我们哪些决策更加重要　
．．　什么是优势　
．．　在自我对弈过程中计算优势值　
．　为演员-评价学习设计神经网络　
．　用演员-评价代理下棋　
．　用经验数据训练一个演员-评价代理　
．　小结　
第三部分　一加一大于二
第　章 AlphaGo：全部集结　
．　为AlphaGo训练深度神经网络　
．．　AlphaGo的网络架构　
．．　AlphaGo棋盘编码器　
．．　训练AlphaGo风格的策略网络　
．　用策略网络启动自我对弈　
．　从自我对弈数据衍生出一个价值网络　
．　用策略网络和价值网络做出更好的搜索　
．．　用神经网络改进蒙特卡洛推演　
．．　用合并价值函数进行树搜索　
．．　实现AlphaGo的搜索算法　
．　训练自己的AlphaGo可能遇到的实践问题　
．　小结　
第　章 AlphaGo Zero：将强化学习集成到树搜索中　
．　为树搜索构建一个神经网络　
．　使用神经网络来指导树搜索　
．．　沿搜索树下行　
．．　扩展搜索树　
．．　选择一个动作　
．　训练　
．　用狄利克雷噪声改进探索　
．　处理超深度神经网络的相关最新技术　
．．　批量归一化　
．．　残差网络　
．　探索额外资源　
．　结语　
．　小结　
附录A　数学基础　
附录B　反向传播算法　
附录C　围棋程序与围棋服务器　
附录D　用AWS来训练和部署围棋程序与围棋服务器　
附录E　将机器人发布到OGS　
・ ・ ・ ・ ・ ・ (收起)第章 深度学习简介 
. 人工智能、机器学习与深度学习 
. 深度学习的发展历程 
. 深度学习的应用 
.. 计算机视觉 
.. 语音识别 
.. 自然语言处理 
.. 人机博弈 
. 深度学习工具介绍和对比 
小结 
第章 TensorFlow环境搭建 
. TensorFlow的主要依赖包 
.. Protocol Buffer 
.. Bazel 
. TensorFlow安装 
.. 使用Docker安装 
.. 使用pip安装 
.. 从源代码编译安装 
. TensorFlow测试样例 
小结 
第章 TensorFlow入门 
. TensorFlow计算模型――计算图 
.. 计算图的概念 
.. 计算图的使用 
. TensorFlow数据模型――张量 
.. 张量的概念 
.. 张量的使用 
. TensorFlow运行模型――会话 
. TensorFlow实现神经网络 
.. TensorFlow游乐场及神经网络简介 
.. 前向传播算法简介 
.. 神经网络参数与TensorFlow变量 
.. 通过TensorFlow训练神经网络模型 
.. 完整神经网络样例程序 
小结 
第章 深层神经网络 
. 深度学习与深层神经网络 
.. 线性模型的局限性 
.. 激活函数实现去线性化 
.. 多层网络解决异或运算 
. 损失函数定义 
.. 经典损失函数 
.. 自定义损失函数 
. 神经网络优化算法 
. 神经网络进一步优化 
.. 学习率的设置 
.. 过拟合问题 
.. 滑动平均模型 
小结 
第章 MNIST数字识别问题 
. MNIST数据处理 
. 神经网络模型训练及不同模型结果对比 
.. TensorFlow训练神经网络 
.. 使用验证数据集判断模型效果 
.. 不同模型效果比较 
. 变量管理 
. TensorFlow模型持久化 
.. 持久化代码实现 
.. 持久化原理及数据格式 
. TensorFlow最佳实践样例程序 
小结 
第章 图像识别与卷积神经网络 
. 图像识别问题简介及经典数据集 
. 卷积神经网络简介 
. 卷积神经网络常用结构 
.. 卷积层 
.. 池化层 
. 经典卷积网络模型 
.. LeNet-模型 
.. Inception-v模型 
. 卷积神经网络迁移学习 
.. 迁移学习介绍 
.. TensorFlow实现迁移学习 
小结 
第章 图像数据处理 
. TFRecord输入数据格式 
.. TFRecord格式介绍 
.. TFRecord样例程序 
. 图像数据处理 
.. TensorFlow图像处理函数 
.. 图像预处理完整样例 
. 多线程输入数据处理框架 
.. 队列与多线程 
.. 输入文件队列 
.. 组合训练数据（batching） 
.. 输入数据处理框架 
小结 
第章 循环神经网络 
. 循环神经网络简介 
. 长短时记忆网络（LTSM）结构 
. 循环神经网络的变种 
.. 双向循环神经网络和深层循环神经网络 
.. 循环神经网络的dropout 
. 循环神经网络样例应用 
.. 自然语言建模 
.. 时间序列预测 
小结 
第章 TensorBoard可视化 
. TensorBoard简介 
. TensorFlow计算图可视化 
.. 命名空间与TensorBoard图上节点 
.. 节点信息 
. 监控指标可视化 
小结 
第章 TensorFlow计算加速 
. TensorFlow使用GPU 
. 深度学习训练并行模式 
. 多GPU并行 
. 分布式TensorFlow 
.. 分布式TensorFlow原理 
.. 分布式TensorFlow模型训练 
.. 使用Caicloud运行分布式TensorFlow 
小结 
・ ・ ・ ・ ・ ・ (收起)前言 .
第一部分 生成式深度学习概述
第 章 生成建模 
. 什么是生成建模？ 
.. 生成建模与判别建模 
.. 机器学习的发展 . 
.. 生成建模的兴起 . 
.. 生成建模的框架 . 
. 概率生成模型 
.. 你好，Wrodl ！ 
.. 你的第一个概率生成模型 . 
.. 朴素贝叶斯 
.. 你好，Wrodl ！续篇 . 
. 生成建模的难题 
表示学习 
. 设置环境 
. 小结 
第 章 深度学习 
. 结构化与非结构化数据 
. 深度神经网络 
Keras 和TensorFlow 
. 第一个深度神经网络 . 
.. 加载数据. 
.. 建立模型. 
.. 编译模型. 
.. 训练模型. 
.. 评估模型. 
. 改进模型 
.. 卷积层 . 
.. 批标准化. 
.. Dropout 层 . 
.. 结合所有层 
. 小结 
第 章 变分自动编码器 
. 画展 
. 自动编码器 . 
.. 第一个自动编码器 . 
.. 编码器 . 
.. 解码器 . 
.. 连接编码器与解码器 
.. 分析自动编码器 . 
. 变化后的画展 
. 构建变分自动编码器 . 
.. 编码器 . 
.. 损失函数. 
.. 分析变分自动编码器 
. 使用VAE 生成面部图像 
.. 训练VAE 
.. 分析VAE . 
.. 生成新面孔 . 
.. 隐空间的算术 
.. 面部变形 
. 小结 . 
第 章 生成对抗网络 
. 神秘兽 
. 生成对抗网络简介 
. 第一个生成对抗网络 
.. 判别器 
.. 生成器 
.. 训练GAN 
. GAN 面临的难题 
.. 损失震荡 
.. 模式收缩 
.. 不提供信息的损失函数 
.. 超参数 
.. 解决GAN 面临的难题 . 
. WGAN 
.. Wasserstein 损失 
.. 利普希茨约束 
.. 权重裁剪 
.. 训练WGAN 
.. 分析WGAN 
. WGAN-GP 
.. 梯度惩罚损失 
.. 分析WGAN-GP 
. 小结 . 
第二部分 教机器绘画、写作、作曲和玩游戏
第 章 绘画 
. 苹果和橙子 
. CycleGAN 
. 第一个CycleGAN 模型 . 
.. 简介 
.. 生成器（U-Net） 
.. 判别器 
.. 编译CycleGAN 
.. 训练CycleGAN 
.. 分析CycleGAN 
. 创建一个模仿莫奈作品的CycleGAN . 
.. 生成器（ResNet） 
.. 分析CycleGAN 
. 神经风格迁移 . 
.. 内容损失 
.. 风格损失 
.. 总方差损失 . 
.. 运行神经风格迁移 
.. 分析神经风格迁移模型 
. 小结 . 
第 章 写作 
. 坏家伙们的文学社 
. 长短期记忆网络 
. 第一个LSTM 网络 
.. 分词 
.. 建立数据集 . 
.. LSTM 架构 . 
.. 嵌入层 
.. LSTM 层 
.. LSTM 元胞 . 
. 生成新文本 
. RNN 扩展 . 
.. 堆叠式循环网络 
.. 门控制循环单元 
.. 双向元胞 
. 编码器- 解码器模型 
. 问答生成器 
.. 问答数据集 . 
.. 模型架构 
.. 推断 
.. 模型的结果 . 
. 小结 . 
第 章 作曲 
. 前提知识 
音符 
・ ・ ・ ・ ・ ・ (收起)第章 深度学习简介
. 人工智能、机器学习与深度学习
. 深度学习的发展历程
. 深度学习的应用
.. 计算机视觉
.. 语音识别
.. 自然语言处理
.. 人机博弈
. 深度学习工具介绍和对比
小结
第章 TensorFlow环境搭建
. TensorFlow的主要依赖包
.. Protocol Buffer
.. Bazel
. TensorFlow安装
.. 使用Docker安装
.. 使用pip安装
.. 从源代码编译安装
. TensorFlow测试样例
小结
第章 TensorFlow入门
. TensorFlow计算模型――计算图
.. 计算图的概念
.. 计算图的使用
. TensorFlow数据模型――张量
.. 张量的概念
.. 张量的使用
. TensorFlow运行模型――会话
. TensorFlow实现神经网络
.. TensorFlow游乐场及神经网络简介
.. 前向传播算法简介
.. 神经网络参数与TensorFlow变量
.. 通过TensorFlow训练神经网络模型
.. 完整神经网络样例程序
小结
第章 深层神经网络
. 深度学习与深层神经网络
.. 线性模型的局限性
.. 激活函数实现去线性化
.. 多层网络解决异或运算
. 损失函数定义
.. 经典损失函数
.. 自定义损失函数
. 神经网络优化算法
. 神经网络进一步优化
.. 学习率的设置
.. 过拟合问题
.. 滑动平均模型
小结
第章 MNIST数字识别问题
. MNIST数据处理
. 神经网络模型训练及不同模型结果对比
.. TensorFlow训练神经网络
.. 使用验证数据集判断模型效果
.. 不同模型效果比较
. 变量管理
. TensorFlow模型持久化
.. 持久化代码实现
.. 持久化原理及数据格式
. TensorFlow最佳实践样例程序
小结
第章 图像识别与卷积神经网络
. 图像识别问题简介及经典数据集
. 卷积神经网络简介
. 卷积神经网络常用结构
.. 卷积层
.. 池化层
. 经典卷积网络模型
.. LeNet-模型
.. Inception-v模型
. 卷积神经网络迁移学习
.. 迁移学习介绍
.. TensorFlow实现迁移学习
小结
第章 图像数据处理
. TFRecord输入数据格式
.. TFRecord格式介绍
.. TFRecord样例程序
. 图像数据处理
.. TensorFlow图像处理函数
.. 图像预处理完整样例
. 多线程输入数据处理框架
.. 队列与多线程
.. 输入文件队列
.. 组合训练数据（batching）
.. 输入数据处理框架
. 数据集（Dataset）
.. 数据集的基本使用方法
.. 数据集的高层操作
小结
第章 循环神经网络
. 循环神经网络简介
. 长短时记忆网络（LSTM）结构
. 循环神经网络的变种
.. 双向循环神经网络和深层循环神经网络
.. 循环神经网络的dropout
. 循环神经网络样例应用
小结
第章 自然语言处理
. 语言模型的背景知识
.. 语言模型简介
.. 语言模型的评价方法
. 神经语言模型
.. PTB数据集的预处理
.. PTB数据的batching方法
.. 基于循环神经网络的神经语言模型
. 神经网络机器翻译
.. 机器翻译背景与SeqSeq模型介绍
.. 机器翻译文本数据的预处理
.. SeqSeq模型的代码实现
.. 注意力机制
小结
第章 TensorFlow高层封装
. TensorFlow高层封装总览
. Keras介绍
.. Keras基本用法
.. Keras高级用法
. Estimator介绍
.. Estimator基本用法
.. Estimator自定义模型
.. 使用数据集（Dataset）作为Estimator输入
小结
第章 TensorBoard可视化
. TensorBoard简介
. TensorFlow计算图可视化
.. 命名空间与TensorBoard图上节点
.. 节点信息
. 监控指标可视化
. 高维向量可视化
小结
第章 TensorFlow计算加速
. TensorFlow使用GPU
. 深度学习训练并行模式
. 多GPU并行
. 分布式TensorFlow
.. 分布式TensorFlow原理
.. 分布式TensorFlow模型训练
小结
・ ・ ・ ・ ・ ・ (收起)第一部分　原理篇
第章　机器学习与模型 
.　模型 
.　参数与训练 
.　损失函数 
.　计算图的训练 
.　小结 
第章　计算图 
.　什么是计算图 
.　前向传播 
.　函数优化与梯度下降法 
.　链式法则与反向传播 
.　在计算图上执行梯度下降法 
.　节点类及其子类 
.　用计算图搭建ADALINE并训练 
.　小结 
第章　优化器 
.　优化流程的抽象实现 
.　BGD、SGD和MBGD 
.　梯度下降优化器 
.　朴素梯度下降法的局限 
.　冲量优化器 
.　AdaGrad优化器 
.　RMSProp优化器 
.　Adam优化器 
.　小结 
第二部分　模型篇
第章　逻辑回归 
.　对数损失函数 
.　Logistic函数 
.　二分类逻辑回归 
.　多分类逻辑回归 
.　交叉熵 
.　实例：鸢尾花 
.　小结 
第章　神经网络 
.　神经元与激活函数 
.　神经网络 
.　多层全连接神经网络 
.　多个全连接层的意义 
.　实例：鸢尾花 
.　实例：手写数字识别 
.　小结 
第章　非全连接神经网络 
.　带二次项的逻辑回归 
.　因子分解机 
.　Wide & Deep 
.　DeepFM 
.　实例：泰坦尼克号幸存者 
.　小结 
第章　循环神经网络 
.　RNN的结构 
.　RNN的输出 
.　实例：正弦波与方波 
.　变长序列 
.　实例：D电磁发音仪单词识别 
.　小结 
第章　卷积神经网络 
.　蒙德里安与莫奈 
.　滤波器 
.　可训练的滤波器 
.　卷积层 
.　池化层 
.　CNN的结构 
.　实例：手写数字识别 
.　小结 
第三部分　工程篇
第章　训练与评估 
.　训练和Trainer训练器 
.　评估和Metrics节点 
.　混淆矩阵 
.　正确率 
.　查准率 
.　查全率 
.　ROC曲线和AUC 
.　小结 
第章　模型保存、预测和服务 
.　模型保存 
.　模型加载和预测 
.　模型服务 
.　客户端 
.　小结 
第章　分布式训练 
.　分布式训练的原理 
.　基于参数服务器的架构 
.　Ring AllReduce原理 
.　Ring AllReduce架构实现 
.　分布式训练性能评测 
.　小结 
第章　工业级深度学习框架 
.　张量 
.　计算加速 
.　GPU 
.　数据接口 
.　模型并行 
.　静态图和动态图 
.　混合精度训练 
.　图优化和编译优化 
.　移动端和嵌入式端 
.　小结 
・ ・ ・ ・ ・ ・ (收起)第 章　PyTorch与深度学习 
．　人工智能　
．　机器学习　
．　深度学习　
．．　深度学习的应用　
．．　深度学习的浮夸宣传　
．．　深度学习发展史　
．．　为何是现在　
．．　硬件可用性　
．．　数据和算法　
．．　深度学习框架　
．　小结　
第　章 神经网络的构成　
．　安装PyTorch　
．　实现第 一个神经网络　
．．　准备数据　
．．　为神经网络创建数据　
．．　加载数据　
．　小结　
第章　深入了解神经网络　
．　详解神经网络的组成部分　
．．　层―神经网络的基本组成　
．．　非线性激活函数　
．．　PyTorch中的非线性激活函数　
．．　使用深度学习进行图像分类　
．　小结　
第章　机器学习基础　
．　三类机器学习问题　
．．　有监督学习　
．．　无监督学习　
．．　强化学习　
．　机器学习术语　
．　评估机器学习模型　
．　数据预处理与特征工程　
．．　向量化　
．．　值归一化　
．．　处理缺失值　
．．　特征工程　
．　过拟合与欠拟合　
．．　获取更多数据　
．．　缩小网络规模　
．．　应用权重正则化　
．．　应用dropout　
．．　欠拟合　
．　机器学习项目的工作流　
．．　问题定义与数据集创建　
．．　成功的衡量标准　
．．　评估协议　
．．　准备数据　
．．　模型基线　
．．　大到过拟合的模型　
．．　应用正则化　
．．　学习率选择策略　
．　小结　
第章　深度学习之计算机视觉　
．　神经网络简介　
．　从零开始构建CNN模型　
．．　Convd　
．．　池化　
．．　非线性激活―ReLU　
．．　视图　
．．　训练模型　
．．　狗猫分类问题―从零开始构建CNN　
．．　利用迁移学习对狗猫分类　
．　创建和探索VGG模型　
．．　冻结层　
．．　微调VGG模型　
．．　训练VGG模型　
．　计算预卷积特征　
．　理解CNN模型如何学习　
．　CNN层的可视化权重　
．　小结　
第章　序列数据和文本的深度学习　
．　使用文本数据　
．．　分词　
．．　向量化　
．　通过构建情感分类器训练词向量　
．．　下载IMDB数据并对文本分词　
．．　构建词表　
．．　生成向量的批数据　
．．　使用词向量创建网络模型　
．．　训练模型　
．　使用预训练的词向量　
．．　下载词向量　
．．　在模型中加载词向量　
．．　冻结embedding层权重　
．　递归神经网络（RNN）　
．　LSTM　
．．　长期依赖　
．．　LSTM网络　
．　基于序列数据的卷积网络　
．　小结　
第章　生成网络　
．　神经风格迁移　
．．　加载数据　
．．　创建VGG模型　
．．　内容损失　
．．　风格损失　
．．　提取损失　
．．　为网络层创建损失函数　
．．　创建优化器　
．．　训练　
．　生成对抗网络（GAN）　
．　深度卷机生成对抗网络　
．．　定义生成网络　
．．　定义判别网络　
．．　定义损失函数和优化器　
．．　训练判别网络　
．．　训练生成网络　
．．　训练整个网络　
．．　检验生成的图片　
．　语言建模　
．．　准备数据　
．．　生成批数据　
．．　定义基于LSTM的模型　
．．　定义训练和评估函数　
．．　训练模型　
．　小结　
第章　现代网络架构　
．　现代网络架构　
．．　ResNet　
．．　Inception　
．　稠密连接卷积网络（DenseNet）　
．．　DenseBlock　
．．　DenseLayer　
．　模型集成　
．．　创建模型　
．．　提取图片特征　
．．　创建自定义数据集和数据加载器　
．．　创建集成模型　
．．　训练和验证模型　
．　encoder-decoder架构　
．．　编码器　
．．　解码器　
．　小结　
第章　未来走向　
．　未来走向　
．　回顾　
．　有趣的创意应用　
．．　对象检测　
．．　图像分割　
．．　PyTorch中的OpenNMT　
．．　Allen NLP　
．．　fast．ai―神经网络不再神秘　
．．　Open Neural Network Exchange　
．　如何跟上前沿　
．　小结　
・ ・ ・ ・ ・ ・ (收起)第章　深度学习入门　　
.　机器学习简介　　
..　监督学习　　
..　无监督学习　　
..　强化学习　　
.　深度学习定义　　
..　人脑的工作机制　　
..　深度学习历史　　
..　应用领域　　
.　神经网络　　
..　生物神经元　　
..　人工神经元　　
.　人工神经网络的学习方式　　
..　反向传播算法　　
..　权重优化　　
..　随机梯度下降法　　
.　神经网络架构　　
..　多层感知器　　
..　DNN架构　　
..　卷积神经网络　　
..　受限玻尔兹曼机　　
.　自编码器　　
.　循环神经网络　　
.　几种深度学习框架对比　　
.　小结　　
第章　TensorFlow初探　　
.　总览　　
..　TensorFlow .x版本特性　　
..　使用上的改进　　
..　TensorFlow安装与入门　　
.　在Linux上安装TensorFlow　　
.　为TensorFlow启用NVIDIA GPU　　
..　第步：安装NVIDIA CUDA　　
..　　第步：安装NVIDIA cuDNN v.+　　
..　　第步：确定GPU卡的CUDA计算能力为.+　　
..　第步：安装libcupti-dev库　　
..　　第步：安装Python
（或Python ）　　
..　第步：安装并升级PIP
（或PIP）　　
..　第步：安装TensorFlow　　
.　如何安装TensorFlow　　
..　直接使用pip安装　　
..　使用virtualenv安装　　
..　从源代码安装　　
.　在Windows上安装TensorFlow　　
..　在虚拟机上安装TensorFlow　　
..　直接安装到Windows　　
.　测试安装是否成功　　
.　计算图　　
.　为何采用计算图　　
.　编程模型　　
.　数据模型　　
..　阶　　
..　形状　　
..　数据类型　　
..　变量　　
..　取回　　
..　注入　　
.　TensorBoard　　
.　实现一个单输入神经元　　
.　单输入神经元源代码　　
.　迁移到TensorFlow .x版本　　
..　如何用脚本升级　　
..　局限　　
..　手动升级代码　　
..　变量　　
..　汇总函数　　
..　简化的数学操作　　
..　其他事项　　
.　小结　　
第章　用TensorFlow构建前馈
神经网络　　
.　前馈神经网络介绍　　
..　前馈和反向传播　　
..　权重和偏差　　
..　传递函数　　
.　手写数字分类　　
.　探究MNIST数据集　　
.　softmax分类器　　
.　TensorFlow模型的保存和还原　　
..　保存模型　　
..　还原模型　　
..　softmax源代码　　
..　softmax启动器源代码　　
.　实现一个五层神经网络　　
..　可视化　　
..　五层神经网络源代码　　
.　ReLU分类器　　
.　可视化　　
.　dropout优化　　
.　可视化　　
.　小结　　
第章　TensorFlow与卷积神经网络　　
.　CNN简介　　
.　CNN架构　　
.　构建你的第一个CNN　　
.　CNN表情识别　　
..　表情分类器源代码　　
..　使用自己的图像测试模型　　
..　源代码　　
.　小结　　
第章　优化TensorFlow自编码器　　
.　自编码器简介　　
.　实现一个自编码器　　
.　增强自编码器的鲁棒性　　
.　构建去噪自编码器　　
.　卷积自编码器　　
..　编码器　　
..　解码器　　
..　卷积自编码器源代码　　
.　小结　　
第章　循环神经网络　　
.　RNN的基本概念　　
.　RNN的工作机制　　
.　RNN的展开　　
.　梯度消失问题　　
.　LSTM网络　　
.　RNN图像分类器　　
.　双向RNN　　
.　文本预测　　
..　数据集　　
..　困惑度　　
..　PTB模型　　
..　运行例程　　
.　小结　　
第章　GPU计算　　
.　GPGPU计算　　
.　GPGPU的历史　　
.　CUDA架构　　
.　GPU编程模型　　
.　TensorFlow中GPU的设置　　
.　TensorFlow的GPU管理　　
.　GPU内存管理　　
.　在多GPU系统上分配单个GPU　　
.　使用多个GPU　　
.　小结　　
第章　TensorFlow高级编程　　
.　Keras简介　　
.　构建深度学习模型　　
.　影评的情感分类　　
.　添加一个卷积层　　
.　Pretty Tensor　　
.　数字分类器　　
.　TFLearn　　
.　泰坦尼克号幸存者预测器　　
.　小结　　
第章　TensorFlow高级多媒体编程　　
.　多媒体分析简介　　
.　基于深度学习的大型对象检测　　
..　瓶颈层　　
..　使用重训练的模型　　
.　加速线性代数　　
..　TensorFlow的核心优势　　
..　加速线性代数的准时编译　　
.　TensorFlow和Keras　　
..　Keras简介　　
..　拥有Keras的好处　　
..　视频问答系统　　
.　Android上的深度学习　　
..　TensorFlow演示程序　　
..　Android入门　　
.　小结　　
第章　强化学习　　
.　强化学习基本概念　　
.　Q-learning算法　　
.　OpenAI Gym框架简介　　
.　FrozenLake-v实现问题　　
.　使用TensorFlow实现Q-learning　　
.　小结　　
・ ・ ・ ・ ・ ・ (收起)上篇 初见
第天 什么是深度学习 
. 星星之火，可以燎原 
. 师夷长技 
.. 谷歌与微软 
.. Facebook、亚马逊与NVIDIA 
. 中国崛起 
.. BAT在路上 
.. 星光闪耀 
.. 企业热是风向标 
. 练习题 
第天 深度学习的过往 
. 传统机器学习的局限性 
. 从表示学习到深度学习 
. 监督学习 
. 反向传播算法 
. 卷积神经网络 
. 深度学习反思 
. 练习题 
. 参考资料 
第天 深度学习工具汇总 
. Caffe 
. Torch & OverFeat 
. MxNet 
. TensorFlow 
. Theano 
. CNTK 
. 练习题 
. 参考资料 
第天 准备Caffe环境 
. Mac OS环境准备 
. Ubuntu环境准备 
. RHEL/Fedora/CentOS环境准备 
. Windows环境准备 
. 常见问题 
. 练习题 
. 参考资料 
第天 Caffe依赖包解析 
. ProtoBuffer 
. Boost 
. GFLAGS 
. GLOG 
. BLAS 
. HDF 
. OpenCV 
. LMDB和LEVELDB 
. Snappy 
. 小结 
. 练习题 
. 参考资料 
第天 运行手写体数字识别例程 
. MNIST数据集 
.. 下载MNIST数据集 
.. MNIST数据格式描述 
.. 转换格式 
. LeNet-模型 
.. LeNet-模型描述 
.. 训练超参数 
.. 训练日志 
.. 用训练好的模型对数据进行预测 
.. Windows下训练模型 
. 回顾 
. 练习题 
. 参考资料 
篇尾语 
中篇 热恋
第天 Caffe代码梳理 
. Caffe目录结构 
. 如何有效阅读Caffe源码 
. Caffe支持哪些深度学习特性 
.. 卷积层 
.. 全连接层 
.. 激活函数 
. 小结 
. 练习题 
. 参考资料 
第天 Caffe数据结构 
. Blob 
.. Blob基本用法 
.. 数据结构描述 
.. Blob是怎样炼成的 
. Layer 
.. 数据结构描述 
.. Layer是怎样建成的 
. Net 
.. Net基本用法 
.. 数据结构描述 
.. Net是怎样绘成的 
. 机制和策略 
. 练习题 
. 参考资料 
第天 Caffe I/O模块 
. 数据读取层 
.. 数据结构描述 
.. 数据读取层实现 
. 数据变换器 
.. 数据结构描述 
.. 数据变换器的实现 
. 练习题 
第天 Caffe模型 
. prototxt表示 
. 内存中的表示 
. 磁盘上的表示 
. Caffe Model Zoo 
. 练习题 
. 参考资料 
第天 Caffe前向传播计算 
. 前向传播的特点 
. 前向传播的实现 
.. DAG构造过程 
.. Net Forward实现 
. 练习题 
第天 Caffe反向传播计算 
. 反向传播的特点 
. 损失函数 
.. 算法描述 
.. 参数描述 
.. 源码分析 
. 反向传播的实现 
. 练习题 
第天 Caffe最优化求解过程 
. 求解器是什么 
. 求解器是如何实现的 
.. 算法描述 
.. 数据结构描述 
.. CNN训练过程 
.. CNN预测过程 
.. Solver的快照和恢复功能 
. 练习题 
第天 Caffe实用工具 
. 训练和预测 
. 特征提取 
. 转换图像格式 
. 计算图像均值 
. 自己编写工具 
. 练习题 
篇尾语 
下篇 升华
第天 Caffe计算加速 
. Caffe计时功能 
. Caffe GPU加速模式 
.. GPU是什么 
.. CUDA是什么 
.. GPU、CUDA和深度学习 
.. Caffe GPU环境准备 
.. 切换到Caffe GPU加速模式 
. Caffe cuDNN加速模式 
.. 获取cuDNN 
.. 切换到Caffe cuDNN加速模式 
.. Caffe不同硬件配置性能 
. 练习题 
. 参考资料 
第天 Caffe可视化方法 
. 数据可视化 
.. MNIST数据可视化 
.. CIFAR数据可视化 
.. ImageNet数据可视化 
. 模型可视化 
.. 网络结构可视化 
.. 网络权值可视化 
. 特征图可视化 
. 学习曲线 
. 小结 
. 练习题 
. 参考资料 
第天 Caffe迁移和部署 
. 从开发测试到生产部署 
. 使用Docker 
.. Docker基本概念 
.. Docker安装 
.. Docker入门 
.. Docker使用进阶 
. 练习题 
. 参考资料 
第天 关于ILSVRC不得不说的一些事儿 
. ImageNet数据集 
. ILSVRC比赛项目 
.. 图像分类（CLS） 
.. 目标定位（LOC） 
.. 目标检测（DET） 
.. 视频目标检测（VID） 
.. 场景分类 
. Caffe ILSVRC实践 
. 练习题 
. 参考资料 
第天 放之四海而皆准 
. 图像分类 
.. 问题描述 
.. 应用案例--商品分类 
. 图像中的字符识别 
.. 问题描述 
.. 应用案例--身份证实名认证 
. 目标检测 
.. 问题描述 
.. 最佳实践--运行R-CNN例程 
. 人脸识别 
.. 问题描述 
.. 最佳实践--使用Face++ SDK实现人脸检测 
. 自然语言处理 
.. 问题描述 
.. 最佳实践--NLP-Caffe 
. 艺术风格 
.. 问题描述 
.. 最佳实践--style-transfer 
. 小结 
. 练习题 
. 参考资料 
第天 继往开来的领路人 
. Caffe Traps and Pitfalls 
.. 不支持任意数据类型 
.. 不够灵活的高级接口 
.. 繁杂的依赖包 
.. 堪忧的卷积层实现 
.. 架构之殇 
.. 应用场景局限性 
. 最佳实践--Caffe 
. 练习题 
. 参考资料 
第天 新生 
. 三人行，必有我师 
. 路漫漫其修远兮，吾将上下而求索 
篇尾语 
结束语 
附录A 其他深度学习工具
・ ・ ・ ・ ・ ・ (收起)第  章 深度学习介绍 
. 人工智能 
. 数据挖掘、机器学习与深度学习
.. 数据挖掘 
.. 机器学习 
.. 深度学习 
. 学习资源与建议 
第  章 深度学习框架 
. 深度学习框架介绍 . 
. PyTorch 介绍. 
.. 什么是 PyTorch. 
.. 为何要使用 PyTorch 
. 配置 PyTorch 深度学习环境 
.. 操作系统的选择. 
.. Python 开发环境的安装 
.. PyTorch 的安装. 
第  章 多层全连接神经网络 
. 热身：PyTorch 基础 
.. Tensor（张量）. 
.. Variable（变量）
.. Dataset（数据集）
.. nn.Module（模组） 
.. torch.optim（优化） 
.. 模型的保存和加载 
. 线性模型 
.. 问题介绍 
.. 一维线性回归
.. 多维线性回归
.. 一维线性回归的代码实现. 
.. 多项式回归 
. 分类问题 
.. 问题介绍 
.. Logistic 起源 
.. Logistic 分布 
.. 二分类的 Logistic 回归 
.. 模型的参数估计. 
.. Logistic 回归的代码实现
. 简单的多层全连接前向网络 . 
.. 模拟神经元 
.. 单层神经网络的分类器 
.. 激活函数 
.. 神经网络的结构. 
.. 模型的表示能力与容量 
. 深度学习的基石：反向传播算法
.. 链式法则 
.. 反向传播算法
.. Sigmoid 函数举例
. 各种优化算法的变式
.. 梯度下降法 
.. 梯度下降法的变式 
. 处理数据和训练模型的技巧 . 
.. 数据预处理 
.. 权重初始化 
.. 防止过拟合 
. 多层全连接神经网络实现 MNIST 手写数字分类 
.. 简单的三层全连接神经网络
.. 添加激活函数
.. 添加批标准化
.. 训练网络 
第  章 卷积神经网络 
. 主要任务及起源 
. 卷积神经网络的原理和结构 . 
.. 卷积层
.. 池化层
.. 全连接层 
.. 卷积神经网络的基本形式. 
. PyTorch 卷积模块 . 
.. 卷积层
.. 池化层
.. 提取层结构 
.. 如何提取参数及自定义初始化 
. 卷积神经网络案例分析. 
.. LeNet. 
.. AlexNet
.. VGGNet 
.. GoogLeNet . 
.. ResNet
. 再实现 MNIST 手写数字分类 . 
. 图像增强的方法 
. 实现 cifar 分类 
第  章 循环神经网络 
. 循环神经网络
.. 问题介绍 
.. 循环神经网络的基本结构. 
.. 存在的问题 
. 循环神经网络的变式：LSTM 与 GRU 
.. LSTM. 
.. GRU. 
.. 收敛性问题 
. 循环神经网络的 PyTorch 实现 
.. PyTorch 的循环网络模块
.. 实例介绍 
. 自然语言处理的应用
.. 词嵌入
.. 词嵌入的 PyTorch 实现 
.. N Gram 模型 
.. 单词预测的 PyTorch 实现
.. 词性判断 
.. 词性判断的 PyTorch 实现
. 循环神经网络的更多应用
.. Many to one 
.. Many to Many（shorter）
.. Seqseq
.. CNN+RNN . 
第  章 生成对抗网络 
. 生成模型 
.. 自动编码器 
.. 变分自动编码器. 
. 生成对抗网络
.. 何为生成对抗网络 
.. 生成对抗网络的数学原理. 
. Improving GAN
.. Wasserstein GAN. 
.. Improving WGAN
. 应用介绍 
.. Conditional GAN. 
.. Cycle GAN . 
第  章 深度学习实战 
. 实例一――猫狗大战：运用预训练卷积神经网络进行特征提取与预测 . 
.. 背景介绍 
.. 原理分析 
.. 代码实现 
.. 总结. 
. 实例二――Deep Dream：探索卷积神经网络眼中的世界
.. 原理介绍 
.. 预备知识：backward . 
.. 代码实现 
.. 总结. 
. 实例三――Neural-Style：使用 PyTorch 进行风格迁移
.. 背景介绍 
.. 原理分析 
.. 代码实现 
.. 总结. 
. 实例四――Seqseq：通过 RNN 实现简单的 Neural Machine Translation . 
.. 背景介绍 
.. 原理分析 
.. 代码实现 
.. 总结. 
・ ・ ・ ・ ・ ・ (收起)第章　深度学习介绍　　
.　开始深度学习之旅　　
..　深度前馈网络　　
..　各种学习算法　　
.　深度学习的相关术语　　
.　深度学习――一场人工智能革命　　
.　深度学习网络的分类　　
..　深度生成或无监督模型　　
..　深度判别模型　　
.　小结　　
第章　大规模数据的分布式深度学习　　
.　海量数据的深度学习　　
.　大数据深度学习面临的挑战　　
..　海量数据带来的挑战（第一个V）　　
..　数据多样性带来的挑战（第二个V）　　
..　数据快速处理带来的挑战（第三个V）　　
..　数据真实性带来的挑战（第四个V）　　
.　分布式深度学习和Hadoop　　
..　Map-Reduce　　
..　迭代Map-Reduce　　
..　YARN　　
..　分布式深度学习设计的重要特征　　
.　深度学习的开源分布式框架Deeplearningj　　
..　Deeplearningj的主要特性　　
..　Deeplearningj功能总结　　
.　在Hadoop YARN上配置Deeplearningj　　
..　熟悉Deeplearningj　　
..　为进行分布式深度学习集成Hadoop YARN和Spark　　
..　Spark在Hadoop YARN上的内存分配规则　　
.　小结　　
第章　卷积神经网络　　
.　卷积是什么　　
.　卷积神经网络的背景　　
.　卷积神经网络的基本层　　
..　卷积神经网络深度的重要性　　
..　卷积层　　
..　为卷积层选择超参数　　
..　ReLU层　　
..　池化层　　
..　全连接层　　
.　分布式深度卷积神经网络　　
..　最受欢迎的深度神经网络及其配置　　
..　训练时间――深度神经网络面临的主要挑战　　
..　将Hadoop应用于深度卷积神经网络　　
.　使用Deeplearningj构建卷积层　　
..　加载数据　　
..　模型配置　　
..　训练与评估　　
.　小结　　
第章　循环神经网络　　
.　循环网络与众不同的原因　　
.　循环神经网络　　
..　展开循环计算　　
..　循环神经网络的记忆　　
..　架构　　
.　随时间反向传播　　
.　长短期记忆　　
..　随时间深度反向传播的问题　　
..　长短期记忆　　
.　双向循环神经网络　　
..　循环神经网络的不足　　
..　解决方案　　
.　分布式深度循环神经网络　　
.　用Deeplearningj训练循环神经网络　　
.　小结　　
第章　受限玻尔兹曼机　　
.　基于能量的模型　　
.　玻尔兹曼机　　
..　玻尔兹曼机如何学习　　
..　玻尔兹曼机的不足　　
.　受限玻尔兹曼机　　
..　基础架构　　
..　受限玻尔兹曼机的工作原理　　
.　卷积受限玻尔兹曼机　　
.　深度信念网络　　
.　分布式深度信念网络　　
..　受限玻尔兹曼机的分布式训练　　
..　深度信念网络的分布式训练　　
.　用Deeplearningj实现受限玻尔兹曼机和深度信念网络　　
..　受限玻尔兹曼机　　
..　深度信念网络　　
.　小结　　
第章　自动编码器　　
.　自动编码器　　
.　稀疏自动编码器　　
..　稀疏编码　　
..　稀疏自动编码器　　
.　深度自动编码器　　
..　训练深度自动编码器　　
..　使用Deeplearningj实现深度自动编码器　　
.　降噪自动编码器　　
..　降噪自动编码器的架构　　
..　堆叠式降噪自动编码器　　
..　使用Deeplearningj实现堆叠式降噪自动编码器　　
.　自动编码器的应用　　
.　小结　　
第章　用Hadoop玩转深度学习　　
.　Hadoop中的分布式视频解码　　
.　使用Hadoop进行大规模图像处理　　
.　使用Hadoop进行自然语言处理　　
..　Web爬虫　　
..　自然语言处理的关键词提取和模块　　
..　从页面评估相关关键词　　
.　小结　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)第 章绪论.
. 知识图谱简介
. 深度学习的优势和挑战
. 深度学习+ 知识图谱= .
.. 知识的表示学习
.. 知识的自动获取
.. 知识的计算应用
. 本书结构
. 本章总结
第一篇世界知识图谱
第 章世界知识的表示学习
. 章节引言
. 相关工作
.. 知识表示学习经典模型
.. 平移模型及其拓展模型
. 基于复杂关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系路径建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
vi j 知识图谱与深度学习
. 基于属性关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体描述信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合层次类型信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体图像信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的自动获取
. 章节引言
. 相关工作
.. 有监督的关系抽取模型
.. 远程监督的关系抽取模型.
. 基于选择性注意力机制的关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系层次注意力机制的关系抽取
.. 算法模型.
目录j vii
.. 实验分析.
.. 小结
. 基于选择性注意力机制的多语言关系抽取.
.. 算法模型.
.. 实验分析.
.. 小结
. 引入对抗训练的多语言关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于知识图谱与文本互注意力机制的知识获取.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的计算应用
. 章节引言
. 细粒度实体分类
.. 算法模型.
.. 实验分析.
.. 小结
. 实体对齐
.. 算法模型.
.. 实验分析.
.. 小结
. 融入知识的信息检索.
.. 算法模型.
.. 实验分析.
.. 小结
viii j 知识图谱与深度学习
. 本章总结
第二篇语言知识图谱
第 章语言知识的表示学习
. 章节引言
. 相关工作
.. 词表示学习
.. 词义消歧.
. 义原的表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于义原的词表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的自动获取
. 章节引言
. 相关工作
.. 知识图谱及其构建
.. 子词和字级NLP 
.. 词表示学习及跨语言的词表示学习
. 基于协同过滤和矩阵分解的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 融入中文字信息的义原预测
.. 算法模型.
目录j ix
.. 实验分析.
.. 小结
. 跨语言词汇的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的计算应用
. 章节引言
. 义原驱动的词典扩展.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 义原驱动的神经语言模型.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章总结与展望
. 本书总结
. 未来展望
.. 更全面的知识类型
.. 更复杂的知识结构
.. 更有效的知识获取
.. 更强大的知识指导
x j 知识图谱与深度学习
.. 更精深的知识推理
. 结束语
相关开源资源
参考文献
后记.
・ ・ ・ ・ ・ ・ (收起)第 章绪论.
. 知识图谱简介
. 深度学习的优势和挑战
. 深度学习+ 知识图谱= .
.. 知识的表示学习
.. 知识的自动获取
.. 知识的计算应用
. 本书结构
. 本章总结
第一篇世界知识图谱
第 章世界知识的表示学习
. 章节引言
. 相关工作
.. 知识表示学习经典模型
.. 平移模型及其拓展模型
. 基于复杂关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系路径建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
vi j 知识图谱与深度学习
. 基于属性关系建模的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体描述信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合层次类型信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 融合实体图像信息的知识表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的自动获取
. 章节引言
. 相关工作
.. 有监督的关系抽取模型
.. 远程监督的关系抽取模型.
. 基于选择性注意力机制的关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于关系层次注意力机制的关系抽取
.. 算法模型.
目录j vii
.. 实验分析.
.. 小结
. 基于选择性注意力机制的多语言关系抽取.
.. 算法模型.
.. 实验分析.
.. 小结
. 引入对抗训练的多语言关系抽取
.. 算法模型.
.. 实验分析.
.. 小结
. 基于知识图谱与文本互注意力机制的知识获取.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章世界知识的计算应用
. 章节引言
. 细粒度实体分类
.. 算法模型.
.. 实验分析.
.. 小结
. 实体对齐
.. 算法模型.
.. 实验分析.
.. 小结
. 融入知识的信息检索.
.. 算法模型.
.. 实验分析.
.. 小结
viii j 知识图谱与深度学习
. 本章总结
第二篇语言知识图谱
第 章语言知识的表示学习
. 章节引言
. 相关工作
.. 词表示学习
.. 词义消歧.
. 义原的表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 基于义原的词表示学习
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的自动获取
. 章节引言
. 相关工作
.. 知识图谱及其构建
.. 子词和字级NLP 
.. 词表示学习及跨语言的词表示学习
. 基于协同过滤和矩阵分解的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 融入中文字信息的义原预测
.. 算法模型.
目录j ix
.. 实验分析.
.. 小结
. 跨语言词汇的义原预测
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章语言知识的计算应用
. 章节引言
. 义原驱动的词典扩展.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 义原驱动的神经语言模型.
.. 相关工作.
.. 任务设定.
.. 算法模型.
.. 实验分析.
.. 小结
. 本章总结
第 章总结与展望
. 本书总结
. 未来展望
.. 更全面的知识类型
.. 更复杂的知识结构
.. 更有效的知识获取
.. 更强大的知识指导
x j 知识图谱与深度学习
.. 更精深的知识推理
. 结束语
相关开源资源
参考文献
后记.
・ ・ ・ ・ ・ ・ (收起)第 章什么是推荐系统
. 推荐系统的概念.
.. 推荐系统的基本概念
.. 深度学习与推荐系统
第 章深度神经网络.
. 什么是深度学习.
.. 深度学习的三次兴起
.. 深度学习的优势
. 神经网络基础
.. 神经元
.. 神经网络.
.. 反向传播.
.. 优化算法.
. 卷积网络基础
.. 卷积层
.. 池化层
.. 常见的网络结构
. 循环网络基础
.. 时序反向传播算法
.. 长短时记忆网络
. 生成对抗基础
.. 对抗博弈.
.. 理论推导.
.. 常见的生成对抗网络
iv j 推荐系统与深度学习
第 章TensorFlow 平台
. 什么是TensorFlow 
. TensorFlow 安装指南.
.. Windows 环境安装.
.. Linux 环境安装.
. TensorFlow 基础.
.. 数据流图.
.. 会话
.. 图可视化.
.. 变量
.. 占位符
.. 优化器
.. 一个简单的例子
. 其他深度学习平台
第 章推荐系统的基础算法
. 基于内容的推荐算法.
.. 基于内容的推荐算法基本流程
.. 基于内容推荐的特征提取.
. 基于协同的推荐算法.
.. 基于物品的协同算法
.. 基于用户的协同算法
.. 基于用户协同和基于物品协同的区别
.. 基于矩阵分解的推荐方法.
.. 基于稀疏自编码的推荐方法.
. 基于社交网络的推荐算法
.. 基于用户的推荐在社交网络中的应用
.. nodevec 技术在社交网络推荐中的应用
. 推荐系统的冷启动问题
.. 如何解决推荐系统冷启动问题
.. 深度学习技术在物品冷启动上的应用
目录j v
第 章混合推荐系统
. 什么是混合推荐系统.
.. 混合推荐系统的意义
.. 混合推荐系统的算法分类.
. 推荐系统特征处理方法
.. 特征处理方法
.. 特征选择方法
. 常见的预测模型
.. 基于逻辑回归的模型
.. 基于支持向量机的模型.
.. 基于梯度提升树的模型.
. 排序学习
.. 基于排序的指标来优化.
.. LR 算法的三种情形.
第 章基于深度学习的推荐模型
. 基于DNN 的推荐算法
. 基于DeepFM 的推荐算法
. 基于矩阵分解和图像特征的推荐算法
. 基于循环网络的推荐算法.
. 基于生成对抗网络的推荐算法.
.. IRGAN 的代码实现.
第 章推荐系统架构设计.
. 推荐系统基本模型
. 推荐系统常见架构
.. 基于离线训练的推荐系统架构设计
.. 面向深度学习的推荐系统架构设计
.. 基于在线训练的推荐系统架构设计
.. 面向内容的推荐系统架构设计
. 推荐系统常用组件
.. 数据上报常用组件
vi j 推荐系统与深度学习
.. 离线存储常用组件
.. 离线计算常用组件
.. 在线存储常用组件
.. 模型服务常用组件
.. 实时计算常用组件
. 推荐系统常见问题
.. 实时性.
.. 多样性.
.. 曝光打击和不良内容过滤.
.. 评估测试.
后记.
图. 淘宝猜你喜欢栏目
图. 百度指数.
图. 歌曲词嵌入模型空间向量.
图. 神经网络的三次兴起
图. 不同层数的神经网络拟合分界面的能力.
图. 不同层数的神经网络表示能力
图. 神经网络的基本结构
图. 感知器算法
图. 三层全连接神经网络
图. 动量对比.
图. 卷积运算.
图. 池化层
图. LeNet 卷积结构.
图. Alex-Net 卷积结构
图. RNN 
图. LSTM 在t 时刻的内部结构
图. GAN 网络
图. TensorFlow 安装截图
图. TensorBoard 计算
图. 腾讯视频APP 推荐页面.
图. 截取自当当网.
图. 截取自QQ 音乐APP.
图. 用户购买物品记录
图. 同时被购买次数矩阵C 
图. 相似度计算结果 
图. 相似度计算结果 
viii j 推荐系统与深度学习
图. 相似度计算结果 
图. 截取自当当网.
图. 物品的倒排索引
图. 用户评分矩阵.
图. Sigma 值
图. NewData 值
图. Mydata 值
图. 自编码神经网络模型
图. 稀疏自编码第一个网络.
图. 稀疏自编码第二个网络.
图. 稀疏自编码第三个网络.
图. 将三个网络组合起来
图. 社交网络关系图示例
图. 融入用户关系和物品关系
图. 社交网络关系图示例
图. 社交网络关系图示例
图. CBOW 和Skip-Gram 示例.
图. Skip-Gram 网络结构
图. CBOW 网络结构
图. word analogy 示例
图. 某网站登录页面
图. QQ 互联开放注册平台 
图. QQ 互联开放注册平台 
图. QQ 互联应用管理页面 
图. QQ 互联应用管理页面 
图. QQ 互联QQ 登录功能获取
图. QQ 音乐APP 中的偏好选择
图. (a) 为每部电影被打分的分布，(b) 为每个用户打分的分布
图. (a) 为每部电影平均分分布，(b) 为每个用户平均分分布.
图. 基于专家数据的CF 与基于用户数据CF 比较.
图目录j ix
图. 音乐频谱示例
图.  个流派的频谱图示例
图. CNN 音频分类结构.
图. CNN+LSTM 组合音频分类模型.
图. 分类预测结果的混淆矩阵
图. 模型倒数第二层 维向量降维可视化
图. 微软how-old.net 
图. SCUT-FBP 数据集示例图
图. 脸部截取后的数据集示例图.
图. CNN 层数过多，误差反而较大
图. 残差网络的基本结构
图. 残差网络完整结构.
图. NetFlix 的实时推荐系统的架构图
图. 整体式混合推荐系统
图. 并行式混合推荐系统
图. 流水线式混合推荐系统.
图. MDLP 特征离散化
图. ChiMerge 特征离散化.
图. 层次化时间按序列特征.
图. Learn to rank 的局限
图. Wide & Deep 模型结构
图. 推荐系统的召回和排序两个阶段
图. 召回模型结构.
图. 序列信息
图. 排序模型结构.
图. 不同NN 的效果
图. DeepFM 模型结构(网络左边为FM 层，右边为DNN 层).
图. FM 一阶部分
图. FM 二阶部分
图. FM/DNN/DeepFM 的比较
x j 推荐系统与深度学习
图. 电影静止帧图片举例
图. Alex-Net 卷积网络.
图. 左图：时间无关的推荐系统。右图：时间相关的推荐系统
图. 基于循环神经网络的推荐系统
图. 判别器
图. 生成器
图. IRGAN 说明
图. 监督学习基本模型.
图. 基于离线训练的推荐系统架构设计
图. 数据上报模块.
图. 离线训练模块.
图. 推荐系统中的存储分层.
图. 在线预测的几个阶段
图. 推荐系统通用性设计
图. 面向深度学习的推荐系统架构设计
图. 利用深度学习进行特征提取
图. 参数服务器架构
图. 基于在线训练的推荐系统架构设计
图. 在线学习之实时特征处理
图. 面向内容的推荐系统架构设计
图. 用于推荐的内容池.
图. Apache Kafka 逻辑架构.
表. 用户A 和B 的评分矩阵.
表. 电影内容特征二进制表示
表. 人脸魅力值打分不同模型的MAE 比较
表. 人脸魅力值打分不同模型的MAE 比较

表. Keras 预训练好的图像分类模型
・ ・ ・ ・ ・ ・ (收起) 概述
. 智能问答：让机器更好地服务于人 
. 问答系统类型介绍 
.. 基于事实的问答系统 
.. 基于常见问题集的问答系统 
.. 开放域的问答系统 
. 使用本书附带的源码程序 
.. 安装依赖软件 
.. 下载源码 
.. 执行示例程序 
.. 联系我们 
. 全书结构 
 机器学习基础
. 线性代数 
.. 标量、向量、矩阵和张量 
.. 矩阵运算 
.. 特殊类型的矩阵 
.. 线性相关 
.. 范数 
. 概率论基础 
.. 随机变量 
.. 期望和方差 
.. 伯努利分布 
.. 二项分布 
.. 泊松分布 
.. 正态分布 
.. 条件概率、联合概率和全概率 
.. 先验概率与后验概率 
.. 边缘概率 
.. 贝叶斯公式 
.. 最大似然估计算法 
.. 线性回归模型 
.. 逻辑斯蒂回归模型 
. 信息论基础 
.. 熵 
.. 联合熵和条件熵 
.. 相对熵与互信息 
.. 信道和信道容量 
.. 最大熵模型 
.. 信息论与机器学习 
. 统计学习 
.. 输入空间、特征空间与输出空间 
.. 向量表示 
.. 数据集 
.. 从概率到函数 
.. 统计学习三要素 
. 隐马尔可夫模型 
.. 随机过程和马尔可夫链 
.. 隐马尔可夫模型的定义 
.. 三个基本假设及适用场景 
.. 概率计算问题之直接计算 
.. 概率计算问题之前向算法 
.. 概率计算问题之后向算法 
.. 预测问题之维特比算法 
.. 学习问题之Baum-Welch 算法 
. 条件随机场模型 
.. 超越HMM 
.. 项目实践 
. 总结 
 自然语言处理基础
. 中文自动分词 
.. 有向无环图 
.. 最大匹配算法 
.. 算法评测 
.. 由字构词的方法 
. 词性标注 
.. 词性标注规范 
.. 隐马尔可夫模型词性标注 
. 命名实体识别 
. 上下文无关文法 
.. 原理介绍 
.. 算法浅析 
. 依存关系分析 
.. 算法浅析 
.. 项目实践 
.. 小结 
. 信息检索系统 
.. 什么是信息检索系统 
.. 衡量信息检索系统的关键指标 
.. 理解非结构化数据 
.. 倒排索引 
.. 处理查询 
.. 项目实践 
.. Elasticsearch 
.. 小结 
. 问答语料 
.. WikiQA 
.. 中文版保险行业语料库InsuranceQA 
. 总结 
 深度学习初步
. 深度学习简史 
.. 感知机 
.. 寒冬和复苏 
.. 走出实验室 
.. 寒冬再临 
.. 走向大规模实际应用 
. 基本架构 
.. 神经元 
.. 输入层、隐藏层和输出层 
.. 标准符号 
. 神经网络是如何学习的 
.. 梯度下降 
.. 反向传播理论 
.. 神经网络全连接层的实现 
.. 使用简单神经网络实现问答任务 
. 调整神经网络超参数 
.. 超参数 
.. 参考建议 
. 卷积神经网络与池化 
.. 简介 
.. 卷积层的前向传播 
.. 池化层的前向传播 
.. 卷积层的实现 
.. 池化层的实现 
.. 使用卷积神经网络实现问答任务 
. 循环神经网络及其变种 
.. 简介 
.. 循环神经网络 
.. 长短期记忆单元和门控循环单元 
.. 循环神经网络的实现 
.. 使用循环神经网络实现问答任务 
. 简易神经网络工具包 
 词向量实现及应用
. 语言模型 
.. 评测 
.. ARPA 格式介绍 
.. 项目实践 
. One-hot 表示法 
. 词袋模型 
. NNLM 和RNNLM 
. wordvec 
.. C-BOW 的原理 
.. Skip-gram 的原理 
.. 计算效率优化 
.. 项目实践 
. GloVe 
.. GloVe 的原理 
.. GloVe 与wordvec 的区别和联系 
.. 项目实践 
. fastText 
.. fastText 的原理 
.. fastText 与wordvec 的区别和联系 
.. 项目实践 
. 中文近义词工具包 
.. 安装 
.. 接口 
. 总结 
 社区问答中的QA 匹配
. 社区问答任务简介 
. 孪生网络模型 
. QACNN 模型 
.. 模型构建 
.. 实验结果 
. Decomposable Attention 模型 
.. 模型介绍 
.. 模型构建 
. 多比较方式的比较C集成模型 
.. 模型介绍 
.. 模型构建 
. BiMPM 模型 
.. 模型介绍 
.. 模型构建 
 机器阅读理解
. 完型填空型机器阅读理解任务 
.. CNN/Daily Mail 数据集 
.. Children’s Book Test（CBT）数据集 
.. GA Reader 模型 
.. SA Reader 模型 
.. AoA Reader 模型 
. 答案抽取型机器阅读理解任务 
.. SQuAD 数据集 
.. MS MARCO 数据集 
.. TriviaQA 数据集 
.. DuReader 数据集 
.. BiDAF 模型 
.. R-Net 模型 
.. S-Net 模型 
. 答案选择型机器阅读理解任务 
. 展望 
参考文献
・ ・ ・ ・ ・ ・ (收起)第  章引言 
．　本书面向的读者　
．　深度学习的历史趋势　
．．　神经网络的众多名称和命运变迁　
．．　与日俱增的数据量　
．．　与日俱增的模型规模　
．．　与日俱增的精度、复杂度和对现实世界的冲击　
第　 部分应用数学与机器学习基础
第　 章线性代数　
．　标量、向量、矩阵和张量　
．　矩阵和向量相乘　
．　单位矩阵和逆矩阵　
．　线性相关和生成子空间　
．　范数　
．　特殊类型的矩阵和向量　
．　特征分解　
．　奇异值分解　
．　Moore-Penrose 伪逆　
．　迹运算　
．　行列式　
．　实例：主成分分析　
第　章概率与信息论　
．　为什么要使用概率　
．　随机变量　
．　概率分布　
．．　离散型变量和概率质量函数　
．．　连续型变量和概率密度函数　
．　边缘概率　
．　条件概率　
．　条件概率的链式法则　
．　独立性和条件独立性　
．　期望、方差和协方差　
．　常用概率分布　
．．　Bernoulli 分布　
．．　Multinoulli 分布　
．．　高斯分布　
．．　指数分布和Laplace 分布　
．．　Dirac 分布和经验分布　
．．　分布的混合　
．　常用函数的有用性质　
．　贝叶斯规则　
．　连续型变量的技术细节　
．　信息论　
．　结构化概率模型　
第　章数值计算　
．　上溢和下溢　
．　病态条件　
．　基于梯度的优化方法　
．　约束优化　
．　实例：线性最小二乘　
第　章机器学习基础　
．　学习算法　
．．　任务T　
．．　性能度量P　
．．　经验E　
．．　示例：线性回归　
．　容量、过拟合和欠拟合　
．．　没有免费午餐定理　
．．　正则化　
．　超参数和验证集　
．　估计、偏差和方差　
．．　点估计　
．．　偏差　
．．　方差和标准差　
．．　权衡偏差和方差以最小化均方误差　
．．　一致性　
．　最大似然估计　
．．　条件对数似然和均方误差　
．．　最大似然的性质　
．　贝叶斯统计　
．　监督学习算法　
．．　概率监督学习　
．．　支持向量机　
．．　其他简单的监督学习算法　
．　无监督学习算法　
．．　主成分分析　
．．　k- 均值聚类　
．　随机梯度下降　
．　构建机器学习算法　
．　促使深度学习发展的挑战　
．．　维数灾难　
．．　局部不变性和平滑正则化　
．．　流形学习　
第　 部分深度网络：现代实践
第　章深度前馈网络　
．　实例：学习XOR　
．　基于梯度的学习　
．．　代价函数　
．．　输出单元　
．　隐藏单元　
．．　整流线性单元及其扩展　
．．　logistic sigmoid 与双曲正切函数　
．．　其他隐藏单元　
．　架构设计　
．．　万能近似性质和深度　
．．　其他架构上的考虑　
．　反向传播和其他的微分算法　
．．　计算图　
．．　微积分中的链式法则　
．．　递归地使用链式法则来实现反向传播　
．．　全连接MLP 中的反向传播计算　
．．　符号到符号的导数　
．．　一般化的反向传播　
．．　实例：用于MLP 训练的反向传播　
．．　复杂化　
．．　深度学习界以外的微分　
．．　高阶微分　
．　历史小记　
第　章深度学习中的正则化　
．　参数范数惩罚　
．．　L 参数正则化　
．．　L 正则化　
．　作为约束的范数惩罚　
．　正则化和欠约束问题　
．　数据集增强　
．　噪声鲁棒性　
．　半监督学习　
．　多任务学习　
．　提前终止　
．　参数绑定和参数共享　
．　稀疏表示　
．　Bagging 和其他集成方法　
．　Dropout　
．　对抗训练　
．　切面距离、正切传播和流形正切分类器　
第　章深度模型中的优化　
．　学习和纯优化有什么不同　
．．　经验风险最小化　
．．　代理损失函数和提前终止　
．．　批量算法和小批量算法　
．　神经网络优化中的挑战　
．．　病态　
．．　局部极小值　
．．　高原、鞍点和其他平坦区域　
．．　悬崖和梯度爆炸　
．．　长期依赖　
．．　非精确梯度　
．．　局部和全局结构间的弱对应　
．．　优化的理论限制　
．　基本算法　
．．　随机梯度下降　
．．　动量　
．．　Nesterov 动量　
．　参数初始化策略　
．　自适应学习率算法　
．．　AdaGrad　
．．　RMSProp　
．．　Adam　
．．　选择正确的优化算法　
．　二阶近似方法　
．．　牛顿法　
．．　共轭梯度　
．．　BFGS　
．　优化策略和元算法　
．．　批标准化　
．．　坐标下降　
．．　Polyak 平均　
．．　监督预训练　
．．　设计有助于优化的模型　
．．　延拓法和课程学习　
第　章卷积网络　
．　卷积运算　
．　动机　
．　池化　
．　卷积与池化作为一种无限强的先验　
．　基本卷积函数的变体　
．　结构化输出　
．　数据类型　
．　高效的卷积算法　
．　随机或无监督的特征　
．　卷积网络的神经科学基础　
．　卷积网络与深度学习的历史　
第　 章序列建模：循环和递归网络　
．　展开计算图　
．　循环神经网络　
．．　导师驱动过程和输出循环网络　
．．　计算循环神经网络的梯度　
．．　作为有向图模型的循环网络　
．．　基于上下文的RNN 序列建模　
．　双向RNN　
．　基于编码{解码的序列到序列架构　
．　深度循环网络　
．　递归神经网络　
．　长期依赖的挑战　
．　回声状态网络　
．　渗漏单元和其他多时间尺度的策略　
．．　时间维度的跳跃连接　
．．　渗漏单元和一系列不同时间尺度　
．．　删除连接　
．　长短期记忆和其他门控RNN　
．．　LSTM　
．．　其他门控RNN　
．　优化长期依赖　
．．　截断梯度　
．．　引导信息流的正则化　
．　外显记忆　
第　 章实践方法论　
．　性能度量　
．　默认的基准模型　
．　决定是否收集更多数据　
．　选择超参数　
．．　手动调整超参数　
．．　自动超参数优化算法　
．．　网格搜索　
．．　随机搜索　
．．　基于模型的超参数优化　
．　调试策略　
．　示例：多位数字识别　
第　 章应用　
．　大规模深度学习　
．．　快速的CPU 实现　
．．　GPU 实现　
．．　大规模的分布式实现　
．．　模型压缩　
．．　动态结构　
．．　深度网络的专用硬件实现　
．　计算机视觉　
．．　预处理　
．．　数据集增强　
．　语音识别　
．　自然语言处理　
．．　n-gram　
．．　神经语言模型　
．．　高维输出　
．．　结合n-gram 和神经语言模型　
．．　神经机器翻译　
．．　历史展望　
．　其他应用　
．．　推荐系统　
．．　知识表示、推理和回答　
第　部分深度学习研究
第　 章线性因子模型　
．　概率PCA 和因子分析　
．　独立成分分析　
．　慢特征分析　
．　稀疏编码　
．　PCA 的流形解释　
第　 章自编码器　
．　欠完备自编码器　
．　正则自编码器　
．．　稀疏自编码器　
．．　去噪自编码器　
．．　惩罚导数作为正则　
．　表示能力、层的大小和深度　
．　随机编码器和解码器　
．　去噪自编码器详解　
．．　得分估计　
．．　历史展望　
．　使用自编码器学习流形　
．　收缩自编码器　
．　预测稀疏分解　
．　自编码器的应用　
第　 章表示学习　
．　贪心逐层无监督预训练　
．　迁移学习和领域自适应　
．　半监督解释因果关系　
．　分布式表示　
．　得益于深度的指数增益　
．　提供发现潜在原因的线索　
第　 章深度学习中的结构化概率模型　
．　非结构化建模的挑战　
．　使用图描述模型结构　
．．　有向模型　
．．　无向模型　
．．　配分函数　
．．　基于能量的模型　
．．　分离和d-分离　
．．　在有向模型和无向模型中转换　
．．　因子图　
．　从图模型中采样　
．　结构化建模的优势　
．　学习依赖关系　
．　推断和近似推断　
．　结构化概率模型的深度学习方法 第  章蒙特卡罗方法　
．　采样和蒙特卡罗方法　
．．　为什么需要采样　
．．　蒙特卡罗采样的基础　
．　重要采样　
．　马尔可夫链蒙特卡罗方法　
．　Gibbs 采样　
．　不同的峰值之间的混合挑战　
．．　不同峰值之间通过回火来混合　
．．　深度也许会有助于混合　
第　 章直面配分函数　
．　对数似然梯度　
．　随机最大似然和对比散度　
．　伪似然　
．　得分匹配和比率匹配　
．　去噪得分匹配　
．　噪声对比估计　
．　估计配分函数　
．．　退火重要采样　
．．　桥式采样　
第　 章近似推断　
．　把推断视作优化问题　
．　期望最大化　
．　最大后验推断和稀疏编码　
．　变分推断和变分学习　
．．　离散型潜变量　
．．　变分法　
．．　连续型潜变量　
．．　学习和推断之间的相互作用　
．　学成近似推断　
．．　醒眠算法　
．．　学成推断的其他形式　
第　 章深度生成模型　
．　玻尔兹曼机　
．　受限玻尔兹曼机　
．．　条件分布　
．．　训练受限玻尔兹曼机　
．　深度信念网络　
．　深度玻尔兹曼机　
．．　有趣的性质　
．．　DBM 均匀场推断　
．．　DBM 的参数学习　
．．　逐层预训练　
．．　联合训练深度玻尔兹曼机　
．　实值数据上的玻尔兹曼机　
．．　Gaussian-Bernoulli RBM　
．．　条件协方差的无向模型　
．　卷积玻尔兹曼机　
．　用于结构化或序列输出的玻尔兹曼机　
．　其他玻尔兹曼机　
．　通过随机操作的反向传播　
．　有向生成网络　
．．　sigmoid 信念网络　
．．　可微生成器网络　
．．　变分自编码器　
．．　生成式对抗网络　
．．　生成矩匹配网络　
．．　卷积生成网络　
．．　自回归网络　
．．　线性自回归网络　
．．　神经自回归网络　
．．　NADE　
．　从自编码器采样　
．．　与任意去噪自编码器相关的马尔可夫链 ．　
．．　夹合与条件采样　
．．　回退训练过程　
．　生成随机网络　
．　其他生成方案　
．　评估生成模型　
．　结论　
参考文献　
索引　
・ ・ ・ ・ ・ ・ (收起)目 录
第章 深度学习的发展介绍 
. 如何阅读本书 
. 深度学习沉浮史 
.. 模拟生物大脑的疯狂远古时代 
.. 联结主义近代 
.. 百花齐放，层次结构主导，模型巨大的当代 
. Python简易教程 
.. Anaconda搭建 
.. IPython Notebook使用 
.. Python基本用法 
.. NumPy 
.. Matplotlib 
. 参考文献 
第章 机器学习快速入门 
. 学习算法 
.. 学习任务 
.. 性能度量 
.. 学习经验 
. 代价函数 
.. 均方误差函数 
.. 极大似然估计 
. 梯度下降法 
.. 批量梯度下降法 
.. 随机梯度下降法 
. 过拟合与欠拟合 
.. 没免费午餐理论 
.. 正则化 
. 超参数与验证集 
. Softmax编码实战 
.. 编码说明 
.. 熟练使用CIFAR- 数据集 
.. 显式循环计算损失函数及其梯度 
.. 向量化表达式计算损失函数及其梯度 
.. 最小批量梯度下降算法训练Softmax分类器 
.. 使用验证数据选择超参数 
. 参考代码 
. 参考文献 
第章 前馈神经网络 
. 神经元 
.. Sigmoid神经元 
.. Tanh神经元 
.. ReLU神经元 
. 前馈神经网络 
.. 输出层单元 
.. 隐藏层单元 
.. 网络结构设计 
. BP算法 
. 深度学习编码实战上 
.. 实现仿射传播 
.. 实现ReLU传播 
.. 组合单层神经元 
.. 实现浅层神经网络 
.. 实现深层全连接网络 
. 参考代码 
. 参考文献 
第章 深度学习正则化 
. 参数范数惩罚 
.. L参数正则化 
.. L正则化 
. 参数绑定与参数共享 
. 噪声注入与数据扩充 
. 稀疏表征 
. 早停 
. Dropout 
.. 个体与集成 
.. Dropout 
. 深度学习编码实战中 
.. Dropout传播 
.. 组合Dropout传播层 
.. Dropout神经网络 
.. 解耦训练器trainer 
.. 解耦更新器updater 
.. 正则化实验 
. 参考代码 
. 参考文献 
第章 深度学习优化 
. 神经网络优化困难 
.. 局部最优 
.. 鞍点 
.. 梯度悬崖 
.. 梯度消失或梯度爆炸 
.. 梯度不精确 
.. 优化理论的局限性 
. 随机梯度下降 
. 动量学习法 
. AdaGrad和RMSProp 
. Adam 
. 参数初始化策略 
. 批量归一化 
.. BN算法详解 
.. BN传播详解 
. 深度学习编码实战下 
.. Momentum 
.. RMSProp 
.. Adam 
.. 更新规则比较 
.. BN前向传播 
.. BN反向传播 
.. 使用BN的全连接网络 
.. BN算法与权重标准差比较 
. 参考代码 
. 参考文献 
第章 卷积神经网络 
. 卷积操作 
. 卷积的意义 
.. 稀疏连接 
.. 参数共享 
. 池化操作 
. 设计卷积神经网络 
.. 跨步卷积 
.. 零填充 
.. 非共享卷积 
.. 平铺卷积 
. 卷积网络编码练习 
.. 卷积前向传播 
.. 卷积反向传播 
.. 最大池化前向传播 
.. 最大池化反向传播 
.. 向量化执行 
.. 组合完整卷积层 
.. 浅层卷积网络 
.. 空间批量归一化 
. 参考代码 
. 参考文献 
第章 循环神经网络 
. 循环神经网络 
.. 循环神经元展开 
.. 循环网络训练 
. 循环神经网络设计 
.. 双向循环网络结构 
.. 编码-解码网络结构 
.. 深度循环网络结构 
. 门控循环神经网络 
.. LSTM 
.. 门控循环单元 
. RNN编程练习 
.. RNN单步传播 
.. RNN时序传播 
.. 词嵌入 
.. RNN输出层 
.. 时序Softmax损失 
.. RNN图片说明任务 
. LSTM编程练习 
.. LSTM单步传播 
.. LSTM时序传播 
.. LSTM实现图片说明任务 
. 参考代码 
.. RNN参考代码 
.. LSTM参考代码 
. 参考文献 
第章 TensorFlow快速入门 
. TensorFlow介绍 
. TensorFlow .安装指南 
.. 双版本切换Anaconda 
.. 安装CUDA . 
.. 安装cuDNN 
.. 安装TensorFlow 
.. 验证安装 
. TensorFlow基础 
.. Tensor 
.. TensorFlow核心API教程 
.. tf.train API 
.. tf.contrib.learn 
. TensorFlow构造CNN 
.. 构建Softmax模型 
.. 使用TensorFlow训练模型 
.. 使用TensorFlow评估模型 
.. 使用TensorFlow构建卷积神经网络 
. TensorBoard快速入门 
.. TensorBoard可视化学习 
.. 计算图可视化 
・ ・ ・ ・ ・ ・ (收起)译者序 iv
序 vii
前言 ix
术语缩写 xxii
符号 xxvii
第  章 简介 
. 自动语音识别：更好的沟通之桥 . . . . . . . . . . . . . . . . . . . . . . . 
.. 人类之间的交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 人机交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 语音识别系统的基本结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 全书结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 第一部分：传统声学模型 . . . . . . . . . . . . . . . . . . . . . . 
.. 第二部分：深度神经网络 . . . . . . . . . . . . . . . . . . . . . . 
.. 第三部分：语音识别中的 DNN-HMM 混合系统 . . . . . . . . . . 
.. 第四部分：深度神经网络中的表征学习 . . . . . . . . . . . . . . 
.. 第五部分：高级的深度模型 . . . . . . . . . . . . . . . . . . . . . 
第一部分 传统声学模型 
第  章 混合高斯模型 
. 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 高斯分布和混合高斯随机变量 . . . . . . . . . . . . . . . . . . . . . . . . 
. 参数估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 采用混合高斯分布对语音特征建模 . . . . . . . . . . . . . . . . . . . . . 
第  章 隐马尔可夫模型及其变体 
. 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 序列与模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 隐马尔可夫模型的性质 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 隐马尔可夫模型的仿真 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 隐马尔可夫模型似然度的计算 . . . . . . . . . . . . . . . . . . . . 
.. 计算似然度的高效算法 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 前向与后向递归式的证明 . . . . . . . . . . . . . . . . . . . . . . 
. 期望最大化算法及其在学习 HMM 参数中的应用 . . . . . . . . . . . . . 
.. 期望最大化算法介绍 . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 使用 EM 算法来学习 HMM 参数――Baum-Welch 算法 . . . . . . 
. 用于解码 HMM 状态序列的维特比算法 . . . . . . . . . . . . . . . . . . . 
.. 动态规划和维特比算法 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 用于解码 HMM 状态的动态规划算法 . . . . . . . . . . . . . . . . 
. 隐马尔可夫模型和生成语音识别模型的变体 . . . . . . . . . . . . . . . . 
.. 用于语音识别的 GMM-HMM 模型 . . . . . . . . . . . . . . . . . 
.. 基于轨迹和隐藏动态模型的语音建模和识别 . . . . . . . . . . . . 
.. 使用生成模型 HMM 及其变体解决语音识别问题 . . . . . . . . . 
第二部分 深度神经网络 
第  章 深度神经网络 
. 深度神经网络框架 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 使用误差反向传播来进行参数训练 . . . . . . . . . . . . . . . . . . . . . 
.. 训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 实际应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 模型初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 权重衰减 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 丢弃法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 批量块大小的选择 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 取样随机化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 惯性系数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学习率和停止准则 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 网络结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 可复现性与可重启性 . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 高级模型初始化技术 
. 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 受限玻尔兹曼机的属性 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 受限玻尔兹曼机参数学习 . . . . . . . . . . . . . . . . . . . . . . 
. 深度置信网络预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 降噪自动编码器预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 鉴别性预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 混合预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 采用丢弃法的预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第三部分 语音识别中的深度神经网络C隐马尔可夫混合模型 
第  章 深度神经网络C隐马尔可夫模型混合系统 
. DNN-HMM 混合系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 用 CD-DNN-HMM 解码 . . . . . . . . . . . . . . . . . . . . . . . . 
.. CD-DNN-HMM 训练过程 . . . . . . . . . . . . . . . . . . . . . . . 
.. 上下文窗口的影响 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. CD-DNN-HMM 的关键模块及分析 . . . . . . . . . . . . . . . . . . . . . 
.. 进行比较和分析的数据集和实验 . . . . . . . . . . . . . . . . . . 
.. 对单音素或者三音素的状态进行建模 . . . . . . . . . . . . . . . . 
.. 越深越好 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 利用相邻的语音帧 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练数据的标注质量的影响 . . . . . . . . . . . . . . . . . . . . . 
.. 调整转移概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基于 KL 距离的隐马尔可夫模型 . . . . . . . . . . . . . . . . . . . . . . . 
第  章 训练和解码的加速 
. 训练加速 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 使用多 GPU 流水线反向传播 . . . . . . . . . . . . . . . . . . . . 
.. 异步随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 增广拉格朗日算法及乘子方向交替算法 . . . . . . . . . . . . . . 
.. 减小模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 加速解码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 并行计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 稀疏网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 低秩近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 用大尺寸 DNN 训练小尺寸 DNN . . . . . . . . . . . . . . . . . . 
.. 多帧 DNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度神经网络序列鉴别性训练 
. 序列鉴别性训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最大相互信息 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 增强型 MMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最小音素错误/状态级最小贝叶斯风险 . . . . . . . . . . . . . . . 
.. 统一的公式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 具体实现中的考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 词图产生 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 词图补偿 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 帧平滑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 学习率调整 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 训练准则选择 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 其他考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 将概率密度估计问题转换为二分类设计问题 . . . . . . . . . . . . 
.. 拓展到未归一化的模型 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 在深度学习网络训练中应用噪声对比估计算法 . . . . . . . . . . 
第四部分 深度神经网络中的特征表示学习 
第  章 深度神经网络中的特征表示学习 
. 特征和分类器的联合学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 特征层级 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 使用随意输入特征的灵活性 . . . . . . . . . . . . . . . . . . . . . . . . . 
. 特征的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对说话人变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对环境变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 
. 对环境的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对噪声的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 对语速变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 
. 缺乏严重信号失真情况下的推广能力 . . . . . . . . . . . . . . . . . . . . 
第  章 深度神经网络和混合高斯模型的融合 
. 在 GMM-HMM 系统中使用由 DNN 衍生的特征 . . . . . . . . . . . . . . 
.. 使用 Tandem 和瓶颈特征的 GMM-HMM 模型 . . . . . . . . . . . 
.. DNN-HMM 混合系统与采用深度特征的 GMM-HMM 系统的比较 
. 识别结果融合技术 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 识别错误票选降低技术（ ROVER） . . . . . . . . . . . . . . . . . 
.. 分段条件随机场（ SCARF） . . . . . . . . . . . . . . . . . . . . . 
.. 最小贝叶斯风险词图融合 . . . . . . . . . . . . . . . . . . . . . . 
. 帧级别的声学分数融合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 多流语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 深度神经网络的自适应技术 
. 深度神经网络中的自适应问题 . . . . . . . . . . . . . . . . . . . . . . . . 
. 线性变换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 线性输入网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 线性输出网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 线性隐层网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 保守训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. L  正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. KL 距离正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 减少每个说话人的模型开销 . . . . . . . . . . . . . . . . . . . . . 
. 子空间方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 通过主成分分析构建子空间 . . . . . . . . . . . . . . . . . . . . . 
.. 噪声感知、说话人感知及设备感知训练 . . . . . . . . . . . . . . 
.. 张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. DNN 说话人自适应的效果 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于 KL 距离的正则化方法 . . . . . . . . . . . . . . . . . . . . . 
.. 说话人感知训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第五部分 先进的深度学习模型 
第  章 深度神经网络中的表征共享和迁移 
. 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 多语言和跨语言语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 基于 Tandem 或瓶颈特征的跨语言语音识别 . . . . . . . . . . . . 
.. 共享隐层的多语言深度神经网络 . . . . . . . . . . . . . . . . . . 
.. 跨语言模型迁移 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 语音识别中深度神经网络的多目标学习 . . . . . . . . . . . . . . . . . . . 
.. 使用多任务学习的鲁棒语音识别 . . . . . . . . . . . . . . . . . . 
.. 使用多任务学习改善音素识别 . . . . . . . . . . . . . . . . . . . . 
.. 同时识别音素和字素（ graphemes） . . . . . . . . . . . . . . . . . 
. 使用视听信息的鲁棒语音识别 . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 循环神经网络及相关模型 
. 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 基本循环神经网络中的状态-空间公式 . . . . . . . . . . . . . . . . . . . . 
. 沿时反向传播学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 最小化目标函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 误差项的递归计算 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 循环神经网络权重的更新 . . . . . . . . . . . . . . . . . . . . . . 
. 一种用于学习循环神经网络的原始对偶技术 . . . . . . . . . . . . . . . . 
.. 循环神经网络学习的难点 . . . . . . . . . . . . . . . . . . . . . . 
.. 回声状态（ Echo-State）性质及其充分条件 . . . . . . . . . . . . . 
.. 将循环神经网络的学习转化为带约束的优化问题 . . . . . . . . . 
.. 一种用于学习 RNN 的原始对偶方法 . . . . . . . . . . . . . . . . 
. 结合长短时记忆单元（ LSTM）的循环神经网络 . . . . . . . . . . . . . . 
.. 动机与应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 长短时记忆单元的神经元架构 . . . . . . . . . . . . . . . . . . . . 
.. LSTM-RNN 的训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 循环神经网络的对比分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 信息流方向的对比：自上而下还是自下而上 . . . . . . . . . . . . 
.. 信息表征的对比：集中式还是分布式 . . . . . . . . . . . . . . . . 
.. 解释能力的对比：隐含层推断还是端到端学习 . . . . . . . . . . 
.. 参数化方式的对比：吝啬参数集合还是大规模参数矩阵 . . . . . 
.. 模型学习方法的对比：变分推理还是梯度下降 . . . . . . . . . . 
.. 识别正确率的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 讨论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
第  章 计算型网络 
. 计算型网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 前向计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 模型训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 典型的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 无操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 含一个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 
.. 含两个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 
.. 用来计算统计量的计算节点类型 . . . . . . . . . . . . . . . . . . 
. 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 循环连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 只在循环中一个接一个地处理样本 . . . . . . . . . . . . . . . . . 
.. 同时处理多个句子 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 创建任意的循环神经网络 . . . . . . . . . . . . . . . . . . . . . . 
第  章 总结及未来研究方向 
. 路线图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 语音识别中的深度神经网络启蒙 . . . . . . . . . . . . . . . . . . 
.. 深度神经网络训练和解码加速 . . . . . . . . . . . . . . . . . . . . 
.. 序列鉴别性训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 特征处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 循环神经网络和长短时记忆神经网络 . . . . . . . . . . . . . . . . 
.. 其他深度模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. 技术前沿和未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 技术前沿简析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. 未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
参考文献 
・ ・ ・ ・ ・ ・ (收起)目录
前言
第章　工具与技术
. 神经网络的类型
. 数据获取
. 数据预处理
第章　摆脱困境
. 确定我们遇到的问题
. 解决运行过程中的错误
. 检查中间结果
. 为最后一层选择正确的激活函数
. 正则化和Dropout
. 网络结构、批尺寸和学习率
第章　使用词嵌入计算文本相似性
. 使用预训练的词嵌入发现词的相似性
. Wordvec数学特性
. 可视化词嵌入
. 在词嵌入中发现实体类
. 计算类内部的语义距离
. 在地图上可视化国家数据
第章　基于维基百科外部链接构建推荐系统
. 收集数据
. 训练电影嵌入
. 构建电影推荐系统
. 预测简单的电影属性
第章　按照示例文本的风格生成文本
. 获取公开领域书籍文本
. 生成类似莎士比亚的文本
. 使用RNN编写代码
. 控制输出温度
. 可视化循环神经网络的活跃程度
第章　问题匹配
. 从Stack Exchange网站获取数据
. 使用Pandas探索数据
. 使用Keras对文本进行特征化
. 构建问答模型
. 用Pandas训练模型
. 检查相似性
第章　推荐表情符号
. 构建一个简单的情感分类器
. 检验一个简单的分类器
. 使用卷积网络进行情感分析
. 收集Twitter数据
. 一个简单的表情符号预测器
. Dropout和多层窗口
. 构建单词级模型
. 构建你自己的嵌入
. 使用循环神经网络进行分类
. 可视化一致性/不一致性
. 组合模型
第章　Sequence-to-Sequence映射
. 训练一个简单的Sequence-to-Sequence模型
. 从文本中提取对话
. 处理开放词汇表
. 训练seqseq 聊天机器人
第章　复用预训练的图像识别网络
. 加载预训练网络
. 图像预处理
. 推测图像内容
. 使用Flickr API收集一组带标签的图像
. 构建一个分辨猫狗的分类器
. 改进搜索结果
. 复训图像识别网络
第章　构建反向图像搜索服务
. 从维基百科中获取图像
. 向N维空间投影图像
. 在高维空间中寻找最近邻
. 探索嵌入中的局部邻域
第章　检测多幅图像
. 使用预训练的分类器检测多个图像
. 使用Faster RCNN进行目标检测
. 在自己的图像上运行Faster RCNN
第章　图像风格
. 可视化卷积神经网络激活值
. 尺度和缩放
. 可视化神经网络所见
. 捕捉图像风格
. 改进损失函数以提升图像相干性
. 将风格迁移至不同图像
. 风格内插
第章　用自编码器生成图像
. 从Google Quick Draw中导入绘图
. 为图像创建自编码器
. 可视化自编码器结果
. 从正确的分布中采样图像
. 可视化变分自编码器空间
. 条件变分编码器
第章　使用深度网络生成图标
. 获得训练用的图标
. 将图标转换为张量表示
. 使用变分自编码器生成图标
. 使用数据扩充提升自编码器的性能
. 构建生成式对抗网络
. 训练生成式对抗网络
. 显示GAN生成的图标
. 将图标编码成绘图指令
. 训练RNN绘制图标
. 使用RNN生成图标
第章　音乐与深度学习
. 为音乐分类器创建训练数据集
. 训练音乐风格检测器
. 对混淆情况进行可视化
. 为已有的音乐编制索引
. 设置Spotify API
. 从Spotify中收集播放列表和歌曲
. 训练音乐推荐系统
. 使用Wordvec模型推荐歌曲
第章　生产化部署机器学习系统
. 使用scikit-learn最近邻计算嵌入
. 使用Postgres存储嵌入
. 填充和查询Postgres存储的嵌入
. 在Postgres中存储高维模型
. 使用Python编写微服务
. 使用微服务部署Keras模型
. 从Web框架中调用微服务
. Tensorflow seqseq模型
. 在浏览器中执行深度学习模型
. 使用TensorFlow服务执行Keras模型
. 在iOS中使用Keras模型
・ ・ ・ ・ ・ ・ (收起)第章 绪论 
. 引言 
. 本书内容 
.. 图像分类 
.. 动作识别 
.. 时序动作定位 
.. 视频 Embedding 
. 本章小结 
第章 经典网络结构回顾 
. 经典图像分类网络 
.. LetNet- 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. Inception V/V 
.. ResNet 
.. preResNet 
.. WRN 
.. 随机深度网络 
.. DenseNet 
.. ResNeXt 
.. SENet 
.. MobileNet 
.. MobileNet V/V 
.. ShuffleNet 
.. ShuffleNet V 
. RNN、LSTM和GRU 
.. RNN 
.. 梯度爆炸与梯度消失 
.. LSTM 
.. GRU 
. 本章小结 
第章 基于D卷积的动作识别 
. 平均汇合 
. NetVLAD和NeXtVLAD 
.. VLAD 
.. NetVLAD 
.. NeXtVLAD 
.. NetFV和其他策略 
. 利用RNN融合各帧特征 
.. D卷积 + RNN的基本结构 
.. 对RNN结构进行改造 
. 利用D卷积融合各帧特征 
.. 什么是D卷积 
.. ECO 
. 双流法 
.. 什么是光流 
.. 双流法的基本网络结构 
.. 双流法的网络结构优化 
. 时序稀疏采样 
.. TSN 
.. TSN的实现 
.. ActionVLAD 
.. StNet 
.. TRN 
. 利用iDT轨迹 
.. DT和iDT 
.. TDD 
. 本章小结 
第章 基于D卷积的动作识别 
. D卷积基础网络结构 
.. CD 
.. ResD/D ResNet 
.. LTC 
. ID 
.. 类动作识别网络 
.. D卷积扩展为D卷积 
.. 类网络对比 
. D卷积的低秩近似 
.. 低秩近似的基本原理 
.. FSTCN 
.. PD 
.. R(+)D 
.. SD 
. TSM 
. D卷积 + RNN 
. ARTNet 
. Non-Local 
.. Non-Local 操作 
.. Non-Local 动作识别网络 
. SlowFast 
.. Slow分支和Fast分支 
.. 网络结构设计 
. D卷积神经网络超参数设计 
.. 多网格训练 
.. XD 
. 本章小结 
第章 时序动作定位 
. 基于滑动窗的算法 
.. S-CNN 
.. TURN 
.. CBR 
. 基于候选时序区间的算法 
.. Faster R-CNN 回顾 
.. R-CD 
.. TAL-Net 
. 自底向上的时序动作定位算法 
.. BSN 
.. TSA-Net 
.. BMN 
. 对时序结构信息建模的算法 
.. TAG 候选时序区间生成算法 
.. SSN 网络结构 
. 逐帧预测的算法 
.. CDC层 
.. CDC 网络结构 
. 单阶段算法 
.. SSAD 
.. SS-TAD 
.. GTAN 
. 本章小结 
第章 视频Embedding 
. 基于视频内容的无监督 Embedding 
.. 编码-解码网络 
.. 视频序列验证 
.. 视频和音频信息 
.. 视频和文本信息 
. WordVec 
.. CBOW和Skip-Gram 
.. 分层 Softmax 
.. 负采样 
. ItemVec 
.. ItemVec 基本形式 
.. ItemVec的改进 
. 基于图的随机游走 
.. DeepWalk 
.. NodeVec 
. 结合一二阶相似度 
.. LINE 
.. SDNE 
. 基于图的邻居结点 
.. GCN 
.. GraphSAGE 
.. GAT 
. 基于多种信息学习视频Embedding 
.. 召回模型 
.. 训练 
. 本章小结 
附录A 视频处理常用工具 
A. FFmpeg 
A. OpenCV 
A. Decord 
A. Lintel 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第 部分深度学习基础篇
 概述
. 人工智能 
.. 人工智能的分类 
.. 人工智能发展史 
. 机器学习 
.. 机器学习的由来 
.. 机器学习发展史 
.. 机器学习方法分类 
.. 机器学习中的基本概念 
. 神经网络 
.. 神经网络发展史 
参考文献 
 神经网络
. 在神经科学中对生物神经元的研究 
.. 神经元激活机制 
.. 神经元的特点 
. 神经元模型 
.. 线性神经元 
.. 线性阈值神经元 
.. Sigmoid 神经元 
.. Tanh 神经元 
.. ReLU 
.. Maxout 
.. Softmax 
.. 小结 
. 感知机 
.. 感知机的提出 
.. 感知机的困境 
. DNN 
.. 输入层、输出层及隐层 
.. 目标函数的选取 
.. 前向传播 
.. 后向传播 
.. 参数更新 
.. 神经网络的训练步骤 
参考文献 
 初始化模型
. 受限玻尔兹曼机 
.. 能量模型 
.. 带隐藏单元的能量模型 
.. 受限玻尔兹曼机基本原理 
.. 二值RBM 
.. 对比散度 
. 自动编码器 
.. 稀疏自动编码器 
.. 降噪自动编码器 
.. 栈式自动编码器 
. 深度信念网络 
参考文献 
 卷积神经网络
. 卷积算子 
. 卷积的特征 
. 卷积网络典型结构 
.. 基本网络结构 
.. 构成卷积神经网络的层 
.. 网络结构模式 
. 卷积网络的层 
.. 卷积层 
.. 池化层 
参考文献 
 循环神经网络
. 循环神经网络简介 
. RNN、LSTM 和GRU 
. 双向RNN 
. RNN 语言模型的简单实现 
参考文献 
 深度学习优化算法
. SGD 
. Momentum 
. NAG 
. Adagrad 
. RMSProp 
. Adadelta 
. Adam 
. AdaMax 
. Nadam 
. 关于优化算法的使用 
参考文献 
 深度学习训练技巧
. 数据预处理 
. 权重初始化 
. 正则化 
.. 提前终止 
.. 数据增强 
.. L/L 参数正则化 
.. 集成 
.. Dropout 
参考文献 
 深度学习框架
. Theano 
.. Theano 
.. 安装 
.. 计算图 
. Torch 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. PyTorch 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. Caffe 
.. 概述 
.. 安装 
.. 核心组件 
.. 小试牛刀 
. TensorFlow 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. MXNet 
.. 概述 
.. 安装 
.. 核心结构 
.. 小试牛刀 
. Keras 
.. 概述 
.. 安装 
.. 模块介绍 
.. 小试牛刀 
参考文献 
第 部分计算机视觉篇
 计算机视觉背景
. 传统计算机视觉 
. 基于深度学习的计算机视觉 
. 参考文献 
 图像分类模型
. LeNet- 
. AlexNet 
. VGGNet 
.. 网络结构 
.. 配置 
.. 讨论 
.. 几组实验 
. GoogLeNet 
.. NIN 
.. GoogLeNet 的动机 
.. 网络结构细节 
.. 训练方法 
.. 后续改进版本 
. ResNet 
.. 基本思想 
.. 网络结构 
. DenseNet 
. DPN 
参考文献 
 目标检测
. 相关研究 
.. 选择性搜索 
.. OverFeat 
. 基于区域提名的方法 
.. R-CNN 
.. SPP-net 
.. Fast R-CNN 
.. Faster R-CNN 
.. R-FCN 
. 端到端的方法 
.. YOLO 
.. SSD 
. 小结 
参考文献 
 语义分割
. 全卷积网络 
.. FCN 
.. DeconvNet 
.. SegNet 
.. DilatedConvNet 
. CRF/MRF 的使用 
.. DeepLab 
.. CRFasRNN 
.. DPN 
. 实例分割 
.. Mask R-CNN 
参考文献 
 图像检索的深度哈希编码
. 传统哈希编码方法 
. CNNH 
. DSH 
. 小结 
参考文献 
第 部分语音识别篇
 传统语音识别基础
. 语音识别简介 
. HMM 简介 
.. HMM 是特殊的混合模型 
.. 转移概率矩阵 
.. 发射概率 
.. Baum-Welch 算法 
.. 后验概率 
.. 前向-后向算法 
. HMM 梯度求解 
.. 梯度算法 
.. 梯度算法 
.. 梯度求解的重要性 
. 孤立词识别 
.. 特征提取 
.. 孤立词建模 
.. GMM-HMM 
. 连续语音识别 
. Viterbi 解码 
. 三音素状态聚类 
. 判别式训练 
参考文献 
 基于WFST 的语音解码
. 有限状态机 
. WFST 及半环定义 
.. WFST 
.. 半环（Semiring） 
. 自动机操作 
.. 自动机基本操作 
.. 转换器基本操作 
.. 优化操作 
. 基于WFST 的语音识别系统 
.. 声学模型WFST 
.. 三音素WFST 
.. 发音字典WFST 
.. 语言模型WFST 
.. WFST 组合和优化 
.. 组合和优化实验 
.. WFST 解码 
参考文献 
 深度语音识别
. CD-DNN-HMM 
. TDNN 
. CTC 
. EESEN 
. Deep Speech 
. Chain 
参考文献 
 CTC 解码
. 序列标注 
. 序列标注任务的解决办法 
.. 序列分类 
.. 分割分类 
.. 时序分类 
. 隐马模型 
. CTC 基本定义 
. CTC 前向算法 
. CTC 后向算法 
. CTC 目标函数 
. CTC 解码基本原理 
.. 最大概率路径解码 
.. 前缀搜索解码 
.. 约束解码 
参考文献 
第 部分自然语言处理篇
 自然语言处理简介
. NLP 的难点 
. NLP 的研究范围 
 词性标注
. 传统词性标注模型 
. 基于神经网络的词性标注模型 
. 基于Bi-LSTM 的神经网络词性标注模型 
参考文献 
 依存句法分析
. 背景 
. SyntaxNet 技术要点 
.. Transition-based 系统 
.. “模板化” 技术 
.. Beam Search 
参考文献 
 wordvec 
. 背景 
.. 词向量 
.. 统计语言模型 
.. 神经网络语言模型 
.. Log-linear 模型 
.. Log-bilinear 模型 
.. 层次化Log-bilinear 模型 
. CBOW 模型 
. Skip-gram 模型 
. Hierarchical Softmax 与Negative Sampling 
. fastText 
. GloVe 
. 小结 
参考文献 
 神经网络机器翻译
. 机器翻译简介 
. 神经网络机器翻译基本模型 
. 基于Attention 的神经网络机器翻译 
. 谷歌机器翻译系统GNMT 
. 基于卷积的机器翻译 
. 小结 
参考文献 
第 部分深度学习研究篇
 Batch Normalization 
. 前向与后向传播 
.. 前向传播 
.. 后向传播 
. 有效性分析 
.. 内部协移 
.. 梯度流 
. 使用与优化方法 
. 小结 
参考文献 
 Attention 
. 从简单RNN 到RNN + Attention 
. Soft Attention 与Hard Attention 
. Attention 的应用 
. 小结 
参考文献 
 多任务学习
. 背景 
. 什么是多任务学习 
. 多任务分类与其他分类概念的关系 
.. 二分类 
.. 多分类 
.. 多标签分类 
.. 相关关系 
. 多任务学习如何发挥作用 
.. 提高泛化能力的潜在原因 
.. 多任务学习机制 
.. 后向传播多任务学习如何发现任务是相关的 
. 多任务学习被广泛应用 
.. 使用未来预测现在 
.. 多种表示和度量 
.. 时间序列预测 
.. 使用不可操作特征 
.. 使用额外任务来聚焦 
.. 有序迁移 
.. 多个任务自然地出现 
.. 将输入变成输出 
. 多任务深度学习应用 
.. 脸部特征点检测 
.. DeepID 
.. Fast R-CNN 
.. 旋转人脸网络 
.. 实例感知语义分割的MNC 
. 小结 
参考文献 
 模型压缩
. 模型压缩的必要性 
. 较浅的网络 
. 剪枝 
. 参数共享 
. 紧凑网络 
. 二值网络 
. 小结 
参考文献 
 增强学习
. 什么是增强学习 
. 增强学习的数学表达形式 
.. MDP 
.. 策略函数 
.. 奖励与回报 
.. 价值函数 
.. 贝尔曼方程 
.. 最优策略性质 
. 用动态规划法求解增强学习问题 
.. Agent 的目标 
.. 策略评估 
.. 策略改进 
.. 策略迭代 
.. 策略迭代的例子 
.. 价值迭代 
.. 价值迭代的例子 
.. 策略函数和价值函数的关系 
. 无模型算法 
.. 蒙特卡罗法 
.. 时序差分法 
.. Q-Learning 
. Q-Learning 的例子 
. AlphaGo 原理剖析 
.. 围棋与机器博弈 
.. Alpha-Beta 树 
.. MCTS 
.. UCT 
.. AlphaGo 的训练策略 
.. AlphaGo 的招式搜索算法 
.. 围棋的对称性 
. AlphaGo Zero 
参考文献 
 GAN 
. 生成模型 
. 生成对抗模型的概念 
. GAN 实战 
. InfoGAN――探寻隐变量的内涵 
. Image-Image Translation 
. WGAN（Wasserstein GAN） 
.. GAN 目标函数的弱点 
.. Wasserstein 度量的优势 
.. WGAN 的目标函数 
参考文献 
A 本书涉及的开源资源列表 
・ ・ ・ ・ ・ ・ (收起) 深度学习简介
. 人工智能、机器学习和深度学习 
.. 引言 
.. 人工智能、机器学习和深度学习三者的关系 
. 神经网络 
.. 感知器 
.. 激活函数 
.. 损失函数 
.. 梯度下降和随机梯度下降 
.. 反向传播算法简述 
.. 其他神经网络 
. 学习方法建议 
.. 网络资源 
.. TensorFlow 官方深度学习教程 
.. 开源社区 
. TensorLayer 
.. 深度学习框架概况 
.. TensorLayer 概括 
.. 实验环境配置 
 多层感知器
. McCulloch-Pitts 神经元模型 
.. 人工神经网络到底能干什么？到底在干什么 
.. 什么是激活函数？什么是偏值 
. 感知器 
.. 什么是线性分类器 
.. 线性分类器有什么优缺点 
.. 感知器实例和异或问题（XOR 问题） 
. 多层感知器 
. 实现手写数字分类 
. 过拟合 
.. 什么是过拟合 
.. Dropout 
.. 批规范化 
.. L、L 和其他正则化方法 
.. Lp 正则化的图形化解释 
. 再实现手写数字分类 
.. 数据迭代器 
.. 通过all_drop 启动与关闭Dropout 
.. 通过参数共享实现训练测试切换 
 自编码器
. 稀疏性 
. 稀疏自编码器 
. 实现手写数字特征提取 
. 降噪自编码器 
. 再实现手写数字特征提取 
. 堆栈式自编码器及其实现 
 卷积神经网络
. 卷积原理 
.. 卷积操作 
.. 张量 
.. 卷积层 
.. 池化层 
.. 全连接层 
. 经典任务 
.. 图像分类 
.. 目标检测 
.. 语义分割 
.. 实例分割 
. 经典卷积网络 
.. LeNet 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. ResNet 
. 实现手写数字分类 
. 数据增强与规范化 
.. 数据增强 
.. 批规范化 
.. 局部响应归一化 
. 实现CIFAR 分类 
.. 方法：tl.prepro 做数据增强 
.. 方法：TFRecord 做数据增强 
. 反卷积神经网络 
 词的向量表达
. 目的与原理 
. WordVec 
.. 简介 
.. Continuous Bag-Of-Words（CBOW）模型 
.. Skip Gram（SG）模型 
.. Hierarchical Softmax 
.. Negative Sampling 
. 实现WordVec 
.. 简介 
.. 实现 
. 重载预训练矩阵 
 递归神经网络
. 为什么需要它 
. 不同的RNNs 
.. 简单递归网络 
.. 回音网络 
. 长短期记忆 
.. LSTM 概括 
.. LSTM 详解 
.. LSTM 变种 
. 实现生成句子 
.. 模型简介 
.. 数据迭代 
.. 损失函数和更新公式 
.. 生成句子及Top K 采样 
.. 接下来还可以做什么 
 深度增强学习
. 增强学习 
.. 概述 
.. 基于价值的增强学习 
.. 基于策略的增强学习 
.. 基于模型的增强学习 
. 深度增强学习 
.. 深度Q 学习 
.. 深度策略网络 
. 更多参考资料 
.. 书籍 
.. 在线课程 
 生成对抗网络
. 何为生成对抗网络 
. 深度卷积对抗生成网络 
. 实现人脸生成 
. 还能做什么 
 高级实现技巧
. 与其他框架对接 
.. 无参数层 
.. 有参数层 
. 自定义层 
.. 无参数层 
.. 有参数层 
. 建立词汇表 
. 补零与序列长度 
. 动态递归神经网络 
. 实用小技巧 
.. 屏蔽显示 
.. 参数名字前缀 
.. 获取特定参数 
.. 获取特定层输出 
 实例一：使用预训练卷积网络
. 高维特征表达 
. VGG 网络 
. 连接TF-Slim 
 实例二：图像语义分割及其医学图像应用
. 图像语义分割概述 
.. 传统图像分割算法简介 
.. 损失函数与评估指标 
. 医学图像分割概述 
. 全卷积神经网络和U-Net 网络结构 
. 医学图像应用：实现脑部肿瘤分割 
.. 数据与数据增强 
.. U-Net 网络 
.. 损失函数 
.. 开始训练 
 实例三：由文本生成图像
. 条件生成对抗网络之GAN-CLS 
. 实现句子生成花朵图片 
 实例四：超高分辨率复原
. 什么是超高分辨率复原 
. 网络结构 
. 联合损失函数 
. 训练网络 
. 使用测试 
 实例五：文本反垃圾
. 任务场景 
. 网络结构 
. 词的向量表示 
. Dynamic RNN 分类器 
. 训练网络 
.. 训练词向量 
.. 文本的表示 
.. 训练分类器 
.. 模型导出 
. TensorFlow Serving 部署 
. 客户端调用 
. 其他常用方法 
中英对照表及其缩写
参考文献
・ ・ ・ ・ ・ ・ (收起)目　　录
第　章 深度学习简介　
．　深度学习与人工智能　
．　深度学习的历史渊源　
．．　从感知机到人工神经网络　
．．　深度学习时代　
．．　巨头之间的角逐　
．　深度学习的影响因素　
．．　大数据　
．．　深度网络架构　
．．　GPU　
．　深度学习为什么如此成功　
．．　特征学习（representation learning）　
．．　迁移学习（transfer learning）　
．　小结　
参考文献　
第　章 PyTorch简介　
．　PyTorch安装　
．　初识PyTorch　
．．　与Python的完美融合　
．．　张量计算　
．．　动态计算图　
．　PyTorch实例：预测房价　
．．　准备数据　
．．　模型设计　
．．　训练　
．．　预测　
．．　术语汇总　
．　小结　
第章　单车预测器：你的第 一个
神经网络　
．　共享单车的烦恼　
．　单车预测器．　
．．　神经网络简介　
．．　人工神经元　
．．　两个隐含层神经元　
．．　训练与运行　
．．　失败的神经预测器　
．．　过拟合　
．　单车预测器．　
．．　数据的预处理过程　
．．　构建神经网络　
．．　测试神经网络　
．　剖析神经网络Neu　
．　小结　
．　Q&A　
第章　机器也懂感情――中文情绪
分类器　
．　神经网络分类器　
．．　如何用神经网络做分类　
．．　分类问题的损失函数　
．　词袋模型分类器　
．．　词袋模型简介　
．．　搭建简单文本分类器　
．　程序实现　
．．　数据获取　
．．　数据处理　
．．　文本数据向量化　
．．　划分数据集　
．．　建立神经网络　
．　运行结果　
．　剖析神经网络　
．　小结　
．　Q&A　
第章　手写数字识别器――认识卷积
神经网络　
．　什么是卷积神经网络　
．．　手写数字识别任务的CNN
网络及运算过程　
．．　卷积运算操作　
．．　池化操作　
．．　立体卷积核　
．．　超参数与参数　
．．　其他说明　
．　手写数字识别器　
．．　数据准备　
．．　构建网络　
．．　运行模型　
．．　测试模型　
．　剖析卷积神经网络　
．．　第 一层卷积核与特征图　
．．　第二层卷积核与特征图　
．．　卷积神经网络的健壮性试验　
．　小结　
．　Q&A　
．　扩展阅读　
第章　手写数字加法机――迁移学习　
．　什么是迁移学习　
．．　迁移学习的由来　
．．　迁移学习的分类　
．．　迁移学习的意义　
．．　如何用神经网络实现迁移
学习　
．　应用案例：迁移学习如何抗击贫困　
．．　背景介绍　
．．　方法探寻　
．．　迁移学习方法　
．　蚂蚁还是蜜蜂：迁移大型卷积神经
网络　
．．　任务描述与初步尝试　
．．　ResNet与模型迁移　
．．　代码实现　
．．　结果分析　
．．　更多的模型与数据　
．　手写数字加法机　
．．　网络架构　
．．　代码实现　
．．　训练与测试　
．．　结果　
．．　大规模实验　
．　小结　
．　实践项目：迁移与效率　
第章　你自己的Prisma――图像
风格迁移　
．　什么是风格迁移　
．．　什么是风格　
．．　风格迁移的涵义　
．　风格迁移技术发展简史　
．．　神经网络之前的风格迁移　
．．　特定风格的实现　
．　神经网络风格迁移　
．．　神经网络风格迁移的优势　
．．　神经网络风格迁移的基本
思想　
．．　卷积神经网络的选取　
．．　内容损失　
．．　风格损失　
．．　风格损失原理分析　
．．　损失函数与优化　
．　神经网络风格迁移实战　
．．　准备工作　
．．　建立风格迁移网络　
．．　风格迁移训练　
．　小结　
．　扩展阅读　
第章　人工智能造假术――图像生成
与对抗学习　
．　反卷积与图像生成　
．．　CNN回顾　
．．　反卷积操作　
．．　反池化过程　
．．　反卷积与分数步伐　
．．　输出图像尺寸公式　
．．　批正则化技术　
．　图像生成实验――最小均方误差
模型　
．．　模型思路　
．．　代码实现　
．．　运行结果　
．　图像生成实验――生成器-识别器
模型　
．．　生成器-识别器模型的实现　
．．　对抗样本　
．　图像生成实验――生成对抗网络
GAN　
．．　GAN的总体架构　
．．　程序实现　
．．　结果展示　
．　小结　
．　Q&A　
．　扩展阅读　
第章　词汇的星空――神经语言模型
与WordVec　
．　词向量技术介绍　
．．　初识词向量　
．．　传统编码方式　
．　NPLM：神经概率语言模型　
．．　NPLM的基本思想　
．．　NPLM的运作过程详解　
．．　读取NPLM中的词向量　
．．　NPLM的编码实现　
．．　运行结果　
．．　NPLM的总结与局限　
．　WordVec　
．．　CBOW模型和Skip-gram模型的结构　
．．　层级软最大　
．．　负采样　
．．　总结及分析　
．　WordVec的应用　
．．　在自己的语料库上训练WordVec词向量　
．．　调用现成的词向量　
．．　女人-男人＝皇后-国王　
．．　使用向量的空间位置进行词对词翻译　
．．　WordVec小结　
．　小结　
．　Q&A　
第　章 LSTM作曲机――序列生成
模型　
．　序列生成问题　
．　RNN与LSTM　
．．　RNN　
．．　LSTM　
．　简单序列的学习问题　
．．　RNN的序列学习　
．．　LSTM的序列学习　
．　LSTM作曲机　
．．　MIDI文件　
．．　数据准备　
．．　模型结构　
．．　代码实现　
．　小结　
．　Q&A　
．　扩展阅读　
・ ・ ・ ・ ・ ・ (收起)第章　编程和数学基础 
.　Python快速入门 
..　快速安装Python 
..　Python基础 
..　Python中的常见运算 
..　Python控制语句 
..　Python常用容器类型 
..　Python常用函数 
..　类和对象 
..　Matplotlib入门 
.　张量库NumPy 
..　什么是张量 
..　创建ndarray对象 
..　ndarray数组的索引和切片 
..　张量的计算 
.　微积分 
..　函数 
..　四则运算和复合运算 
..　极限和导数 
..　导数的四则运算和链式法则 
..　计算图、正向计算和反向传播求导 
..　多变量函数的偏导数与梯度 
..　向量值函数的导数与Jacobian矩阵 
..　积分 
.　概率基础 
..　概率 
..　条件概率、联合概率、全概率公式、贝叶斯公式 
..　随机变量 
..　离散型随机变量的概率分布 
..　连续型随机变量的概率密度 
..　随机变量的分布函数 
..　期望、方差、协方差、协变矩阵 
第章　梯度下降法 
.　函数极值的必要条件 
.　梯度下降法基础 
.　梯度下降法的参数优化策略 
..　Momentum法 
..　AdaGrad法 
..　AdaDelta法 
..　RMSprop法 
..　Adam法 
.　梯度验证 
..　比较数值梯度和分析梯度 
..　通用的数值梯度 
.　分离梯度下降法与参数优化策略 
..　参数优化器 
..　接受参数优化器的梯度下降法 
第章　线性回归、逻辑回归和softmax回归 
.　线性回归 
..　餐车利润问题 
..　机器学习与人工智能 
..　什么是线性回归 
..　用正规方程法求解线性回归问题 
..　用梯度下降法求解线性回归问题 
..　调试学习率 
..　梯度验证 
..　预测 
..　多特征线性回归 
.　数据的规范化 
..　预测大坝出水量 
..　数据的规范化过程 
.　模型的评估 
..　欠拟合和过拟合 
..　验证集和测试集 
..　学习曲线 
..　偏差和方差 
.　正则化 
.　逻辑回归 
..　逻辑回归基础 
..　逻辑回归的NumPy实现 
..　实战：鸢尾花分类的NumPy实现 
.　softmax回归 
..　spiral数据集 
..　softmax函数 
..　softmax回归模型 
..　多分类交叉熵损失 
..　通过加权和计算交叉熵损失 
..　softmax回归的梯度计算 
..　softmax回归的梯度下降法的实现 
..　spiral数据集的softmax回归模型 
.　批梯度下降法和随机梯度下降法 
..　MNIST手写数字集 
..　用部分训练样本训练逻辑回归模型 
..　批梯度下降法 
..　随机梯度下降法 
第章　神经网络 
.　神经网络概述 
..　感知机和神经元 
..　激活函数 
..　神经网络与深度学习 
..　多个样本的正向计算 
..　输出 
..　损失函数 
..　基于数值梯度的神经网络训练 
.　反向求导 
..　正向计算和反向求导 
..　计算图 
..　损失函数关于输出的梯度 
..　层神经网络的反向求导 
..　层神经网络的Python实现 
..　任意层神经网络的反向求导 
.　实现一个简单的深度学习框架 
..　神经网络的训练过程 
..　网络层的代码实现 
..　网络层的梯度检验 
..　神经网络的类 
..　神经网络的梯度检验 
..　基于深度学习框架的MNIST手写数字识别 
..　改进的通用神经网络框架：分离加权和与激活函数 
..　独立的参数优化器 
..　fashion-mnist的分类训练 
..　读写模型参数 
第章　改进神经网络性能的基本技巧 
.　数据处理 
..　数据增强 
..　规范化 
..　特征工程 
.　参数调试 
..　权重初始化 
..　优化参数 
.　批规范化 
..　什么是批规范化 
..　批规范化的反向求导 
..　批规范化的代码实现 
.　正则化 
..　权重正则化 
..　Dropout 
..　早停法 
.　梯度爆炸和梯度消失 
第章　卷积神经网络 
.　卷积入门 
..　什么是卷积 
..　一维卷积 
..　二维卷积 
..　多通道输入和多通道输出 
..　池化 
.　卷积神经网络概述 
..　全连接神经元和卷积神经元 
..　卷积层和卷积神经网络 
..　卷积层和池化层的反向求导及代码实现 
..　卷积神经网络的代码实现 
.　卷积的矩阵乘法 
..　一维卷积的矩阵乘法 
..　二维卷积的矩阵乘法 
..　一维卷积反向求导的矩阵乘法 
..　二维卷积反向求导的矩阵乘法 
.　基于坐标索引的快速卷积 
.　典型卷积神经网络结构 
..　LeNet- 
..　AlexNet 
..　VGG 
..　残差网络 
..　Inception网络 
..　NiN 
第章　循环神经网络 
.　序列问题和模型 
..　股票价格预测问题 
..　概率序列模型和语言模型 
..　自回归模型 
..　生成自回归数据 
..　时间窗方法 
..　时间窗采样 
..　时间窗方法的建模和训练 
..　长期预测和短期预测 
..　股票价格预测的代码实现 
..　k-gram语言模型 
.　循环神经网络基础 
..　无记忆功能的非循环神经网络 
..　具有记忆功能的循环神经网络 
.　穿过时间的反向传播 
.　单层循环神经网络的实现 
..　初始化模型参数 
..　正向计算 
..　损失函数 
..　反向求导 
..　梯度验证 
..　梯度下降训练 
..　序列数据的采样 
..　序列数据的循环神经网络训练和预测 
.　循环神经网络语言模型和文本的生成 
..　字符表 
..　字符序列样本的采样 
..　模型的训练和预测 
.　循环神经网络中的梯度爆炸和梯度消失 
.　长短期记忆网络 
..　LSTM的神经元 
..　LSTM的反向求导 
..　LSTM的代码实现 
..　LSTM的变种 
.　门控循环单元 
..　门控循环单元的工作原理 
..　门控循环单元的代码实现 
.　循环神经网络的类及其实现 
..　用类实现循环神经网络 
..　循环神经网络单元的类实现 
.　多层循环神经网络和双向循环神经网络 
..　多层循环神经网络 
..　多层循环神经网络的训练和预测 
..　双向循环神经网络 
.　SeqSeq模型 
..　机器翻译概述 
..　SeqSeq模型的实现 
..　字符级的SeqSeq模型 
..　基于WordVec的SeqSeq模型 
..　基于词嵌入层的SeqSeq模型 
..　注意力机制 
第章　生成模型 
.　生成模型概述 
.　自动编码器 
..　什么是自动编码器 
..　稀疏编码器 
..　自动编码器的代码实现 
.　变分自动编码器 
..　什么是变分自动编码器 
..　变分自动编码器的损失函数 
..　变分自动编码器的参数重采样 
..　变分自动编码器的反向求导 
..　变分自动编码器的代码实现 
.　生成对抗网络 
..　生成对抗网络的原理 
..　生成对抗网络训练过程的代码实现 
.　生成对抗网络建模实例 
..　一组实数的生成对抗网络建模 
..　二维坐标点的生成对抗网络建模 
..　MNIST手写数字集的生成对抗网络建模 
..　生成对抗网络的训练技巧 
.　生成对抗网络的损失函数及其概率解释 
..　生成对抗网络的损失函数的全局最优解 
..　Kullback-Leibler散度和Jensen-Shannon散度 
..　生成对抗网络的最大似然解释 
.　改进的损失函数――Wasserstein GAN 
..　Wasserstein GAN的原理 
..　Wasserstein GAN的代码实现 
.　深度卷积对抗网络 
..　一维转置卷积 
..　二维转置卷积 
..　卷积对抗网络的代码实现 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第一部分　元编程基础技术
第章 基本技巧　
.　元函数与type_traits　
..　元函数介绍　
..　类型元函数　
..　各式各样的元函数　
..　type_traits　
..　元函数与宏　
..　本书中元函数的命名方式　
.　模板型模板参数与容器模板　
..　模板作为元函数的输入　
..　模板作为元函数的输出　
..　容器模板　
.　顺序、分支与循环代码的编写　
..　顺序执行的代码　
..　分支执行的代码　
..　循环执行的代码　
..　小心：实例化爆炸与编译崩溃　
..　分支选择与短路逻辑　
.　奇特的递归模板式　
.　小结　
.　练习　
第章 异类词典与policy模板　
.　具名参数简介　
.　异类词典　
..　模块的使用方式　
..　键的表示　
..　异类词典的实现　
..　VarTypeDict的性能简析　
..　用std::tuple作为缓存　
.　policy模板　
..　policy介绍　
..　定义policy与policy对象（模板）　
..　使用policy　
..　背景知识：支配与虚继承　
..　policy对象与policy支配结构　
..　policy选择元函数　
..　使用宏简化policy对象的声明　
.　小结　
.　练习　
第二部分 深度学习框架
第章　深度学习概述　
.　深度学习简介　
..　从机器学习到深度学习　
..　各式各样的人工神经网络　
..　深度学习系统的组织与训练　
.　本书所实现的框架：MetaNN　
..　从矩阵计算工具到深度学习框架　
..　MetaNN介绍　
..　本书将要讨论的内容　
..　本书不会涉及的主题　
.　小结　
第章　类型体系与基本数据类型　
.　类型体系　
..　类型体系介绍　
..　迭代器分类体系　
..　将标签作为模板参数　
..　MetaNN的类型体系　
..　与类型体系相关的元函数　
.　设计理念　
..　支持不同的计算设备与计算单元　
..　存储空间的分配与维护　
..　浅拷贝与写操作检测　
..　底层接口扩展　
..　类型转换与求值　
..　数据接口规范　
.　标量　
..　类模板的声明　
..　基于CPU的特化版本　
..　标量的主体类型　
.　矩阵　
..　Matrix类模板　
..　特殊矩阵：平凡矩阵、全零矩阵与独热向量　
..　引入新的矩阵类　
.　列表　
..　Batch模板　
..　Array模板　
..　重复与Duplicate模板　
.　小结　
.　练习　
第章　运算与表达式模板　
.　表达式模板简介　
.　MetaNN运算模板的设计思想　
..　Add模板的问题　
..　运算模板的行为分析　
.　运算分类　
.　辅助模板　
..　辅助类模板OperElementType_/OperDeviceType_　
..　辅助类模板OperXXX_　
..　辅助类模板OperCateCal　
..　辅助类模板OperOrganizer　
..　辅助类模板OperSeq　
.　运算模板的框架　
..　运算模板的类别标签　
..　UnaryOp的定义　
.　运算实现示例　
..　Sigmoid运算　
..　Add运算　
..　转置运算　
..　折叠运算　
.　MetaNN已支持的运算列表　
..　一元运算　
..　二元运算　
..　三元运算　
.　运算的折衷与局限性　
..　运算的折衷　
..　运算的局限性　
.　小结　
.　练习　
第章　基本层　
.　层的设计理念　
..　层的介绍　
..　层对象的构造　
..　参数矩阵的初始化与加载　
..　正向传播　
..　存储中间结果　
..　反向传播　
..　参数矩阵的更新　
..　参数矩阵的获取　
..　层的中性检测　
.　层的辅助逻辑　
..　初始化模块　
..　DynamicData类模板　
..　层的常用policy对象　
..　InjectPolicy元函数　
..　通用I/O结构　
..　通用操作函数　
.　层的具体实现　
..　AddLayer　
..　ElementMulLayer　
..　BiasLayer　
.　MetaNN已实现的基本层　
.　小结　
.　练习　
第章　复合层与循环层　
.　复合层的接口与设计理念　
..　基本结构　
..　结构描述语法　
..　policy的继承关系　
..　policy的修正　
..　复合层的构造函数　
..　一个完整的复合层构造示例　
.　policy继承与修正逻辑的实现　
..　policy继承逻辑的实现　
..　policy修正逻辑的实现　
.　ComposeTopology的实现　
..　功能介绍　
..　拓扑排序算法介绍　
..　ComposeTopology包含的主要步骤　
..　结构描述子句与其划分　
..　结构合法性检查　
..　拓扑排序的实现　
..　子层实例化元函数　
.　ComposeKernel的实现　
..　类模板的声明　
..　子层对象管理　
..　参数获取、梯度收集与中性检测　
..　参数初始化与加载　
..　正向传播　
..　反向传播　
.　复合层实现示例　
.　循环层　
..　GruStep　
..　构建RecurrentLayer类模板　
..　RecurrentLayer的使用　
.　小结　
.　练习　
第章　求值与优化　
.　MetaNN的求值模型　
..　运算的层次结构　
..　求值子系统的模块划分　
.　基本求值逻辑　
..　主体类型的求值接口　
..　非主体基本数据类型的求值　
..　运算模板的求值　
..　DyanmicData与求值　
.　求值过程的优化　
..　避免重复计算　
..　同类计算合并　
..　多运算协同优化　
.　小结　
.　练习　
后记―方家休见笑，吾道本艰难　
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
序
前言
第章　打造深度学习工具箱
.　TensorFlow
..　安装
..　使用举例
.　TFLearn
.　PaddlePaddle
..　安装
..　使用举例
.　Karas
.　本章小结
第章　卷积神经网络
.　传统的图像分类算法
.　基于CNN的图像分类算法
..　局部连接
..　参数共享
..　池化
..　典型的CNN结构及实现
..　AlexNet的结构及实现
..　VGG的结构及实现
.　基于CNN的文本处理
..　典型的CNN结构
..　典型的CNN代码实现
.　本章小结
第章　循环神经网络
.　循环神经算法概述
.　单向循环神经网络结构与实现
.　双向循环神经网络结构与实现
.　循环神经网络在序列分类的应用
.　循环神经网络在序列生成的应用
.　循环神经网络在序列标记的应用
.　循环神经网络在序列翻译的应用
.　本章小结
第章　基于OpenSOC的机器学习框架
.　OpenSOC框架
.　数据源系统
.　数据收集层
.　消息系统层
.　实时处理层
.　存储层
..　HDFS
..　HBase
..　Elasticsearch
.　分析处理层
.　计算系统
.　实战演练
.　本章小结
第章　验证码识别
.　数据集
.　特征提取
.　模型训练与验证
..　K近邻算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　垃圾邮件识别
.　数据集
.　特征提取
..　词袋模型
..　TF-IDF模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
..　深度学习算法之RNN
.　本章小结
第章　负面评论识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　骚扰短信识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之MLP
.　本章小结
第章　Linux后门检测
.　数据集
.　特征提取
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　用户行为分析与恶意行为检测
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词袋和N-Gram模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　隐式马尔可夫算法
..　深度学习算法之MLP
.　本章小结
第章　WebShell检测
.　数据集
..　WordPress
..　PHPCMS
..　phpMyAdmin
..　Smarty
..　Yii
.　特征提取
..　词袋和TF-IDF模型
..　opcode和N-Gram模型
..　opcode调用序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　智能扫描器
.　自动生成XSS攻击载荷
..　数据集
..　特征提取
..　模型训练与验证
.　自动识别登录界面
..　数据集
..　特征提取
..　模型训练与验证
.　本章小结
第章　DGA域名识别
.　数据集
.　特征提取
..　N-Gram模型
..　统计特征模型
..　字符序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
..　深度学习算法之RNN
.　本章小结
第章　恶意程序分类识别
.　数据集
.　特征提取
.　模型训练与验证
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　反信用卡欺诈
.　数据集
.　特征提取
..　标准化
..　标准化和降采样
..　标准化和过采样
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
・ ・ ・ ・ ・ ・ (收起)第章 数据科学概述 
.　挑战　
..　工程实现的挑战　
..　模型搭建的挑战　
.　机器学习　
..　机器学习与传统编程　
..　监督式学习和非监督式学习　
.　统计模型　
.　关于本书　
第章 Python安装指南与简介：告别空谈　
.　Python简介　
..　什么是Python　
..　Python在数据科学中的地位　
..　不可能绕过的第三方库　
.　Python安装　
..　Windows下的安装　
..　Mac下的安装　
..　Linux下的安装　
.　Python上手实践　
..　Python shell　
..　第 一个Python程序：Word Count　
..　Python编程基础　
..　Python的工程结构　
.　本章小结　
第章　数学基础：恼人但又不可或缺的知识　
.　矩阵和向量空间　
..　标量、向量与矩阵　
..　特殊矩阵　
..　矩阵运算　
..　代码实现　
..　向量空间　
.　概率：量化随机　
..　定义概率：事件和概率空间　
..　条件概率：信息的价值　
..　随机变量：两种不同的随机　
..　正态分布：殊途同归　
..　P-value：自信的猜测　
.　微积分　
..　导数和积分：位置、速度　
..　极限：变化的终点　
..　复合函数：链式法则　
..　多元函数：偏导数　
..　极值与最值：最优选择　
.　本章小结　
第章　线性回归：模型之母　
.　一个简单的例子　
..　从机器学习的角度看这个问题　
..　从统计学的角度看这个问题　
.　上手实践：模型实现　
..　机器学习代码实现　
..　统计方法代码实现　
.　模型陷阱　
..　过度拟合：模型越复杂越好吗　
..　模型幻觉之统计学方案：假设检验　
..　模型幻觉之机器学习方案：惩罚项　
..　比较两种方案　
.　模型持久化　
..　模型的生命周期　
..　保存模型　
.　本章小结　
第章　逻辑回归：隐藏因子　
.　二元分类问题：是与否　
..　线性回归：为何失效　
..　窗口效应：看不见的才是关键　
..　逻辑分布：胜者生存　
..　参数估计之似然函数：统计学角度　
..　参数估计之损失函数：机器学习角度　
..　参数估计之最终预测：从概率到选择　
..　空间变换：非线性到线性　
.　上手实践：模型实现　
..　初步分析数据：直观印象　
..　搭建模型　
..　理解模型结果　
.　评估模型效果：孰优孰劣　
..　查准率与查全率　
..　ROC曲线与AUC　
.　多元分类问题：超越是与否　
..　多元逻辑回归：逻辑分布的威力　
..　One-vs.-all：从二元到多元　
..　模型实现　
.　非均衡数据集　
..　准确度悖论　
..　一个例子　
..　解决方法　
.　本章小结　
第章　工程实现：计算机是怎么算的　
.　算法思路：模拟滚动　
.　数值求解：梯度下降法　
.　上手实践：代码实现　
..　TensorFlow基础　
..　定义模型　
..　梯度下降　
..　分析运行细节　
.　更优化的算法：随机梯度下降法　
..　算法细节　
..　代码实现　
..　两种算法比较　
.　本章小结　
第章　计量经济学的启示：他山之石　
.　定量与定性：变量的数学运算合理吗　
.　定性变量的处理　
..　虚拟变量　
..　上手实践：代码实现　
..　从定性变量到定量变量　
.　定量变量的处理　
..　定量变量转换为定性变量　
..　上手实践：代码实现　
..　基于卡方检验的方法　
.　显著性　
.　多重共线性：多变量的烦恼　
..　多重共线性效应　
..　检测多重共线性　
..　解决方法　
..　虚拟变量陷阱　
.　内生性：变化来自何处　
..　来源　
..　内生性效应　
..　工具变量　
..　逻辑回归的内生性　
..　模型的联结　
.　本章小结　
第章　监督式学习： 目标明确　
.　支持向量学习机　
..　直观例子　
..　用数学理解直观　
..　从几何直观到最优化问题　
..　损失项　
..　损失函数与惩罚项　
..　Hard margin 与soft margin比较　
..　支持向量学习机与逻辑回归：隐藏的假设　
.　核函数　
..　空间变换：从非线性到线性　
..　拉格朗日对偶　
..　支持向量　
..　核函数的定义：优化运算　
..　常用的核函数　
..　Scale variant　
.　决策树　
..　决策规则　
..　评判标准　
..　代码实现　
..　决策树预测算法以及模型的联结　
..　剪枝　
.　树的集成　
..　随机森林　
..　Random forest embedding　
..　GBTs之梯度提升　
..　GBTs之算法细节　
.　本章小结　
第章　生成式模型：量化信息的价值　
.　贝叶斯框架　
..　蒙提霍尔问题　
..　条件概率　
..　先验概率与后验概率　
..　参数估计与预测公式　
..　贝叶斯学派与频率学派　
.　朴素贝叶斯　
..　特征提取：文字到数字　
..　伯努利模型　
..　多项式模型　
..　TF-IDF　
..　文本分类的代码实现　
..　模型的联结　
.　判别分析　
..　线性判别分析　
..　线性判别分析与逻辑回归比较　
..　数据降维　
..　代码实现　
..　二次判别分析　
.　隐马尔可夫模型　
..　一个简单的例子　
..　马尔可夫链　
..　模型架构　
..　中文分词：监督式学习　
..　中文分词之代码实现　
..　股票市场：非监督式学习　
..　股票市场之代码实现　
.　本章小结　
第章 非监督式学习：聚类与降维　
.　K-means　
..　模型原理　
..　收敛过程　
..　如何选择聚类个数　
..　应用示例　
.　其他聚类模型　
..　混合高斯之模型原理　
..　混合高斯之模型实现　
..　谱聚类之聚类结果　
..　谱聚类之模型原理　
..　谱聚类之图片分割　
.　Pipeline　
.　主成分分析　
..　模型原理　
..　模型实现　
..　核函数　
..　Kernel PCA的数学原理　
..　应用示例　
.　奇异值分解　
..　定义　
..　截断奇异值分解　
..　潜在语义分析　
..　大型推荐系统　
.　本章小结　
第章 分布式机器学习：集体力量　
.　Spark简介　
..　Spark安装　
..　从MapReduce到Spark　
..　运行Spark　
..　Spark DataFrame　
..　Spark的运行架构　
.　最优化问题的分布式解法　
..　分布式机器学习的原理　
..　一个简单的例子　
.　大数据模型的两个维度　
..　数据量维度　
..　模型数量维度　
.　开源工具的另一面　
..　一个简单的例子　
..　开源工具的阿喀琉斯之踵　
.　本章小结　
第章 神经网络：模拟人的大脑　
.　神经元　
..　神经元模型　
..　Sigmoid神经元与二元逻辑回归　
..　Softmax函数与多元逻辑回归　
.　神经网络　
..　图形表示　
..　数学基础　
..　分类例子　
..　代码实现　
..　模型的联结　
.　反向传播算法　
..　随机梯度下降法回顾　
..　数学推导　
..　算法步骤　
.　提高神经网络的学习效率　
..　学习的原理　
..　激活函数的改进　
..　参数初始化　
..　不稳定的梯度　
.　本章小结　
第章 深度学习：继续探索　
.　利用神经网络识别数字　
..　搭建模型　
..　防止过拟合之惩罚项　
..　防止过拟合之dropout　
..　代码实现　
.　卷积神经网络　
..　模型结构之卷积层　
..　模型结构之池化层　
..　模型结构之完整结构　
..　代码实现　
..　结构真的那么重要吗　
.　其他深度学习模型　
..　递归神经网络　
..　长短期记忆　
..　非监督式学习　
.　本章小结　
・ ・ ・ ・ ・ ・ (收起)基础篇
第章 深度学习概述 
. 深度学习发展简史 
. 有监督学习 
.. 图像分类 
.. 目标检测 
.. 人脸识别 
.. 语音识别 
. 无监督学习 
.. 无监督学习概述 
.. 生成对抗网络 
. 强化学习 
.. AlphaGo 
.. AlphaGo Zero 
. 小结 
参考文献 
第章 深度神经网络 
. 神经元 
. 感知机 
. 前向传递 
.. 前向传递的流程 
.. 激活函数 
.. 损失函数 
. 后向传递 
.. 后向传递的流程 
.. 梯度下降 
.. 参数修正 
. 防止过拟合 
.. dropout 
.. 正则化 
. 小结 
第章 卷积神经网络 
. 卷积层 
.. valid 卷积 
.. full 卷积 
.. same 卷积 
. 池化层 
. 反卷积 
. 感受野 
. 卷积网络实例 
.. Lenet- 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. ResNet 
.. MobileNet 
. 小结 
进阶篇
第章 两阶段目标检测方法 
. R-CNN 
.. 算法流程 
.. 训练过程 
. SPP-Net 
.. 网络结构 
.. 空间金字塔池化 
. Fast R-CNN 
.. 感兴趣区域池化层 
.. 网络结构 
.. 全连接层计算加速 
.. 目标分类 
.. 边界框回归 
.. 训练过程 
. Faster R-CNN 
.. 网络结构 
.. RPN 
.. 训练过程 
. R-FCN 
.. R-FCN 网络结构 
.. 位置敏感的分数图 
.. 位置敏感的RoI 池化 
.. R-FCN 损失函数 
.. Caffe 网络模型解析 
. Mask R-CNN 
.. 实例分割简介 
.. COCO 数据集的像素级标注 
.. 网络结构 
.. U-Net 
.. SegNet 
. 小结 
第章 单阶段目标检测方法 
. SSD 
.. default box 
.. 网络结构 
.. Caffe 网络模型解析 
.. 训练过程 
. RetinaNet 
.. FPN 
.. 聚焦损失函数 
. RefineDet 
.. 网络模型 
.. Caffe 网络模型解析 
.. 训练过程 
. YOLO 
.. YOLO v 
.. YOLO v 
.. YOLO v 
. 目标检测算法应用 
.. 高速公路坑洞检测 
.. 息肉检测 
. 小结 
应用篇
第章 肋骨骨折检测 
. 国内外研究现状 
. 解决方案 
. 预处理 
. 肋骨骨折检测 
. 实验结果分析 
. 小结 
参考文献 
第章 肺结节检测 
. 国内外研究现状 
.. 肺结节可疑位置推荐算法 
.. 假阳性肺结节抑制算法 
. 总体框架 
.. 肺结节数据集 
.. 肺结节检测难点 
.. 算法框架 
. 肺结节可疑位置推荐算法 
.. CT图像的预处理 
.. 肺结节分割算法 
.. 优化方法 
.. 推断方法 
. 可疑肺结节定位算法 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
. 假阳性肺结节抑制算法 
.. 假阳性肺结节抑制网络 
.. 优化策略 
.. 推断策略 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
.. 可疑位置推荐与假阳抑制算法整合 
. 小结 
参考文献 
第章 车道线检测 
. 国内外研究现状 
. 主要研究内容 
.. 总体解决方案 
.. 各阶段概述 
. 车道线检测系统的设计与实现 
.. 车道线图像数据标注与筛选 
.. 车道线图片预处理 
.. 车道线分割模型训练 
.. 车道线检测 
.. 车道线检测结果 
. 车道线检测系统的性能测试 
.. 车道线检测质量测试 
.. 车道线检测时间测试 
. 小结 
参考文献 
第章 交通视频分析 
. 国内外研究现状 
. 主要研究内容 
.. 总体设计 
.. 精度和性能要求 
. 交通视频分析 
.. 车辆检测和车牌检测 
.. 车牌识别功能设计详解 
.. 车辆品牌及颜色的识别 
.. 目标跟踪设计详解 
. 系统测试 
.. 车辆检测 
.. 车牌检测 
.. 车牌识别 
.. 车辆品牌识别 
.. 目标跟踪 
. 小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
序
前言
第章　打造深度学习工具箱
.　TensorFlow
..　安装
..　使用举例
.　TFLearn
.　PaddlePaddle
..　安装
..　使用举例
.　Karas
.　本章小结
第章　卷积神经网络
.　传统的图像分类算法
.　基于CNN的图像分类算法
..　局部连接
..　参数共享
..　池化
..　典型的CNN结构及实现
..　AlexNet的结构及实现
..　VGG的结构及实现
.　基于CNN的文本处理
..　典型的CNN结构
..　典型的CNN代码实现
.　本章小结
第章　循环神经网络
.　循环神经算法概述
.　单向循环神经网络结构与实现
.　双向循环神经网络结构与实现
.　循环神经网络在序列分类的应用
.　循环神经网络在序列生成的应用
.　循环神经网络在序列标记的应用
.　循环神经网络在序列翻译的应用
.　本章小结
第章　基于OpenSOC的机器学习框架
.　OpenSOC框架
.　数据源系统
.　数据收集层
.　消息系统层
.　实时处理层
.　存储层
..　HDFS
..　HBase
..　Elasticsearch
.　分析处理层
.　计算系统
.　实战演练
.　本章小结
第章　验证码识别
.　数据集
.　特征提取
.　模型训练与验证
..　K近邻算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　垃圾邮件识别
.　数据集
.　特征提取
..　词袋模型
..　TF-IDF模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
..　深度学习算法之RNN
.　本章小结
第章　负面评论识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　骚扰短信识别
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词汇表模型
..　WordVec模型和DocVec模型
.　模型训练与验证
..　朴素贝叶斯算法
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之MLP
.　本章小结
第章　Linux后门检测
.　数据集
.　特征提取
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　用户行为分析与恶意行为检测
.　数据集
.　特征提取
..　词袋和TF-IDF模型
..　词袋和N-Gram模型
..　词汇表模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　隐式马尔可夫算法
..　深度学习算法之MLP
.　本章小结
第章　WebShell检测
.　数据集
..　WordPress
..　PHPCMS
..　phpMyAdmin
..　Smarty
..　Yii
.　特征提取
..　词袋和TF-IDF模型
..　opcode和N-Gram模型
..　opcode调用序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　深度学习算法之MLP
..　深度学习算法之CNN
.　本章小结
第章　智能扫描器
.　自动生成XSS攻击载荷
..　数据集
..　特征提取
..　模型训练与验证
.　自动识别登录界面
..　数据集
..　特征提取
..　模型训练与验证
.　本章小结
第章　DGA域名识别
.　数据集
.　特征提取
..　N-Gram模型
..　统计特征模型
..　字符序列模型
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
..　深度学习算法之RNN
.　本章小结
第章　恶意程序分类识别
.　数据集
.　特征提取
.　模型训练与验证
..　支持向量机算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
第章　反信用卡欺诈
.　数据集
.　特征提取
..　标准化
..　标准化和降采样
..　标准化和过采样
.　模型训练与验证
..　朴素贝叶斯算法
..　XGBoost算法
..　深度学习算法之多层感知机
.　本章小结
・ ・ ・ ・ ・ ・ (收起)第章　编程和数学基础 
.　Python快速入门 
..　快速安装Python 
..　Python基础 
..　Python中的常见运算 
..　Python控制语句 
..　Python常用容器类型 
..　Python常用函数 
..　类和对象 
..　Matplotlib入门 
.　张量库NumPy 
..　什么是张量 
..　创建ndarray对象 
..　ndarray数组的索引和切片 
..　张量的计算 
.　微积分 
..　函数 
..　四则运算和复合运算 
..　极限和导数 
..　导数的四则运算和链式法则 
..　计算图、正向计算和反向传播求导 
..　多变量函数的偏导数与梯度 
..　向量值函数的导数与Jacobian矩阵 
..　积分 
.　概率基础 
..　概率 
..　条件概率、联合概率、全概率公式、贝叶斯公式 
..　随机变量 
..　离散型随机变量的概率分布 
..　连续型随机变量的概率密度 
..　随机变量的分布函数 
..　期望、方差、协方差、协变矩阵 
第章　梯度下降法 
.　函数极值的必要条件 
.　梯度下降法基础 
.　梯度下降法的参数优化策略 
..　Momentum法 
..　AdaGrad法 
..　AdaDelta法 
..　RMSprop法 
..　Adam法 
.　梯度验证 
..　比较数值梯度和分析梯度 
..　通用的数值梯度 
.　分离梯度下降法与参数优化策略 
..　参数优化器 
..　接受参数优化器的梯度下降法 
第章　线性回归、逻辑回归和softmax回归 
.　线性回归 
..　餐车利润问题 
..　机器学习与人工智能 
..　什么是线性回归 
..　用正规方程法求解线性回归问题 
..　用梯度下降法求解线性回归问题 
..　调试学习率 
..　梯度验证 
..　预测 
..　多特征线性回归 
.　数据的规范化 
..　预测大坝出水量 
..　数据的规范化过程 
.　模型的评估 
..　欠拟合和过拟合 
..　验证集和测试集 
..　学习曲线 
..　偏差和方差 
.　正则化 
.　逻辑回归 
..　逻辑回归基础 
..　逻辑回归的NumPy实现 
..　实战：鸢尾花分类的NumPy实现 
.　softmax回归 
..　spiral数据集 
..　softmax函数 
..　softmax回归模型 
..　多分类交叉熵损失 
..　通过加权和计算交叉熵损失 
..　softmax回归的梯度计算 
..　softmax回归的梯度下降法的实现 
..　spiral数据集的softmax回归模型 
.　批梯度下降法和随机梯度下降法 
..　MNIST手写数字集 
..　用部分训练样本训练逻辑回归模型 
..　批梯度下降法 
..　随机梯度下降法 
第章　神经网络 
.　神经网络概述 
..　感知机和神经元 
..　激活函数 
..　神经网络与深度学习 
..　多个样本的正向计算 
..　输出 
..　损失函数 
..　基于数值梯度的神经网络训练 
.　反向求导 
..　正向计算和反向求导 
..　计算图 
..　损失函数关于输出的梯度 
..　层神经网络的反向求导 
..　层神经网络的Python实现 
..　任意层神经网络的反向求导 
.　实现一个简单的深度学习框架 
..　神经网络的训练过程 
..　网络层的代码实现 
..　网络层的梯度检验 
..　神经网络的类 
..　神经网络的梯度检验 
..　基于深度学习框架的MNIST手写数字识别 
..　改进的通用神经网络框架：分离加权和与激活函数 
..　独立的参数优化器 
..　fashion-mnist的分类训练 
..　读写模型参数 
第章　改进神经网络性能的基本技巧 
.　数据处理 
..　数据增强 
..　规范化 
..　特征工程 
.　参数调试 
..　权重初始化 
..　优化参数 
.　批规范化 
..　什么是批规范化 
..　批规范化的反向求导 
..　批规范化的代码实现 
.　正则化 
..　权重正则化 
..　Dropout 
..　早停法 
.　梯度爆炸和梯度消失 
第章　卷积神经网络 
.　卷积入门 
..　什么是卷积 
..　一维卷积 
..　二维卷积 
..　多通道输入和多通道输出 
..　池化 
.　卷积神经网络概述 
..　全连接神经元和卷积神经元 
..　卷积层和卷积神经网络 
..　卷积层和池化层的反向求导及代码实现 
..　卷积神经网络的代码实现 
.　卷积的矩阵乘法 
..　一维卷积的矩阵乘法 
..　二维卷积的矩阵乘法 
..　一维卷积反向求导的矩阵乘法 
..　二维卷积反向求导的矩阵乘法 
.　基于坐标索引的快速卷积 
.　典型卷积神经网络结构 
..　LeNet- 
..　AlexNet 
..　VGG 
..　残差网络 
..　Inception网络 
..　NiN 
第章　循环神经网络 
.　序列问题和模型 
..　股票价格预测问题 
..　概率序列模型和语言模型 
..　自回归模型 
..　生成自回归数据 
..　时间窗方法 
..　时间窗采样 
..　时间窗方法的建模和训练 
..　长期预测和短期预测 
..　股票价格预测的代码实现 
..　k-gram语言模型 
.　循环神经网络基础 
..　无记忆功能的非循环神经网络 
..　具有记忆功能的循环神经网络 
.　穿过时间的反向传播 
.　单层循环神经网络的实现 
..　初始化模型参数 
..　正向计算 
..　损失函数 
..　反向求导 
..　梯度验证 
..　梯度下降训练 
..　序列数据的采样 
..　序列数据的循环神经网络训练和预测 
.　循环神经网络语言模型和文本的生成 
..　字符表 
..　字符序列样本的采样 
..　模型的训练和预测 
.　循环神经网络中的梯度爆炸和梯度消失 
.　长短期记忆网络 
..　LSTM的神经元 
..　LSTM的反向求导 
..　LSTM的代码实现 
..　LSTM的变种 
.　门控循环单元 
..　门控循环单元的工作原理 
..　门控循环单元的代码实现 
.　循环神经网络的类及其实现 
..　用类实现循环神经网络 
..　循环神经网络单元的类实现 
.　多层循环神经网络和双向循环神经网络 
..　多层循环神经网络 
..　多层循环神经网络的训练和预测 
..　双向循环神经网络 
.　SeqSeq模型 
..　机器翻译概述 
..　SeqSeq模型的实现 
..　字符级的SeqSeq模型 
..　基于WordVec的SeqSeq模型 
..　基于词嵌入层的SeqSeq模型 
..　注意力机制 
第章　生成模型 
.　生成模型概述 
.　自动编码器 
..　什么是自动编码器 
..　稀疏编码器 
..　自动编码器的代码实现 
.　变分自动编码器 
..　什么是变分自动编码器 
..　变分自动编码器的损失函数 
..　变分自动编码器的参数重采样 
..　变分自动编码器的反向求导 
..　变分自动编码器的代码实现 
.　生成对抗网络 
..　生成对抗网络的原理 
..　生成对抗网络训练过程的代码实现 
.　生成对抗网络建模实例 
..　一组实数的生成对抗网络建模 
..　二维坐标点的生成对抗网络建模 
..　MNIST手写数字集的生成对抗网络建模 
..　生成对抗网络的训练技巧 
.　生成对抗网络的损失函数及其概率解释 
..　生成对抗网络的损失函数的全局最优解 
..　Kullback-Leibler散度和Jensen-Shannon散度 
..　生成对抗网络的最大似然解释 
.　改进的损失函数――Wasserstein GAN 
..　Wasserstein GAN的原理 
..　Wasserstein GAN的代码实现 
.　深度卷积对抗网络 
..　一维转置卷积 
..　二维转置卷积 
..　卷积对抗网络的代码实现 
参考文献 
・ ・ ・ ・ ・ ・ (收起)基础篇
第章 深度学习概述 
. 深度学习发展简史 
. 有监督学习 
.. 图像分类 
.. 目标检测 
.. 人脸识别 
.. 语音识别 
. 无监督学习 
.. 无监督学习概述 
.. 生成对抗网络 
. 强化学习 
.. AlphaGo 
.. AlphaGo Zero 
. 小结 
参考文献 
第章 深度神经网络 
. 神经元 
. 感知机 
. 前向传递 
.. 前向传递的流程 
.. 激活函数 
.. 损失函数 
. 后向传递 
.. 后向传递的流程 
.. 梯度下降 
.. 参数修正 
. 防止过拟合 
.. dropout 
.. 正则化 
. 小结 
第章 卷积神经网络 
. 卷积层 
.. valid 卷积 
.. full 卷积 
.. same 卷积 
. 池化层 
. 反卷积 
. 感受野 
. 卷积网络实例 
.. Lenet- 
.. AlexNet 
.. VGGNet 
.. GoogLeNet 
.. ResNet 
.. MobileNet 
. 小结 
进阶篇
第章 两阶段目标检测方法 
. R-CNN 
.. 算法流程 
.. 训练过程 
. SPP-Net 
.. 网络结构 
.. 空间金字塔池化 
. Fast R-CNN 
.. 感兴趣区域池化层 
.. 网络结构 
.. 全连接层计算加速 
.. 目标分类 
.. 边界框回归 
.. 训练过程 
. Faster R-CNN 
.. 网络结构 
.. RPN 
.. 训练过程 
. R-FCN 
.. R-FCN 网络结构 
.. 位置敏感的分数图 
.. 位置敏感的RoI 池化 
.. R-FCN 损失函数 
.. Caffe 网络模型解析 
. Mask R-CNN 
.. 实例分割简介 
.. COCO 数据集的像素级标注 
.. 网络结构 
.. U-Net 
.. SegNet 
. 小结 
第章 单阶段目标检测方法 
. SSD 
.. default box 
.. 网络结构 
.. Caffe 网络模型解析 
.. 训练过程 
. RetinaNet 
.. FPN 
.. 聚焦损失函数 
. RefineDet 
.. 网络模型 
.. Caffe 网络模型解析 
.. 训练过程 
. YOLO 
.. YOLO v 
.. YOLO v 
.. YOLO v 
. 目标检测算法应用 
.. 高速公路坑洞检测 
.. 息肉检测 
. 小结 
应用篇
第章 肋骨骨折检测 
. 国内外研究现状 
. 解决方案 
. 预处理 
. 肋骨骨折检测 
. 实验结果分析 
. 小结 
参考文献 
第章 肺结节检测 
. 国内外研究现状 
.. 肺结节可疑位置推荐算法 
.. 假阳性肺结节抑制算法 
. 总体框架 
.. 肺结节数据集 
.. 肺结节检测难点 
.. 算法框架 
. 肺结节可疑位置推荐算法 
.. CT图像的预处理 
.. 肺结节分割算法 
.. 优化方法 
.. 推断方法 
. 可疑肺结节定位算法 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
. 假阳性肺结节抑制算法 
.. 假阳性肺结节抑制网络 
.. 优化策略 
.. 推断策略 
. 实验结果与分析 
.. 实验结果 
.. 改进点效果分析 
.. 可疑位置推荐与假阳抑制算法整合 
. 小结 
参考文献 
第章 车道线检测 
. 国内外研究现状 
. 主要研究内容 
.. 总体解决方案 
.. 各阶段概述 
. 车道线检测系统的设计与实现 
.. 车道线图像数据标注与筛选 
.. 车道线图片预处理 
.. 车道线分割模型训练 
.. 车道线检测 
.. 车道线检测结果 
. 车道线检测系统的性能测试 
.. 车道线检测质量测试 
.. 车道线检测时间测试 
. 小结 
参考文献 
第章 交通视频分析 
. 国内外研究现状 
. 主要研究内容 
.. 总体设计 
.. 精度和性能要求 
. 交通视频分析 
.. 车辆检测和车牌检测 
.. 车牌识别功能设计详解 
.. 车辆品牌及颜色的识别 
.. 目标跟踪设计详解 
. 系统测试 
.. 车辆检测 
.. 车牌检测 
.. 车牌识别 
.. 车辆品牌识别 
.. 目标跟踪 
. 小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)序言
前言
如何使用本书 ――写在第十次印刷之际
主要符号表
第章 绪论
. 引言
. 基本术语
. 假设空间
. 归纳偏好
. 发展历程
. 应用现状
. 阅读材料
习题
参考文献
休息一会儿
第章 模型评估与选择
. 经验误差与过拟合
. 评估方法
. 性能度量
. 比较检验
. 偏差与方差
. 阅读材料
习题
参考文献
休息一会儿
第章 线性模型
. 基本形式
. 线性回归
. 对数几率回归
. 线性判别分析
. 多分类学习
. 类别不平衡问题
. 阅读材料
习题
参考文献
休息一会儿
第章 决策树
. 基本流程
. 划分选择
. 剪枝处理
. 连续与缺失值
. 多变量决策树
. 阅读材料
习题
参考文献
休息一会儿
第章 神经网络
. 神经元模型
. 感知机与多层网络
. 误差逆传播算法
. 全局最小与局部极小
. 其他常见神经网络
. 深度学习
. 阅读材料
习题
参考文献
休息一会儿
第章 支持向量机
. 间隔与支持向量
. 对偶问题
. 核函数
. 软间隔与正则化
. 支持向量回归
. 核方法
. 阅读材料
习题
参考文献
休息一会儿
第章 贝叶斯分类器
. 贝叶斯决策论
. 极大似然估计
. 朴素贝叶斯分类器
. 半朴素贝叶斯分类器
. 贝叶斯网
. EM算法
. 阅读材料
习题
参考文献
休息一会儿
第章 集成学习
. 个体与集成
. Boosting
. Bagging与随机森林
. 结合策略
. 多样性
. 阅读材料
习题
参考文献
休息一会儿
第章 聚类
. 聚类任务
. 性能度量
. 距离计算
. 原型聚类
. 密度聚类
. 层次聚类
. 阅读材料
习题
参考文献
休息一会儿
第章 降维与度量学习
. k近邻学习
. 低维嵌入
. 主成分分析
. 归纳偏好
. 流形学习
. 度量学习
. 阅读材料
习题
参考文献
休息一会儿
第章 特征选择与稀疏学习
. 子集搜索与评价
. 过滤式选择
.包裹式选择
. 嵌入式选择与L正则化
. 稀疏表示与字典学习
. 压缩感知
. 阅读材料
习题
参考文献
休息一会儿
第章 计算学习理论
. 基础知识
. PAC学习
. 有限假设空间
. VC维
. Rademacher复杂度
. 稳定性
. 阅读材料
习题
参考文献
休息一会儿
第章 半监督学习
. 未标记样本
. 生成式方法
. 半监督SVM
. 图半监督学习
. 基于分歧的方法
. 半监督聚类
. 阅读材料
习题
参考文献
休息一会儿
第章 概率图模型
. 隐马尔可夫模型
. 马尔可夫随机场
. 条件随机场
.学习与推断
. 近似推断
. 话题模型
. 阅读材料
习题
参考文献
休息一会儿
第章 规则学习
. 基本概念
. 序贯覆盖
. 剪枝优化
. 一阶规则学习
. 归纳逻辑程序设计
. 阅读材料
习题
参考文献
休息一会儿
第章 强化学习
. 任务与奖赏
. K-摇臂赌博机
. 有模型学习
. 免模型学习
. 值函数近似
. 模仿学习
. 阅读材料
习题
参考文献
休息一会儿
附录
A 矩阵
B 优化
C 概率分布
后记
・ ・ ・ ・ ・ ・ (收起)前言 
第一部分 机器学习的基础知识 
第  章 机器学习概览
 . 什么是机器学习 
. 为什么使用机器学习 
. 机器学习的应用示例 
. 机器学习系统的类型 
. 机器学习的主要挑战 
. 测试与验证 
. 练习题 
第  章 端到端的机器学习项目 
. 使用真实数据
 . 观察大局 
. 获取数据 
. 从数据探索和可视化中获得洞见 
. 机器学习算法的数据准备 
. 选择和训练模型 
. 微调模型 
. 启动、监控和维护你的系统 .
. 试试看 
. 练习题 
第  章 分类 
. MNIST 
. 训练二元分类器 
. 性能测量 
. 多类分类器 
. 误差分析 
. 多标签分类 
. 多输出分类 
. 练习题 
第  章 训练模型 
. 线性回归 
. 梯度下降 
. 多项式回归 
. 学习曲线 
. 正则化线性模型 
. 逻辑回归 
. 练习题 
第  章 支持向量机 
. 线性 SVM 分类 
. 非线性 SVM 分类 
. SVM 回归 
. 工作原理 
. 练习题 
第  章 决策树 
. 训练和可视化决策树 
. 做出预测 
. 估计类概率 
. CART 训练算法 
. 计算复杂度 
. 基尼不纯度或熵 
. 正则化超参数 
. 回归 
. 不稳定性 
. 练习题 
第  章 集成学习和随机森林 
. 投票分类器 
. bagging 和 pasting 
. 随机补丁和随机子空间 
. 随机森林 
. 提升法 
. 堆叠法 
. 练习题 
第  章 降维 
. 维度的诅咒 
. 降维的主要方法 
. PCA 
. 内核 PCA . 
. LLE 
. 其他降维技术 
. 练习题 
第  章 无监督学习技术 
. 聚类 
. 高斯混合模型 
. 练习题 
第二部分 神经网络与深度学习 
第  章 Keras 人工神经网络简介 
. 从生物神经元到人工神经元 
. 使用 Keras 实现 MLP 
. 微调神经网络超参数 
. 练习题 
第  章 训练深度神经网络 
. 梯度消失与梯度爆炸问题 
. 重用预训练层 
. 更快的优化器 
. 通过正则化避免过拟合 
. 总结和实用指南 
. 练习题 
第  章 使用 TensorFlow 自定义模型和训练 
. TensorFlow 快速浏览 
. 像 NumPy 一样使用 TensorFlow 
. 定制模型和训练算法 
. TensorFlow 函数和图 
. 练习题 
第  章 使用 TensorFlow 加载和预处理数据 
. 数据 API 
. TFRecord 格式 
. 预处理输入特征 
. TF Transform 
. TensorFlow 数据集项目 
. 练习题 
第  章 使用卷积神经网络的深度计算机视觉 
. 视觉皮层的架构 
. 卷积层 
. 池化层 
. CNN 架构 
. 使用 Keras 实现 ResNet- CNN 
. 使用 Keras 的预训练模型 
. 迁移学习的预训练模型 
. 分类和定位 
. 物体检测 
. 语义分割 
. 练习题 
第  章 使用 RNN 和 CNN 处理序列 
. 循环神经元和层 
. 训练 RNN 
. 预测时间序列 
. 处理长序列 
. 练习题 
第  章 使用 RNN 和注意力机制进行自然语言处理 
. 使用字符 RNN 生成莎士比亚文本 
. 情感分析 
. 神经机器翻译的编码器 - 解码器网络 
. 注意力机制 
. 最近语言模型的创新 
. 练习题 ... 
第  章 使用自动编码器和 GAN 的表征学习和生成学习 
. 有效的数据表征 
. 使用不完整的线性自动编码器执行 PCA 
. 堆叠式自动编码器 
. 卷积自动编码器 
. 循环自动编码器 
. 去噪自动编码器 
. 稀疏自动编码器 
. 变分自动编码器 
. 生成式对抗网络 
. 练习题 
第  章 强化学习 
. 学习优化奖励 
. 策略搜索 
. OpenAI Gym 介绍 
. 神经网络策略 
. 评估动作：信用分配问题 
. 策略梯度 
. 马尔可夫决策过程 
. 时序差分学习 
. Q 学习 
. 实现深度 Q 学习 
. 深度 Q 学习的变体 
. TF-Agents 库 
. 一些流行的 RL 算法概述 
. 练习题 
第  章 大规模训练和部署TensorFlow 模型 
. 为 TensorFlow 模型提供服务 
. 将模型部署到移动端或嵌入式设备 
. 使用 GPU 加速计算 
. 跨多个设备的训练模型 
. 练习题 
. 致谢 
附录 A 课后练习题解答 .....
附录 B 机器学习项目清单 ..
附录 C SVM 对偶问题 
附录 D 自动微分 .
附录 E 其他流行的人工神经网络架构 ...
附录 F 特殊数据结构..
附录 G TensorFlow 图 ......
・ ・ ・ ・ ・ ・ (收起)引子：AI 菜鸟的挑战― 天上线智能预警系统
第壹 课 机器学习快速上手路径―唯有实战
． 机器学习的家族谱
．． 新手入门机器学习的 个好消息
．． 机器学习*是从数据中发现规律
．． 机器学习的类别―监督学习及其他
．． 机器学习的重要分支―深度学习
．． 机器学习新热点―强化学习
．． 机器学习的两大应用场景―回归与分类
．． 机器学习的其他应用场景
． 快捷的云实战学习模式
．． 在线学习平台上的机器学习课程
．． 用Jupyter Notebook 直接实战
．． 用Google Colab 开发第壹个机器学习程序
．． 在Kaggle 上参与机器学习竞赛
．． 在本机上“玩”机器学习
． 基本机器学习术语
．． 特征
．． 标签
．． 模型
． Python 和机器学习框架
．． 为什么选择用Python
．． 机器学习和深度学习框架
． 机器学习项目实战架构
．． 第壹 个环节：问题定义
．． 第 个环节：数据的收集和预处理
．． 第 个环节：选择机器学习模型
．． 第 个环节：训练机器，确定参数
．． 第 个环节：超参数调试和性能优化
． 本课内容小结
． 课后练习
第 课 数学和Python 基础知识―*天搞定
． 函数描述了事物间的关系
．． 什么是函数
．． 机器学习中的函数
． 捕捉函数的变化趋势
．． 连续性是求导的前提条件
．． 通过求导发现y 如何随x 而变
．． 凸函数有一个全局*低点
． 梯度下降是机器学习的动力之源
．． 什么是梯度
．． 梯度下降：下山的隐喻
．． 梯度下降有什么用
． 机器学习的数据结构―张量
．． 张量的轴、阶和形状
．． 标量―D（阶）张量
．． 向量―D（阶）张量
．． 矩阵―D（阶）张量
．． 序列数据 ―D（阶）张量
．． 图像数据 ―D（阶）张量
．． 视频数据―D（阶）张量
．． 数据的维度和空间的维度
． Python 的张量运算
．． 机器学习中张量的创建
．． 通过索引和切片访问张量中的数据
．． 张量的整体操作和逐元素运算
．． 张量的变形和转置
．． Python 中的广播
．． 向量和矩阵的点积运算
． 机器学习的几何意义
．． 机器学习的向量空间
．． 深度学习和数据流形
． 概率与统计研究了随机事件的规律
．． 什么是概率
．． 正态分布
．． 标准差和方差
． 本课内容小结
． 课后练习
第 课 线性回归―预测网店的销售额
． 问题定义：小冰的网店广告该如何投放
． 数据的收集和预处理
．． 收集网店销售额数据
．． 数据读取和可视化
．． 数据的相关分析
．． 数据的散点图
．． 数据集清洗和规范化
．． 拆分数据集为训练集和测试集
．． 把数据归一化
． 选择机器学习模型
．． 确定线性回归模型
．． 假设（预测）函数―h （x ）
．． 损失（误差）函数―L （w ，b ）
． 通过梯度下降找到*佳参数
．． 训练机器要有正确的方向
．． 凸函数确保有*小损失点
．． 梯度下降的实现
．． 学习速率也很重要
． 实现一元线性回归模型并调试超参数
．． 权重和偏置的初始值
．． 进行梯度下降
．． 调试学习速率
．． 调试迭代次数
．． 在测试集上进行预测
．． 用轮廓图描绘L 、w 和b 的关系
． 实现多元线性回归模型
．． 向量化的点积运算
．． 多变量的损失函数和梯度下降
．． 构建一个线性回归函数模型
．． 初始化权重并训练机器
． 本课内容小结
． 课后练习
第 课 逻辑回归―给病患和鸢尾花分类
． 问题定义：判断客户是否患病
． 从回归问题到分类问题
．． 机器学习中的分类问题
．． 用线性回归+ 阶跃函数完成分类
．． 通过Sigmiod 函数进行转换
．． 逻辑回归的假设函数
．． 逻辑回归的损失函数
．． 逻辑回归的梯度下降
． 通过逻辑回归解决二元分类问题
．． 数据的准备与分析
．． 建立逻辑回归模型
．． 开始训练机器
．． 测试分类结果
．． 绘制损失曲线
．． 直接调用Sklearn 库
．． 哑特征的使用
． 问题定义：确定鸢尾花的种类
． 从二元分类到多元分类
．． 以一对多
．． 多元分类的损失函数
． 正则化、欠拟合和过拟合
．． 正则化
．． 欠拟合和过拟合
．． 正则化参数
． 通过逻辑回归解决多元分类问题
．． 数据的准备与分析
．． 通过Sklearn 实现逻辑回归的多元分类
．． 正则化参数―C 值的选择
． 本课内容小结
． 课后练习
第 课 深度神经网络―找出可能流失的客户
． 问题定义：咖哥接手的金融项目
． 神经网络的原理
．． 神经网络极简史
．． 传统机器学习算法的局限性
．． 神经网络的优势
． 从感知器到单隐层网络
．． 感知器是*基本的神经元
．． 假设空间要能覆盖特征空间
．． 单神经元特征空间的局限性
．． 分层：加入一个网络隐层
． 用Keras 单隐层网络预测客户流失率
．． 数据的准备与分析
．． 先尝试逻辑回归算法
．． 单隐层神经网络的Keras 实现
．． 训练单隐层神经网络
．． 训练过程的图形化显示
． 分类数据不平衡问题：只看准确率够用吗
．． 混淆矩阵、精que率、召回率和F 分数
．． 使用分类报告和混淆矩阵
．． 特征缩放的魔力
．． 阈值调整、欠采样和过采样
． 从单隐层神经网络到深度神经网络
．． 梯度下降：正向传播和反向传播
．． 深度神经网络中的一些可调超参数
．． 梯度下降优化器
．． 激活函数：从Sigmoid 到ReLU
．． 损失函数的选择
．． 评估指标的选择
． 用Keras 深度神经网络预测客户流失率
．． 构建深度神经网络
．． 换一换优化器试试
．． 神经网络正则化：添加Dropout 层
． 深度神经网络的调试及性能优化
．． 使用回调功能
．． 使用TensorBoard
．． 神经网络中的过拟合
．． 梯度消失和梯度bao炸
． 本课内容小结
． 课后练习
第课 卷积神经网络―识别狗狗的图像
． 问题定义：有趣的狗狗图像识别
． 卷积网络的结构
． 卷积层的原理
．． 机器通过“模式”进行图像识别
．． 平移不变的模式识别
．． 用滑动窗口抽取局部特征
．． 过滤器和响应通道
．． 对特征图进行卷积运算
．． 模式层级结构的形成
．． 卷积过程中的填充和步幅
． 池化层的功能
． 用卷积网络给狗狗图像分类
．． 图像数据的读入
．． 构建简单的卷积网络
．． 训练网络并显示误差和准确率
． 卷积网络性能优化
．． 第壹招：更新优化器并设置学习速率
．． 第招：添加Dropout 层
．． “大杀器”：进行数据增强
． 卷积网络中特征通道的可视化
． 各种大型卷积网络模型
．． 经典的VGGNet
．． 采用Inception 结构的GoogLeNet
．． 残差网络ResNet
． 本课内容小结
． 课后练习
第 课 循环神经网络―鉴定留言及探索系外行星
． 问题定义：鉴定评论文本的情感属性
． 循环神经网络的原理和结构
．． 什么是序列数据
．． 前馈神经网络处理序列数据的局限性
．． 循环神经网络处理序列问题的策略
．． 循环神经网络的结构
． 原始文本如何转化成向量数据
．． 文本的向量化：分词
．． 通过One-hot 编码分词
．． 词嵌入
． 用SimpleRNN 鉴定评论文本
．． 用Tokenizer 给文本分词
．． 构建包含词嵌入的SimpleRNN
．． 训练网络并查看验证准确率
． 从SimpleRNN 到LSTM
．． SimpleRNN 的局限性
．． LSTM 网络的记忆传送带
． 用LSTM 鉴定评论文本
． 问题定义：太阳系外哪些恒星有行星环绕
． 用循环神经网络处理时序问题
．． 时序数据的导入与处理
．． 建模：CNN 和RNN 的组合
．． 输出阈值的调整
．． 使用函数式API
． 本课内容小结
． 课后练习
第 课 经典算法“宝刀未老”
． K *近邻
． 支持向量机
． 朴素贝叶斯
． 决策树
．． 熵和特征节点的选择
．． 决策树的深度和剪枝
． 随机森林
． 如何选择*佳机器学习算法
． 用网格搜索超参数调优
． 本课内容小结
． 课后练习
第 课 集成学习“笑傲江湖”
． 偏差和方差―机器学习性能优化的风向标
．． 目标：降低偏差与方差
．． 数据集大小对偏差和方差的影响
．． 预测空间的变化带来偏差和方差的变化
． Bagging 算法―多个基模型的聚合
．． 决策树的聚合
．． 从树的聚合到随机森林
．． 从随机森林到ji端随机森林
．． 比较决策树、树的聚合、随机森林、ji端随机森林的效率
． Boosting 算法―锻炼弱模型的“肌肉”
．． AdaBoost 算法
．． 梯度提升算法
．． XGBoost 算法
．． Bagging 算法与Boosting 算法的不同之处
． Stacking/Blending 算法―以预测结果作为新特征
．． Stacking 算法
．． Blending 算法
． Voting/Averaging 算法―集成基模型的预测结果
．． 通过Voting 进行不同算法的集成
．． 通过Averaging 集成不同算法的结果
． 本课内容小结
． 课后练习
第壹 课 监督学习之外―其他类型的机器学习
． 无监督学习―聚类
．． K 均值算法
．． K 值的选取：手肘法
．． 用聚类辅助理解营销数据
． 无监督学习―降维
．． PCA 算法
．． 通过PCA 算法进行图像特征采样
． 半监督学习
．． 自我训练
．． 合作训练
．． 半监督聚类
． 自监督学习
．． 潜隐空间
．． 自编码器
．． 变分自编码器
． 生成式学习
．． 机器学习的生成式
．． 生成式对抗网络
． 本课内容小结
． 课后练习
第壹 课 强化学习实战―咖哥的冰湖挑战
． 问题定义：帮助智能体完成冰湖挑战
． 强化学习基础知识
．． 延迟满足
．． 更复杂的环境
．． 强化学习中的元素
．． 智能体的视角
． 强化学习基础算法Q-Learning 详解
．． 迷宫游戏的示例
．． 强化学习中的局部*优
．． ε -Greedy 策略
．． Q-Learning 算法的伪代码
． 用Q-Learning 算法来解决冰湖挑战问题
．． 环境的初始化
．． Q-Learning 算法的实现
．． Q-Table 的更新过程
． 从Q-Learning 算法到SARSA算法
．． 异策略和同策略
．． SARSA 算法的实现
． 用SARSA 算法来解决冰湖挑战问题
． Deep Q Network 算法：用深度网络实现Q-Learning
． 本课内容小结
． 课后练习
尾声：如何实现机器学习中的知识迁移及持续性的学习
练习答案
・ ・ ・ ・ ・ ・ (收起)目 录
草  蒲 血 督 学 习
第  章 机器学习及监督学习概论 
. 机器学习 
. 机器学习的分类 
.. 基本分类 
.. 按模型分类 
.. 按算法分类 
.. 按技巧分类 
. 机器学习方法主要素 
.. 模型 
.. 策略 
.. 算法 
. 模型评估与模型选择 
.. 训练误差与测试误差 
.. 过拟合与模型选择 
. 正则化与交叉验证 
.. 正则化 
.. 交叉验证 
. 泛化能力 
.. 泛化误差 
.. 泛化误差上界 
. 生成模型与判别模型 
. 监督学习应用 
.. 分类问题 
.. 标注问题 
.. 回归问题 
本章概要 
继续阅读 
习题 
参考文献 
VIII 机器学习方法
第  章 感知机 
. 感知机模型 
. 感知机学习策略 
.. 数据集的线性可分性 
.. 感知机学习策略 
. 感知机学习算法 
.. 感知机学习算法的原始形式 
.. 算法的收敛性 
.. 感知机学习算法的对偶形式 
本章概要 
继续阅读 
习题 
参考文献 
第  章 k 近邻法 
. k 近邻算法 
. k 近邻模型 
.. 模型 
.. 距离度量 
.. k 值的选择 
.. 分类决策规则 
. k 近邻法的实现：kd 树 
.. 构造 kd 树 
.. 搜索 kd 树 
本章概要 
继续阅读 
习题 
参考文献 
第  章 朴素贝叶斯法 
. 朴素贝叶斯法的学习与分类 
.. 基本方法 
.. 后验概率最大化的含义 
. 朴素贝叶斯法的参数估计 
.. 极大似然估计 
.. 学习与分类算法 
.. 贝叶斯估计 
本章概要 
继续阅读 
目录 IX
习题 
参考文献 
第  章 决策树 
. 决策树模型与学习 
.. 决策树模型 
.. 决策树与 if-then 规则 
.. 决策树与条件概率分布 
.. 决策树学习 
. 特征选择 
.. 特征选择问题 
.. 信息增益 
.. 信息增益比 
. 决策树的生成 
.. ID 算法 
.. C. 的生成算法 
. 决策树的剪枝 
. CART 算法 
.. CART 生成 
.. CART 剪枝 
本章概要 
继续阅读 
习题 
参考文献 
第  章 逻辑斯谛回归与最大烟模型 
. 逻辑斯谛回归模型 
.. 逻辑斯谛分布 
.. 二项逻辑斯谛回归模型 
.. 模型参数估计 
.. 多项逻辑斯谛回归 
. 最大煽模型 
.. 最大煽原理 
.. 最大煽模型的定义 
.. 最大煽模型的学习 
.. 极大似然估计 
. 模型学习的最优化算法 
.. 改进的迭代尺度法 
.. 拟牛顿法 
X 机器学习方法
本章概要 
继续阅读 
习题 
参考文献 
第  章 支持向量机 
. 线性可分支持向量机与硬间隔最大化 
.. 线性可分支持向量机 
.. 函数间隔和儿何间隔 
.. 间隔最大化 
.. 学习的对偶算法 
. 线性支持向量机与软间隔最大化 
.. 线性支持向量机 
.. 学习的对偶算法 
.. 支持向量 
.. 合页损失函数 
. 非线性支持向量机与核函数 
.. 核技巧 
.. 正定核 
.. 常用核函数 
.. 非线性支持向量分类机 
. 序列最小最优化算法 
.. 两个变量二次规划的求解方法 
.. 变量的选择方法 
.. SMO 算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 Boosting 
AdaBoost 算法 
.. Boosting 的基本思路 
AdaBoost 算法 
AdaBoost 的例子 
. AdaBoost 算法的训练误差分析 
. AdaBoost 算法的解释 
.. 前向分步算法 
.. 前向分步算法与 AdaBoost 
目录 XI
. 提升树 
.. 提升树模型 
.. 提升树算法 
.. 梯度提升 
本章概要 
继续阅读 
习题 
参考文献 
第  章 EM 算法及其推广 
. EM 算法的引入 
.. EM 算法 
.. EM 算法的导出 
.. EM 算法在无监督学习中的应用 
. EM 算法的收敛性 
. EM 算法在高斯混合模型学习中的应用 
.. 高斯混合模型 
.. 高斯混合模型参数估计的 EM 算法 
. EM 算法的推广 
.. F 函数的极大-极大算法 
.. GEM 算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 隐马尔可夫模型 
. 隐马尔可夫模型的基本概念 
.. 隐马尔可夫模型的定义 
.. 观测序列的生成过程 
.. 隐马尔可夫模型的  个基本问题 
. 概率计算算法 
.. 直接计算法 
.. 前向算法 
.. 后向算法 
.. 一些概率与期望值的计算 
. 学习算法 
.. 监督学习方法 
.. Baum-Welch 算法 
XII 机器学习方法
.. Baum-Welch 模型参数估计公式 
. 预测算法 
.. 近似算法 
.. 维特比算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 条件随机场 
. 概率无向图模型 
.. 模型定义 
.. 概率无向图模型的因子分解 
. 条件随机场的定义与形式 
.. 条件随机场的定义 
.. 条件随机场的参数化形式 
.. 条件随机场的简化形式 
.. 条件随机场的矩阵形式 
. 条件随机场的概率计算问题 
.. 前向-后向算法 
.. 概率计算 
.. 期望值的计算 
. 条件随机场的学习算法 
.. 改进的迭代尺度法 
.. 拟牛顿法 
. 条件随机场的预测算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 监督学习方法总结 
草  蒲 元元血血督学学习习
第  章 无监督学习概论 
. 无监督学习基本原理 
. 基本问题 
. 机器学习主要素 
. 无监督学习方法 
目录 XIII
本章概要 
继续阅读 
参考文献 
第  章 聚类方法 
. 聚类的基本概念 
.. 相似度或距离 
.. 类或簇 
.. 类与类之间的距离 
. 层次聚类 
. k 均值聚类 
.. 模型 
.. 策略 
.. 算法 
.. 算法特性 
本章概要 
继续阅读 
习题 
参考文献 
第  章 奇异值分解 
. 奇异值分解的定义与性质 
.. 定义与定理 
.. 紧奇异值分解与截断奇异值分解 
.. 儿何解释 
.. 主要性质 
. 奇异值分解的计算 
. 奇异值分解与矩阵近似 
.. 弗罗贝尼乌斯范数 
.. 矩阵的最优近似 
.. 矩阵的外积展开式 
本章概要 
继续阅读 
习题 
参考文献 
第  章 主成分分析 
. 总体主成分分析 
.. 基本想法 
XIV 机器学习方法
.. 定义和导出 
.. 主要性质 
.. 主成分的个数 
.. 规范化变量的总体主成分 
. 样本主成分分析 
.. 样本主成分的定义和性质 
.. 相关矩阵的特征值分解算法 
.. 数据矩阵的奇异值分解算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 潜在语义分析 
. 单词向量空间与话题向量空间 
.. 单词向量空间 
.. 话题向量空间 
. 潜在语义分析算法 
.. 矩阵奇异值分解算法 
.. 例子 
. 非负矩阵分解算法 
.. 非负矩阵分解 
.. 潜在语义分析模型 
.. 非负矩阵分解的形式化 
.. 算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 概率潜在语义分析 
. 概率潜在语义分析模型 
.. 基本想法 
.. 生成模型 
.. 共现模型 
.. 模型性质 
. 概率潜在语义分析的算法 
本章概要 
继续阅读 
目录 XV
习题 
参考文献 
第  章 马尔可夫链蒙特卡罗法 
. 蒙特卡罗法 
.. 随机抽样 
.. 数学期望估计 
.. 积分计算 
. 马尔可夫链 
.. 基本定义 
.. 离散状态马尔可夫链 
.. 连续状态马尔可夫链 
.. 马尔可夫链的性质 
. 马尔可夫链蒙特卡罗法 
.. 基本想法 
.. 基本步骤 
.. 马尔可夫链蒙特卡罗法与统计学习 
Metropolis-Hastings 算法 
.. 基本原理 
Metropolis-Hastings 算法 
单分量 Metropolis-Hastings 算法 
. 吉布斯抽样 
.. 基本原理 
.. 吉布斯抽样算法 
.. 抽样计算 
本章概要 
继续阅读 
习题 
参考文献 
第  章 潜在狄利克雷分配 
. 狄利克雷分布 
.. 分布定义 
.. 共辄先验 
. 潜在狄利克雷分自模型 
.. 基本想法 
.. 模型定义 
.. 概率图模型 
.. 随机变量序列的可交换性 
XVI 机器学习方法
.. 概率公式 
. LDA 的吉布斯抽样算法 
.. 基本想法 
.. 算法的主要部分 
.. 算法的后处理 
.. 算法 
. LDA 的变分 EM 算法 
.. 变分推理 
.. 变分 EM 算法 
.. 算法推导 
.. 算法总结 
本章概要 
继续阅读 
习题 
参考文献 
第  章 PageRank 算法 
PageRank 的定义 
.. 基本想法 
.. 有向图和随机游走模型 
.. PageRank 的基本定义 
.. PageRank 的一般定义 
PageRank 的计算 
.. 迭代算法 
.. 幕法 
.. 代数算法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 无监督学习方法总结 
. 无监督学习方法的关系和特点 
.. 各种方法之间的关系 
.. 无监督学习方法 
.. 基础机器学习方法 
. 话题模型之间的关系和特点 
参考文献 
目录 XVII
草  蒲 深 反 学 习
第  章 前馈神经网络 
. 前馈神经网络的模型 
.. 前馈神经网络定义 
.. 前馈神经网络的例子 
.. 前馈神经网络的表示能力 
. 前馈神经网络的学习算法 
.. 前馈神经网络学习 
.. 前馈神经网络学习的优化算法 
.. 反向传播算法 
.. 在计算图上的实现 
.. 算法的实现技巧 
. 前馈神经网络学习的正则化 
.. 深度学习中的正则化 
.. 早停法 
.. 暂返法 
本章概要 
继续阅读 
习题 
参考文献 
第  章 卷积神经网络 
. 卷积神经网络的模型 
.. 背景 
.. 卷积 
.. 汇聚 
.. 卷积神经网络 
.. 卷积神经网络性质 
. 卷积神经网络的学习算法 
.. 卷积导数 
.. 反向传播算法 
. 图像分类中的应用 
.. AlexNet 
.. 残差网络 
本章概要 
继续阅读 
习题 
参考文献 
XVIII 机器学习方法
第  章 循环神经网络 
. 简单循环神经网络 
.. 模型 
.. 学习算法 
. 常用循环神经网络 
.. 长短期记忆网络 
.. 门控循环单元网络 
.. 深度循环神经网络 
.. 双向循环神经网络 
. 自然语言生成中的应用 
.. 词向量 
.. 语言模型与语言生成 
本章概要 
继续阅读 
习题 
参考文献 
第  章 序列到序列模型 
. 序列到序列基本模型 
.. 序列到序列学习 
.. 基本模型 
RNN Search 模型 
.. 注意力 
.. 模型定义 
.. 模型特点 
Transformer 模型 
.. 模型架构 
.. 模型特点 
本章概要 
继续阅读 
习题 
参考文献 
第  章 预训练语言模型 
. GPT 模型 
.. 预训练语言模型 
.. 模型和学习 
. BERT 模型 
.. 去噪自动编码器 
.. 模型和学习 
目录 XIX
.. 模型特点 
本章概要 
继续阅读 
习题 
参考文献 
第  章 生成对抗网络 
. GAN 基本模型 
.. 模型 
.. 学习算法 
.. 理论分析 
. 图像生成中的应用 
.. 转置卷积 
.. DCGAN 
本章概要 
继续阅读 
习题 
参考文献 
第  章 深度学习方法总结 
. 深度学习的模型 
. 深度学习的方法 
. 深度学习的优化算法 
. 深度学习的优缺点 
参考文献 
附录 A 梯度下降法 
附录 B 牛顿法和拟牛顿法 
附录 C 拉格朗日对偶性 
附录 D 矩阵的基本子空间 
附录 E KL 散度的定义和狄利克雷分布的性质 
附录 F 软最大化函数的偏导数和交叉烟损失函数的偏导数 
索引 
・ ・ ・ ・ ・ ・ (收起)目录
前言 ix
第  章　引言 
.　为何选择机器学习 
..　机器学习能够解决的问题 
..　熟悉任务和数据 
.　为何选择Python 
.　scikit-learn 
.　必要的库和工具 
..　Jupyter Notebook 
..　NumPy 
..　SciPy 
..　matplotlib 
..　pandas 
..　mglearn 
.　Python  与Python  的对比 
.　本书用到的版本 
.　第 一个应用：鸢尾花分类 
..　初识数据 
..　衡量模型是否成功：训练数据与测试数据 
..　要事第 一：观察数据 
..　构建第 一个模型：k 近邻算法 
..　做出预测 
..　评估模型 
.　小结与展望 
第  章　监督学习 
.　分类与回归 
.　泛化、过拟合与欠拟合 
.　监督学习算法 
..　一些样本数据集 
..　k 近邻 
..　线性模型 
..　朴素贝叶斯分类器 
..　决策树 
..　决策树集成 
..　核支持向量机 
..　神经网络（深度学习） 
.　分类器的不确定度估计 
..　决策函数 
..　预测概率 
..　多分类问题的不确定度 
.　小结与展望 
第 章　无监督学习与预处理 
.　无监督学习的类型 
.　无监督学习的挑战 
.　预处理与缩放 
..　不同类型的预处理 
..　应用数据变换 
..　对训练数据和测试数据进行相同的缩放 
..　预处理对监督学习的作用 
.　降维、特征提取与流形学习 
..　主成分分析 
..　非负矩阵分解 
..　用t-SNE 进行流形学习 
.　聚类 
..　k 均值聚类 
..　凝聚聚类 
..　DBSCAN 
..　聚类算法的对比与评估 
..　聚类方法小结 
.　小结与展望 
第 章　数据表示与特征工程 
.　分类变量 
..　One-Hot 编码（虚拟变量） 
..　数字可以编码分类变量 
.　分箱、离散化、线性模型与树 
.　交互特征与多项式特征 
.　单变量非线性变换 
.　自动化特征选择 
..　单变量统计 
..　基于模型的特征选择 
..　迭代特征选择 
.　利用专家知识 
.　小结与展望 
第 章　模型评估与改进 
.　交叉验证 
..　scikit-learn 中的交叉验证 
..　交叉验证的优点 
..　分层k 折交叉验证和其他策略 
.　网格搜索 
..　简单网格搜索 
..　参数过拟合的风险与验证集 
..　带交叉验证的网格搜索 
.　评估指标与评分 
..　牢记目标 
..　二分类指标 
..　多分类指标 
..　回归指标 
..　在模型选择中使用评估指标 
.　小结与展望 
第 章　算法链与管道 
.　用预处理进行参数选择 
.　构建管道 
.　在网格搜索中使用管道 
.　通用的管道接口 
..　用make_pipeline 方便地创建管道 
..　访问步骤属性 
..　访问网格搜索管道中的属性 
.　网格搜索预处理步骤与模型参数 
.　网格搜索选择使用哪个模型 
.　小结与展望 
第 章　处理文本数据 
.　用字符串表示的数据类型 
.　示例应用：电影评论的情感分析 
.　将文本数据表示为词袋 
..　将词袋应用于玩具数据集 
..　将词袋应用于电影评论 
.　停用词 
.　用tf-idf 缩放数据 
.　研究模型系数 
.　多个单词的词袋（n 元分词） 
.　分词、词干提取与词形还原 
.　主题建模与文档聚类 
.　小结与展望 
第 章　全书总结 
.　处理机器学习问题 
.　从原型到生产 
.　测试生产系统 
.　构建你自己的估计器 
.　下一步怎么走 
..　理论 
..　其他机器学习框架和包 
..　排序、推荐系统与其他学习类型 
..　概率建模、推断与概率编程 
..　神经网络 
..　推广到更大的数据集 
..　磨练你的技术 
.　总结 
关于作者 
关于封面 
・ ・ ・ ・ ・ ・ (收起)序（王斌 小米AI 实验室主任、NLP 首席科学家）
前言
主要符号表
第章 绪论
式(.)
式(.)
第章 模型评估与选择
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 线性模型
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 决策树
式(.)
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 神经网络
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
ii j 目录
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 支持向量机
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 贝叶斯分类器
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
附注
参考文献
第章 集成学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 聚类
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 降维与度量学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 特征选择与稀疏学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 计算学习理论
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
参考文献
第章 半监督学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 概率图模型
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 规则学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
第章 强化学习
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
式(.)
・ ・ ・ ・ ・ ・ (收起)序
前言
第章 概率思想：构建理论基础 
. 理论基石：条件概率、独立性与贝叶斯 
.. 从概率到条件概率 
.. 条件概率的具体描述 
.. 条件概率的表达式分析 
.. 两个事件的独立性 
.. 从条件概率到全概率公式 
.. 聚焦贝叶斯公式 
.. 本质内涵：由因到果，由果推因 
. 事件的关系：深入理解独立性 
.. 重新梳理两个事件的独立性 
.. 不相容与独立性 
.. 条件独立 
.. 独立与条件独立 
.. 独立重复实验 
第章 变量分布：描述随机世界 
. 离散型随机变量：分布与数字特征 
.. 从事件到随机变量 
.. 离散型随机变量及其要素 
.. 离散型随机变量的分布列 
.. 分布列和概率质量函数 
.. 二项分布及二项随机变量 
.. 几何分布及几何随机变量 
.. 泊松分布及泊松随机变量 
. 连续型随机变量：分布与数字特征 
.. 概率密度函数 
.. 连续型随机变量区间概率的计算 
.. 连续型随机变量的期望与方差 
.. 正态分布及正态随机变量 
.. 指数分布及指数随机变量 
.. 均匀分布及其随机变量 
. 多元随机变量（上）：联合、边缘与条件 
.. 实验中引入多个随机变量 
.. 联合分布列 
.. 边缘分布列 
.. 条件分布列 
.. 集中梳理核心的概率理论 
. 多元随机变量（下）：独立与相关 
.. 随机变量与事件的独立性 
.. 随机变量之间的独立性 
.. 独立性示例 
.. 条件独立的概念 
.. 独立随机变量的期望和方差 
.. 随机变量的相关性分析及量化方法 
.. 协方差及协方差矩阵 
.. 相关系数的概念 
. 多元随机变量实践：聚焦多元正态分布 
.. 再谈相关性：基于二元标准正态分布 
.. 二元一般正态分布 
.. 聚焦相关系数 
.. 独立和相关性的关系 
. 多元高斯分布：参数特征和几何意义 
.. 从一元分布到多元分布 
.. 多元高斯分布的参数形式 
.. 二元高斯分布的具体示例 
.. 多元高斯分布的几何特征 
.. 二元高斯分布几何特征实例分析 
第章 参数估计：探寻最大可能 
. 极限思维：大数定律与中心极限定理 
.. 一个背景话题 
.. 大数定律 
.. 大数定律的模拟 
.. 中心极限定理 
.. 中心极限定理的工程意义 
.. 中心极限定理的模拟 
.. 大数定律的应用：蒙特卡罗方法 
. 推断未知：统计推断的基本框架 
.. 进入统计学 
.. 统计推断的例子 
.. 统计推断中的一些重要概念 
.. 估计量的偏差与无偏估计 
.. 总体均值的估计 
.. 总体方差的估计 
. 极大似然估计 
.. 极大似然估计法的引例 
.. 似然函数的由来 
.. 极大似然估计的思想 
.. 极大似然估计值的计算 
.. 简单极大似然估计案例 
.. 高斯分布参数的极大似然估计 
. 含有隐变量的参数估计问题 
.. 参数估计问题的回顾 
.. 新情况：场景中含有隐变量 
.. 迭代法：解决含有隐变量情形的抛硬币问题 
.. 代码实验 
. 概率渐增：EM算法的合理性 
.. EM算法的背景介绍 
.. 先抛出EM算法的迭代公式 
.. EM算法为什么是有效的 
. 探索EM公式的底层逻辑与由来 
.. EM公式中的E步和M步 
.. 剖析EM算法的由来 
. 探索高斯混合模型：EM 迭代实践 
.. 高斯混合模型的引入 
.. 从混合模型的角度看内部机理 
.. 高斯混合模型的参数估计 
. 高斯混合模型的参数求解 
.. 利用 EM 迭代模型参数的思路 
.. 参数估计示例 
.. 高斯混合模型的应用场景 
第章 随机过程：聚焦动态特征 
. 由静向动：随机过程导引 
.. 随机过程场景举例：博彩 
.. 随机过程场景举例：股价的变化 
.. 随机过程场景举例：股价变化过程的展现 
.. 两类重要的随机过程概述 
. 状态转移：初识马尔可夫链 
.. 马尔可夫链三要素 
.. 马尔可夫性：灵魂特征 
.. 转移概率和状态转移矩阵 
.. 马尔可夫链性质的总结 
.. 一步到达与多步转移的含义 
.. 多步转移与矩阵乘法 
.. 路径概率问题 
. 变与不变：马尔可夫链的极限与稳态 
.. 极限与初始状态无关的情况 
.. 极限依赖于初始状态的情况 
.. 吸收态与收敛分析 
.. 可达与常返 
.. 周期性问题 
.. 马尔可夫链的稳态分析和判定 
.. 稳态的求法 
. 隐马尔可夫模型：明暗两条线 
.. 从马尔可夫链到隐马尔可夫模型 
.. 典型实例：盒子摸球实验 
.. 典型实例：小宝宝的日常生活 
.. 隐马尔可夫模型的外在表征 
.. 推动模型运行的内核三要素 
.. 关键性质：齐次马尔可夫性和观测独立性 
. 概率估计：隐马尔可夫模型观测序列描述 
.. 隐马尔可夫模型的研究内容 
.. 模型研究问题的描述 
.. 一个直观的思路 
.. 更优的方法：前向概率算法 
.. 概率估计实践 
.. 代码实践 
. 状态解码：隐马尔可夫模型隐状态揭秘 
.. 隐状态解码问题的描述 
.. 最大路径概率与维特比算法 
.. 应用维特比算法进行解码 
.. 维特比算法的案例实践 
.. 代码实践 
. 连续域上的无限维：高斯过程 
.. 高斯过程的一个实际例子 
.. 高斯过程的核心要素和严谨描述 
.. 径向基函数的代码演示 
.. 高斯过程回归原理详解 
.. 高斯过程回归代码演示 
第章 统计推断：贯穿近似策略 
. 统计推断的基本思想和分类 
.. 统计推断的根源和场景 
.. 后验分布：推断过程的关注重点 
.. 精确推断和近似推断 
.. 确定性近似：变分推断概述 
. 随机近似方法 
.. 蒙特卡罗方法的理论支撑 
.. 随机近似的核心：蒙特卡罗 
.. 接受-拒绝采样的问题背景 
.. 接受-拒绝采样的方法和步骤 
.. 接受-拒绝采样的实践 
.. 接受-拒绝采样方法背后的内涵挖掘 
.. 重要性采样 
.. 两种采样方法的问题及思考 
. 采样绝佳途径：借助马尔可夫链的稳态性质 
.. 马尔可夫链回顾 
.. 核心：马尔可夫链的平稳分布 
.. 马尔可夫链进入稳态的转移过程 
.. 稳态及转移过程演示 
.. 马尔可夫链稳态的价值和意义 
.. 基于马尔可夫链进行采样的原理分析 
.. 采样过程实践与分析 
.. 一个显而易见的问题和难点 
. 马尔可夫链-蒙特卡罗方法详解 
.. 稳态判定：细致平稳条件 
.. Metropolis-Hastings采样方法的原理 
.. 如何理解随机游走叠加接受概率 
.. 如何实现随机游走叠加接受概率 
.. 建议转移概率矩阵Q的设计 
.. Metropolis-Hastings方法的步骤和代码演示 
. Gibbs采样方法简介 
.. Gibbs方法核心流程 
.. Gibbs采样的合理性 
.. Gibbs采样代码实验 
・ ・ ・ ・ ・ ・ (收起)第章　初识Python与Jupyter 
.　Python概要 
..　为什么要学习Python 
..　Python中常用的库 
.　Python的版本之争 
.　安装Anaconda 
..　Linux环境下的Anaconda安装 
..　conda命令的使用 
..　Windows环境下的Anaconda安装 
.　运行Python 
..　验证Python 
..　Python版本的Hello World 
..　Python的脚本文件 
..　代码缩进 
..　代码注释 
.　Python中的内置函数 
.　文学化编程―Jupyter 
..　Jupyter的由来 
..　Jupyter的安装 
..　Jupyter的使用 
..　Markdown编辑器 
.　Jupyter中的魔法函数 
..　%lsmagic函数 
..　%matplotlib inline函数 
..　%timeit函数 
..　%%writefile函数 
..　其他常用的魔法函数 
..　在Jupyter中执行shell命令 
.　本章小结 
.　思考与提高 
第章　数据类型与程序控制结构 
.　为什么需要不同的数据类型 
.　Python中的基本数据类型 
..　数值型（Number） 
..　布尔类型（Boolean） 
..　字符串型（String） 
..　列表（List） 
..　元组（Tuple） 
..　字典（Dictionary） 
..　集合（Set） 
.　程序控制结构 
..　回顾那段难忘的历史 
.. 顺序结构 
.. 选择结构 
.. 循环结构 
.　高效的推导式 
..　列表推导式 
..　字典推导式 
..　集合推导式 
.　本章小结 
.　思考与提高 
第章　自建Python模块与第三方模块 
.　导入Python标准库 
.　编写自己的模块 
.　模块的搜索路径 
.　创建模块包 
.　常用的内建模块 
.. collection模块 
..　datetime模块 
..　json模块 
..　random模块 
.　本章小结 
.　思考与提高 
第章　Python函数 
.　Python中的函数 
..　函数的定义 
..　函数返回多个值 
.. 函数文档的构建 
.　函数参数的“花式”传递 
..　关键字参数 
..　可变参数 
..　默认参数 
..　参数序列的打包与解包 
..　传值还是传引用 
.　函数的递归 
.. 感性认识递归 
.. 思维与递归思维 
.. 递归调用的函数 
.　函数式编程的高阶函数 
..　lambda表达式 
.. filter()函数 
.. map()函数 
.. reduce()函数 
.. sorted()函数 
. 本章小结 
. 思考与提高 
第章　Python高级特性 
.　面向对象程序设计 
..　面向过程与面向对象之辩 
.. 类的定义与使用 
.. 类的继承 
.　生成器与迭代器 
.. 生成器 
.. 迭代器 
. 文件操作 
.. 打开文件 
.. 读取一行与读取全部行 
.. 写入文件 
.　异常处理 
.. 感性认识程序中的异常 
.. 异常处理的三步走 
. 错误调试 
.. 利用print()输出观察变量 
.. assert断言 
.　本章小结 
.　思考与提高 
第章　NumPy向量计算 
.　为何需要NumPy 
.　如何导入NumPy 
. 生成NumPy数组 
..　利用序列生成 
..　利用特定函数生成 
.. Numpy数组的其他常用函数 
.　N维数组的属性 
. NumPy数组中的运算 
.. 向量运算 
.. 算术运算 
.. 逐元素运算与张量点乘运算 
.　爱因斯坦求和约定 
..　不一样的标记法 
..　NumPy中的einsum()方法 
. NumPy中的“轴”方向 
. 操作数组元素 
.. 通过索引访问数组元素 
.. NumPy中的切片访问 
.. 二维数组的转置与展平 
. NumPy中的广播 
. NumPy数组的高级索引 
.. “花式”索引 
.. 布尔索引 
. 数组的堆叠操作 
.. 水平方向堆叠hstack() 
.. 垂直方向堆叠vstack() 
.. 深度方向堆叠hstack() 
.. 列堆叠与行堆叠 
.. 数组的分割操作 
. NumPy中的随机数模块 
. 本章小结 
. 思考与提高 
第章　Pandas数据分析 
. Pandas简介 
. Pandas的安装 
. Series类型数据 
.. Series的创建 
.. Series中的数据访问 
.. Series中的向量化操作与布尔索引 
.. Series中的切片操作 
.. Series中的缺失值 
.. Series中的删除与添加操作 
.. Series中的name属性 
. DataFrame 类型数据 
.. 构建DataFrame 
.. 访问DataFrame中的列与行 
.. DataFrame中的删除操作 
.. DataFrame中的“轴”方向 
.. DataFrame中的添加操作 
. 基于Pandas的文件读取与分析 
.. 利用Pandas读取文件 
.. DataFrame中的常用属性 
.. DataFrame中的常用方法 
.. DataFrame的条件过滤 
.. DataFrame的切片操作 
.. DataFrame的排序操作 
.. Pandas的聚合和分组运算 
.. DataFrame的透视表 
.. DataFrame的类SQL操作 
.. DataFrame中的数据清洗方法 
. 泰坦尼克幸存者数据预处理 
.. 数据集简介 
.. 数据集的拼接 
.. 缺失值的处理 
. 本章小结 
. 思考与提高 
第章　Matplotlib与Seaborn可视化分析 
. Matplotlib与图形绘制 
. 绘制简单图形 
. pyplot的高级功能 
.. 添加图例与注释 
.. 设置图形标题及坐标轴 
.. 添加网格线 
.. 绘制多个子图 
.. Axes与Subplot的区别 
. 散点图 
. 条形图与直方图 
.. 垂直条形图 
.. 水平条形图 
.. 并列条形图 
.. 叠加条形图 
.. 直方图 
. 饼图 
. 箱形图 
. 误差条 
. 绘制三维图形 
. 与Pandas协作绘图―以谷歌流感趋势数据为例 
.. 谷歌流感趋势数据描述 
.. 导入数据与数据预处理 
.. 绘制时序曲线图 
.. 选择合适的数据可视化表达 
.. 基于条件判断的图形绘制 
.. 绘制多个子图 
. 惊艳的Seaborn 
.. pairplot（对图） 
.. heatmap（热力图） 
.. boxplot（箱形图） 
.. violin plot（小提琴图） 
.. Density Plot（密度图） 
. 本章小结 
. 思考与提高 
第章　机器学习初步 
. 机器学习定义 
..　什么是机器学习 
.. 机器学习的三个步骤 
.. 传统编程与机器学习的差别 
.. 为什么机器学习不容易 
.　监督学习 
..　感性认识监督学习 
..　监督学习的形式化描述 
.. 损失函数 
.　非监督学习 
.　半监督学习 
. 机器学习的哲学视角 
. 模型性能评估 
.. 经验误差与测试误差 
.. 过拟合与欠拟合 
.. 模型选择与数据拟合 
. 性能度量 
..　二分类的混淆矩阵 
.. 查全率、查准率与F分数 
.. P-R曲线 
.. ROC曲线 
.. AUC 
.　本章小结 
.　思考与提高 
第章　sklearn与经典机器学习算法 
. 机器学习的利器―sklearn 
.. sklearn简介 
.. sklearn的安装 
. 线性回归 
..　线性回归的概念 
.. 使用sklearn实现波士顿房价预测 
.　k-近邻算法 
.. 算法简介 
..　k值的选取 
..　特征数据的归一化 
..　邻居距离的度量 
.. 分类原则的制定 
..　基于sklearn的k-近邻算法实战 
. Logistic回归 
.. 为什么需要Logistic回归 
.. Logistic源头初探 
.. Logistic回归实战 
. 神经网络学习算法 
.. 人工神经网络的定义 
.. 神经网络中的“学习”本质 
.. 神经网络结构的设计 
.. 利用sklearn搭建多层神经网络 
. 非监督学习的代表―k均值聚类 
.. 聚类的基本概念 
.. 簇的划分 
.. k均值聚类算法核心 
.. k均值聚类算法优缺点 
.. 基于sklearn的k均值聚类算法实战 
. 本章小结 
. 思考与提高 
・ ・ ・ ・ ・ ・ (收起)赛题一 工业蒸汽量预测
 赛题理解 
. 赛题背景 
. 赛题目标 
. 数据概览 
. 评估指标 
. 赛题模型 
 数据探索 
. 理论知识 
.. 变量识别 
.. 变量分析 
.. 缺失值处理 
.. 异常值处理 
.. 变量转换 
.. 新变量生成 
. 赛题数据探索 
.. 导入工具包 
.. 读取数据 
.. 查看数据 
.. 可视化数据分布 
.. 查看特征变量的相关性 
 特征工程 
. 特征工程的重要性和处理 
. 数据预处理和特征处理 
.. 数据预处理 
.. 特征处理 
. 特征降维 
.. 特征选择 
.. 线性降维 
. 赛题特征工程 
.. 异常值分析 
.. 最大值和最小值的
归一化 
.. 查看数据分布 
.. 特征相关性 
.. 特征降维 
.. 多重共线性分析 
.. PCA处理 
 模型训练 
. 回归及相关模型 
.. 回归的概念 
.. 回归模型训练和预测 
.. 线性回归模型 
.. K近邻回归模型 
.. 决策树回归模型 
.. 集成学习回归模型 
. 赛题模型训练 
.. 导入相关库 
.. 切分数据 
.. 多元线性回归 
.. K近邻回归 
.. 随机森林回归 
.. LGB模型回归 
 模型验证 
. 模型评估的概念和方法 
.. 欠拟合与过拟合 
.. 模型的泛化与正则化 
.. 回归模型的评估指标和
调用方法 
.. 交叉验证 
. 模型调参 
.. 调参 
.. 网格搜索 
.. 学习曲线 
.. 验证曲线 
. 赛题模型验证和调参 
.. 模型过拟合与欠拟合 
.. 模型正则化 
.. 模型交叉验证 
.. 模型超参空间及调参 
.. 学习曲线和验证曲线 
 特征优化 
. 特征优化的方法 
.. 合成特征 
.. 特征的简单变换 
.. 用决策树创造新特征 
.. 特征组合 
. 赛题特征优化 
.. 导入数据 
.. 特征构造方法 
.. 特征构造函数 
.. 特征降维处理 
.. 模型训练和评估 
 模型融合 
. 模型优化 
.. 模型学习曲线 
.. 模型融合提升技术 
.. 预测结果融合策略 
.. 其他提升方法 
. 赛题模型融合 
.. 导入工具包 
.. 获取训练数据和测试
数据 
.. 模型评价函数 
.. 采用网格搜索训练
模型 
.. 单一模型预测效果 
.. 模型融合Boosting方法 
.. 多模型预测Bagging
方法 
.. 多模型融合Stacking
方法 
.. 模型验证 
.. 使用lr_reg和lgb_reg
进行融合预测 

赛题二 天猫用户重复购买预测
 赛题理解 
. 赛题背景 
. 数据介绍 
. 评估指标 
. 赛题分析 
 数据探索 
. 理论知识 
.. 缺失数据处理 
.. 不均衡样本 
.. 常见的数据分布 
. 赛题数据探索 
.. 导入工具包 
.. 读取数据 
.. 数据集样例查看 
.. 查看数据类型和数据
大小 
.. 查看缺失值 
.. 观察数据分布 
.. 探查影响复购的各种
因素 
 特征工程 
. 特征工程介绍 
.. 特征工程的概念 
.. 特征归一化 
.. 类别型特征的转换 
.. 高维组合特征的处理 
.. 组合特征 
.. 文本表示模型 
. 赛题特征工程思路 
. 赛题特征工程构造 
.. 工具导入 
.. 数据读取 
.. 对数据进行内存压缩 
.. 数据处理 
.. 定义特征统计函数 
.. 提取统计特征 
.. 利用Countvector和
TF-IDF提取特征 
.. 嵌入特征 

.. Stacking分类特征 
 模型训练 
. 分类的概念 
. 分类相关模型 
.. 逻辑回归分类模型 
.. K近邻分类模型 
.. 高斯贝叶斯分类模型 
.. 决策树分类模型 
.. 集成学习分类模型 
 模型验证 
. 模型验证指标 
.. 准确度 
.. 查准率和查全率 
.. F值 
.. 分类报告 
.. 混淆矩阵 
.. ROC 
.. AUC曲线 
. 赛题模型验证和评估 
.. 基础代码 
.. 简单验证 
.. 设置交叉验证方式 
.. 模型调参 
.. 混淆矩阵 
.. 不同的分类模型 
.. 自己封装模型 
 特征优化 
. 特征选择技巧 
. 赛题特征优化 
.. 基础代码 
.. 缺失值补全 
.. 特征选择 
赛题三 OO优惠券预测
 赛题理解 
. 赛题介绍 
. 赛题分析 
 数据探索 
. 理论知识 
.. 数据探索的定义 
.. 数据探索的目的 
.. 相关Python包 
. 初步的数据探索 
.. 数据读取 
.. 数据查看 
.. 数据边界探索 
.. 训练集与测试集的
相关性 
.. 数据统计 
. 数据分布 
.. 对文本数据的数值化
处理 
.. 数据分布可视化 
 特征工程 
. 赛题特征工程思路 
. 赛题特征构建 
.. 工具函数 
.. 特征群生成函数 
.. 特征集成函数 
.. 特征输出 
. 对特征进行探索 
.. 特征读取函数 
.. 特征总览 
.. 查看特征的分布 
.. 特征相关性分析 
 模型训练 
. 模型训练与评估 
. 不同算法模型的性能对比 
.. 朴素贝叶斯 
.. 逻辑回归 
.. 决策树 
.. 随机森林 
.. XGBoost 
.. LightGBM 
.. 不同特征效果对比 
. 结果输出 
 模型验证 
. 评估指标 
. 交叉验证 
. 模型比较 
. 验证结果可视化 
. 结果分析 
. 模型调参 
. 实际方案 
 提交结果 
. 整合及输出结果 
. 结果提交及线上验证 
赛题四 阿里云安全恶意程序检测
 赛题理解 
. 赛题介绍 
. 赛题分析 
 数据探索 
. 训练集数据探索 
.. 数据特征类型 
.. 数据分布 
.. 缺失值 
.. 异常值 
.. 标签分布 
. 测试集数据探索 
.. 数据信息 
.. 缺失值 
.. 数据分布 
.. 异常值 
. 数据集联合分析 
.. file_id分析 
.. API分析 
 特征工程与基线模型 
. 特征工程概述 
.. 特征工程介绍 
.. 构造特征 
.. 特征选择 
. 构造线下验证集 
.. 评估穿越 
.. 训练集和测试集的特征
差异性 
.. 训练集和测试集的分布
差异性 
. 基线模型 
.. 数据读取 
.. 特征工程 

.. 基线构建 
.. 特征重要性分析 
.. 模型测试 
 高阶数据探索 
. 变量分析 
. 高阶数据探索实战 
.. 数据读取 
.. 多变量交叉探索 
 特征工程进阶与方案优化 
. pivot特征构建 
.. pivot特征 
.. pivot特征构建时间 
.. pivot特征构建细节和
特点 
. 业务理解和结果分析 
.. 结合模型理解业务 
.. 多分类问题预测结果
分析 
. 特征工程进阶实践 
.. 特征工程基础部分 
.. 特征工程进阶部分 
.. 基于LightGBM的模型
验证 
.. 模型结果分析 
.. 模型测试 
 优化技巧与解决方案升级 
. 优化技巧：Python处理大数据
的技巧 
.. 内存管理控制 
.. 加速数据处理的技巧 
.. 其他开源工具包 
. 深度学习解决方案：TextCNN
建模 
.. 问题转化 
.. TextCNN建模 
.. 数据预处理 
.. TextCNN网络结构 
.. TextCNN训练和测试 
.. 结果提交 
 开源方案学习 
・ ・ ・ ・ ・ ・ (收起)第一部分 通用流程
第　章 问题建模　
.　评估指标　
..　分类指标　
..　回归指标　
..　排序指标　
.　样本选择　
..　数据去噪　
..　采样　
..　原型选择和训练集选择　
.　交叉验证　
..　留出法　
..　K折交叉验证　
..　自助法　
参考文献　
第　章 特征工程　
.　特征提取　
..　探索性数据分析　
..　数值特征　
..　类别特征　
..　时间特征　
..　空间特征　
..　文本特征　
.　特征选择　
..　过滤方法　
..　封装方法　
..　嵌入方法　
..　小结　
..　工具介绍　
参考文献　
第章　常用模型　
.　逻辑回归　
..　逻辑回归原理　
..　逻辑回归应用　
.　场感知因子分解机　
..　因子分解机原理　
..　场感知因子分解机原理　
..　场感知因子分解机的应用　
.　梯度提升树　
..　梯度提升树原理　
..　梯度提升树的应用　
参考文献　
第章　模型融合　
.　理论分析　
..　融合收益　
..　模型误差 分歧分解　
..　模型多样性度量　
..　多样性增强　
.　融合方法　
..　平均法　
..　投票法　
..　Bagging　
..　Stacking　
..　小结　
参考文献　
第二部分　数据挖掘
第章　用户画像　
.　什么是用户画像　
.　用户画像数据挖掘　
..　画像数据挖掘整体架构　
..　用户标识　
..　特征数据　
..　样本数据　
..　标签建模　
.　用户画像应用　
..　用户画像实时查询系统　
..　人群画像分析系统　
..　其他系统　
..　线上应用效果　
.　小结　
参考文献　
第章　POI实体链接　
.　问题的背景与难点　
.　国内酒店POI实体链接解决方案　
..　酒店POI实体链接　
..　数据清洗　
..　特征生成　
..　模型选择与效果评估　
..　索引粒度的配置　
.　其他场景的策略调整　
.　小结　
第章　评论挖掘　
.　评论挖掘的背景　
..　评论挖掘的粒度　
..　评论挖掘的维度　
..　评论挖掘的整合思考　
.　评论标签提取　
..　数据的获取及预处理　
..　无监督的标签提取方法　
..　基于深度学习的标签提取方法　
.　标签情感分析　
..　评论标签情感分析的特殊性　
..　基于深度学习的情感分析方法　
..　评论标签情感分析的后续优 化与思考　
.　评论挖掘的未来应用及实践　
.　小结　
参考文献　
第三部分　搜索和推荐
第章　OO场景下的查询理解与 用户引导　
.　现代搜索引擎原理　
.　精确理解查询　
..　用户查询意图的定义与识别　
..　查询实体识别与结构化　
..　召回策略的变迁　
..　查询改写　
..　词权重与相关性计算　
..　类目相关性与人工标注　
..　查询理解小结　
.　引导用户完成搜索　
..　用户引导的产品定义与衡量 标准　
..　搜索前的引导――查询词 推荐　
..　搜索中的引导――查询补全　
..　搜索后的引导――相关搜索　
..　效率提升与效果提升　
..　用户引导小结　
.　小结　
参考文献　
第章　OO场景下排序的特点　
.　系统概述　
.　在线排序服务　
.　多层正交A/B测试　
.　特征获取　
.　离线调研系统　
.　特征工程　
.　排序模型　
.　场景化排序　
.　小结　
第　章 推荐在OO场景的应用　
.　典型的OO推荐场景　
.　OO推荐场景特点　
..　OO场景的地理位置因素　
..　OO场景的用户历史行为　
..　OO场景的实时推荐　
.　美团推荐实践――推荐框架　
.　美团推荐实践――推荐召回　
..　基于协同过滤的召回　
..　基于位置的召回　
..　基于搜索查询的召回　
..　基于图的召回　
..　基于实时用户行为的召回　
..　替补策略　
.　美团推荐实践――推荐排序　
..　排序特征　
..　排序样本　
..　排序模型　
.　推荐评价指标　
参考文献　
第四部分　计算广告
第　章 OO场景下的广告营销　
.　OO场景下的广告业务特点　
.　商户、用户和平台三者利益平衡　
..　商户效果感知　
..　用户体验　
..　平台收益　
.　OO广告机制设计　
..　广告位设定　
..　广告召回机制　
..　广告排序机制　
.　OO推送广告　
.　OO广告系统工具　
..　面向开发人员的系统工具　
..　面向广告主和运营人员的 工具　
.　小结　
参考文献　
第　章 用户偏好和损失建模　
.　如何定义用户偏好　
..　什么是用户偏好　
..　如何衡量用户偏好　
..　对不同POI 的偏好　
..　用户对 POI 偏好的衡量　
.　广告价值与偏好损失的兑换　
..　优化目标　
..　模型建模　
.　Pairwise 模型学习　
..　GBRank　
..　RankNet　
参考文献　
第五部分　深度学习
第　章 深度学习概述　
.　深度学习技术发展历程　
.　深度学习基础结构　
.　深度学习研究热点　
..　基于深度学习的生成式模型　
..　深度强化学习　
参考文献　
第　章 深度学习在文本领域的应用　
.　基于深度学习的文本匹配　
.　基于深度学习的排序模型　
..　排序模型简介　
..　深度学习排序模型的演进　
..　美团的深度学习排序模型 尝试　
.　小结　
参考文献　
第　章 深度学习在计算机视觉中的 应用　
.　基于深度学习的OCR　
..　OCR技术发展历程　
..　基于深度学习的文字检测　
..　基于序列学习的文字识别　
..　小结　
.　基于深度学习的图像智能审核　
..　基于深度学习的水印检测　
..　明星脸识别　
..　色情图片检测　
..　场景分类　
.　基于深度学习的图像质量排序　
..　图像美学质量评价　
..　面向点击预测的图像质量 评价　
.　小结　
参考文献　
第六部分　算法工程
第　章 大规模机器学习　
.　并行计算编程技术　
..　向量化　
..　多核并行OpenMP　
..　GPU编程　
..　多机并行MPI　
..　并行编程技术小结　
.　并行计算模型　
..　BSP　
..　SSP　
..　ASP　
..　参数服务器　
.　并行计算案例　
..　XGBoost并行库Rabit　
..　MXNet并行库PS-Lite　
.　美团并行计算机器学习平台　
参考文献　
第　章 特征工程和实验平台　
.　特征平台　
..　特征生产　
..　特征上线　
..　在线特征监控　
.　实验管理平台　
..　实验平台概述　
..　美团实验平台――Gemini　
・ ・ ・ ・ ・ ・ (收起)第章 向量和向量空间 
. 向量 
.. 描述向量 
.. 向量的加法 
.. 向量的数量乘法 
. 向量空间 
.. 什么是向量空间 
.. 线性组合 
.. 线性无关 
.. 子空间 
. 基和维数 
.. 极大线性无关组 
.. 基 
.. 维数 
. 内积空间 
.. 什么是内积空间 
.. 点积和欧几里得空间 
. 距离和角度 
.. 距离 
.. 基于距离的分类 
.. 范数和正则化 
.. 角度 
. 非欧几何 
第章 矩阵 
. 基础知识 
.. 什么是矩阵 
.. 初等变换 
.. 矩阵加法 
.. 数量乘法 
.. 矩阵乘法 
. 线性映射 
.. 理解什么是线性 
.. 线性映射 
.. 矩阵与线性映射 
.. 齐次坐标系 
. 矩阵的逆和转置 
.. 逆矩阵 
.. 转置矩阵 
.. 矩阵LU分解 
. 行列式 
.. 计算方法和意义 
.. 线性方程组 
. 矩阵的秩 
. 稀疏矩阵 
.. 生成稀疏矩阵 
.. 稀疏矩阵压缩 
. 图与矩阵 
.. 图的基本概念 
.. 邻接矩阵 
.. 关联矩阵 
.. 拉普拉斯矩阵 
第章 特征值和特征向量 
. 基本概念 
.. 定义 
.. 矩阵的迹 
.. 一般性质 
. 应用示例 
.. 动力系统微分方程 
.. 马尔科夫矩阵 
. 相似矩阵 
.. 相似变换 
.. 几何理解 
.. 对角化 
. 正交和投影 
.. 正交集和标准正交基 
.. 正交矩阵 
.. 再探对称矩阵 
.. 投影 
. 矩阵分解 
.. QR分解 
.. 特征分解 
.. 奇异值分解 
.. 数据压缩 
.. 降噪 
. 最小二乘法（） 
.. 正规方程 
.. 线性回归（） 
第章 向量分析 
. 向量的代数运算 
.. 叉积 
.. 张量和外积 
. 向量微分 
.. 函数及其导数 
.. 偏导数 
.. 梯度 
.. 矩阵导数 
. 最优化方法 
.. 简单的线性规划 
.. 最小二乘法（） 
.. 梯度下降法 
.. 线性回归（） 
.. 牛顿法 
. 反向传播算法 
.. 神经网络 
.. 参数学习 
.. 损失函数 
.. 激活函数 
.. 理论推导 
第章 概率 
. 基本概念 
.. 试验和事件 
.. 理解概率 
.. 条件概率 
. 贝叶斯定理 
.. 事件的独立性 
.. 全概率公式 
.. 理解贝叶斯定理 
. 随机变量和概率分布 
.. 随机变量 
.. 离散型随机变量的分布 
.. 连续型随机变量的分布 
.. 多维随机变量及分布 
.. 条件概率分布 
. 随机变量的和 
.. 离散型随机变量的和 
.. 连续型随机变量的和 
. 随机变量的数字特征 
.. 数学期望 
.. 方差和协方差 
.. 计算相似度 
.. 协方差矩阵 
第章 数理统计 
. 样本和抽样 
.. 总体和样本 
.. 统计量 
. 点估计 
.. 最大似然估计 
.. 线性回归（） 
.. 最大后验估计 
.. 估计的选择标准 
. 区间估计 
. 参数检验 
.. 基本概念 
.. 正态总体均值的假设检验 
.. 正态总体方差的假设检验 
.. p值检验 
.. 用假设检验比较模型 
. 非参数检验 
.. 拟合优度检验 
.. 列联表检验 
第章 信息与熵 
. 度量信息 
. 信息熵 
. 联合熵和条件熵 
. 相对熵和交叉熵 
. 互信息 
. 连续分布 
附录 
后记 
・ ・ ・ ・ ・ ・ (收起)目　录

第一部分　分类
第章　机器学习基础　　
. 　何谓机器学习　　
.. 　传感器和海量数据　　
.. 　机器学习非常重要　　
. 　关键术语　　
. 　机器学习的主要任务　　
. 　如何选择合适的算法　　
. 　开发机器学习应用程序的步骤　　
. 　Python语言的优势　　
.. 　可执行伪代码　　
.. 　Python比较流行　　
.. 　Python语言的特色　　
.. 　Python语言的缺点　　
. 　NumPy函数库基础　　
. 　本章小结　　
第章　k-近邻算法 　　
. 　k-近邻算法概述　　
.. 　准备：使用Python导入数据　　
.. 　从文本文件中解析数据　　
.. 　如何测试分类器　　
. 　示例：使用k-近邻算法改进约会网站的配对效果　　
.. 　准备数据：从文本文件中解析数据　　
.. 　分析数据：使用Matplotlib创建散点图　　
.. 　准备数据：归一化数值　　
.. 　测试算法：作为完整程序验证分类器　　
.. 　使用算法：构建完整可用系统　　
. 　示例：手写识别系统　　
.. 　准备数据：将图像转换为测试向量　　
.. 　测试算法：使用k-近邻算法识别手写数字　　
. 　本章小结　　
第章　决策树 　　
. 　决策树的构造　　
.. 　信息增益　　
.. 　划分数据集　　
.. 　递归构建决策树　　
. 　在Python中使用Matplotlib注解绘制树形图　　
.. 　Matplotlib注解　　
.. 　构造注解树　　
. 　测试和存储分类器　　
.. 　测试算法：使用决策树执行分类　　
.. 　使用算法：决策树的存储　　
. 　示例：使用决策树预测隐形眼镜类型　　
. 　本章小结　　
第章　基于概率论的分类方法：朴素贝叶斯 　　
. 　基于贝叶斯决策理论的分类方法　　
. 　条件概率　　
. 　使用条件概率来分类　　
. 　使用朴素贝叶斯进行文档分类　　
. 　使用Python进行文本分类　　
.. 　准备数据：从文本中构建词向量　　
.. 　训练算法：从词向量计算概率　　
.. 　测试算法：根据现实情况修改分类器　　
.. 　准备数据：文档词袋模型　　
. 　示例：使用朴素贝叶斯过滤垃圾邮件　　
.. 　准备数据：切分文本　　
.. 　测试算法：使用朴素贝叶斯进行交叉验证　　
. 　示例：使用朴素贝叶斯分类器从个人广告中获取区域倾向　　
.. 　收集数据：导入RSS源　　
.. 　分析数据：显示地域相关的用词　　
. 　本章小结　　
第章　Logistic回归 　　
. 　基于Logistic回归和Sigmoid函数的分类　　
. 　基于最优化方法的最佳回归系数确定　　
.. 　梯度上升法　　
.. 　训练算法：使用梯度上升找到最佳参数　　
.. 　分析数据：画出决策边界　　
.. 　训练算法：随机梯度上升　　
. 　示例：从疝气病症预测病马的死亡率　　
.. 　准备数据：处理数据中的缺失值　　
.. 　测试算法：用Logistic回归进行分类　　
. 　本章小结　　
第章　支持向量机　　
. 　基于最大间隔分隔数据　　
. 　寻找最大间隔　　
.. 　分类器求解的优化问题　　
.. 　SVM应用的一般框架　　
. 　SMO高效优化算法　　
.. 　Platt的SMO算法　　
.. 　应用简化版SMO算法处理小规模数据集　　
. 　利用完整Platt SMO算法加速优化　　
. 　在复杂数据上应用核函数　　
.. 　利用核函数将数据映射到高维空间　　
.. 　径向基核函数　　
.. 　在测试中使用核函数　　
. 　示例：手写识别问题回顾　　
. 　本章小结　　
第章　利用AdaBoost元算法提高分类
性能 　　
. 　基于数据集多重抽样的分类器　　
.. 　bagging：基于数据随机重抽样的分类器构建方法　　
.. 　boosting　　
. 　训练算法：基于错误提升分类器的性能　　
. 　基于单层决策树构建弱分类器　　
. 　完整AdaBoost算法的实现　　
. 　测试算法：基于AdaBoost的分类　　
. 　示例：在一个难数据集上应用AdaBoost　　
. 　非均衡分类问题　　
.. 　其他分类性能度量指标：正确率、召回率及ROC曲线　　
.. 　基于代价函数的分类器决策控制　　
.. 　处理非均衡问题的数据抽样方法　　
. 　本章小结　　
第二部分　利用回归预测数值型数据
第章　预测数值型数据：回归 　　
. 　用线性回归找到最佳拟合直线　　
. 　局部加权线性回归　　
. 　示例：预测鲍鱼的年龄　　
. 　缩减系数来“理解”数据　　
.. 　岭回归　　
.. 　lasso　　
.. 　前向逐步回归　　
. 　权衡偏差与方差　　
. 　示例：预测乐高玩具套装的价格　　
.. 　收集数据：使用Google购物的API　　
.. 　训练算法：建立模型　　
. 　本章小结　　
第章　树回归　　
. 　复杂数据的局部性建模　　
. 　连续和离散型特征的树的构建　　
. 　将CART算法用于回归　　
.. 　构建树　　
.. 　运行代码　　
. 　树剪枝　　
.. 　预剪枝　　
.. 　后剪枝　　
. 　模型树　　
. 　示例：树回归与标准回归的比较　　
. 　使用Python的Tkinter库创建GUI　　
.. 　用Tkinter创建GUI　　
.. 　集成Matplotlib和Tkinter　　
. 　本章小结　　
第三部分　无监督学习
第章　利用K-均值聚类算法对未标注数据分组　　
. 　K-均值聚类算法　　
. 　使用后处理来提高聚类性能　　
. 　二分K-均值算法　　
. 　示例：对地图上的点进行聚类　　
.. 　Yahoo! PlaceFinder API　　
.. 　对地理坐标进行聚类　　
. 　本章小结　　
第章　使用Apriori算法进行关联分析　　
. 　关联分析　　
. 　Apriori原理　　
. 　使用Apriori算法来发现频繁集　　
.. 　生成候选项集　　
.. 　组织完整的Apriori算法　　
. 　从频繁项集中挖掘关联规则　　
. 　示例：发现国会投票中的模式　　
.. 　收集数据：构建美国国会投票记录的事务数据集　　
.. 　测试算法：基于美国国会投票记录挖掘关联规则　　
. 　示例：发现毒蘑菇的相似特征　　
. 　本章小结　　
第章　使用FP-growth算法来高效发现频繁项集　　
. 　FP树：用于编码数据集的有效方式　　
. 　构建FP树　　
.. 　创建FP树的数据结构　　
.. 　构建FP树　　
. 　从一棵FP树中挖掘频繁项集　　
.. 　抽取条件模式基　　
.. 　创建条件FP树　　
. 　示例：在Twitter源中发现一些共现词　　
. 　示例：从新闻网站点击流中挖掘　　
. 　本章小结　　
第四部分　其他工具
第章　利用PCA来简化数据　　
. 　降维技术　　
. 　PCA　　
.. 　移动坐标轴　　
.. 　在NumPy中实现PCA　　
. 　示例：利用PCA对半导体制造数据降维　　
. 　本章小结　　
第章　利用SVD简化数据　　
. 　SVD的应用　　
.. 　隐性语义索引　　
.. 　推荐系统　　
. 　矩阵分解　　
. 　利用Python实现SVD　　
. 　基于协同过滤的推荐引擎　　
.. 　相似度计算　　
.. 　基于物品的相似度还是基于用户的相似度？　　
.. 　推荐引擎的评价　　
. 　示例：餐馆菜肴推荐引擎　　
.. 　推荐未尝过的菜肴　　
.. 　利用SVD提高推荐的效果　　
.. 　构建推荐引擎面临的挑战　　
. 　基于SVD的图像压缩　　
. 　本章小结　　
第章　大数据与MapReduce　　
. 　MapReduce：分布式计算的框架　　
. 　Hadoop流　　
.. 　分布式计算均值和方差的mapper　　
.. 　分布式计算均值和方差的reducer　　
. 　在Amazon网络服务上运行Hadoop程序　　
.. 　AWS上的可用服务　　
.. 　开启Amazon网络服务之旅　　
.. 　在EMR上运行Hadoop作业　　
. 　MapReduce上的机器学习　　
. 　在Python中使用mrjob来自动化MapReduce　　
.. 　mrjob与EMR的无缝集成　　
.. 　mrjob的一个MapReduce脚本剖析　　
. 　示例：分布式SVM的Pegasos算法　　
.. 　Pegasos算法　　
.. 　训练算法：用mrjob实现MapReduce版本的SVM　　
. 　你真的需要MapReduce吗？　　
. 　本章小结　　
附录A 　Python入门　　
附录B 　线性代数　　
附录C 　概率论复习　　
附录D 　资源　　
索引　　
版权声明　　
・ ・ ・ ・ ・ ・ (收起)第章　Spark的环境搭建与运行　　
.　Spark的本地安装与配置　　
.　Spark集群　　
.　Spark编程模型　　
..　SparkContext类与SparkConf 类　　
..　Spark shell　　
..　弹性分布式数据集　　
..　广播变量和累加器　　
.　Spark Scala编程入门　　
.　Spark Java编程入门　　
.　Spark Python编程入门　　
.　在Amazon EC上运行Spark　　
.　小结　　
第章　设计机器学习系统　　
.　MovieStream介绍　　
.　机器学习系统商业用例　　
..　个性化　　
..　目标营销和客户细分　　
..　预测建模与分析　　
.　机器学习模型的种类　　
.　数据驱动的机器学习系统的组成　　
..　数据获取与存储　　
..　数据清理与转换　　
..　模型训练与测试回路　　
..　模型部署与整合　　
..　模型监控与反馈　　
..　批处理或实时方案的选择　　
.　机器学习系统架构　　
.　小结　　
第章　Spark上数据的获取、处理与准备　　
.　获取公开数据集　　
.　探索与可视化数据　　
..　探索用户数据　　
..　探索电影数据　　
..　探索评级数据　　
.　处理与转换数据　　
.　从数据中提取有用特征　　
..　数值特征　　
..　类别特征　　
..　派生特征　　
..　文本特征　　
..　正则化特征　　
..　用软件包提取特征　　
.　小结　　
第章　构建基于Spark的推荐引擎　　
.　推荐模型的分类　　
..　基于内容的过滤　　
..　协同过滤　　
..　矩阵分解　　
.　提取有效特征　　
.　训练推荐模型　　
..　使用MovieLens k数据集训练模型　　
..　使用隐式反馈数据训练模型　　
.　使用推荐模型　　
..　用户推荐　　
..　物品推荐　　
.　推荐模型效果的评估　　
..　均方差　　
..　K值平均准确率　　
..　使用MLlib内置的评估函数　　
.　小结　　
第章　Spark构建分类模型　　
.　分类模型的种类　　
..　线性模型　　
..　朴素贝叶斯模型　　
..　决策树　　
.　从数据中抽取合适的特征　　
.　训练分类模型　　
.　使用分类模型　　
.　评估分类模型的性能　　
..　预测的正确率和错误率　　
..　准确率和召回率　　
..　ROC曲线和AUC　　
.　改进模型性能以及参数调优　　
..　特征标准化　　
..　其他特征　　
..　使用正确的数据格式　　
..　模型参数调优　　
.　小结　　
第章　Spark构建回归模型　　
.　回归模型的种类　　
..　最小二乘回归　　
..　决策树回归　　
.　从数据中抽取合适的特征　　
.　回归模型的训练和应用　　
.　评估回归模型的性能　　
..　均方误差和均方根误差　　
..　平均绝对误差　　
..　均方根对数误差　　
..　R-平方系数　　
..　计算不同度量下的性能　　
.　改进模型性能和参数调优　　
..　变换目标变量　　
..　模型参数调优　　
.　小结　　
第章　Spark构建聚类模型　　
.　聚类模型的类型　　
..　K-均值聚类　　
..　混合模型　　
..　层次聚类　　
.　从数据中提取正确的特征　　
.　训练聚类模型　　
.　使用聚类模型进行预测　　
.　评估聚类模型的性能　　
..　内部评价指标　　
..　外部评价指标　　
..　在MovieLens数据集计算性能　　
.　聚类模型参数调优　　
.　小结　　
第章　Spark应用于数据降维　　
.　降维方法的种类　　
..　主成分分析　　
..　奇异值分解　　
..　和矩阵分解的关系　　
..　聚类作为降维的方法　　
.　从数据中抽取合适的特征　　
.　训练降维模型　　
.　使用降维模型　　
..　在LFW数据集上使用PCA投影数据　　
..　PCA和SVD模型的关系　　
.　评价降维模型　　
.　小结　　
第章　Spark高级文本处理技术　　
.　处理文本数据有什么特别之处　　
.　从数据中抽取合适的特征　　
..　短语加权表示　　
..　特征哈希　　
..　从新闻组数据集中提取TF-IDF特征　　
.　使用TF-IDF模型　　
..　 Newsgroups数据集的文本相似度和TF-IDF特征　　
..　基于 Newsgroups数据集使用TF-IDF训练文本分类器　　
.　评估文本处理技术的作用　　
.　WordVec 模型　　
.　小结　　
第章　Spark Streaming在实时机器学习上的应用　　
.　在线学习　　
.　流处理　　
..　Spark Streaming介绍　　
..　使用Spark Streaming缓存和容错　　
.　创建Spark Streaming应用　　
..　消息生成端　　
..　创建简单的流处理程序　　
..　流式分析　　
..　有状态的流计算　　
.　使用Spark Streaming进行在线学习　　
..　流回归　　
..　一个简单的流回归程序　　
..　流K-均值　　
.　在线模型评估　　
.　小结　　
・ ・ ・ ・ ・ ・ (收起)第 章一元函数微积分
. 极限与连续. . . . . . . . . . . . . . 
.. 可数集与不可数集. . . . . . . . 
.. 数列的极限. . . . . . . . . . . . 
.. 函数的极限. . . . . . . . . . . . 
.. 函数的连续性与间断点. . . . . 
.. 上确界与下确界. . . . . . . . . 
.. 李普希茨连续性. . . . . . . . . 
.. 无穷小量. . . . . . . . . . . . . 
. 导数与微分. . . . . . . . . . . . . . 
.. 一阶导数. . . . . . . . . . . . . 
.. 机器学习中的常用函数. . . . . 
.. 高阶导数. . . . . . . . . . . . . 
.. 微分. . . . . . . . . . . . . . . . 
.. 导数与函数的单调性. . . . . . 
.. 极值判别法则. . . . . . . . . . 
.. 导数与函数的凹凸性. . . . . . 
. 微分中值定理. . . . . . . . . . . . . 
.. 罗尔中值定理. . . . . . . . . . 
.. 拉格朗日中值定理. . . . . . . . 
.. 柯西中值定理. . . . . . . . . . 
. 泰勒公式. . . . . . . . . . . . . . . . 
. 不定积分. . . . . . . . . . . . . . . . 
.. 不定积分的定义与性质. . . . . 
.. 换元积分法. . . . . . . . . . . . 
.. 分部积分法. . . . . . . . . . . . 
. 定积分. . . . . . . . . . . . . . . . . 
.. 定积分的定义与性质. . . . . . 
.. 牛顿-莱布尼茨公式. . . . . . . 
.. 定积分的计算. . . . . . . . . . 
.. 变上限积分. . . . . . . . . . . . 
.. 定积分的应用. . . . . . . . . . 
.. 广义积分. . . . . . . . . . . . . 
. 常微分方程. . . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 一阶线性微分方程. . . . . . . . 
第 章线性代数与矩阵论
. 向量及其运算. . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 基本运算. . . . . . . . . . . . . 
.. 向量的范数. . . . . . . . . . . . 
.. 解析几何. . . . . . . . . . . . . 
.. 线性相关性. . . . . . . . . . . . 
.. 向量空间. . . . . . . . . . . . . 
.. 应用――线性回归. . . . . . . . 
.. 应用――线性分类器与支持
向量机. . . . . . . . . . . . . . 
. 矩阵及其运算. . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 基本运算. . . . . . . . . . . . . 
.. 逆矩阵. . . . . . . . . . . . . . 
.. 矩阵的范数. . . . . . . . . . . . 
.. 应用――人工神经网络. . . . . 
.. 线性变换. . . . . . . . . . . . . 
. 行列式. . . . . . . . . . . . . . . . . 
.. 行列式的定义与性质. . . . . . 
.. 计算方法. . . . . . . . . . . . . 
. 线性方程组. . . . . . . . . . . . . . 
.. 高斯消元法. . . . . . . . . . . . 
.. 齐次方程组. . . . . . . . . . . . 
.. 非齐次方程组. . . . . . . . . . 
. 特征值与特征向量. . . . . . . . . . 
.. 特征值与特征向量. . . . . . . . 
.. 相似变换. . . . . . . . . . . . . 
.. 正交变换. . . . . . . . . . . . . 
.. QR 算法. . . . . . . . . . . . . . 
.. 广义特征值. . . . . . . . . . . . 
.. 瑞利商. . . . . . . . . . . . . . 
.. 谱范数与特征值的关系. . . . . 
.. 条件数. . . . . . . . . . . . . . 
.. 应用――谱归一化与谱正则化. . . . . . . . . . . . . . . . . 
. 二次型. . . . . . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 正定二次型与正定矩阵. . . . . 
.. 标准型. . . . . . . . . . . . . . 
. 矩阵分解. . . . . . . . . . . . . . . . 
.. 楚列斯基分解. . . . . . . . . . 
.. QR 分解. . . . . . . . . . . . . . 
.. 特征值分解. . . . . . . . . . . . 
.. 奇异值分解. . . . . . . . . . . . 
第 章多元函数微积分
. 偏导数. . . . . . . . . . . . . . . . . 
.. 一阶偏导数. . . . . . . . . . . . 
.. 高阶偏导数. . . . . . . . . . . . 
.. 全微分. . . . . . . . . . . . . . 
.. 链式法则. . . . . . . . . . . . . 
. 梯度与方向导数. . . . . . . . . . . . 
.. 梯度. . . . . . . . . . . . . . . . 
.. 方向导数. . . . . . . . . . . . . 
.. 应用――边缘检测与HOG
特征. . . . . . . . . . . . . . . . 
. 黑塞矩阵. . . . . . . . . . . . . . . . 
.. 黑塞矩阵的定义与性质. . . . . 
.. 凹凸性. . . . . . . . . . . . . . 
.. 极值判别法则. . . . . . . . . . 
.. 应用――最小二乘法. . . . . . . 
. 雅可比矩阵. . . . . . . . . . . . . . 
.. 雅可比矩阵的定义和性质. . . . 
.. 链式法则的矩阵形式. . . . . . 
. 向量与矩阵求导. . . . . . . . . . . . 
.. 常用求导公式. . . . . . . . . . 
.. 应用――反向传播算法. . . . . 
. 微分算法. . . . . . . . . . . . . . . . 
.. 符号微分. . . . . . . . . . . . . 
.. 数值微分. . . . . . . . . . . . . 
.. 自动微分. . . . . . . . . . . . . 
. 泰勒公式. . . . . . . . . . . . . . . . 
. 多重积分. . . . . . . . . . . . . . . . 
.. 二重积分. . . . . . . . . . . . . 
.. 三重积分. . . . . . . . . . . . . 
.. n 重积分. . . . . . . . . . . . . 
. 无穷级数. . . . . . . . . . . . . . . . 
.. 常数项级数. . . . . . . . . . . . 
.. 函数项级数. . . . . . . . . . . . 
第 章最优化方法
. 基本概念. . . . . . . . . . . . . . . . 
.. 问题定义. . . . . . . . . . . . . 
.. 迭代法的基本思想. . . . . . . . 
. 一阶优化算法. . . . . . . . . . . . . 
.. 梯度下降法. . . . . . . . . . . . 
.. 最速下降法. . . . . . . . . . . . 
.. 梯度下降法的改进. . . . . . . . 
.. 随机梯度下降法. . . . . . . . . 
.. 应用――人工神经网络. . . . . 
. 二阶优化算法. . . . . . . . . . . . . 
.. 牛顿法. . . . . . . . . . . . . . 
.. 拟牛顿法. . . . . . . . . . . . . 
. 分治法. . . . . . . . . . . . . . . . . 
.. 坐标下降法. . . . . . . . . . . . 
.. SMO 算法. . . . . . . . . . . . . 
.. 分阶段优化. . . . . . . . . . . . 
.. 应用――logistic 回归. . . . . . 
. 凸优化问题. . . . . . . . . . . . . . 
.. 数值优化算法面临的问题. . . . 
.. 凸集. . . . . . . . . . . . . . . . 
.. 凸优化问题及其性质. . . . . . 
.. 机器学习中的凸优化问题. . . . 
. 带约束的优化问题. . . . . . . . . . 
.. 拉格朗日乘数法. . . . . . . . . 
.. 应用――线性判别分析. . . . . 
.. 拉格朗日对偶. . . . . . . . . . 
.. KKT 条件. . . . . . . . . . . . . 
.. 应用――支持向量机. . . . . . . 
. 多目标优化问题. . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 求解算法. . . . . . . . . . . . . 
.. 应用――多目标神经结构搜
索. . . . . . . . . . . . . . . . . 
. 泛函极值与变分法. . . . . . . . . . 
.. 泛函与变分. . . . . . . . . . . . 
.. 欧拉―拉格朗日方程. . . . . . 
.. 应用――证明两点之间直线
最短. . . . . . . . . . . . . . . . 
. 目标函数的构造. . . . . . . . . . . . 
.. 有监督学习. . . . . . . . . . . . 
.. 无监督学习. . . . . . . . . . . . 
.. 强化学习. . . . . . . . . . . . . 
第 章概率论
. 随机事件与概率. . . . . . . . . . . . 
.. 随机事件概率. . . . . . . . . . 
.. 条件概率. . . . . . . . . . . . . 
.. 全概率公式. . . . . . . . . . . . 
.. 贝叶斯公式. . . . . . . . . . . . 
.. 条件独立. . . . . . . . . . . . . 
. 随机变量. . . . . . . . . . . . . . . . 
.. 离散型随机变量. . . . . . . . . 
.. 连续型随机变量. . . . . . . . . 
.. 数学期望. . . . . . . . . . . . . 
.. 方差与标准差. . . . . . . . . . 
.. Jensen 不等式. . . . . . . . . . . 
. 常用概率分布. . . . . . . . . . . . . 
.. 均匀分布. . . . . . . . . . . . . 
.. 伯努利分布. . . . . . . . . . . . 
.. 二项分布. . . . . . . . . . . . . 
.. 多项分布. . . . . . . . . . . . . 
.. 几何分布. . . . . . . . . . . . . 
.. 正态分布. . . . . . . . . . . . . 
.. t 分布. . . . . . . . . . . . . . . 
.. 应用――颜色直方图. . . . . . . 
.. 应用――贝叶斯分类器. . . . . 
. 分布变换. . . . . . . . . . . . . . . . 
.. 随机变量函数. . . . . . . . . . 
.. 逆变换采样算法. . . . . . . . . 
. 随机向量. . . . . . . . . . . . . . . . 
.. 离散型随机向量. . . . . . . . . 
.. 连续型随机向量. . . . . . . . . 
.. 数学期望. . . . . . . . . . . . . 
.. 协方差. . . . . . . . . . . . . . 
.. 常用概率分布. . . . . . . . . . 
.. 分布变换. . . . . . . . . . . . . 
.. 应用――高斯混合模型. . . . . 
. 极限定理. . . . . . . . . . . . . . . . 
.. 切比雪夫不等式. . . . . . . . . 
.. 大数定律. . . . . . . . . . . . . 
.. 中心极限定理. . . . . . . . . . 
. 参数估计. . . . . . . . . . . . . . . . 
.. 最大似然估计. . . . . . . . . . 
.. 最大后验概率估计. . . . . . . . 
.. 贝叶斯估计. . . . . . . . . . . . 
.. 核密度估计. . . . . . . . . . . . 
.. 应用――logistic 回归. . . . . . 
.. 应用――EM 算法. . . . . . . . 
.. 应用――Mean Shift 算法. . . . 
. 随机算法. . . . . . . . . . . . . . . . 
.. 基本随机数生成算法. . . . . . 
.. 遗传算法. . . . . . . . . . . . . 
.. 蒙特卡洛算法. . . . . . . . . . 
. 采样算法. . . . . . . . . . . . . . . . 
.. 拒绝采样. . . . . . . . . . . . . 
.. 重要性采样. . . . . . . . . . . . 
第 章信息论
. 熵与联合熵. . . . . . . . . . . . . . 
.. 信息量与熵. . . . . . . . . . . . 
.. 熵的性质. . . . . . . . . . . . . 
.. 应用――决策树. . . . . . . . . 
.. 联合熵. . . . . . . . . . . . . . 
. 交叉熵. . . . . . . . . . . . . . . . . 
.. 交叉熵的定义. . . . . . . . . . 
.. 交叉熵的性质. . . . . . . . . . 
.. 应用――softmax 回归. . . . . . 
. Kullback-Leibler 散度. . . . . . . . . 
.. KL 散度的定义. . . . . . . . . . 
.. KL 散度的性质. . . . . . . . . . 
.. 与交叉熵的关系. . . . . . . . . 
.. 应用――流形降维. . . . . . . . 
.. 应用――变分推断. . . . . . . . 
. Jensen-Shannon 散度. . . . . . . . . 
.. JS 散度的定义. . . . . . . . . . 
.. JS 散度的性质. . . . . . . . . . 
.. 应用――生成对抗网络. . . . . 
. 互信息. . . . . . . . . . . . . . . . . 
.. 互信息的定义. . . . . . . . . . 
.. 互信息的性质. . . . . . . . . . 
.. 与熵的关系. . . . . . . . . . . . 
.. 应用――特征选择. . . . . . . . 
. 条件熵. . . . . . . . . . . . . . . . . 
.. 条件熵定义. . . . . . . . . . . . 
.. 条件熵的性质. . . . . . . . . . 
.. 与熵以及互信息的关系. . . . . 
. 总结. . . . . . . . . . . . . . . . . . 
第 章随机过程
. 马尔可夫过程. . . . . . . . . . . . . 
.. 马尔可夫性. . . . . . . . . . . . 
.. 马尔可夫链的基本概念. . . . . 
.. 状态的性质与分类. . . . . . . . 
.. 平稳分布与极限分布. . . . . . 
.. 细致平衡条件. . . . . . . . . . 
.. 应用――隐马尔可夫模型. . . . 
.. 应用――强化学习. . . . . . . . 
. 马尔可夫链采样算法. . . . . . . . . 
.. 基本马尔可夫链采样. . . . . . 
.. MCMC 采样算法. . . . . . . . . 
.. Metropolis-Hastings 算法. . . . . 
.. Gibbs 算法. . . . . . . . . . . . 
. 高斯过程. . . . . . . . . . . . . . . . 
.. 高斯过程性质. . . . . . . . . . 
.. 高斯过程回归. . . . . . . . . . 
.. 应用――贝叶斯优化. . . . . . . 
第 章图论
. 图的基本概念. . . . . . . . . . . . . 
.. 基本概念. . . . . . . . . . . . . 
.. 应用――计算图与自动微分. . . 
.. 应用――概率图模型. . . . . . . 
.. 邻接矩阵与加权度矩阵. . . . . 
.. 应用――样本集的相似度图. . . 
. 若干特殊的图. . . . . . . . . . . . . 
.. 联通图. . . . . . . . . . . . . . 
.. 二部图. . . . . . . . . . . . . . 
.. 应用――受限玻尔兹曼机. . . . 
.. 有向无环图. . . . . . . . . . . . 
.. 应用――神经结构搜索. . . . . 
. 重要的算法. . . . . . . . . . . . . . 
.. 遍历算法. . . . . . . . . . . . . 
.. 最短路径算法. . . . . . . . . . 
.. 拓扑排序算法. . . . . . . . . . 
. 谱图理论. . . . . . . . . . . . . . . . 
.. 拉普拉斯矩阵. . . . . . . . . . 
.. 归一化拉普拉斯矩阵. . . . . . 
.. 应用――流形降维. . . . . . . . 
・ ・ ・ ・ ・ ・ (收起)绪论　机器学习概述　　
第章　机器学习的构成要素　　
.　任务：可通过机器学习解决的问题　　
..　探寻结构　　
..　性能评价　　
.　模型：机器学习的输出　　
..　几何模型　　
..　概率模型　　
..　逻辑模型　　
..　分组模型与评分模型　　
.　特征：机器学习的马达　　
..　特征的两种用法　　
..　特征的构造与变换　　
..　特征之间的交互　　
.　总结与展望　　
第章　两类分类及相关任务　　
.　分类　　
..　分类性能的评价　　
..　分类性能的可视化　　
.　评分与排序　　
..　排序性能的评价及可视化　　
..　将排序器转化为分类器　　
.　类概率估计　　
..　类概率估计量　　
..　将排序器转化为概率估计子　　
.　小结与延伸阅读　　
第章　超越两类分类　　
.　处理多类问题　　
..　多类分类　　
..　多类得分及概率　　
.　回归　　
.　无监督学习及描述性学习　　
..　预测性聚类与描述性聚类　　
..　其他描述性模型　　
.　小结与延伸阅读　　
第章　概念学习　　
.　假设空间　　
..　最小一般性　　
..　内部析取　　
.　通过假设空间的路径　　
..　最一般相容假设　　
..　封闭概念　　
.　超越合取概念　　
.　可学习性　　
.　小结与延伸阅读　　
第章　树模型　　
.　决策树　　
.　排序与概率估计树　　
.　作为减小方差的树学习方法　　
..　回归树　　
..　聚类树　　
.　小结与延伸阅读　　
第章　规则模型　　
.　学习有序规则列表　　
.　学习无序规则集　　
..　用于排序和概率估计的规则集　　
..　深入探究规则重叠　　
.　描述性规则学习　　
..　用于子群发现的规则学习　　
..　关联规则挖掘　　
.　一阶规则学习　　
.　小结与延伸阅读　　
第章　线性模型　　
.　最小二乘法　　
..　多元线性回归　　
..　正则化回归　　
..　利用最小二乘回归实现分类　　
.　感知机　　
.　支持向量机　　
.　从线性分类器导出概率　　
.　超越线性的核方法　　
.　小结与延伸阅读　　
第章　基于距离的模型　　
.　距离测度的多样性　　
.　近邻与范例　　
.　最近邻分类器　　
.　基于距离的聚类　　
..　K均值算法　　
..　K中心点聚类　　
..　silhouette　　
.　层次聚类　　
.　从核函数到距离　　
.　小结与延伸阅读　　
第章　概率模型　　
.　正态分布及其几何意义　　
.　属性数据的概率模型　　
..　利用朴素贝叶斯模型实现分类　　
..　训练朴素贝叶斯模型　　
.　通过优化条件似然实现鉴别式学习　　
.　含隐变量的概率模型　　
..　期望最大化算法　　
..　高斯混合模型　　
.　基于压缩的模型　　
.　小结与延伸阅读　　
第章　特征　　
.　特征的类型　　
..　特征上的计算　　
..　属性特征、有序特征及数量特征　　
..　结构化特征　　
.　特征变换　　
..　阈值化与离散化　　
..　归一化与标定　　
..　特征缺失　　
.　特征的构造与选择　　
.　小结与延伸阅读　　
第章　模型的集成　　
.　Bagging与随机森林　　
.　Boosting　　
.　集成学习进阶　　
..　偏差、方差及裕量　　
..　其他集成方法　　
..　元学习　　
.　小结与延伸阅读　　
第章　机器学习的实验　　
.　度量指标的选择　　
.　量指标的获取　　
.　如何解释度量指标　　
.　小结与延伸阅读　　
后记　路在何方　　
记忆要点　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)出版者的话
译者序
前言
缩写和符号
术语
第章 导言
. 什么是神经网络
. 人类大脑
. 神经元模型
. 被看作有向图的神经网络
. 反馈
. 网络结构
. 知识表示
. 学习过程
. 学习任务
. 结束语
注释和参考文献
第章 Rosenblatt感知器
. 引言
. 感知器
. 感知器收敛定理
. 高斯环境下感知器与贝叶斯分类器的关系
. 计算机实验：模式分类
. 批量感知器算法
. 小结和讨论
注释和参考文献
习题
第章 通过回归建立模型
. 引言
. 线性回归模型：初步考虑
. 参数向量的最大后验估计
. 正则最小二乘估计和MAP估计之间的关系
. 计算机实验：模式分类
. 最小描述长度原则
. 固定样本大小考虑
. 工具变量方法
. 小结和讨论
注释和参考文献
习题
第章 最小均方算法
. 引言
. LMS算法的滤波结构
. 无约束最优化：回顾
. 维纳滤波器
. 最小均方算法
. 用马尔可夫模型来描画LMS算法和维纳滤波器的偏差
. 朗之万方程：布朗运动的特点
. Kushner直接平均法
. 小学习率参数下统计LMS学习理论
. 计算机实验Ⅰ：线性预测
. 计算机实验Ⅱ：模式分类
. LMS算法的优点和局限
. 学习率退火方案
. 小结和讨论
注释和参考文献
习题
第章 多层感知器
. 引言
. 一些预备知识
. 批量学习和在线学习
. 反向传播算法
. 异或问题
. 改善反向传播算法性能的试探法
. 计算机实验：模式分类
. 反向传播和微分
. Hessian矩阵及其在在线学习中的规则
. 学习率的最优退火和自适应控制
. 泛化
. 函数逼近
. 交叉验证
. 复杂度正则化和网络修剪
. 反向传播学习的优点和局限
. 作为最优化问题看待的监督学习
. 卷积网络
. 非线性滤波
. 小规模和大规模学习问题
. 小结和讨论
注释和参考文献
习题
第章 核方法和径向基函数网络
. 引言
. 模式可分性的Cover定理
. 插值问题
. 径向基函数网络
. K-均值聚类
. 权向量的递归最小二乘估计
. RBF网络的混合学习过程
. 计算机实验：模式分类
. 高斯隐藏单元的解释
. 核回归及其与RBF网络的关系
. 小结和讨论
注释和参考文献
习题
第章 支持向量机
. 引言
. 线性可分模式的最优超平面
. 不可分模式的最优超平面
. 使用核方法的支持向量机
. 支持向量机的设计
. XOR问题
. 计算机实验:模式分类
. 回归：鲁棒性考虑
. 线性回归问题的最优化解
. 表示定理和相关问题
. 小结和讨论
注释和参考文献
习题
第章 正则化理论
. 引言
. 良态问题的Hadamard条件
. Tikhonov正则化理论
. 正则化网络
. 广义径向基函数网络
. 再论正则化最小二乘估计
. 对正则化的附加要点
. 正则化参数估计
. 半监督学习
. 流形正则化：初步的考虑
. 可微流形
. 广义正则化理论
. 光谱图理论
. 广义表示定理
. 拉普拉斯正则化最小二乘算法
. 用半监督学习对模式分类的实验
. 小结和讨论
注释和参考文献
习题
第章 主分量分析
. 引言
. 自组织原则
. 自组织的特征分析
. 主分量分析：扰动理论
. 基于Hebb的最大特征滤波器
. 基于Hebb的主分量分析
. 计算机实验：图像编码
. 核主分量分析
. 自然图像编码中的基本问题
. 核Hebb算法
. 小结和讨论
注释和参考文献
习题
第章 自组织映射
. 引言
. 两个基本的特征映射模型
. 自组织映射
. 特征映射的性质
. 计算机实验Ⅰ：利用SOM解网格动力学问题
. 上下文映射
. 分层向量量化
. 核自组织映射
. 计算机实验Ⅱ：利用核SOM解点阵动力学问题
. 核SOM和相对熵之间的关系
. 小结和讨论
注释和参考文献
习题
第章 信息论学习模型
. 引言
. 熵
. 最大熵原则
. 互信息
. 相对熵
. 系词
. 互信息作为最优化的目标函数
. 最大互信息原则
. 最大互信息和冗余减少
. 空间相干特征
. 空间非相干特征
. 独立分量分析
. 自然图像的稀疏编码以及与ICA编码的比较
. 独立分量分析的自然梯度学习
. 独立分量分析的最大似然估计
. 盲源分离的最大熵学习
. 独立分量分析的负熵最大化
. 相关独立分量分析
. 速率失真理论和信息瓶颈
. 数据的最优流形表达
. 计算机实验：模式分类
. 小结和讨论
注释和参考文献
习题
第章 植根于统计力学的随机方法
. 引言
. 统计力学
. 马尔可夫链
. Metropolis算法
. 模拟退火
. Gibbs抽样
. Boltzmann机
. logistic信度网络
. 深度信度网络
. 确定性退火
. 和EM算法的类比
. 小结和讨论
注释和参考文献
习题
第章 动态规划
. 引言
. 马尔可夫决策过程
. Bellman最优准则
. 策略迭代
. 值迭代
. 逼近动态规划：直接法
. 时序差分学习
. Q学习
. 逼近动态规划：非直接法
. 最小二乘策略评估
. 逼近策略迭代
. 小结和讨论
注释和参考文献
习题
第章 神经动力学
. 引言
. 动态系统
. 平衡状态的稳定性
. 吸引子
. 神经动态模型
. 作为递归网络范例的吸引子操作
. Hopfield模型
. Cohen-Grossberg定理
. 盒中脑状态模型
. 奇异吸引子和混沌
. 混沌过程的动态重构
. 小结和讨论
注释和参考文献
习题
第章 动态系统状态估计的贝叶斯滤波
. 引言
. 状态空间模型
. 卡尔曼滤波器
. 发散现象及平方根滤波
. 扩展的卡尔曼滤波器
. 贝叶斯滤波器
. 数值积分卡尔曼滤波器:基于卡尔曼滤波器
. 粒子滤波器
. 计算机实验：扩展的卡尔曼滤波器和粒子滤波器对比评价
. 大脑功能建模中的
卡尔曼滤波
. 小结和讨论
注释和参考文献
习题
第章 动态驱动递归网络
. 引言
. 递归网络体系结构
. 通用逼近定理
. 可控性和可观测性
. 递归网络的计算能力
. 学习算法
. 通过时间的反向传播
. 实时递归学习
. 递归网络的消失梯度
. 利用非线性逐次状态估计的递归网络监督学习框架
. 计算机实验：Mackay-Glass吸引子的动态重构
. 自适应考虑
. 实例学习：应用于神经控制的模型参考
. 小结和讨论
注释和参考文献
习题
参考文献
・ ・ ・ ・ ・ ・ (收起)推荐序
译者序
前言
致谢
关于技术评审人
第章　机器学习简介 
.　机器学习的起源 
.　机器学习的使用与滥用 
.　机器如何学习 
..　抽象化和知识表达 
..　一般化 
..　评估学习的成功性 
.　将机器学习应用于数据中的步骤 
.　选择机器学习算法 
..　考虑输入的数据 
..　考虑机器学习算法的类型 
..　为数据匹配合适的算法 
.　使用R进行机器学习 
.　总结 
第章　数据的管理和理解 
.　R数据结构 
.　向量 
.　因子 
..　列表 
..　数据框 
..　矩阵和数组 
.　用R管理数据 
..　保存和加载R数据结构 
..　用CSV文件导入和保存数据 
..　从SQL数据库导入数据 
.　探索和理解数据 
..　探索数据的结构 
..　探索数值型变量 
..　探索分类变量 
..　探索变量之间的关系 
.　总结 
第章　懒惰学习――使用近邻分类 
.　理解使用近邻进行分类 
..　kNN算法 
..　为什么kNN算法是懒惰的 
.　用kNN算法诊断乳腺癌 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　概率学习――朴素贝叶斯分类 
.　理解朴素贝叶斯 
..　贝叶斯方法的基本概念 
..　朴素贝叶斯算法 
.　例子――基于贝叶斯算法的手机垃圾短信过滤 
..　第步――收集数据 
..　第步――探索和准备数据 
..　数据准备――处理和分析文本数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提升模型的性能 
.　总结 
第章　分而治之――应用决策树和规则进行分类 
.　理解决策树 
..　分而治之 
..　C.决策树算法 
.　例子――使用C.决策树识别高风险银行贷款 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　理解分类规则 
..　独立而治之 
..　单规则（R）算法 
..　RIPPER算法 
..　来自决策树的规则 
.　例子――应用规则学习识别有毒的蘑菇 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　预测数值型数据――回归方法 
.　理解回归 
..　简单线性回归 
..　普通最小二乘估计 
..　相关系数 
..　多元线性回归 
.　例子――应用线性回归预测医疗费用 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　理解回归树和模型树 
.　例子――用回归树和模型树估计葡萄酒的质量 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　黑箱方法――神经网络和支持向量机 
.　理解神经网络 
..　从生物神经元到人工神经元 
..　激活函数 
..　网络拓扑 
..　用后向传播训练神经网络 
.　用人工神经网络对混凝土的强度进行建模 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　理解支持向量机 
..　用超平面分类 
..　寻找最大间隔 
..　对非线性空间使用核函数 
.　用支持向量机进行光学字符识别 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　探寻模式――基于关联规则的购物篮分析 
.　理解关联规则 
.　例子――用关联规则确定经常一起购买的食品杂货 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　寻找数据的分组――k均值聚类 
.　理解聚类 
..　聚类――一种机器学习任务 
..　k均值聚类算法 
..　用k均值聚类探寻青少年市场细分 
..　第步――收集数据 
..　第步――探索和准备数据 
..　第步――基于数据训练模型 
..　第步――评估模型的性能 
..　第步――提高模型的性能 
.　总结 
第章　模型性能的评价 
.　度量分类方法的性能 
..　在R中处理分类预测数据 
..　深入探讨混淆矩阵 
..　使用混淆矩阵度量性能 
..　准确度之外的其他性能评价指标 
..　性能权衡的可视化 
.　评估未来的性能 
..　保持法 
..　交叉验证 
..　自助法抽样 
.　总结 
第章　提高模型的性能 
.　调整多个模型来提高性能 
.　使用元学习来提高模型的性能 
..　理解集成学习 
..　bagging 
..　boosting 
..　随机森林 
.　总结 
第章　其他机器学习主题 
.　分析专用数据 
..　用RCurl添加包从网上获取数据 
..　用XML添加包读/写XML格式数据 
..　用rjson添加包读/写JSON 
..　用xlsx添加包读/写Microsoft Excel电子表格 
..　生物信息学数据 
..　社交网络数据和图数据 
.　提高R语言的性能 
..　处理非常大的数据集 
..　使用并行处理来加快学习过程 
..　GPU计算 
..　部署最优的学习算法 
.　总结 
・ ・ ・ ・ ・ ・ (收起)第章　Python机器学习入门　　
. 　梦之队：机器学习与Python　　
. 　这本书将教给你什么（以及不会教什么）　　
. 　遇到困难的时候怎么办　　
. 　开始　　
.. 　NumPy、SciPy和Matplotlib简介　　
.. 　安装Python　　
.. 　使用NumPy和SciPy智能高效地处理数据　　
.. 　学习NumPy　　
.. 　学习SciPy　　
. 　我们第一个（极小的）机器学习应用　　
.. 　读取数据　　
.. 　预处理和清洗数据　　
.. 　选择正确的模型和学习算法　　
. 　小结　　
第章　如何对真实样本分类　　
. 　Iris数据集　　
.. 　第一步是可视化　　
.. 　构建第一个分类模型　　
. 　构建更复杂的分类器　　
. 　更复杂的数据集和更复杂的分类器　　
.. 　从Seeds数据集中学习　　
.. 　特征和特征工程　　
.. 　最邻近分类　　
. 　二分类和多分类　　
. 　小结　　
第章　聚类：寻找相关的帖子　　
. 　评估帖子的关联性　　
.. 　不应该怎样　　
.. 　应该怎样　　
. 　预处理：用相近的公共词语个数来衡量相似性　　
.. 　将原始文本转化为词袋　　
.. 　统计词语　　
.. 　词语频次向量的归一化　　
.. 　删除不重要的词语　　
.. 　词干处理　　
.. 　停用词兴奋剂　　
.. 　我们的成果和目标　　
. 　聚类　　
.. 　K均值　　
.. 　让测试数据评估我们的想法　　
.. 　对帖子聚类　　
. 　解决我们最初的难题　　
. 　调整参数　　
. 　小结　　
第章　主题模型　　
. 　潜在狄利克雷分配（LDA）　　
. 　在主题空间比较相似度　　
. 　选择主题个数　　
. 　小结　　
第章　分类：检测劣质答案　　
. 　路线图概述　　
. 　学习如何区分出优秀的答案　　
.. 　调整样本　　
.. 　调整分类器　　
. 　获取数据　　
.. 　将数据消减到可处理的程度　　
.. 　对属性进行预选择和处理　　
.. 　定义什么是优质答案　　
. 　创建第一个分类器　　
.. 　从k邻近（kNN）算法开始　　
.. 　特征工程　　
.. 　训练分类器　　
.. 　评估分类器的性能　　
.. 　设计更多的特征　　
. 　决定怎样提升效果　　
.. 　偏差?方差及其折中　　
.. 　解决高偏差　　
.. 　解决高方差　　
.. 　高偏差或低偏差　　
. 　采用逻辑回归　　
.. 　一点数学和一个小例子　　
.. 　在帖子分类问题上应用逻辑回归　　
. 　观察正确率的背后：准确率和召回率　　
. 　为分类器瘦身　　
. 　出货　　
. 　小结　　
第章　分类II：情感分析　　
. 　路线图概述　　
. 　获取推特（Twitter）数据　　
. 　朴素贝叶斯分类器介绍　　
.. 　了解贝叶斯定理　　
.. 　朴素　　
.. 　使用朴素贝叶斯进行分类　　
.. 　考虑未出现的词语和其他古怪情况　　
.. 　考虑算术下溢　　
. 　创建第一个分类器并调优　　
.. 　先解决一个简单问题　　
.. 　使用所有的类　　
.. 　对分类器的参数进行调优　　
. 　清洗推文　　
. 　将词语类型考虑进去　　
.. 　确定词语的类型　　
.. 　用SentiWordNet成功地作弊　　
.. 　我们第一个估算器　　
.. 　把所有东西融合在一起　　
. 　小结　　
第章　回归：推荐　　
. 　用回归预测房价　　
.. 　多维回归　　
.. 　回归里的交叉验证　　
. 　惩罚式回归　　
.. 　L和L惩罚　　
.. 　在Scikit-learn中使用Lasso或弹性网　　
. 　P大于N的情形　　
.. 　基于文本的例子　　
.. 　巧妙地设置超参数（hyperparameter）　　
.. 　评分预测和推荐　　
. 　小结　　
第章　回归：改进的推荐　　
. 　改进的推荐　　
.. 　使用二值推荐矩阵　　
.. 　审视电影的近邻　　
.. 　组合多种方法　　
. 　购物篮分析　　
.. 　获取有用的预测　　
.. 　分析超市购物篮　　
.. 　关联规则挖掘　　
.. 　更多购物篮分析的高级话题　　
. 　小结　　
第章　分类III：音乐体裁分类　　
. 　路线图概述　　
. 　获取音乐数据　　
. 　观察音乐　　
. 　用FFT构建第一个分类器　　
.. 　增加实验敏捷性　　
.. 　训练分类器　　
.. 　在多分类问题中用混淆矩阵评估正确率　　
.. 　另一种方式评估分类器效果：受试者工作特征曲线（ROC）　　
. 　用梅尔倒频谱系数（MFCC）提升分类效果　　
. 　小结　　
第章　计算机视觉：模式识别　　
. 　图像处理简介　　
. 　读取和显示图像　　
.. 　图像处理基础　　
.. 　加入椒盐噪声　　
.. 　模式识别　　
.. 　计算图像特征　　
.. 　设计你自己的特征　　
. 　在更难的数据集上分类　　
. 　局部特征表示　　
. 　小结　　
第章　降维　　
. 　路线图　　
. 　选择特征　　
.. 　用筛选器检测冗余特征　　
.. 　用封装器让模型选择特征　　
. 　其他特征选择方法　　
. 　特征抽取　　
.. 　主成分分析（PCA）　　
.. 　PCA的局限性以及LDA会有什么帮助　　
. 　多维标度法（MDS）　　
. 　小结　　
第章　大数据　　
. 　了解大数据　　
. 　用Jug程序包把你的处理流程分解成几个任务　　
.. 　关于任务　　
.. 　复用部分结果　　
.. 　幕后的工作原理　　
.. 　用Jug分析数据　　
. 　使用亚马逊Web服务（AWS）　　
.. 　构建你的第一台机器　　
.. 　用starcluster自动创建集群　　
. 　小结　　
附录A 　更多机器学习知识　　
A. 　在线资源　　
A. 　参考书　　
A.. 　问答网站　　
A.. 　博客　　
A.. 　数据资源　　
A.. 　竞争日益加剧　　
A. 　还剩下什么　　
A. 　小结　　
索引　　
・ ・ ・ ・ ・ ・ (收起)第章 引言 
. 学习与智能优化：燎原之火 
. 寻找黄金和寻找伴侣 
. 需要的只是数据 
. 超越传统的商业智能 
. LION方法的实施 
. “动手”的方法 
第章 懒惰学习：最近邻方法 
第章 学习需要方法 
. 从已标记的案例中学习：最小化和泛化 
. 学习、验证、测试 
. 不同类型的误差 
第一部分 监督学习
第章 线性模型 
. 线性回归 
. 处理非线性函数关系的技巧 
. 用于分类的线性模型 
. 大脑是如何工作的 
. 线性模型为何普遍，为何成功 
. 最小化平方误差和 
. 数值不稳定性和岭回归 
第章 广义线性最小二乘法 
. 拟合的优劣和卡方分布 
. 最小二乘法与最大似然估计 
.. 假设检验 
.. 交叉验证 
. 置信度的自助法 
第章 规则、决策树和森林 
. 构造决策树 
. 民主与决策森林 
第章 特征排序及选择 
. 特征选择：情境 
. 相关系数 
. 相关比 
. 卡方检验拒绝统计独立性 
. 熵和互信息 
第章 特定非线性模型 
. logistic 回归 
. 局部加权回归 
. 用LASSO来缩小系数和选择输入值 
第章 神经网络：多层感知器 
. 多层感知器 
. 通过反向传播法学习 
.. 批量和bold driver反向传播法 
.. 在线或随机反向传播 
.. 训练多层感知器的高级优化 
第章 深度和卷积网络 
. 深度神经网络 
.. 自动编码器 
.. 随机噪声、屏蔽和课程 
. 局部感受野和卷积网络 
第章 统计学习理论和支持向量机 
. 经验风险最小化 
.. 线性可分问题 
.. 不可分问题 
.. 非线性假设 
.. 用于回归的支持向量 
第章 最小二乘法和健壮内核机器 
. 最小二乘支持向量机分类器 
. 健壮加权最小二乘支持向量机 
. 通过修剪恢复稀疏 
. 算法改进：调谐QP、原始版本、无补偿 
第章 机器学习中的民主 
. 堆叠和融合 
. 实例操作带来的多样性：装袋法和提升法 
. 特征操作带来的多样性 
. 输出值操作带来的多样性：纠错码 
. 训练阶段随机性带来的多样性 
. 加性logistic回归 
. 民主有助于准确率－拒绝的折中 
第章 递归神经网络和储备池计算 
. 递归神经网络 
. 能量极小化霍普菲尔德网络 
. 递归神经网络和时序反向传播 
. 递归神经网络储备池学习 
. 超限学习机 
第二部分 无监督学习和聚类
第章 自顶向下的聚类：K均值 
. 无监督学习的方法 
. 聚类：表示与度量 
. 硬聚类或软聚类的K均值方法 
第章 自底向上（凝聚）聚类 
. 合并标准以及树状图 
. 适应点的分布距离：马氏距离 
. 附录：聚类的可视化 
第章 自组织映射 
. 将实体映射到原型的人工皮层 
. 使用成熟的自组织映射进行分类 
第章 通过线性变换降维（投影） 
. 线性投影 
. 主成分分析 
. 加权主成分分析：结合坐标和关系 
. 通过比值优化进行线性判别 
. 费希尔线性判别分析 
第章 通过非线性映射可视化图与网络 
. 最小应力可视化 
. 一维情况：谱图绘制 
. 复杂图形分布标准 
第章 半监督学习 
. 用部分无监督数据进行学习 
.. 低密度区域中的分离 
.. 基于图的算法 
.. 学习度量 
.. 集成约束和度量学习 
第三部分 优化：力量之源
第章 自动改进的局部方法 
. 优化和学习 
. 基于导数技术的一维情况 
.. 导数可以由割线近似 
.. 一维最小化 
. 求解高维模型（二次正定型） 
.. 梯度与最速下降法 
.. 共轭梯度法 
. 高维中的非线性优化 
.. 通过线性查找的全局收敛 
.. 解决不定黑塞矩阵 
.. 与模型信赖域方法的关系 
.. 割线法 
.. 缩小差距：二阶方法与线性复杂度 
. 不涉及导数的技术：反馈仿射振荡器 
.. RAS：抽样区域的适应性 
.. 为健壮性和多样化所做的重复 
第章 局部搜索和反馈搜索优化 
. 基于扰动的局部搜索 
. 反馈搜索优化：搜索时学习 
. 基于禁忌的反馈搜索优化 
第章 合作反馈搜索优化 
. 局部搜索过程的智能协作 
. CoRSO：一个政治上的类比 
. CoRSO的例子：RSO与RAS合作 
第章 多目标反馈搜索优化 
. 多目标优化和帕累托最优 
. 脑－计算机优化：循环中的用户 
第四部分 应用精选
第章 文本和网页挖掘 
. 网页信息检索与组织 
.. 爬虫 
.. 索引 
. 信息检索与排名 
.. 从文档到向量：向量－空间模型 
.. 相关反馈 
.. 更复杂的相似性度量 
. 使用超链接来进行网页排名 
. 确定中心和权威：HITS 
. 聚类 
第章 协同过滤和推荐 
. 通过相似用户结合评分 
. 基于矩阵分解的模型 
参考文献 
索引 
・ ・ ・ ・ ・ ・ (收起)序言一
序言二
前　言
作者介绍
第章　绪论/ 
.　人工智能及其飞速发展/ 
.　大规模、分布式机器学习/ 
.　本书的安排/ 
参考文献/ 
第章　机器学习基础/ 
.　机器学习的基本概念/ 
.　机器学习的基本流程/ 
.　常用的损失函数/ 
..　Hinge损失函数/ 
..　指数损失函数/ 
..　交叉熵损失函数/ 
.　常用的机器学习模型/ 
..　线性模型/ 
..　核方法与支持向量机/ 
..　决策树与Boosting/ 
..　神经网络/ 
.　常用的优化方法/ 
.　机器学习理论/ 
..　机器学习算法的泛化误差/ 
..　泛化误差的分解/ 
..　基于容度的估计误差的上界/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习框架/ 
.　大数据与大模型的挑战/ 
.　分布式机器学习的基本流程/ 
.　数据与模型划分模块/ 
.　单机优化模块/ 
.　通信模块/ 
..　通信的内容/ 
..　通信的拓扑结构/ 
..　通信的步调/ 
..　通信的频率/ 
.　数据与模型聚合模块/ 
.　分布式机器学习理论/ 
.　分布式机器学习系统/ 
.　总结/ 
参考文献/ 
第章　单机优化之确定性算法/ 
.　基本概述/ 
..　机器学习的优化框架/ 
..　优化算法的分类和发展历史/ 
.　一阶确定性算法/ 
..　梯度下降法/ 
..　投影次梯度下降法/ 
..　近端梯度下降法/ 
..　Frank-Wolfe算法/ 
..　Nesterov加速法/ 
..　坐标下降法/ 
.　二阶确定性算法/ 
..　牛顿法/ 
..　拟牛顿法/ 
.　对偶方法/ 
.　总结/ 
参考文献/ 
第章　单机优化之随机算法/ 
.　基本随机优化算法/ 
..　随机梯度下降法/ 
..　随机坐标下降法/ 
..　随机拟牛顿法/ 
..　随机对偶坐标上升法/ 
..　小结/ 
.　随机优化算法的改进/ 
..　方差缩减方法/ 
..　算法组合方法/ 
.　非凸随机优化算法/ 
..　Ada系列算法/ 
..　非凸理论分析/ 
..　逃离鞍点问题/ 
..　等级优化算法/ 
.　总结/ 
参考文献/ 
第章　数据与模型并行/ 
.　基本概述/ 
.　计算并行模式/ 
.　数据并行模式/ 
..　数据样本划分/ 
..　数据维度划分/ 
.　模型并行模式/ 
..　线性模型/ 
..　神经网络/ 
.　总结/ 
参考文献/ 
第章　通信机制/ 
.　基本概述/ 
.　通信的内容/ 
..　参数或参数的更新/ 
..　计算的中间结果/ 
..　讨论/ 
.　通信的拓扑结构/ 
..　基于迭代式MapReduce/AllReduce的通信拓扑/ 
..　基于参数服务器的通信拓扑/ 
..　基于数据流的通信拓扑/ 
..　讨论/ 
.　通信的步调/ 
..　同步通信/ 
..　异步通信/ 
..　同步和异步的平衡/ 
..　讨论/ 
.　通信的频率/ 
..　时域滤波/ 
..　空域滤波/ 
..　讨论/ 
.　总结/ 
参考文献/ 
第章　数据与模型聚合/ 
.　基本概述/ 
.　基于模型加和的聚合方法/ 
..　基于全部模型加和的聚合/ 
..　基于部分模型加和的聚合/ 
.　基于模型集成的聚合方法/ 
..　基于输出加和的聚合/ 
..　基于投票的聚合/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习算法/ 
.　基本概述/ 
.　同步算法/ 
..　同步SGD方法/ 
..　模型平均方法及其改进/ 
..　ADMM算法/ 
..　弹性平均SGD算法/ 
..　讨论/ 
.　异步算法/ 
..　异步SGD/ 
..　Hogwild!算法/ 
..　Cyclades算法/ 
..　带延迟处理的异步算法/ 
..　异步方法的进一步加速/ 
..　讨论/ 
.　同步和异步的对比与融合/ 
..　同步和异步算法的实验对比/ 
..　同步和异步的融合/ 
.　模型并行算法/ 
..　DistBelief/ 
..　AlexNet/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习理论/ 
.　基本概述/ 
.　收敛性分析/ 
..　优化目标和算法/ 
..　数据和模型并行/ 
..　同步和异步/ 
.　加速比分析/ 
..　从收敛速率到加速比/ 
..　通信量的下界/ 
.　泛化分析/ 
..　优化的局限性/ 
..　具有更好泛化能力的非凸优化算法/ 
.　总结/ 
参考文献/ 
第章　分布式机器学习系统/ 
.　基本概述/ 
.　基于IMR的分布式机器学习系统/ 
..　IMR和Spark/ 
..　Spark MLlib/ 
.　基于参数服务器的分布式机器学习系统/ 
..　参数服务器/ 
..　Multiverso参数服务器/ 
.　基于数据流的分布式机器学习系统/ 
..　数据流/ 
..　TensorFlow数据流系统/ 
.　实战比较/ 
.　总结/ 
参考文献/ 
第章　结语/ 
.　全书总结/ 
.　未来展望/ 
索引/ 
・ ・ ・ ・ ・ ・ (收起)前言
第一部分 机器学习基础
第章 机器学习概览
什么是机器学习
为什么要使用机器学习
机器学习系统的种类
监督式/无监督式学习
批量学习和在线学习
基于实例与基于模型的学习
机器学习的主要挑战
训练数据的数量不足
训练数据不具代表性
质量差的数据
无关特征
训练数据过度拟合
训练数据拟合不足
退后一步
测试与验证
练习
第章 端到端的机器学习项目
使用真实数据
观察大局
框架问题
选择性能指标
检查假设
获取数据
创建工作区
下载数据
快速查看数据结构
创建测试集
从数据探索和可视化中获得洞见
将地理数据可视化
寻找相关性
试验不同属性的组合
机器学习算法的数据准备
数据清理
处理文本和分类属性
自定义转换器
特征缩放
转换流水线
选择和训练模型
培训和评估训练集
使用交叉验证来更好地进行评估
微调模型
网格搜索
随机搜索
集成方法
分析最佳模型及其错误
通过测试集评估系统
启动、监控和维护系统
试试看
练习
第章 分类
MNIST
训练一个二元分类器
性能考核
使用交叉验证测量精度
混淆矩阵
精度和召回率
精度/召回率权衡
ROC曲线
多类别分类器
错误分析
多标签分类
多输出分类
练习
第章 训练模型
线性回归
标准方程
计算复杂度
梯度下降
批量梯度下降
随机梯度下降
小批量梯度下降
多项式回归
学习曲线
正则线性模型
岭回归
套索回归
弹性网络
早期停止法
逻辑回归
概率估算
训练和成本函数
决策边界
Softmax回归
练习
第章 支持向量机
线性SVM分类
软间隔分类
非线性SVM分类
多项式核
添加相似特征
高斯RBF核函数
计算复杂度
SVM回归
工作原理
决策函数和预测
训练目标
二次规划
对偶问题
核化SVM
在线SVM
练习
第章 决策树
决策树训练和可视化
做出预测
估算类别概率
CART训练算法
计算复杂度
基尼不纯度还是信息熵
正则化超参数
回归
不稳定性
练习
第章 集成学习和随机森林
投票分类器
bagging和pasting
Scikit-Learn的bagging和pasting
包外评估
Random Patches和随机子空间
随机森林
极端随机树
特征重要性
提升法
AdaBoost
梯度提升
堆叠法
练习
第章 降维
维度的诅咒
数据降维的主要方法
投影
流形学习
PCA
保留差异性
主成分
低维度投影
使用Scikit-Learn
方差解释率
选择正确数量的维度
PCA压缩
增量PCA
随机PCA
核主成分分析
选择核函数和调整超参数
局部线性嵌入
其他降维技巧
练习
第二部分 神经网络和深度学习
第章 运行TensorFlow
安装
创建一个计算图并在会话中执行
管理图
节点值的生命周期
TensorFlow中的线性回归
实现梯度下降
手工计算梯度
使用自动微分
使用优化器
给训练算法提供数据
保存和恢复模型
用TensorBoard来可视化图和训练曲线
命名作用域
模块化
共享变量
练习
第章 人工神经网络简介
从生物神经元到人工神经元
生物神经元
具有神经元的逻辑计算
感知器
多层感知器和反向传播
用TensorFlow的高级API来训练MLP
使用纯TensorFlow训练DNN
构建阶段
执行阶段
使用神经网络
微调神经网络的超参数
隐藏层的个数
每个隐藏层中的神经元数
激活函数
练习
第章 训练深度神经网络
梯度消失/爆炸问题
Xavier初始化和He初始化
非饱和激活函数
批量归一化
梯度剪裁
重用预训练图层
重用TensorFlow模型
重用其他框架的模型
冻结低层
缓存冻结层
调整、丢弃或替换高层
模型动物园
无监督的预训练
辅助任务中的预训练
快速优化器
Momentum优化
Nesterov梯度加速
AdaGrad
RMSProp
Adam优化
学习速率调度
通过正则化避免过度拟合
提前停止
和正则化
dropout
最大范数正则化
数据扩充
实用指南
练习
第章 跨设备和服务器的分布式TensorFlow
一台机器上的多个运算资源
安装
管理GPU RAM
在设备上操作
并行执行
控制依赖
多设备跨多服务器
开启一个会话
master和worker服务
分配跨任务操作
跨多参数服务器分片变量
用资源容器跨会话共享状态
使用TensorFlow队列进行异步通信
直接从图中加载数据
在TensorFlow集群上并行化神经网络
一台设备一个神经网络
图内与图间复制
模型并行化
数据并行化
练习
第章 卷积神经网络
・ ・ ・ ・ ・ ・ (收起)译者序
前言
第章　引言
.　应用与问题
.　定义与术语
.　交叉验证
.　学习情境
.　本书概览
第章　PAC学习框架
.　PAC学习模型
.　对有限假设集的学习保证――一致的情况
.　对有限假设集的学习保证――不一致的情况
.　泛化性
..　确定性与随机性情境
..　贝叶斯误差与噪声
..　估计误差与近似误差
..　模型选择
.　文献评注
.　习题
第章　Rademacher复杂度和VC-维
.　Rademacher复杂度
.　生长函数
.　VC-维
.　下界
.　文献评注
.　习题
第章　支持向量机
.　线性分类
.　可分情况下的支持向量机
..　原始优化问题
..　支持向量
..　对偶优化问题
..　留一法
.　不可分情况下的支持向量机
..　原始优化问题
..　支持向量
..　对偶优化问题
.　间隔理论
.　文献评注
.　习题
第章　核方法
.　引言
.　正定对称核
..　定义
..　再生核希尔伯特空间
..　性质
.　基于核的算法
..　具有PDS核的SVM
..　表示定理
..　学习保证
.　负定对称核
.　序列核
..　加权转换器
..　有理核
.　文献评注
.　习题
第章　boosting
.　引言
.　AdaBoost算法
..　经验误差的界
..　与坐标下降的关系
..　与逻辑回归的关系
..　实践中的标准使用方式
.　理论结果
..　基于VC-维的分析
..　基于间隔的分析
..　间隔最大化
..　博弈论解释
.　讨论
.　文献评注
.　习题
第章　在线学习
.　引言
.　有专家建议的预测
..　错误界和折半算法
..　加权多数算法
..　随机加权多数算法
..　指数加权平均算法
.　线性分类
..　感知机算法
..　Winnow算法
.　在线到批处理的转换
.　与博弈论的联系
.　文献评注
.　习题
第章　多分类
.　多分类问题
.　泛化界
.　直接型多分类算法
..　多分类SVM
..　多分类boosting算法
..　决策树
.　类别分解型多分类算法
..　一对多
..　一对一
..　纠错编码
.　结构化预测算法
.　文献评注
.　习题
第章　排序
.　排序问题
.　泛化界
.　使用SVM进行排序
.　RankBoost
..　经验误差界
..　与坐标下降的关系
..　排序问题集成算法的间隔界
.　二部排序
..　二部排序中的boosting算法
..　ROC曲线下面积
.　基于偏好的情境
..　两阶段排序问题
..　确定性算法
..　随机性算法
..　关于其他损失函数的扩展
.　讨论
.　文献评注
.　习题
第章　回归
.　回归问题
.　泛化界
..　有限假设集
..　Rademacher复杂度界
..　伪维度界
.　回归算法
..　线性回归
..　核岭回归
..　支持向量回归
..　Lasso
..　组范数回归算法
..　在线回归算法
.　文献评注
.　习题
第章　算法稳定性
.　定义
.　基于稳定性的泛化保证
.　基于核的正则化算法的稳定性
..　应用于回归算法：SVR和KRR
..　应用于分类算法：SVM
..　讨论
.　文献评述
.　习题
第章　降维
.　主成分分析
.　核主成分分析
.　KPCA和流形学习
..　等距映射
..　拉普拉斯特征映射
..　局部线性嵌入
.　Johnson-Lindenstrauss引理
.　文献评注
.　习题
第章　学习自动机和语言
.　引言
.　有限自动机
.　高效精确学习
..　被动学习
..　通过查询学习
..　通过查询学习自动机
.　极限下的识别
.　文献评注
.　习题
第章　强化学习
.　学习情境
.　马尔可夫决策过程模型
.　策略
..　定义
..　策略值
..　策略评估
..　最优策略
.　规划算法
..　值迭代
..　策略迭代
..　线性规划
.　学习算法
..　随机逼近
..　TD（）算法
..　Q-学习算法
..　SARSA
..　TD（λ）算法
..　大状态空间
.　文献评注
结束语
附录A　线性代数回顾
附录B　凸优化
附录C　概率论回顾
附录D　集中不等式
附录E　符号
索引
参考文献
・ ・ ・ ・ ・ ・ (收起)序言
第 一章 机器学习概述 
． 机器学习简介 
．． 机器学习简史 
．． 机器学习主要流派 
． 机器学习、人工智能和数据挖掘 
．． 什么是人工智能 
．． 机器学习、人工智能与数据挖掘 
． 典型机器学习应用领域 
． 机器学习算法 
． 机器学习的一般流程 
第 二章 机器学习基本方法 
． 统计分析 
．． 统计基础 
．． 常见概率分布 
．． 参数估计 
．． 假设检验 
．． 线性回归 
．． Logistics回归 
．． 判别分析 
．． 非线性模型 
． 高维数据降维 
．． 主成分分析 
．． 线性判别分析 
．． 局部线性嵌入 
． 特征工程 
．． 特征构造 
．． 特征选择 
．． 特征提取 
． 模型训练 
．． 模型训练常见术语 
．． 训练数据收集 
． 可视化分析 
．． 可视化分析的作用 
．． 可视化分析方法 
．． 可视化分析常用工具 
．． 常见的可视化图表 
．． 可视化分析面临的挑战 
第三章 决策树与分类算法 
． 决策树算法 
．． 分支处理 
．． 连续属性离散化 
．． 过拟合问题 
．． 分类效果评价 
． 集成学习 
．． 装袋法 
．． 提升法 
．． GBDT 
．． 随机森林 
． 决策树应用 
第四章 聚类分析 
． 聚类分析概念 
．． 聚类方法分类 
．． 良好聚类算法的特征 
． 聚类分析的度量 
．． 外部指标 
．． 内部指标 
． 基于划分的方法 
．． k-均值算法 
．． k-medoids算法 
．． k-prototype算法 
． 基于密度聚类 
．． DBSCAN算法 
．． OPTICS算法 
．． DENCLUE算法 
． 基于层次的聚类 
．． BIRCH聚类 
．． CURE算法 
． 基于网格的聚类 
． 基于模型的聚类 
．． 概率模型聚类 
．． 模糊聚类 
．． Kohonen神经网络聚类 
第五章 文本分析 
． 文本分析介绍 
． 文本特征提取及表示 
．． TF-IDF 
．． 信息增益 
．． 互信息 
．． 卡方统计量 
．． 词嵌入 
．． 语言模型 
．． 向量空间模型 
． 知识图谱 
．． 知识图谱相关概念 
．． 知识图谱的存储 
．． 知识图谱挖掘与计算 
．． 知识图谱的构建过程 
． 词法分析 
．． 文本分词 
．． 命名实体识别 
．． 词义消歧 
． 句法分析 
． 语义分析 
． 文本分析应用 
．． 文本分类 
．． 信息抽取 
．． 问答系统 
．． 情感分析 
．． 自动摘要 
第六章 神经网络 
． 神经网络介绍 
．． 前馈神经网络 
．． 反馈神经网络 
．． 自组织神经网络 
． 神经网络相关概念 
．． 激活函数 
．． 损失函数 
．． 学习率 
．． 过拟合 
．． 模型训练中的问题 
．． 神经网络效果评价 
． 神经网络应用 
第七章 贝叶斯网络 
． 贝叶斯理论概述 
．． 贝叶斯方法的基本观点 
．． 贝叶斯网络的应用 
． 贝叶斯概率基础 
．． 概率论 
．． 贝叶斯概率 
． 朴素贝叶斯分类模型 
． 贝叶斯网络 
． 贝叶斯网络的应用 
．． 中文分词 
．． 机器翻译 
．． 故障诊断 
．． 疾病诊断 
第八章 支持向量机 
． 支持向量机模型 
．． 核函数 
．． 模型原理分析 
． 支持向量机应用 
第九章 进化计算 
． 遗传算法的基础 
．． 基因重组（交叉）与基因突变 
．． 遗传算法实现技术 
．． 遗传算法案例 
． 蚁群算法 
．． 蚁群算法应用案例 
． 蜂群算法简介 
．． 蜂群算法应用案例 
第十章 分布式机器学习 
． 分布式机器学习基础 
．． 参数服务器 
．． 分布式并行计算类型 
． 分布式机器学习框架 
． 并行决策树 
． 并行k-均值算法 
第十一章 深度学习 
． 卷积神经网络 
．． 卷积神经网络的整体结构 
．． 常见卷积神经网络 
． 循环神经网络 
．． RNN基本原理 
．． 长短期记忆网络 
．． 门限循环单元 
． 深度学习流行框架 
第十二章 高等级深度学习 
． 高等级卷积神经网络 
．． 目标检测与追踪 
．． 目标分割 
． 高等级循环神经网络应用 
．． Encoder-Decoder模型 
．． 注意力模型 
．． LSTM高等级应用 
． 无监督式深度学习 
．． 深度信念网络 
．． 自动编码器网络 
．． 生成对抗网络模型 
． 强化学习 
．． 增强学习基础 
．． 深度增强学习 
． 迁移学习 
． 对偶学习 
第十三章 推荐系统 
． 推荐系统介绍 
．． 推荐系统的应用场景 
． 推荐系统通用模型 
．． 推荐系统结构 
．． 基于内容的推荐 
．． 基于协同过滤的推荐算法 
．． 基于图的模型 
．． 基于关联规则的推荐 
．． 基于知识的推荐 
．． 基于标签的推荐 
． 推荐系统评测 
．． 评测方法 
．． 评测指标 
． 推荐系统常见问题 
．． 冷启动问题 
．． 推荐系统注意事项 
． 推荐系统实例 
第十四章 实验 
． 华为FusionInsight产品平台介绍 
． 银行定期存款业务预测 
．． 上传银行客户及存贷款数据 
．． 准备存款业务分析工作区 
．． 创建数据挖掘流程 
．． 定期存款业务模型保存和应用 
． 客户分群 
．． 分析业务需求 
．． 上传客户信息数据 
．． 准备客户分群工作区 
．． 创建数据挖掘流程 
．． 客户分群模型保存和应用 
・ ・ ・ ・ ・ ・ (收起)第章 基础知识 
.　准备数据 
..　数据格式 
..　变量类型 
..　变量选择 
..　特征工程 
..　缺失数据 
.　选择算法 
..　无监督学习 
..　监督学习 
..　强化学习 
..　注意事项 
.　参数调优 
.　评价模型 
..　分类指标 
..　回归指标 
..　验证 
.　小结 
第章　k均值聚类 
.　找出顾客群 
.　示例：影迷的性格特征 
.　定义群组 
..　有多少个群组 
..　每个群组中有谁 
.　局限性 
.　小结 
第章　主成分分析 
.　食物的营养成分 
.　主成分 
.　示例：分析食物种类 
.　局限性 
.　小结 
第章　关联规则 
.　发现购买模式 
.　支持度、置信度和提升度 
.　示例：分析杂货店的销售数据 
.　先验原则 
..　寻找具有高支持度的项集 
..　寻找具有高置信度或高提升度的关联规则 
.　局限性 
.　小结 
第章　社会网络分析 
.　展现人际关系 
.　示例：国际贸易 
.　Louvain方法 
.　PageRank算法 
.　局限性 
.　小结 
第章　回归分析 
.　趋势线 
.　示例：预测房价 
.　梯度下降法 
.　回归系数 
.　相关系数 
.　局限性 
.　小结 
第章　k最近邻算法和异常检测 
.　食品检测 
.　物以类聚，人以群分 
.　示例：区分红白葡萄酒 
.　异常检测 
.　局限性 
.　小结 
第章　支持向量机 
.　医学诊断 
.　示例：预测心脏病 
.　勾画最佳分界线 
.　局限性 
.　小结 
第章　决策树 
.　预测灾难幸存者 
.　示例：逃离泰坦尼克号 
.　生成决策树 
.　局限性 
.　小结 
第章　随机森林 
.　集体智慧 
.　示例：预测犯罪行为 
.　集成模型 
.　自助聚集法 
.　局限性 
.　小结 
第章　神经网络 
.　建造人工智能大脑 
.　示例：识别手写数字 
.　神经网络的构成 
.　激活规则 
.　局限性 
.　小结 
第章　A/B测试和多臂老虎机 
.　初识A/B测试 
.　A/B测试的局限性 
.　epsilon递减策略 
.　示例：多臂老虎机 
.　胜者为先 
.　epsilon递减策略的局限性 
.　小结 
附录A　无监督学习算法概览 
附录B　监督学习算法概览 
附录C　调节参数列表 
附录D　更多评价指标 
术语表 
关于作者 
・ ・ ・ ・ ・ ・ (收起)推荐序
作者序
致谢
译者序
关于本书
作者简介
关于封面插图
第部分机器学习工作流程
第章什么是机器学习
.理解机器学习
.使用数据进行决策
..传统方法
..机器学习方法
..机器学习的五大优势
..面临的挑战
.跟踪机器学习流程：从数据到部署
..数据集合和预处理
..数据构建模型
..模型性能评估
..模型性能优化
.提高模型性能的高级技巧
..数据预处理和特征工程
..用在线算法持续改进模型
..具有数据量和速度的规模化模型
.总结
.本章术语
第章实用数据处理
.起步：数据收集
..应包含哪些特征
..如何获得目标变量的真实值
..需要多少训练数据
..训练集是否有足够的代表性
.数据预处理
..分类特征
..缺失数据处理
..简单特征工程
..数据规范化
.数据可视化
..马赛克图
..盒图
..密度图
..散点图
.总结
.本章术语
第章建模和预测
.基础机器学习建模
..寻找输入和目标间的关系
..寻求好模型的目的
..建模方法类型
..有监督和无监督学习
.分类：把数据预测到桶中
..构建分类器并预测
..非线性数据与复杂分类
..多类别分类
.回归：预测数值型数据
..构建回归器并预测
..对复杂的非线性数据进行回归
.总结
.本章术语
第章模型评估与优化
.模型泛化：评估新数据的预测准确性
..问题：过度拟合与乐观模型
..解决方案：交叉验证
..交叉验证的注意事项
.分类模型评估
..分类精度和混淆矩阵
..准确度权衡与ROC曲线
..多类别分类
.回归模型评估
..使用简单回归性能指标
..检验残差
.参数调整优化模型
..机器学习算法和它们的调整参数
..网格搜索
.总结
.本章术语
第章基础特征工程
.动机：为什么特征工程很有用
..什么是特征工程
..使用特征工程的个原因
..特征工程与领域专业知识
.基本特征工程过程
..实例：事件推荐
..处理日期和时间特征
..处理简单文本特征
.特征选择
..前向选择和反向消除
..数据探索的特征选择
..实用特征选择实例
.总结
.本章术语
第部分实 际 应 用
第章案例：NYC出租车数据
.数据：NYC出租车旅程和收费信息
..数据可视化
..定义问题并准备数据
.建模
..基本线性模型
..非线性分类器
..包含分类特征
..包含日期-时间特征
..模型的启示
.总结
.本章术语
第章高级特征工程
.高级文本特征
..词袋模型
..主题建模
..内容拓展
.图像特征
..简单图像特征
..提取物体和形状
.时间序列特征
..时间序列数据的类型
..时间序列数据的预测
..经典时间序列特征
..事件流的特征工程
.总结
.本章术语
第章NLP高级案例：电影评论情感预测
.研究数据和应用场景
..数据集初探
..检查数据
..应用场景有哪些
.提取基本NLP特征并构建初始模型
..词袋特征
..用朴素贝叶斯算法构建模型
..tf-idf算法规范词袋特征
..优化模型参数
.高级算法和模型部署的考虑
..wordvec特征
..随机森林模型
.总结
.本章术语
第章扩展机器学习流程
.扩展前需考虑的问题
..识别关键点
..选取训练数据子样本代替扩展性
..可扩展的数据管理系统
.机器学习建模流程扩展
.预测扩展
..预测容量扩展
..预测速度扩展
.总结
.本章术语
第章案例：数字显示广告
.显示广告
.数字广告数据
.特征工程和建模策略
.数据大小和形状
.奇异值分解
.资源估计和优化
.建模
.K近邻算法
.随机森林算法
.其他实用考虑
.总结
.本章术语
.摘要和结论
附录常用机器学习算法
名词术语中英文对照
・ ・ ・ ・ ・ ・ (收起)第  章 机器学习是什么――机器学习定义 .. 
引言.. 
. 数据. 
.. 结构型与非结构型数据 
.. 原始数据与加工.. 
.. 样本内数据与样本外数据 . 
. 机器学习类别 
.. 有监督学习 
.. 无监督学习 
.. 半监督学习. 
.. 增强学习 
.. 深度学习 
.. 迁移学习.. 
. 性能度量. 
.. 误差函数.. 
.. 回归度量.. 
.. 分类度量.. 
. 总结.. 
参考资料.. 
第  章 机器学习可行吗――计算学习理论 
引言 
. 基础知识. 
.. 二分类. 
.. 对分 
.. 增长函数.. 
.. 突破点. 
. 核心推导. 
.. 机器学习可行条件 . 
.. 从已知推未知. 
.. 从民意调查到机器学习 
.. 从单一到有限. 
.. 从有限到无限. 
.. 从无限到有限. 
. 结论应用. 
.. VC 不等式 
.. VC 维度 .. 
.. 模型复杂度 
.. 样本复杂度 
. 总结.. 
参考资料.. 
技术附录.. 
第  章 机器学习怎么学――模型评估选择 
引言 
. 模型评估. 
. 训练误差和测试误差. 
.. 训练误差.. 
.. 真实误差.. 
.. 测试误差.. 
.. 学习理论.. 
. 验证误差和交叉验证误差. 
.. 验证误差.. 
.. 交叉验证误差. 
.. 学习理论.. 
. 误差剖析. 
.. 误差来源.. 
.. 偏差―方差权衡 
. 模型选择. 
. 总结.. 
参考资料.. 
技术附录.. 
第  章 线性回归 
引言 
. 基础知识. 
.. 标量微积分 
.. 向量微积分 
. 模型介绍. 
.. 核心问题.. 
.. 通用线性回归模型 . 
.. 特征缩放.. 
.. 学习率设定 
.. 数值算法比较. 
.. 代码实现.. 
. 总结.. 
参考资料.. 
第  章 对率回归 
引言 
. 基础内容. 
.. 联系函数.. 
.. 函数绘图.. 
. 模型介绍. 
.. 核心问题.. 
.. 查准和查全. 
.. 类别不平衡. 
.. 线性不可分. 
.. 多分类问题. 
.. 代码实现 
. 总结. 
参考资料. 
第  章 正则化回归 . 
引言. 
. 基础知识 
.. 等值线图. 
.. 坐标下降. 
. 模型介绍 
.. 核心问题. 
.. 模型对比 
.. 最佳模型 
.. 代码实现 
. 总结 
参考资料 
第  章 支持向量机 . 
引言 
. 基础知识.. 
.. 向量初体验. 
.. 拉格朗日量. 
.. 原始和对偶. 
. 模型介绍.. 
.. 硬间隔 SVM 原始问题. 
.. 硬间隔 SVM 对偶问题. 
.. 软间隔 SVM 原始问题. 
.. 软间隔 SVM 对偶问题. 
.. 空间转换 
.. 核技巧. 
.. 核 SVM . 
.. SMO 算法 .. 
.. 模型选择 
. 总结 
参考资料 
技术附录 
第  章 朴素贝叶斯 . 
引言 
. 基础知识.. 
.. 两种概率学派.. 
.. 两种独立类别.. 
.. 两种学习算法.. 
.. 两种估计方法.. 
.. 两类概率分布.. 
. 模型介绍.. 
.. 问题剖析 
.. 朴素贝叶斯算法 
.. 多元伯努利模型 
.. 多项事件模型.. 
.. 高斯判别分析模型 . 
.. 多分类问题. 
.. 拉普拉斯校正.. 
.. 最大似然估计和最大后验估计 . 
. 总结 
参考资料 
技术附录 
第  章 决策树 . 
引言 
. 基础知识.. 
.. 多数规则 
.. 熵和条件熵. 
.. 信息增益和信息增益比 . 
.. 基尼指数 
. 模型介绍.. 
.. 二分类决策树.. 
.. 多分类决策树.. 
.. 连续值分裂. 
.. 欠拟合和过拟合. 
.. 预修剪和后修剪 
.. 数据缺失 
.. 代码实现 
. 总结 
参考资料 
第  章 人工神经网络 
引言 
. 基本知识 
.. 转换函数 
.. 单输入单层单输出神经网络 . 
.. 多输入单层单输出神经网络 . 
.. 多输入单层多输出神经网络 . 
.. 多输入多层多输出神经网络 . 
. 模型应用 
.. 创建神经网络模型 .. 
.. 回归应用 
.. 分类应用 
第  章 正向/反向传播 
引言 
. 基础知识 
.. 神经网络元素 
.. 链式法则 
. 算法介绍 
.. 正向传播 
.. 梯度下降 
.. 反向传播 
.. 代码实现 
. 总结 
参考资料 
技术附录 
第  章 集成学习. 
引言 
. 结合假设 
.. 语文和数学. 
.. 准确和多样. 
.. 独裁和民主. 
.. 学习并结合. 
. 装袋法. 
.. 基本概念 
.. 自助采样 
.. 结合假设 
. 提升法. 
.. 基本概念 
.. 最优加权 
.. 结合假设 
. 集成方式 
.. 同质学习器. 
.. 异质学习器. 
. 总结 
参考资料 
第  章 随机森林和提升树 . 
引言 
. 基础知识 
.. 分类回归树. 
.. 前向分布算法 
.. 置换检验 
. 模型介绍 
.. 随机森林 
.. 提升树.. 
.. 代码实现 
. 总结 
参考资料 
第  章 极度梯度提升 
引言 
. 基础知识. 
.. 树的重定义 
.. 树的复杂度. 
. 模型介绍 
.. XGB 简介. 
.. XGB 的泛化度 
.. XGB 的精确度 
.. XGB 的速度.. 
.. 代码实现 
. 总结 
参考资料 
第  章 本书总结. 
. 正交策略 
. 单值评估指标.. 
. 偏差和方差. 
.. 理论定义 
.. 实用定义 
.. 最优误差 
.. 两者权衡 
.. 学习曲线 
结语 
・ ・ ・ ・ ・ ・ (收起)前言
第章　机器学习概述 
.　什么是机器学习 
.　机器学习的几个需求层次 
.　机器学习的基本原理 
.　机器学习的基本概念 
..　书中用到的术语介绍 
..　机器学习的基本模式 
..　优化方法 
.　机器学习问题分类 
.　常用的机器学习算法 
.　机器学习算法的性能衡量指标 
.　数据对算法结果的影响 
第章　机器学习所需的环境 
.　常用环境 
.　Python简介 
..　Python的安装 
..　Python的基本用法 
.　Numpy简介 
..　Numpy的安装 
..　Numpy的基本用法 
.　Scikit-Learn简介 
..　Scikit-Learn的安装 
..　Scikit-Learn的基本用法 
.　Pandas简介 
..　Pandas的安装 
..　Pandas的基本用法 
第章　线性回归算法 
.　线性回归：“钢铁直男”解决回归问题的正确方法 
..　用于预测未来的回归问题 
..　怎样预测未来 
..　线性方程的“直男”本性 
..　最简单的回归问题―线性回归问题 
.　线性回归的算法原理 
..　线性回归算法的基本思路 
..　线性回归算法的数学解析 
..　线性回归算法的具体步骤 
.　在Python中使用线性回归算法 
.　线性回归算法的使用场景 
第章　Logistic回归分类算法 
.　Logistic回归：换上“S型曲线马甲”的线性回归 
..　分类问题：选择困难症患者的自我救赎 
..　Logistic函数介绍 
..　此回归非彼回归：“LR”辨析 
.　Logistic回归的算法原理 
..　Logistic回归算法的基本思路 
..　Logistic回归算法的数学解析 
..　Logistic回归算法的具体步骤 
.　在Python中使用Logistic回归算法 
.　Logistic回归算法的使用场景 
第章　KNN分类算法 
.　KNN分类算法：用多数表决进行分类 
..　用“同类相吸”的办法解决分类问题 
..　KNN分类算法的基本方法：多数表决 
..　表决权问题 
..　KNN的具体含义 
.　KNN分类的算法原理 
..　KNN分类算法的基本思路 
..　KNN分类算法的数学解析 
..　KNN分类算法的具体步骤 
.　在Python中使用KNN分类算法 
.　KNN分类算法的使用场景 
第章　朴素贝叶斯分类算法 
.　朴素贝叶斯：用骰子选择 
..　从统计角度看分类问题 
..　贝叶斯公式的基本思想 
..　用贝叶斯公式进行选择 
.　朴素贝叶斯分类的算法原理 
..　朴素贝叶斯分类算法的基本思路 
..　朴素贝叶斯分类算法的数学解析 
..　朴素贝叶斯分类算法的具体步骤 
.　在Python中使用朴素贝叶斯分类算法 
.　朴素贝叶斯分类算法的使用场景 
第章　决策树分类算法 
.　决策树分类：用“老朋友”if-else进行选择 
..　程序员的选择观：if-else 
..　如何种植一棵有灵魂的“树” 
..　决策条件的选择艺术 
..　决策树的剪枝问题 
.　决策树分类的算法原理 
..　决策树分类算法的基本思路 
..　决策树分类算法的数学解析 
..　决策树分类算法的具体步骤 
.　在Python中使用决策树分类算法 
.　决策树分类算法的使用场景 
第章　支持向量机分类算法 
.　支持向量机：线性分类器的“王者” 
..　距离是不同类别的天然间隔 
..　何为“支持向量” 
..　从更高维度看“线性不可分” 
.　支持向量机分类的算法原理 
..　支持向量机分类算法的基本思路 
..　支持向量机分类算法的数学解析 
..　支持向量机分类算法的具体步骤 
.　在Python中使用支持向量机分类算法 
.　支持向量机分类算法的使用场景 
第章　K-means聚类算法 
.　用投票表决实现“物以类聚” 
..　聚类问题就是“物以类聚”的实施问题 
..　用“K”来决定归属类别 
..　度量“相似”的距离 
..　聚类问题中的多数表决 
.　K-means聚类的算法原理 
..　K-means聚类算法的基本思路 
..　K-means聚类算法的数学解析 
..　K-means聚类算法的具体步骤 
.　在Python中使用K-means聚类算法 
.　K-means聚类算法的使用场景 
第章　神经网络分类算法 
.　用神经网络解决分类问题 
..　神经元的“内心世界” 
..　从神经元看分类问题 
..　神经网络的“细胞”：人工神经元 
..　构成网络的魔力 
..　神经网络与深度学习 
.　神经网络分类的算法原理 
..　神经网络分类算法的基本思路 
..　神经网络分类算法的数学解析 
..　神经网络分类算法的具体步骤 
.　在Python中使用神经网络分类算法 
.　神经网络分类算法的使用场景 
第章　集成学习方法 
.　集成学习方法：三个臭皮匠赛过诸葛亮 
..　集成学习方法与经典机器学习算法的关系 
..　集成学习的主要思想 
..　几种集成结构 
.　集成学习方法的具体实现方式 
..　Bagging算法 
..　Boosting算法 
..　Stacking算法 
.　在Python中使用集成学习方法 
.　集成学习方法的使用场景 
・ ・ ・ ・ ・ ・ (收起)第章　机器学习应用快速入门　　
.　机器学习与数据科学　　
..　机器学习能够解决的问题　　
..　机器学习应用流程　　
.　数据与问题定义　　
.　数据收集　　
..　发现或观察数据　　
..　生成数据　　
..　采样陷阱　　
.　数据预处理　　
..　数据清洗　　
..　填充缺失值　　
..　剔除异常值　　
..　数据转换　　
..　数据归约　　
.　无监督学习　　
..　查找相似项目　　
..　聚类　　
.　监督学习　　
..　分类　　
..　回归　　
.　泛化与评估　　
.　小结　　
第章　面向机器学习的Java库与平台　　
.　Java环境　　
.　机器学习库　　
..　Weka　　
..　Java机器学习　　
..　Apache Mahout　　
..　Apache Spark　　
..　Deeplearningj　　
..　MALLET　　
..　比较各个库　　
.　创建机器学习应用　　
.　处理大数据　　
.　小结　　
第章　基本算法――分类、回归和聚类　　
.　开始之前　　
.　分类　　
..　数据　　
..　加载数据　　
..　特征选择　　
..　学习算法　　
..　对新数据分类　　
..　评估与预测误差度量　　
..　混淆矩阵　　
..　选择分类算法　　
.　回归　　
..　加载数据　　
..　分析属性　　
..　创建与评估回归模型　　
..　避免常见回归问题的小技巧　　
.　聚类　　
..　聚类算法　　
..　评估　　
.　小结　　
第章　利用集成方法预测客户关系　　
.　客户关系数据库　　
..　挑战　　
..　数据集　　
..　评估　　
.　最基本的朴素贝叶斯分类器基准　　
..　获取数据　　
..　加载数据　　
.　基准模型　　
..　评估模型　　
..　实现朴素贝叶斯基准线　　
.　使用集成方法进行高级建模　　
..　开始之前　　
..　数据预处理　　
..　属性选择　　
..　模型选择　　
..　性能评估　　
.　小结　　
第章　关联分析　　
.　购物篮分析　　
.　关联规则学习　　
..　基本概念　　
..　Apriori算法　　
..　FP-增长算法　　
..　超市数据集　　
.　发现模式　　
..　Apriori算法　　
..　FP-增长算法　　
.　在其他领域中的应用　　
..　医疗诊断　　
..　蛋白质序列　　
..　人口普查数据　　
..　客户关系管理　　
..　IT运营分析　　
.　小结　　
第章　使用Apache Mahout制作推荐引擎　　
.　基本概念　　
..　关键概念　　
..　基于用户与基于项目的分析　　
..　计算相似度的方法　　
..　利用与探索　　
.　获取Apache Mahout　　
.　创建一个推荐引擎　　
..　图书评分数据集　　
..　加载数据　　
..　协同过滤　　
.　基于内容的过滤　　
.　小结　　
第章　欺诈与异常检测　　
.　可疑与异常行为检测　　
.　可疑模式检测　　
.　异常模式检测　　
..　分析类型　　
..　事务分析　　
..　规划识别　　
.　保险理赔欺诈检测　　
..　数据集　　
..　为可疑模式建模　　
.　网站流量异常检测　　
..　数据集　　
..　时序数据中的异常检测　　
.　小结　　
第章　利用Deeplearningj进行图像识别　　
.　图像识别简介　　
.　图像分类　　
..　Deeplearningj　　
..　MNIST数据集　　
..　加载数据　　
..　创建模型　　
.　小结　　
第章　利用手机传感器进行行为识别　　
.　行为识别简介　　
..　手机传感器　　
..　行为识别流水线　　
..　计划　　
.　从手机收集数据　　
..　安装Android Studio　　
..　加载数据采集器　　
..　收集训练数据　　
.　创建分类器　　
..　减少假性转换　　
..　将分类器嵌入移动应用　　
.　小结　　
第章　利用Mallet进行文本挖掘――主题模型与垃圾邮件检测　　
.　文本挖掘简介　　
..　主题模型　　
..　文本分类　　
.　安装Mallet　　
.　使用文本数据　　
..　导入数据　　
..　对文本数据做预处理　　
.　为BBC新闻做主题模型　　
..　BBC数据集　　
..　建模　　
..　评估模型　　
..　重用模型　　
.　垃圾邮件检测　　
..　垃圾邮件数据集　　
..　特征生成　　
..　训练与测试模型　　
.　小结　　
第章　机器学习进阶　　
.　现实生活中的机器学习　　
..　噪声数据　　
..　类不平衡　　
..　特征选择困难　　
..　模型链　　
..　评价的重要性　　
..　从模型到产品　　
..　模型维护　　
.　标准与标记语言　　
..　CRISP-DM　　
..　SEMMA方法　　
..　预测模型标记语言　　
.　云端机器学习　　
.　Web资源与比赛　　
..　数据集　　
..　在线课程　　
..　比赛　　
..　网站与博客　　
..　场馆与会议　　
.　小结　　
・ ・ ・ ・ ・ ・ (收起)第部分 背景知识
第章 机器学习概述 
. 背景 
. 发展现状 
.. 数据现状 
.. 机器学习算法现状 
. 机器学习基本概念 
.. 机器学习流程 
.. 数据源结构 
.. 算法分类 
.. 过拟合问题 
.. 结果评估 
. 本章小结 
第部分 算法流程
第章 场景解析 
. 数据探查 
. 场景抽象 
. 算法选择 
. 本章小结 
第章 数据预处理 
. 采样 
.. 随机采样 
.. 系统采样 
.. 分层采样 
. 归一化 
. 去除噪声 
. 数据过滤 
. 本章小结 
第章 特征工程 
. 特征抽象 
. 特征重要性评估 
. 特征衍生 
. 特征降维 
.. 特征降维的基本概念 
.. 主成分分析 
. 本章小结 
第章 机器学习算法――常规算法 
. 分类算法 
.. K近邻 
.. 朴素贝叶斯 
.. 逻辑回归 
.. 支持向量机 
.. 随机森林 
. 聚类算法 
.. K-means 
.. DBSCAN 
. 回归算法 
. 文本分析算法 
.. 分词算法――Hmm 
.. TF-IDF 
.. LDA 
. 推荐类算法 
. 关系图算法 
.. 标签传播 
.. Dijkstra最短路径 
. 本章小结 
第章 机器学习算法――深度学习 
. 深度学习概述 
.. 深度学习的发展 
.. 深度学习算法与传统
算法的比较 
. 深度学习的常见结构 
.. 深度神经网络 
.. 卷积神经网络 
.. 循环神经网络 
. 本章小结 
第部分 工具介绍
第章 常见机器学习工具介绍 
. 概述 
. 单机版机器学习工具 
.. SPSS 
.. R语言 
.. 工具对比 
. 开源分布式机器学习工具 
.. Spark MLib 
.. TensorFlow 
. 企业级云机器学习工具 
.. 亚马逊AWS ML 
.. 阿里云机器学习PAI 
. 本章小结 
第部分 实战应用
第章 业务解决方案 
. 心脏病预测 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 商品推荐系统 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 金融风控案例 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 新闻文本分析 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 农业贷款发放预测 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 雾霾天气成因分析 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 图片识别 
.. 场景解析 
.. 实验搭建 
.. 小结 
. 本章小结 
第部分 知识图谱
第章 知识图谱 
. 未来数据采集 
. 知识图谱的概述 
. 知识图谱开源
工具 
. 本章小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第一部分 场景化机器学习
第章 机器学习如何应用于业务　
. 为什么我们的业务系统如此糟糕　
. 为什么如今自动化很重要　
.. 什么是生产率　
.. 机器学习如何提高生产率　
. 机器如何做出决策　
.. 人：是否基于规则　
.. 你能相信一个基于模式的答案吗　
.. 机器学习如何能提升你的业务系统　
. 机器能帮Karen做决策吗　
.. 目标变量　
.. 特征　
. 机器如何学习　
. 在你的公司落实使用机器学习进行决策　
. 工具　
.. AWS和SageMaker是什么，它们如何帮助你　
.. Jupyter笔记本是什么　
. 配置SageMaker为解决第~章中的场景做准备　
. 是时候行动了　
. 小结　
第二部分 公司机器学习的六个场景
第章 你是否应该将采购订单发送给技术审批人　
. 决策　
. 数据　
. 开始你的训练过程　
. 运行Jupyter笔记本并进行预测　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集、验证集和测试集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 小结　
第章 你是否应该致电客户以防客户流失　
. 你在决策什么　
. 处理流程　
. 准备数据集　
.. 转换操作：标准化数据　
.. 转换操作：计算周与周之间的变化　
. XGBoost基础　
.. XGBoost的工作原理　
.. 机器学习模型如何确定函数的AUC的好坏　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集、验证集和测试集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第章 你是否应该将事件上报给支持团队　
. 你在决策什么　
. 处理流程　
. 准备数据集　
. NLP　
.. 生成词向量　
.. 决定每组包含多少单词　
. BlazingText及其工作原理　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集和验证集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第章 你是否应该质疑供应商发送给你的发票　
. 你在决策什么　
. 处理流程　
. 准备数据集　
. 什么是异常　
. 监督机器学习与无监督机器学习　
. 随机裁剪森林及其工作原理　
.. 样本　
.. 样本　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集和验证集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：测试模型　
. 删除端点并停止笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第章 预测你公司的每月能耗　
. 你在决策什么　
.. 时间序列数据介绍　
.. Kiara的时间序列数据：每日能耗　
. 加载处理时间序列数据的Jupyter笔记本　
. 准备数据集：绘制时间序列数据　
.. 通过循环展示数据列　
.. 创建多个图表　
. 神经网络是什么　
. 准备构建模型　
.. 将数据集上传到S　
.. 在SageMaker上设置笔记本　
. 构建模型　
.. 第一部分：加载并检查数据　
.. 第二部分：将数据转换为正确的格式　
.. 第三部分：创建训练集和测试集　
.. 第四部分：训练模型　
.. 第五部分：部署模型　
.. 第六部分：进行预测并绘制结果　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第 章 优化你公司的每月能耗预测　
. DeepAR对周期性事件的处理能力　
. DeepAR的最大优势：整合相关的时间序列　
. 整合额外的数据集到Kiara的能耗模型　
. 准备构建模型　
.. 下载我们准备的笔记本　
.. 在SageMaker上设置文件夹　
.. 将笔记本上传到SageMaker　
.. 从S存储桶下载数据集　
.. 在S上创建文件夹以保存你的数据　
.. 将数据集上传到你的AWS存储桶　
. 构建模型　
.. 第一部分：设置笔记本　
.. 第二部分：导入数据集　
.. 第三部分：将数据转换为正确的格式　
.. 第四部分：创建训练集和测试集　
.. 第五部分：配置模型并设置服务器以构建模型　
.. 第六部分：进行预测并绘制结果　
. 删除端点并停止你的笔记本实例　
.. 删除端点　
.. 停止笔记本实例　
. 检查以确保端点已被删除　
. 小结　
第三部分 将机器学习应用到生产环境中
第章 通过Web提供预测服务　
. 为什么通过Web提供决策和预测服务这么难　
. 本章的步骤概述　
. SageMaker端点　
. 设置SageMaker端点　
.. 上传笔记本　
.. 上传数据　
.. 运行笔记本并创建端点　
. 设置无服务器API端点　
.. 在AWS账户上设置AWS证书　
.. 在本地计算机上设置AWS证书　
.. 配置证书　
. 创建Web端点　
.. 安装Chalice　
.. 创建Hello World API　
.. 添加为SageMaker端点提供服务的代码　
.. 配置权限　
.. 更新requirements.txt文件　
.. 部署Chalice　
. 提供决策服务　
. 小结　
第章 案例研究　
. 案例研究：WorkPac　
.. 项目设计　
.. 第一阶段：准备并测试模型　
.. 第二阶段：实施POC　
.. 第三阶段：将流程嵌入公司的运营中　
.. 接下来的工作　
.. 吸取的教训　
. 案例研究：Faethm　
.. AI核心　
.. 使用机器学习优化Faethm公司的流程　
.. 第一阶段：获取数据　
.. 第二阶段：识别特征　
.. 第三阶段：验证结果　
.. 第四阶段：应用到生产环境中　
. 结论　
.. 观点：建立信任　
.. 观点：正确获取数据　
.. 观点：设计操作模式以充分利用机器学习能力　
.. 观点：在各个方面都使用了机器学习后，你的公司看起来怎么样　
. 小结　
附录A 注册AWS　
附录B 设置并使用S以存储文件　
附录C 设置并使用AWS SageMaker来构建机器学习系统　
附录D 停止全部服务　
附录E 安装Python　
・ ・ ・ ・ ・ ・ (收起)第 章 MATLAB机器学习初体验 
.　机器学习基础　
.　机器学习算法的分类　
..　监督学习　
..　非监督学习　
..　强化学习　
.　选择正确的算法　
.　构建机器学习模型的流程　
.　MATLAB中的机器学习支持简介　
..　操作系统、硬件平台要求　
..　MATLAB安装要求　
.　统计机器学习工具箱　
..　数据类型　
..　统计机器学习工具箱功能简介　
.　神经网络工具箱　
.　MATLAB中的统计学和线性代数　
.　总结　
第　章 使用MATLAB导入数据和组织数据　
.　熟悉MATLAB桌面　
.　将数据导入MATLAB　
..　导入向导　
..　通过程序语句导入数据　
.　从MATLAB导出数据　
.　处理媒体文件　
..　处理图像数据　
..　音频的导入/导出　
.　数据组织　
..　元胞数组　
..　结构体数组　
..　table类型　
..　分类数组　
.　总结　
第章　从数据到知识挖掘　
.　区分变量类别　
..　定量变量　
..　定性变量　
.　数据准备　
..　初步查看数据　
..　找到缺失值　
..　改变数据类型　
..　替换缺失值　
..　移除缺失值　
..　为表格排序　
..　找到数据中的异常值　
..　将多个数据源合并成一个数据源　
.　探索性统计指标―数值测量　
..　位置测量　
..　分散度的测量　
..　分布形状的测量　
.　探索性可视化　
..　图形数据统计分析对话框　
..　柱状图　
..　箱形图　
..　散点图　
.　总结　
第章　找到变量之间的关系―回归方法　
.　寻找线性关系　
..　最小二乘回归　
..　基本拟合接口　
.　如何创建一个线性回归模型　
..　通过稳健回归消除异常值的影响　
..　多元线性回归　
.　多项式回归　
.　回归学习器App　
.　总结　
第章　模式识别之分类算法　
.　决策树分类　
.　概率分类模型―朴素贝叶斯分类　
..　概率论基础　
..　使用朴素贝叶斯进行分类　
..　MATLAB中的贝叶斯方法　
.　判别分析分类　
.　k邻近算法　
.　MATLAB分类学习器App　
.　总结　
第章　无监督学习　
.　聚类分析简介　
..　相似度与离散度指标　
..　聚类方法类型简介　
.　层次聚类算法　
..　层次聚类中的相似度指标　
..　定义层次聚类中的簇　
..　如何理解层次聚类图　
..　验证聚类结果　
.　k均值聚类―基于均值聚类　
..　k均值算法　
..　函数kmeans()　
..　silhouette图―可视化聚类结果　
.　k中心点聚类―基于样本中心聚类　
..　什么是中心点　
..　函数kmedoids()　
..　评估聚类结果　
.　高斯混合模型聚类　
..　高斯分布　
..　MATLAB中的GMM支持　
..　使用后验概率分布进行聚类　
.　总结　
第章　人工神经网络――模拟人脑的思考方式　
.　神经网络简介　
.　神经网络基础构成　
..　隐藏层数量　
..　每层的节点数量　
..　神经网络训练方法　
.　神经网络工具箱　
.　工具箱的用户界面　
.　使用神经网络进行数据拟合　
..　如何使用拟合App（nftool）　
..　脚本分析　
.　总结　
第章　降维――改进机器学习模型的性能　
.　特征选择　
..　分步回归　
..　MATLAB中的分步回归　
.　特征提取　
.　总结　
第章　机器学习实战　
.　用于预测混凝土质量的数据拟合　
.　使用神经网络诊断甲状腺疾病　
.　使用模糊聚类对学生进行分簇　
.　总结　
・ ・ ・ ・ ・ ・ (收起)译者序
前 言
致 谢
第章 引言
. 传统机器学习范式
. 案例
. 终身学习简史
. 终身学习的定义
. 知识类型和关键挑战
. 评估方法和大数据的角色
. 本书大纲
第章 相关学习范式
. 迁移学习
.. 结构对应学习
.. 朴素贝叶斯迁移分类器
.. 迁移学习中的深度学习
.. 迁移学习与终身学习的区别
. 多任务学习
.. 多任务学习中的任务相关性
.. GO-MTL：使用潜在基础任务的多任务学习
.. 多任务学习中的深度学习
.. 多任务学习与终身学习的区别
. 在线学习
. 强化学习
. 元学习
. 小结
第章 终身监督学习
. 定义和概述
. 基于记忆的终身学习
.. 两个基于记忆的学习方法
.. 终身学习的新表达
. 终身神经网络
.. MTL网络
.. 终身EBNN
. ELLA：高效终身学习算法
.. 问题设定
.. 目标函数
.. 解决一个低效问题
.. 解决第二个低效问题
.. 主动的任务选择
. 终身朴素贝叶斯分类
.. 朴素贝叶斯文本分类
.. LSC的基本思想
.. LSC技术
.. 讨论
. 基于元学习的领域词嵌入
. 小结和评估数据集
第章 持续学习与灾难性遗忘
. 灾难性遗忘
. 神经网络中的持续学习
. 无遗忘学习
. 渐进式神经网络
. 弹性权重合并
. iCaRL：增量分类器与表示学习
.. 增量训练
.. 更新特征表示
.. 为新类构建范例集
.. 在iCaRL中完成分类
. 专家网关
.. 自动编码网关
.. 测量训练的任务相关性
.. 为测试选择相关的专家
.. 基于编码器的终身学习
. 生成式重放的持续学习
.. 生成式对抗网络
.. 生成式重放
评估灾难性遗忘
. 小结和评估数据集
第章 开放式学习
. 问题定义和应用
. 基于中心的相似空间学习
.. 逐步更新CBS学习模型
.. 测试CBS学习模型
.. 用于未知类检测的CBS学习
. DOC：深度开放式分类
.. 前馈层和一对其余层
.. 降低开放空间
.. DOC用于图像分类
.. 发现未知类
. 小结和评估数据集
第章 终身主题建模
. 终身主题建模的主要思想
. LTM：终身主题模型
.. LTM模型
.. 主题知识挖掘
.. 融合过去的知识
.. Gibbs采样器的条件分布
. AMC：少量数据的终身主题模型
.. AMC整体算法
.. 挖掘must-link知识
.. 挖掘cannot-link知识
.. 扩展的Pólya瓮模型
.. Gibbs采样器的采样分布
. 小结和评估数据集
第章 终身信息提取
. NELL：停止语言学习器
.. NELL结构
.. NELL中的提取器与学习
.. NELL中的耦合约束
. 终身评价目标提取
.. 基于的终身学习
.. AER算法
.. 知识学习
.. 使用过去知识
. 在工作中学习
.. 条件随机场
.. 一般依赖特征
.. L-CRF算法
. Lifelong-RL：终身松弛标记法
.. 松弛标记法
.. 终身松弛标记法
. 小结和评估数据集
第章 聊天机器人的持续知识学习
. LiLi：终身交互学习与推理
. LiLi的基本思想
. LiLi的组件
. 运行示例
. 小结和评估数据集
第章 终身强化学习
. 基于多环境的终身强化学习
. 层次贝叶斯终身强化学习
.. 动机
.. 层次贝叶斯方法
.. MTRL算法
.. 更新层次模型参数
.. 对MDP进行采样
. PG-ELLA：终身策略梯度强化学习
.. 策略梯度强化学习
.. 策略梯度终身学习设置
.. 目标函数和优化
.. 终身学习的安全策略搜索
.. 跨领域终身强化学习
. 小结和评估数据集
第章 结论及未来方向
参考文献
・ ・ ・ ・ ・ ・ (收起)第章　Python机器学习实践入门 
.　机器学习常用概念 
.　数据的准备、处理和可视化
―NumPy、pandas和matplotlib教程 
..　NumPy的用法 
..　理解pandas模块 
..　matplotlib教程 
.　本书使用的科学计算库 
.　机器学习的应用场景 
.　小结 
第章　无监督机器学习 
.　聚类算法 
..　分布方法 
..　质心点方法 
..　密度方法 
..　层次方法 
.　降维 
.　奇异值分解（SVD） 
.　小结 
第章　有监督机器学习 
.　模型错误评估 
.　广义线性模型 
..　广义线性模型的概率
解释 
..　k近邻 
.　朴素贝叶斯 
..　多项式朴素贝叶斯 
..　高斯朴素贝叶斯 
.　决策树 
.　支持向量机 
.　有监督学习方法的对比 
..　回归问题 
..　分类问题 
.　隐马尔可夫模型 
.　小结 
第章　Web挖掘技术 
.　Web结构挖掘 
..　Web爬虫 
..　索引器 
..　排序―PageRank
算法 
.　Web内容挖掘 
句法解析 
.　自然语言处理 
.　信息的后处理 
..　潜在狄利克雷分配 
..　观点挖掘（情感
分析） 
.　小结 
第章　推荐系统 
.　效用矩阵 
.　相似度度量方法 
.　协同过滤方法 
..　基于记忆的协同
过滤 
..　基于模型的协同
过滤 
.　CBF方法 
..　商品特征平均得分
方法 
..　正则化线性回归
方法 
.　用关联规则学习，构建推荐
系统 
.　对数似然比推荐方法 
.　混合推荐系统 
.　推荐系统评估 
..　均方根误差（RMSE）
评估 
..　分类效果的度量方法 
.　小结 
第章　开始Django之旅 
.　HTTP―GET和POST方法的
基础 
..　Django的安装和
服务器的搭建 
..　配置 
.　编写应用―Django
最重要的功能 
..　model 
..　HTML网页背后的
URL和view 
..　URL声明和view 
.　管理后台 
..　shell接口 
..　命令 
..　RESTful应用编程
接口（API） 
.　小结 
第章　电影推荐系统Web应用 
.　让应用跑起来 
.　model 
.　命令 
.　实现用户的注册、登录和
登出功能 
.　信息检索系统（电影查询） 
.　打分系统 
.　推荐系统 
.　管理界面和API 
.　小结 
第章　影评情感分析应用 
.　影评情感分析应用用法
简介 
.　搜索引擎的选取和应用的
代码 
.　Scrapy的配置和情感分析
应用代码 
..　Scrapy的设置 
..　Scraper 
..　Pipeline 
..　爬虫 
.　Django model 
.　整合Django和Scrapy 
..　命令（情感分析模型和
删除查询结果） 
..　情感分析模型加载器 
..　删除已执行过的查询 
..　影评情感分析器―
Django view和HTML
代码 
.　PageRank：Django view和
算法实现 
.　管理后台和API 
.　小结 
・ ・ ・ ・ ・ ・ (收起)第章　监督学习　　
.　简介　　
.　数据预处理技术　　
..　准备工作　　
..　详细步骤　　
.　标记编码方法　　
.　创建线性回归器　　
..　准备工作　　
..　详细步骤　　
.　计算回归准确性　　
..　准备工作　　
..　详细步骤　　
.　保存模型数据　　
.　创建岭回归器　　
..　准备工作　　
..　详细步骤　　
.　创建多项式回归器　　
..　准备工作　　
..　详细步骤　　
.　估算房屋价格　　
..　准备工作　　
..　详细步骤　　
.　计算特征的相对重要性　　
.　评估共享单车的需求分布　　
..　准备工作　　
..　详细步骤　　
..　更多内容　　
第章　创建分类器　　
.　简介　　
.　建立简单分类器　　
..　详细步骤　　
..　更多内容　　
.　建立逻辑回归分类器　　
.　建立朴素贝叶斯分类器　　
.　将数据集分割成训练集和测试集　　
.　用交叉验证检验模型准确性　　
..　准备工作　　
..　详细步骤　　
.　混淆矩阵可视化　　
.　提取性能报告　　
.　根据汽车特征评估质量　　
..　准备工作　　
..　详细步骤　　
.　生成验证曲线　　
.　生成学习曲线　　
.　估算收入阶层　　
第章　预测建模　　
.　简介　　
.　用SVM建立线性分类器　　
..　准备工作　　
..　详细步骤　　
.　用SVM建立非线性分类器　　
.　解决类型数量不平衡问题　　
.　提取置信度　　
.　寻找最优超参数　　
.　建立事件预测器　　
..　准备工作　　
..　详细步骤　　
.　估算交通流量　　
..　准备工作　　
..　详细步骤　　
第章　无监督学习――聚类　　
.　简介　　
.　用k-means算法聚类数据　　
.　用矢量量化压缩图片　　
.　建立均值漂移聚类模型　　
.　用凝聚层次聚类进行数据分组　　
.　评价聚类算法的聚类效果　　
.　用DBSCAN算法自动估算集群数量　　
.　探索股票数据的模式　　
.　建立客户细分模型　　
第章　构建推荐引擎　　
.　简介　　
.　为数据处理构建函数组合　　
.　构建机器学习流水线　　
..　详细步骤　　
..　工作原理　　
.　寻找最近邻　　
.　构建一个KNN分类器　　
..　详细步骤　　
..　工作原理　　
.　构建一个KNN回归器　　
..　详细步骤　　
..　工作原理　　
.　计算欧氏距离分数　　
.　计算皮尔逊相关系数　　
.　寻找数据集中的相似用户　　
.　生成电影推荐　　
第章　分析文本数据　　
.　简介　　
.　用标记解析的方法预处理数据　　
.　提取文本数据的词干　　
..　详细步骤　　
..　工作原理　　
.　用词形还原的方法还原文本的基本形式　　
.　用分块的方法划分文本　　
.　创建词袋模型　　
..　详细步骤　　
..　工作原理　　
.　创建文本分类器　　
..　详细步骤　　
..　工作原理　　
.　识别性别　　
.　分析句子的情感　　
..　详细步骤　　
..　工作原理　　
.　用主题建模识别文本的模式　　
..　详细步骤　　
..　工作原理　　
第章　语音识别　　
.　简介　　
.　读取和绘制音频数据　　
.　将音频信号转换为频域　　
.　自定义参数生成音频信号　　
.　合成音乐　　
.　提取频域特征　　
.　创建隐马尔科夫模型　　
.　创建一个语音识别器　　
第章　解剖时间序列和时序数据　　
.　简介　　
.　将数据转换为时间序列格式　　
.　切分时间序列数据　　
.　操作时间序列数据　　
.　从时间序列数据中提取统计数字　　
.　针对序列数据创建隐马尔科夫模型　　
..　准备工作　　
..　详细步骤　　
.　针对序列文本数据创建条件随机场　　
..　准备工作　　
..　详细步骤　　
.　用隐马尔科夫模型分析股票市场数据　　
第章　图像内容分析　　
.　简介　　
.　用OpenCV-Pyhon操作图像　　
.　检测边　　
.　直方图均衡化　　
.　检测棱角　　
.　检测SIFT特征点　　
.　创建Star特征检测器　　
.　利用视觉码本和向量量化创建特征　　
.　用极端随机森林训练图像分类器　　
.　创建一个对象识别器　　
第章　人脸识别　　
.　简介　　
.　从网络摄像头采集和处理视频信息　　
.　用Haar级联创建一个人脸识别器　　
.　创建一个眼睛和鼻子检测器　　
.　做主成分分析　　
.　做核主成分分析　　
.　做盲源分离　　
.　用局部二值模式直方图创建一个人脸识别器　　
第章　深度神经网络　　
.　简介　　
.　创建一个感知器　　
.　创建一个单层神经网络　　
.　创建一个深度神经网络　　
.　创建一个向量量化器　　
.　为序列数据分析创建一个递归神经网络　　
.　在光学字符识别数据库中将字符可视化　　
.　用神经网络创建一个光学字符识别器　　
第章　可视化数据　　
.　简介　　
.　画D散点图　　
.　画气泡图　　
.　画动态气泡图　　
.　画饼图　　
.　画日期格式的时间序列数据　　
.　画直方图　　
.　可视化热力图　　
.　动态信号的可视化模拟　　
・ ・ ・ ・ ・ ・ (收起)目录
第章　机器学习基础　　
.　机器学习概要　　
什么是机器学习　　
机器学习的种类　　
机器学习的应用　　
.　机器学习的步骤　　
数据的重要性　　
有监督学习（分类）的例子　　
无监督学习（聚类）的例子　　
可视化　　
图形的种类和画法：使用Matplotlib显示图形的方法　　
使用pandas理解和处理数据　　
本章小结　　
第章　有监督学习　　
.　算法：线性回归　　
概述　　
算法说明　　
详细说明　　
.　算法：正则化　　
概述　　
算法说明　　
详细说明　　
.　算法：逻辑回归　　
概述　　
算法说明　　
详细说明　　
.　算法：支持向量机　　
概述　　
算法说明　　
详细说明　　
.　算法：支持向量机（核方法）　　
概述　　
算法说明　　
详细说明　　
.　算法：朴素贝叶斯　　
概述　　
算法说明　　
详细说明　　
.　算法：随机森林　　
概述　　
算法说明　　
详细说明　　
.　算法：神经网络　　
概述　　
算法说明　　
详细说明　　
.　算法：KNN　　
概述　　
算法说明　　
详细说明　　
第章　无监督学习　　
.　算法：PCA　　
概述　　
算法说明　　
详细说明　　
.　算法：LSA　　
概述　　
算法说明　　
详细说明　　
.　算法：NMF　　
概述　　
算法说明　　
详细说明　　
.　算法：LDA　　
概述　　
算法说明　　
详细说明　　
.　算法：k-means算法　　
概述　　
算法说明　　
详细说明　　
.　算法：混合高斯分布　　
概述　　
算法说明　　
详细说明　　
.　算法：LLE　　
概述　　
算法说明　　
详细说明　　
.　算法：t-SNE　　
概述　　
算法说明　　
详细说明　　
第章　评估方法和各种数据的处理　　
.　评估方法　　
有监督学习的评估　　
分类问题的评估方法　　
回归问题的评估方法　　
均方误差和决定系数指标的不同　　
与其他算法进行比较　　
超参数的设置　　
模型的过拟合　　
防止过拟合的方法　　
将数据分为训练数据和验证数据　　
交叉验证　　
搜索超参数　　
.　文本数据的转换处理　　
基于单词出现次数的转换　　
基于tf-idf的转换　　
应用于机器学习模型　　
.　图像数据的转换处理　　
直接将像素信息作为数值使用　　
将转换后的向量数据作为输入来应用机器学习模型　　
第章　环境搭建 
.　Python 的安装　　
Windows　　
macOS　　
Linux　　
使用Anaconda在Windows上安装　　
.　虚拟环境　　
通过官方安装程序安装Python的情况　　
通过Anaconda安装Python的情况　　
.　第三方包的安装　　
什么是第三方包　　
安装第三方包的方法　　
参考文献　　
・ ・ ・ ・ ・ ・ (收起)第章　学习前的准备　　
.　关于机器学习 
..　学习机器学习的窍门 
..　机器学习中问题的分类 
..　本书的结构 
.　安装Python 
.　Jupyter Notebook 
..　Jupyter Notebook的用法 
..　输入Markdown格式文本 
..　更改文件名 
.　安装Keras和TensorFlow 
第章　Python基础知识　　
.　四则运算 
..　四则运算的用法 
..　幂运算 
.　变量 
..　利用变量进行计算 
..　变量的命名 
.　类型 
..　类型的种类 
..　检查类型 
..　字符串 
.　print 语句 
..　print语句的用法 
..　同时显示数值和字符串的方法 
..　同时显示数值和字符串的方法 
.　list（数组变量） 
..　list的用法 
..　二维数组 
..　创建连续的整数数组 
.　tuple（数组） 
..　tuple的用法 
..　读取元素 
..　长度为的tuple 
.　if 语句 
..　if语句的用法 
..　比较运算符 
.　for 语句 
..　for语句的用法 
..　enumerate的用法 
.　向量 
..　NumPy的用法 
..　定义向量 
..　读取元素 
..　替换元素 
..　创建连续整数的向量 
..　ndarray的注意事项 
.　矩阵 
..　定义矩阵 
..　矩阵的大小 
..　读取元素 
..　替换元素 
..　生成元素为和的ndarray 
..　生成元素随机的矩阵 
..　改变矩阵的大小 
.　矩阵的四则运算 
..　矩阵的四则运算 
..　标量×矩阵 
..　算术函数 
..　计算矩阵乘积 
.　切片 
.　替换满足条件的数据 
.　help 
.　函数 
..　函数的用法 
..　参数与返回值 
.　保存文件 
..　保存一个ndarray类型变量 
..　保存多个ndarray类型变量 
第章　数据可视化　　
.　绘制二维图形 
..　绘制随机图形 
..　代码清单的格式 
..　绘制三次函数f (x) = (x - ) x (x + ) 
..　确定绘制范围 
..　绘制图形 
..　装饰图形 
..　并列显示多张图形 
.　绘制三维图形 
..　包含两个变量的函数 
..　用颜色表示数值：pcolor 
..　绘制三维图形：surface 
..　绘制等高线：contour 
第章　机器学习中的数学　　
.　向量 
..　什么是向量 
..　用Python定义向量 
..　列向量的表示方法 
..　转置的表示方法 
..　加法和减法 
..　标量积 
..　内积 
..　向量的模 
.　求和符号 
..　带求和符号的数学式的变形 
..　通过内积求和 
.　累乘符号 
.　导数 
..　多项式的导数 
..　带导数符号的数学式的变形 
..　复合函数的导数 
..　复合函数的导数：链式法则 
.　偏导数 
..　什么是偏导数 
..　偏导数的图形 
..　绘制梯度的图形 
..　多变量的复合函数的偏导数 
..　交换求和与求导的顺序 
.　矩阵 
..　什么是矩阵 
..　矩阵的加法和减法 
..　标量积 
..　矩阵的乘积 
..　单位矩阵 
..　逆矩阵 
..　转置 
..　矩阵和联立方程式 
..　矩阵和映射 
.　指数函数和对数函数 
..　指数 
..　对数 
..　指数函数的导数 
..　对数函数的导数 
..　Sigmoid函数 
..　Softmax函数 
..　Softmax函数和Sigmoid函数 
..　高斯函数 
..　二维高斯函数 
第章　有监督学习：回归　　
.　一维输入的直线模型 
..　直线模型 
..　平方误差函数 
..　求参数（梯度法） 
..　直线模型参数的解析解 
.　二维输入的平面模型 
..　数据的表示方法 
..　平面模型 
..　平面模型参数的解析解 
.　D维线性回归模型 
..　D维线性回归模型 
..　参数的解析解 
..　扩展到不通过原点的平面 
.　线性基底函数模型 
.　过拟合问题 
.　新模型的生成 
.　模型的选择 
.　小结 
第章　有监督学习：分类　　
.　一维输入的二元分类 
..　问题设置 
..　使用概率表示类别分类 
..　最大似然估计 
..　逻辑回归模型 
..　交叉熵误差 
..　学习法则的推导 
..　通过梯度法求解 
.　二维输入的二元分类 
..　问题设置 
..　逻辑回归模型 
.　二维输入的三元分类 
..　三元分类逻辑回归模型 
..　交叉熵误差 
..　通过梯度法求解 
第章　神经网络与深度学习　　
.　神经元模型 
..　神经细胞 
..　神经元模型 
.　神经网络模型 
..　二层前馈神经网络 
..　二层前馈神经网络的实现 
..　数值导数法 
..　通过数值导数法应用梯度法 
..　误差反向传播法 
..　求.E / .vkj 
..　求.E / .wji 
..　误差反向传播法的实现 
..　学习后的神经元的特性 
.　使用Keras实现神经网络模型 
..　二层前馈神经网络 
..　Keras的使用流程 
第章　神经网络与深度学习的应用（手写数字识别）　　
.　MINST数据集 
.　二层前馈神经网络模型 
.　ReLU激活函数 
.　空间过滤器 
.　卷积神经网络 
.　池化 
.　Dropout 
.　融合了各种特性的MNIST识别网络模型 
第章　无监督学习　　
.　二维输入数据 
.　K-means算法 
..　K-means算法的概要 
..　步骤：准备变量与初始化 
..　步骤：更新R 
..　步骤：更新μ 
..　失真度量 
.　混合高斯模型 
..　基于概率的聚类 
..　混合高斯模型 
..　EM算法的概要 
..　步骤：准备变量与初始化 
..　步骤（步骤E）：更新γ 
..　步骤（步骤M）：更新π、μ和Σ 
..　似然 
第章　本书小结　　
后记　　
・ ・ ・ ・ ・ ・ (收起)译者序
原书前言
致谢
第章 文本机器学习导论
.导论
..本章内容组织结构
.文本学习有何特别之处
.文本分析模型
..文本预处理和相似度计算
..降维与矩阵分解
..文本聚类
..文本分类与回归建模
..结合文本与异构数据的联合分析
..信息检索与网页搜索
..序列语言建模与嵌入
..文本摘要
..信息提取
..意见挖掘与情感分析
..文本分割与事件检测
.本章小结
.参考资料
..软件资源
.习题
第章 文本预处理与相似度计算
.导论
..本章内容组织结构
.原始文本提取与词条化
..文本提取中与网页相关的问题
.从词条中提取词项
..停用词移除
..连字符
..大小写转换
..基于用法的合并
..词干提取
.向量空间表示与归一化
.文本中的相似度计算
..idf归一化和词干提取是否总是有用
.本章小结
.参考资料
..软件资源
.习题
第章 矩阵分解与主题建模
.导论
..本章内容组织结构
..将二分解归一化为标准的三分解
.奇异值分解（SVD)
..SVD的例子
..实现SVD的幂迭代法
..SVD/LSA的应用
..SVD/LSA的优缺点
.非负矩阵分解
..非负矩阵分解的可解释性
..非负矩阵分解的例子
..融入新文档
..非负矩阵分解的优缺点
.概率潜在语义分析（PLSA）
..与非负矩阵分解的联系
..与SVD的比较
..PLSA的例子
..PLSA的优缺点
.隐含狄利克雷分布（LDA）概览
..简化的LDA模型
..平滑的LDA模型
.非线性变换和特征工程
..选择一个相似度函数
..Nystrom估计
..相似度矩阵的部分可用性
.本章小结
.参考资料
..软件资源
.习题
第章 文本聚类
.导论
..本章内容组织结构
.特征选择与特征工程
..特征选择
..特征工程
.主题建模和矩阵分解
..混合隶属度模型与重叠簇
..非重叠簇与双聚类：矩阵分解的角度
.面向聚类的生成混合模型
..伯努利模型
..多项式模型
..与混合隶属度主题模型的比较
..与朴素贝叶斯分类模型的联系
.k均值算法
..收敛与初始化
..计算复杂度
..与概率模型的联系
.层次聚类算法
..高效实现与计算复杂度
..与k均值的自然联姻
.聚类集成
..选择集成分量
..混合来自不同分量的结果
.将文本当作序列来进行聚类
..面向聚类的核方法
..数据相关的核方法：谱聚类
.聚类到有监督学习的转换
..实际问题
.聚类评估
..内部有效性度量的缺陷
..外部有效性度量
.本章小结
.参考资料
..软件资源
.习题
第章 文本分类：基本模型
.导论
..标记的类型与回归建模
..训练与测试
..归纳、直推和演绎学习器
..基本模型
..分类器中与文本相关的挑战
.特征选择与特征工程
..基尼系数
..条件熵
..逐点互信息
..紧密相关的度量方式
..χ-统计量
..嵌入式特征选择模型
..特征工程技巧
.朴素贝叶斯模型
..伯努利模型
..多项式模型
..实际观察
..利用朴素贝叶斯对输出进行排序
..朴素贝叶斯的例子
..半监督朴素贝叶斯
.最近邻分类器
..-最近邻分类器的属性
..Rocchio与最近质心分类
..加权最近邻
..自适应最近邻：一系列有效的方法
.决策树与随机森林
..构造决策树的基本步骤
..分裂一个节点
..多变量分裂
..决策树在文本分类中的问题
..随机森林
..把随机森林看作自适应最近邻方法
.基于规则的分类器
..顺序覆盖算法
..从决策树中生成规则
..关联分类器
..预测
.本章小结
.参考资料
..软件资源
.习题
第章 面向文本的线性分类与回归
.导论
..线性模型的几何解释
..我们需要偏置变量吗
..使用正则化的线性模型的一般定义
..将二值预测推广到多类
..面向文本的线性模型的特点
.最小二乘回归与分类
..使用L正则化的最小二乘回归
..LASSO:使用L正则化的最小二乘回归
..Fisher线性判别与最小二乘分类器
.支持向量机(SVM)
..正则优化解释
..最大间隔解释
..Pegasos：在原始空间中求解SVM 
..对偶SVM优化形式
..对偶SVM的学习算法
..对偶SVM的自适应最近邻解释
.对数几率回归
..正则优化解释
..对数几率回归的训练算法
..对数几率回归的概率解释
..多元对数几率回归与其他推广
..关于对数几率回归性能的评述
.线性模型的非线性推广
..基于显式变换的核SVM
..为什么传统的核函数能够提升线性可分性
..不同核函数的优缺点
..核技巧
..核技巧的系统性应用
.本章小结
.参考资料
..软件资源
.习题
第章 分类器的性能与评估
.导论
..本章内容组织结构
.偏置-方差权衡
..一个形式化的观点
..偏置和方差的迹象
.偏置-方差权衡在性能方面可能的影响
..训练数据规模的影响
..数据维度的影响
..文本中模型选择可能的影响
.利用集成方法系统性地提升性能
..bagging与子采样
..boosting
.分类器评估
..分割为训练部分和测试部分
..绝对准确率度量
..面向分类和信息检索的排序度量
.本章小结
.参考资料
..boosting与对数几率回归的联系
..分类器评估
..软件资源
..用于评估的数据集
.习题
第章 结合异构数据的联合文本挖掘
.导论
..本章内容组织结构
.共享矩阵分解的技巧
..分解图
..应用：结合文本和网页链接进行共享分解
..应用：结合文本与无向社交网络
..应用：结合文本的图像迁移学习
..应用：结合评分和文本的推荐系统
..应用：跨语言文本挖掘
.分解机
.联合概率建模技术
..面向聚类的联合概率模型
..朴素贝叶斯分类器
.到图挖掘技术的转换
.本章小结
.参考资料
..软件资源
.习题
第章 信息检索与搜索引擎
.导论
..本章内容组织结构
.索引和查询处理
..词典数据结构
..倒排索引
..线性时间的索引构建
..查询处理
..效率优化
.信息检索模型的评分
..基于tf-idf的向量空间模型
..二值独立模型
..使用词项频率的BM模型
..信息检索中的统计语言模型
.网络爬虫与资源发现
..一个基本的爬虫算法
..带偏好的爬虫
..多线程
..避开蜘蛛陷阱
..用于近似重复检测的Shingling方法
.搜索引擎中的查询处理
..分布式索引构建
..动态索引更新
..查询处理
..信誉度的重要性
.基于链接的排序算法
..PageRank
..HITS
.本章小结
.参考资料
..软件资源
.习题
第章 文本序列建模与深度学习
.导论
..本章内容组织结构
.统计语言模型
..skip-gram模型
..与嵌入的关系
.核方法
.单词-上下文矩阵分解模型 
..使用计数的矩阵分解
..GloVe嵌入
..PPMI矩阵分解
..位移PPMI矩阵分解
..融入句法和其他特征
.单词距离的图形化表示
.神经语言模型
..神经网络简介
..基于wordvec的神经嵌入
..wordvec(SGNS)是对数几率矩阵分解
..除了单词以外：基于docvec的段落嵌入
.循环神经网络(RNN)
..实际问题
..RNN的语言建模示例
..图像描述应用
..序列到序列学习与机器翻译
..句子级分类应用
..使用语言特征的词条级分类
..多层循环网络
.本章小结
.参考资料
..软件资源
.习题
第章 文本摘要
.导论
..提取式摘要与抽象式摘要
..提取式摘要中的关键步骤
..提取式摘要中的分割阶段
..本章内容组织结构
.提取式摘要的主题词方法
..词项概率
..归一化频率权重
..主题签名
..句子选择方法
.提取式摘要的潜在方法
..潜在语义分析
..词汇链
..基于图的方法
..质心摘要
.面向提取式摘要的机器学习
..特征提取
..使用哪种分类器
.多文档摘要
..基于质心的摘要
..基于图的方法
.抽象式摘要
..句子压缩
..信息融合
..信息排列
.本章小结
.参考资料
..软件资源
.习题
第章 信息提取
.导论
..历史演变
..自然语言处理的角色
..本章内容组织结构
.命名实体识别
..基于规则的方法
..转化为词条级分类任务
..隐马尔可夫模型
..最大熵马尔可夫模型
..条件随机场
.关系提取
..转换为分类问题
..利用显式的特征工程进行关系预测
..利用隐式的特征工程进行关系预测：核方法
.本章小结
.参考资料
..弱监督学习方法
..无监督与开放式信息提取 
..软件资源
.习题
第章 意见挖掘与情感分析
.导论
..意见词典
..把意见挖掘看作槽填充和信息提取任务
..本章内容组织结构
.文档级情感分析
..面向分类的无监督方法
.短语级与句子级情感分类
..句子级与短语级分析的应用
..主观性分类到最小割问题的归约
..句子级与短语级极性分析中的上下文
.把基于方面的意见挖掘看作信息提取任务
..Hu和Liu的无监督方法
..OPINE：一种无监督方法
..把有监督意见提取看作词条级分类任务
.虚假意见
..面向虚假评论检测的有监督方法
..面向虚假评论制造者检测的无监督方法
.意见摘要
..评分总结
..情感总结
..基于短语与句子的情感总结
..提取式与抽象式总结
.本章小结
.参考资料
..软件资源
.习题
第章 文本分割与事件检测
.导论
..与话题检测和追踪的关系
..本章内容组织结构
.文本分割
..TextTiling
..C方法
..基于现成的分类器的有监督的分割
..基于马尔可夫模型的有监督的分割
.文本流挖掘
..流式文本聚类
..面向首次报道检测的应用 
.事件检测
..无监督的事件检测
..把有监督的事件检测看作有监督的分割任务
..把事件检测看作一个信息提取问题
.本章小结
.参考资料
..软件资源
.习题
参考文献
・ ・ ・ ・ ・ ・ (收起)译者序
前言
第章探索数据分析
.Scala入门
.去除分类字段的重复值
.数值字段概述
.基本抽样、分层抽样和一致抽样
.使用Scala和Spark的Note―book工作
.相关性的基础
.总结
第章数据管道和建模
.影响图
.序贯试验和风险处理
.探索与利用问题
.不知之不知
.数据驱动系统的基本组件
..数据收集
..数据转换层
..数据分析与机器学习
..UI组件
..动作引擎
..关联引擎
..监控
.优化和交互
.总结
第章使用Spark和MLlib
.安装Spark
.理解Spark的架构
..任务调度
..Spark的组件
..MQTT、ZeroMQ、Flume和Kafka
..HDFS、Cassandra、S和Tachyon
..Mesos、YARN和Standa―lone
.应用
..单词计数
..基于流的单词计数
..SparkSQL和数据框
.机器学习库
..SparkR
..图算法：Graphx和Graph―Frames
.Spark的性能调整
.运行Hadoop的HDFS
.总结
第章监督学习和无监督学习
.记录和监督学习
..Iirs数据集
..类标签点
..SVMWithSGD
..logistic回归
..决策树
..bagging和boosting：集成学习方法
.无监督学习
.数据维度
.总结
第章回归和分类
.回归是什么
.连续空间和度量
.线性回归
.logistic回归
.正则化
.多元回归
.异方差
.回归树
.分类的度量
.多分类问题
.感知机
.泛化误差和过拟合
.总结
第章使用非结构化数据
.嵌套数据
.其他序列化格式
.Hive和Impala
.会话化
.使用特质
.使用模式匹配
.非结构化数据的其他用途
.概率结构
.投影
.总结
第章使用图算法
.图简介
.SBT
.Scala的图项目
..增加节点和边
..图约束
..JSON
.GraphX
..谁收到电子邮件
..连通分量
..三角形计数
..强连通分量
..PageRank
..SVD++
.总结
第章Scala与R和Python的集成
.R的集成
..R和SparkR的相关配置
..数据框
..线性模型
..广义线性模型
..在SparkR中读取JSON文件
..在SparkR中写入Parquet文件
..从R调用Scala
.Python的集成
..安装Python
..PySpark
..从Java／Scala调用Python
.总结
第章Scala中的NLP
.文本分析流程
.Spark的MLlib库
..TF―IDF
..LDA
.分词、标注和分块
.POS标记
.使用wordvec寻找词关系
.总结
第章高级模型监控
.系统监控
.进程监控
.模型监控
..随时间变化的性能
..模型停用标准
..A／B测试
.总结
・ ・ ・ ・ ・ ・ (收起)目 录
第章 概 述
. 什么是机器学习――从一个小故事开始 / 
. 机器学习的一些应用场景――蝙蝠公司的业务单元 / 
. 机器学习应该如何入门――世上无难事 / 
. 有监督学习与无监督学习 / 
. 机器学习中的分类与回归 / 
. 模型的泛化、过拟合与欠拟合 / 
. 小结 / 
第章 基于Python语言的环境配置
. Python的下载和安装 / 
. Jupyter Notebook的安装与使用方法 / 
.. 使用pip进行Jupyter Notebook的下载和安装 / 
.. 运行Jupyter Notebook / 
.. Jupyter Notebook的使用方法 / 
. 一些必需库的安装及功能简介 / 
.. Numpy――基础科学计算库 / 
.. Scipy――强大的科学计算工具集 / 
.. pandas――数据分析的利器 / 
.. matplotlib――画出优美的图形 / 
深入浅出Python 机器学习
VIII
. scikit-learn――非常流行的Python机器学习库 / 
. 小结 / 
第章 K最近邻算法――近朱者赤，近墨者黑
. K最近邻算法的原理 / 
. K最近邻算法的用法 / 
.. K最近邻算法在分类任务中的应用 / 
.. K最近邻算法处理多元分类任务 / 
.. K最近邻算法用于回归分析 / 
. K最近邻算法项目实战――酒的分类 / 
.. 对数据集进行分析 / 
.. 生成训练数据集和测试数据集 / 
.. 使用K最近邻算法进行建模 / 
.. 使用模型对新样本的分类进行预测 / 
. 小结 / 
第章 广义线性模型――“耿直”的算法模型
. 线性模型的基本概念 / 
.. 线性模型的一般公式 / 
.. 线性模型的图形表示 / 
.. 线性模型的特点 / 
. 最基本的线性模型――线性回归 / 
.. 线性回归的基本原理 / 
.. 线性回归的性能表现 / 
. 使用L正则化的线性模型――岭回归 / 
.. 岭回归的原理 / 
.. 岭回归的参数调节 / 
. 使用L正则化的线性模型――套索回归 / 
.. 套索回归的原理 / 
.. 套索回归的参数调节 / 
.. 套索回归与岭回归的对比 / 
目
录
IX
. 小结 / 
第章 朴素贝叶斯――打雷啦，收衣服啊
. 朴素贝叶斯基本概念 / 
.. 贝叶斯定理 / 
.. 朴素贝叶斯的简单应用 / 
. 朴素贝叶斯算法的不同方法 / 
.. 贝努利朴素贝叶斯 / 
.. 高斯朴素贝叶斯 / 
.. 多项式朴素贝叶斯 / 
. 朴素贝叶斯实战――判断肿瘤是良性还是恶性 / 
.. 对数据集进行分析 / 
.. 使用高斯朴素贝叶斯进行建模 / 
.. 高斯朴素贝叶斯的学习曲线 / 
. 小结 / 
第章 决策树与随机森林――会玩读心术的算法
. 决策树 / 
.. 决策树基本原理 / 
.. 决策树的构建 / 
.. 决策树的优势和不足 / 
. 随机森林 / 
.. 随机森林的基本概念 / 
.. 随机森林的构建 / 
.. 随机森林的优势和不足 / 
. 随机森林实例――要不要和相亲对象进一步发展 / 
.. 数据集的准备 / 
.. 用get_dummies处理数据 / 
.. 用决策树建模并做出预测 / 
. 小结 / 
第章 支持向量机SVM――专治线性不可分
. 支持向量机SVM基本概念 / 
.. 支持向量机SVM的原理 / 
.. 支持向量机SVM的核函数 / 
. SVM的核函数与参数选择 / 
.. 不同核函数的SVM对比 / 
.. 支持向量机的gamma参数调节 / 
.. SVM算法的优势与不足 / 
. SVM实例――波士顿房价回归分析 / 
.. 初步了解数据集 / 
.. 使用SVR进行建模 / 
. 小结 / 
第章 神经网络――曾入“冷宫”，如今得宠
. 神经网络的前世今生 / 
.. 神经网络的起源 / 
.. 第一个感知器学习法则 / 
.. 神经网络之父――杰弗瑞・欣顿 / 
. 神经网络的原理及使用 / 
.. 神经网络的原理 / 
.. 神经网络中的非线性矫正 / 
.. 神经网络的参数设置 / 
. 神经网络实例――手写识别 / 
.. 使用MNIST数据集 / 
.. 训练MLP神经网络 / 
.. 使用模型进行数字识别 / 
. 小结 / 
第章 数据预处理、降维、特征提取及聚类――快
刀斩乱麻
. 数据预处理 / 
.. 使用StandardScaler进行数据预处理 / 
.. 使用MinMaxScaler进行数据预处理 / 
.. 使用RobustScaler进行数据预处理 / 
.. 使用Normalizer进行数据预处理 / 
.. 通过数据预处理提高模型准确率 / 
. 数据降维 / 
.. PCA主成分分析原理 / 
.. 对数据降维以便于进行可视化 / 
.. 原始特征与PCA主成分之间的关系 / 
. 特征提取 / 
.. PCA主成分分析法用于特征提取 / 
.. 非负矩阵分解用于特征提取 / 
. 聚类算法 / 
.. K均值聚类算法 / 
.. 凝聚聚类算法 / 
.. DBSCAN算法 / 
. 小结 / 
第章 数据表达与特征工程――锦上再添花
. 数据表达 / 
.. 使用哑变量转化类型特征 / 
.. 对数据进行装箱处理 / 
. 数据“升维” / 
.. 向数据集添加交互式特征 / 
.. 向数据集添加多项式特征 / 
. 自动特征选择 / 
.. 使用单一变量法进行特征选择 / 
.. 基于模型的特征选择 / 
.. 迭代式特征选择 / 
. 小结 / 
第章 模型评估与优化――只有更好，没有最好
. 使用交叉验证进行模型评估 / 
.. scikit-learn中的交叉验证法 / 
.. 随机拆分和“挨个儿试试” / 
.. 为什么要使用交叉验证法 / 
. 使用网格搜索优化模型参数 / 
.. 简单网格搜索 / 
.. 与交叉验证结合的网格搜索 / 
. 分类模型的可信度评估 / 
.. 分类模型中的预测准确率 / 
.. 分类模型中的决定系数 / 
. 小结 / 
第章 建立算法的管道模型――团结就是力量
. 管道模型的概念及用法 / 
.. 管道模型的基本概念 / 
.. 使用管道模型进行网格搜索 / 
. 使用管道模型对股票涨幅进行回归分析 / 
.. 数据集准备 / 
.. 建立包含预处理和MLP模型的管道模型 / 
.. 向管道模型添加特征选择步骤 / 
. 使用管道模型进行模型选择和参数调优 / 
.. 使用管道模型进行模型选择 / 
.. 使用管道模型寻找更优参数 / 
. 小结 / 
第章 文本数据处理――亲，见字如“数”
. 文本数据的特征提取、中文分词及词袋模型 / 
.. 使用CountVectorizer对文本进行特征提取 / 
.. 使用分词工具对中文文本进行分词 / 
.. 使用词袋模型将文本数据转为数组 / 
. 对文本数据进一步进行优化处理 / 
.. 使用n-Gram改善词袋模型 / 
.. 使用tf-idf模型对文本数据进行处理 / 
.. 删除文本中的停用词 / 
. 小结 / 
第章 从数据获取到话题提取――从“研究员”
到“段子手”
. 简单页面的爬取 / 
.. 准备Requests库和User Agent / 
.. 确定一个目标网站并分析其结构 / 
.. 进行爬取并保存为本地文件 / 
. 稍微复杂一点的爬取 / 
.. 确定目标页面并进行分析 / 
.. Python中的正则表达式 / 
.. 使用BeautifulSoup进行HTML解析 / 
.. 对目标页面进行爬取并保存到本地 / 
. 对文本数据进行话题提取 / 
.. 寻找目标网站并分析结构 / 
.. 编写爬虫进行内容爬取 / 
.. 使用潜在狄利克雷分布进行话题提取 / 
. 小结 / 
第章 人才需求现状与未来学习方向――你是不
是下一个“大牛”
. 人才需求现状 / 
.. 全球AI从业者达万，人才需求年翻倍 / 
.. AI人才需求集中于一线城市，七成从业者月薪过万 / 
.. 人才困境仍难缓解，政策支援亟不可待 / 
. 未来学习方向 / 
.. 用于大数据分析的计算引擎 / 
.. 深度学习开源框架 / 
.. 使用概率模型进行推理 / 
. 技能磨炼与实际应用 / 
.. Kaggle算法大赛平台和OpenML平台 / 
.. 在工业级场景中的应用 / 
.. 对算法模型进行A/B测试 / 
. 小结 / 
参考文献 / 
・ ・ ・ ・ ・ ・ (收起)对本书的赞誉
序一
序二
序三
前言
第章　通向智能安全的旅程 
.　人工智能、机器学习与深度学习 
.　人工智能的发展 
.　国内外网络安全形势 
.　人工智能在安全领域的应用 
.　算法和数据的辩证关系 
.　本章小结 
参考资源 
第章　打造机器学习工具箱 
.　Python在机器学习领域的优势 
..　NumPy 
..　SciPy 
..　NLTK 
..　Scikit-Learn 
.　TensorFlow简介与环境搭建 
.　本章小结 
参考资源 
第章　机器学习概述 
.　机器学习基本概念 
.　数据集 
..　KDD 数据 
..　HTTP DATASET CSIC  
..　SEA数据集 
..　ADFA-LD数据集 
..　Alexa域名数据 
..　Scikit-Learn数据集 
..　MNIST数据集 
..　Movie Review Data 
..　SpamBase数据集 
..　Enron数据集 
.　特征提取 
..　数字型特征提取 
..　文本型特征提取 
..　数据读取 
.　效果验证 
.　本章小结 
参考资源 
第章　Web安全基础 
.　XSS攻击概述 
..　XSS的分类 
..　XSS特殊攻击方式 
..　XSS平台简介 
..　近年典型XSS攻击事件分析 
.　SQL注入概述 
..　常见SQL注入攻击 
..　常见SQL注入攻击载荷 
..　SQL常见工具 
..　近年典型SQL注入事件分析 
.　WebShell概述 
..　WebShell功能 
..　常见WebShell 
.　僵尸网络概述 
..　僵尸网络的危害 
..　近年典型僵尸网络攻击事件分析 
.　本章小结 
参考资源 
第章　K近邻算法 
.　K近邻算法概述 
.　示例：hello world！K近邻 
.　示例：使用K近邻算法检测异常操作（一） 
.　示例：使用K近邻算法检测异常操作（二） 
.　示例：使用K近邻算法检测Rootkit 
.　示例：使用K近邻算法检测WebShell 
.　本章小结 
参考资源 
第章　决策树与随机森林算法 
.　决策树算法概述 
.　示例：hello world！决策树 
.　示例：使用决策树算法检测POP暴力破解 
.　示例：使用决策树算法检测FTP暴力破解 
.　随机森林算法概述 
.　示例：hello world！随机森林 
.　示例：使用随机森林算法检测FTP暴力破解 
.　本章小结 
参考资源 
第章　朴素贝叶斯算法 
.　朴素贝叶斯算法概述 
.　示例：hello world！朴素贝叶斯 
.　示例：检测异常操作 
.　示例：检测WebShell（一） 
.　示例：检测WebShell（二） 
.　示例：检测DGA域名 
.　示例：检测针对Apache的DDoS攻击 
.　示例：识别验证码 
.　本章小结 
参考资源 
第章　逻辑回归算法 
.　逻辑回归算法概述 
.　示例：hello world！逻辑回归 
.　示例：使用逻辑回归算法检测Java溢出攻击 
.　示例：识别验证码 
.　本章小结 
参考资源 
第章　支持向量机算法 
.　支持向量机算法概述 
.　示例：hello world！支持向量机 
.　示例：使用支持向量机算法识别XSS 
.　示例：使用支持向量机算法区分僵尸网络DGA家族 
..　数据搜集和数据清洗 
..　特征化 
..　模型验证 
.　本章小结 
参考资源 
第章　K-Means与DBSCAN算法 
.　K-Means算法概述 
.　示例：hello world！K-Means 
.　示例：使用K-Means算法检测DGA域名 
.　DBSCAN算法概述 
.　示例：hello world！DBSCAN 
.　本章小结 
参考资源 
第章　Apriori与FP-growth算法 
.　Apriori算法概述 
.　示例：hello world！Apriori 
.　示例：使用Apriori算法挖掘XSS相关参数 
.　FP-growth算法概述 
.　示例：hello world！FP-growth 
.　示例：使用FP-growth算法挖掘疑似僵尸主机 
.　本章小结 
参考资源 
第章　隐式马尔可夫算法 
.　隐式马尔可夫算法概述 
.　hello world! 隐式马尔可夫 
.　示例：使用隐式马尔可夫算法识别XSS攻击（一） 
.　示例：使用隐式马尔可夫算法识别XSS攻击（二） 
.　示例：使用隐式马尔可夫算法识别DGA域名 
.　本章小结 
参考资源 
第章　图算法与知识图谱 
.　图算法概述 
.　示例：hello world！有向图 
.　示例：使用有向图识别WebShell 
.　示例：使用有向图识别僵尸网络 
.　知识图谱概述 
.　示例：知识图谱在风控领域的应用 
..　检测疑似账号被盗 
..　检测疑似撞库攻击 
..　检测疑似刷单 
.　示例：知识图谱在威胁情报领域的应用 
..　挖掘后门文件潜在联系 
..　挖掘域名潜在联系 
.　本章小结 
参考资源 
第章　神经网络算法 
.　神经网络算法概述 
.　示例：hello world！神经网络 
.　示例：使用神经网络算法识别验证码 
.　示例：使用神经网络算法检测Java溢出攻击 
.　本章小结 
参考资源 
第章　多层感知机与DNN算法 
.　神经网络与深度学习 
.　TensorFlow编程模型 
..　操作 
..　张量 
..　变量 
..　会话 
.　TensorFlow的运行模式 
.　示例：在TensorFlow下识别验证码（一） 
.　示例：在TensorFlow下识别验证码（二） 
.　示例：在TensorFlow下识别验证码（三） 
.　示例：在TensorFlow下识别垃圾邮件（一） 
.　示例：在TensorFlow下识别垃圾邮件（二） 
.　本章小结 
参考资源 
第章　循环神经网络算法 
.　循环神经网络算法概述 
.　示例：识别验证码 
.　示例：识别恶意评论 
.　示例：生成城市名称 
.　示例：识别WebShell 
.　示例：生成常用密码 
.　示例：识别异常操作 
.　本章小结 
参考资源 
第章　卷积神经网络算法 
.　卷积神经网络算法概述 
.　示例：hello world！卷积神经网络 
.　示例：识别恶意评论 
.　示例：识别垃圾邮件 
.　本章小结 
参考资源 
・ ・ ・ ・ ・ ・ (收起)第一部分 初始
 初识机器学习 
. 学习机器学习的误区 
. 什么是机器学习 
. Python 中的机器学习 
. 学习机器学习的原则 
. 学习机器学习的技巧 
. 这本书不涵盖以下内容 
. 代码说明 
. 总结 
 Python 机器学习的生态圈 
. Python 
. SciPy 
. scikit-learn 
. 环境安装 
. 总结 
 第一个机器学习项目 
. 机器学习中的 Hello World 项目 
. 导入数据 
. 概述数据 
. 数据可视化 
. 评估算法 
. 实施预测 
. 总结 
 Python 和 SciPy 速成 
. Python 速成 
. NumPy 速成 
. Matplotlib 速成 
. Pandas 速成 
. 总结 
第二部分 数据理解
 数据导入 
. CSV 文件 
. Pima Indians 数据集 
. 采用标准 Python 类库导入数据 
. 采用 NumPy 导入数据 
. 采用 Pandas 导入数据 
. 总结 
 数据理解 
. 简单地查看数据 
. 数据的维度 
. 数据属性和类型 
. 描述性统计 
. 数据分组分布（适用于分类算法） 
. 数据属性的相关性 
. 数据的分布分析 
. 总结 
 数据可视化 
. 单一图表 
. 多重图表 
. 总结 
第三部分 数据准备
 数据预处理 
. 为什么需要数据预处理 
. 格式化数据 
. 调整数据尺度 
. 正态化数据 
. 标准化数据 
. 二值数据 
. 总结 
 数据特征选定 
. 特征选定 
. 单变量特征选定 
. 递归特征消除 
. 主要成分分析 
. 特征重要性 
. 总结 
第四部分 选择模型
 评估算法 
. 评估算法的方法 
. 分离训练数据集和评估数据集 
. K 折交叉验证分离 
. 弃一交叉验证分离 
. 重复随机分离评估数据集与训练数据集 
. 总结 
 算法评估矩阵 
. 算法评估矩阵 
. 分类算法矩阵 
. 回归算法矩阵 
. 总结 
 审查分类算法 
. 算法审查 
. 算法概述 
. 线性算法 
. 非线性算法 
. 总结 
 审查回归算法 
. 算法概述 
. 线性算法 
. 非线性算法 
. 总结 
 算法比较 
. 选择最佳的机器学习算法 
. 机器学习算法的比较 
. 总结 
 自动流程 
. 机器学习的自动流程 
. 数据准备和生成模型的 Pipeline 
. 特征选择和生成模型的 Pipeline 
. 总结 
第五部分 优化模型
 集成算法 
. 集成的方法 
. 装袋算法 
. 提升算法 
. 投票算法 
. 总结 
 算法调参 
. 机器学习算法调参 
. 网格搜索优化参数 
. 随机搜索优化参数 
. 总结 
第六部分 结果部署
 持久化加载模型 
. 通过 pickle 序列化和反序列化机器学习的模型 
. 通过 joblib 序列化和反序列化机器学习的模型 
. 生成模型的技巧 
. 总结 
第七部分 项目实践
 预测模型项目模板 
. 在项目中实践机器学习 
. 机器学习项目的 Python 模板 
. 各步骤的详细说明 
. 使用模板的小技巧 
. 总结 
 回归项目实例 
. 定义问题 
. 导入数据 
. 理解数据 
. 数据可视化 
. 分离评估数据集 
. 评估算法 
. 调参改善算法 
. 集成算法 
. 集成算法调参 
. 确定最终模型 
. 总结 
 二分类实例 
. 问题定义 
. 导入数据 
. 分析数据 
. 分离评估数据集 
. 评估算法 
. 算法调参 
. 集成算法 
. 确定最终模型 
. 总结 
 文本分类实例 
. 问题定义 
. 导入数据 
. 文本特征提取 
. 评估算法 
. 算法调参 
. 集成算法 
. 集成算法调参 
. 确定最终模型 
. 总结 
・ ・ ・ ・ ・ ・ (收起)第 章 走进机器学习
. 机器学习概述
. 机器学习过程
第 章 了解Python
. 为什么选择Python
. 下载和安装Python
.. 在Windows中安装Python
.. Anaconda
. 首个Python程序
. Python基础
. 数据结构与循环
第章 特征工程
. 什么是特征
. 为什么执行特征工程
. 特征提取
. 特征选择
. 特征工程方法――通用准则
.. 处理数值特征
.. 处理分类特征
.. 处理基于时间的特征
.. 处理文本特征
.. 缺失数据
.. 降维
. 用Python进行特征工程
.. Pandas基本操作
.. 常见任务
第章 数据可视化
. 折线图
. 条形图
. 饼图
. 直方图
. 散点图
. 箱线图
. 采用面向对象的方式绘图
. Seaborn
.. 分布图
.. 双变量分布
.. 二元分布的核密度估计
.. 成对双变量分布
.. 分类散点图
.. 小提琴图
.. 点图
第章 回归
. 简单回归
. 多元回归
. 模型评价
.. 训练误差
.. 泛化误差
.. 测试误差
.. 不可约误差
.. 偏差―方差权衡
第章 更多回归
. 概述
. 岭回归
. 套索回归
.. 全子集算法
.. 用于特征选择的贪心算法
.. 特征选择的正则化
. 非参数回归
.. K-最近邻回归
.. 核回归
第章 分类
. 线性分类器
. 逻辑回归
. 决策树
.. 关于树的术语
.. 决策树学习
.. 决策边界
. 随机森林
. 朴素贝叶斯
第章 无监督学习
. 聚类
. K-均值聚类
.. 随机分配聚类质心的问题
.. 查找K的值
. 分层聚类
.. 距离矩阵
.. 连接
第章 文本分析
. 使用Python进行基本文本处理
.. 字符串比较
.. 字符串转换
.. 字符串操作
. 正则表达式
. 自然语言处理
.. 词干提取
.. 词形还原
.. 分词
. 文本分类
. 主题建模
第 章 神经网络与深度学习
. 矢量化
. 神经网络
.. 梯度下降
.. 激活函数
.. 参数初始化
.. 优化方法
.. 损失函数
. 深度学习
. 深度学习架构
.. 深度信念网络
.. 卷积神经网络
.. 循环神经网络
.. 长短期记忆网络
.. 深度堆栈网络
. 深度学习框架
第 章 推荐系统
. 基于流行度的推荐引擎
. 基于内容的推荐引擎
. 基于分类的推荐引擎
. 协同过滤
第 章 时间序列分析
. 处理日期和时间
. 窗口函数
. 相关性
. 时间序列预测
・ ・ ・ ・ ・ ・ (收起)前　言
第部分　实时机器学习方法论
第章　实时机器学习综述 
.　什么是机器学习 
.　机器学习发展的前世今生 
..　历史上机器学习无法调和的难题 
..　现代机器学习的新融合 
.　机器学习领域分类 
.　实时是个“万灵丹” 
.　实时机器学习的分类 
..　硬实时机器学习 
..　软实时机器学习 
..　批实时机器学习 
.　实时应用对机器学习的要求 
.　案例：Netflix在机器学习竞赛中学到的经验 
..　Netflix 用户信息被逆向工程 
..　Netflix 最终胜出者模型无法在生产环境中使用 
.　实时机器学习模型的生存期 
第章　实时监督式机器学习 
.　什么是监督式机器学习 
..　“江湖门派”对预测模型的
不同看法 
..　工业界的学术门派 
..　实时机器学习实战的思路 
.　怎样衡量监督式机器学习模型 
..　统计量的优秀 
..　应用业绩的优秀 
.　实时线性分类器介绍 
..　广义线性模型的定义 
..　训练线性模型 
..　冷启动问题 
第章　数据分析工具 Pandas 
.　颠覆 R 的 Pandas 
.　Pandas 的安装 
.　利用 Pandas 分析实时股票报价数据 
..　外部数据导入 
..　数据分析基本操作 
..　可视化操作 
..　秒级收盘价变化率初探 
.　数据分析的三个要点 
..　不断验证假设 
..　全面可视化，全面监控化 
第章　机器学习工具 Scikit-learn 
.　如何站在风口上？向Scikit-learn 学习 
..　传统的线下统计软件 R 
..　底层软件黑盒子 Weka 
..　跨界产品 Scikit-learn 
..　Scikit-learn的优势 
.　Scikit-learn 的安装 
.　Scikit-learn 的主要模块 
..　监督式、非监督式机器学习 
..　建模函数fit和predict 
..　数据预处理 
..　自动化建模预测 Pipeline 
.　利用 Scikit-learn 进行股票价格波动预测 
..　数据导入和预处理 
..　编写专有时间序列数据预处理模块 
..　利用 Pipeline 进行建模 
..　评价建模效果 
..　引入成交量和高维交叉项进行建模 
..　本书没有告诉你的 
第部分　实时机器学习架构
第章　实时机器学习架构设计 
.　设计实时机器学习架构的
四个要点 
.　Lambda 架构和主要成员 
..　实时响应层 
..　快速处理层 
..　批处理层 
.　常用的实时机器学习架构 
..　瀑布流架构 
..　并行响应架构 
..　实时更新模型混合架构 
.　小结 
第章　集群部署工具 Docker 
.　Docker 的前世今生 
.　容器虚拟机的基本组成部分 
.　Docker 引擎命令行工具 
..　Docker 引擎的安装 
..　Docker 引擎命令行的基本操作 
.　通过 Dockerfile 配置容器虚拟机 
..　利用 Dockerfile 配置基本容器虚拟机 
..　利用 Dockerfile 进行虚拟机和宿主机之间的文件传输 
.　服务器集群配置工具Docker Compose 
..　Docker Compose 的安装 
..　Docker Compose 的基本操作 
..　利用 Docker Compose 创建网页计数器集群 
.　远端服务器配置工具Docker Machine 
..　Docker Machine 的安装 
..　安装 Oracle VirtualBox 
..　创建和管理 VirtualBox中的虚拟机 
..　在 Docker Machine 和 VirtualBox的环境中运行集群 
..　利用 Docker Machine 在 Digital Ocean 上配置运行集群 
.　其他有潜力的 Docker 工具 
第章　实时消息队列和RabbitMQ 
.　实时消息队列 
.　AMQP 和 RabbitMQ 简介 
.　RabbitMQ的主要构成部分 
.　常用交换中心模式 
..　直连结构 
..　扇形结构 
..　话题结构 
..　报头结构 
.　消息传导设计模式 
..　任务队列 
..　Pub/Sub 发布/监听 
..　远程命令 
.　利用 Docker 快速部署RabbitMQ 
.　利用 RabbitMQ 开发队列服务 
..　准备案例材料 
..　实时报价存储服务 
..　实时走势预测服务 
..　整合运行实验 
..　总结和改进 
第章　实战数据库综述 
.　SQL 与 NoSQL，主流数据库分类 
..　关系型数据库 
..　非关系型数据库 NoSQL 
.　数据库的性能 
..　耐分割 
..　 一致性 
..　可用性 
..　CAP 定理 
.　SQL和NoSQL对比 
..　数据存储、读取方式 
..　数据库的扩展方式 
..　性能比较 
.　数据库的发展趋势 
..　不同数据库之间自动化同步更为方便 
..　云数据库的兴起 
..　底层和应用层多层化 
.　MySQL 简介 
.　Cassandra简介 
..　Cassandra交互方式简介 
..　利用Docker安装Cassandra 
..　使用Cassandra存储数据 
第章　实时数据监控 ELK 集群 
.　Elasticsearch、LogStash和Kibana 的前世今生 
..　Elasticsearch 的平凡起家 
..　LogStash 卑微的起源 
..　Kibana 惊艳登场 
..　ELK 协同作战 
.　Elasticsearch 基本架构 
..　文档 
..　索引和文档类型 
..　分片和冗余 
..　Elasticsearch 和数据库进行比较 
.　Elasticsearch 快速入门 
..　用 Docker 运行 Elasticsearch 容器虚拟机 
..　创建存储文档、文档类型和索引 
..　搜索文档 
..　对偶搜索 
.　Kibana 快速入门 
..　利用 Docker 搭建ELK 集群 
..　配置索引格式 
..　交互式搜索 
..　可视化操作 
..　实时检测面板 
第章　机器学习系统设计模式 
.　 设计模式的前世今生 
..　单机设计模式逐渐式微 
..　微服务取代设计模式的示例 
..　微服务设计模式的兴起 
.　读：高速键值模式 
..　问题场景 
..　解决方案 
..　其他使用场景 
.　读：缓存高速查询模式 
..　问题场景 
..　解决方案 
..　适用场景 
.　更新：异步数据库更新模式 
..　问题场景 
..　解决方案 
..　使用场景案例 
.　更新：请求重定向模式 
..　问题场景 
..　解决方案 
..　更新流程 
..　使用场景案例 
.　处理：硬实时并行模式 
..　问题场景 
..　解决方案 
..　使用场景案例 
.　处理：分布式任务队列模式 
..　问题场景 
..　解决方案 
..　Storm 作为分布式任务队列 
..　适用场景 
..　结构的演进 
.　处理：批实时处理模式 
..　问题场景 
..　解决方案 
..　适用场景 
第部分　未来展望
第章　Serverless 架构 
.　Serverless 架构的前世今生 
.　Serverless 架构对实时
机器学习的影响 
第章　深度学习的风口 
.　深度学习的前世今生 
.　深度学习的难点 
.　如何选择深度学习工具 
..　与现有编程平台、技能整合的难易程度 
..　此平台除做深度学习之外，还能做什么 
..　深度学习平台的成熟程度 
.　未来发展方向 
・ ・ ・ ・ ・ ・ (收起)I IMAGE FORMATION 
 Geometric Camera Models 
. Image Formation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Pinhole Perspective . . . . . . . . . . . . . . . . . . . . . . . 
.. Weak Perspective . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Cameras with Lenses . . . . . . . . . . . . . . . . . . . . . . . 
.. The Human Eye . . . . . . . . . . . . . . . . . . . . . . . . . 
. Intrinsic and Extrinsic Parameters . . . . . . . . . . . . . . . . . . . 
.. Rigid Transformations and Homogeneous Coordinates . . . . 
.. Intrinsic Parameters . . . . . . . . . . . . . . . . . . . . . . . 
.. Extrinsic Parameters . . . . . . . . . . . . . . . . . . . . . . . 
.. Perspective Projection Matrices . . . . . . . . . . . . . . . . . 
.. Weak-Perspective Projection Matrices . . . . . . . . . . . . . 
. Geometric Camera Calibration . . . . . . . . . . . . . . . . . . . . . 
.. ALinear Approach to Camera Calibration . . . . . . . . . . . 
.. ANonlinear Approach to Camera Calibration . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Light and Shading 
. Modelling Pixel Brightness . . . . . . . . . . . . . . . . . . . . . . . 
.. Reflection at Surfaces . . . . . . . . . . . . . . . . . . . . . . 
.. Sources and Their Effects . . . . . . . . . . . . . . . . . . . . 
.. The Lambertian+Specular Model . . . . . . . . . . . . . . . . 
.. Area Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Inference from Shading . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Radiometric Calibration and High Dynamic Range Images . . 
.. The Shape of Specularities . . . . . . . . . . . . . . . . . . . 
.. Inferring Lightness and Illumination . . . . . . . . . . . . . . 
.. Photometric Stereo: Shape from Multiple Shaded Images . . 
. Modelling Interreflection . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Illumination at a Patch Due to an Area Source . . . . . 
.. Radiosity and Exitance . . . . . . . . . . . . . . . . . . . . . 
.. An Interreflection Model . . . . . . . . . . . . . . . . . . . . . 
.. Qualitative Properties of Interreflections . . . . . . . . . . . . 
. Shape from One Shaded Image . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Color 
. Human Color Perception . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Color Matching . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Color Receptors . . . . . . . . . . . . . . . . . . . . . . . . . 
. The Physics of Color . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Color of Light Sources . . . . . . . . . . . . . . . . . . . 
.. The Color of Surfaces . . . . . . . . . . . . . . . . . . . . . . 
. Representing Color . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Linear Color Spaces . . . . . . . . . . . . . . . . . . . . . . . 
.. Non-linear Color Spaces . . . . . . . . . . . . . . . . . . . . . 
. AModel of Image Color . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Diffuse Term . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Specular Term . . . . . . . . . . . . . . . . . . . . . . . . 
. Inference from Color . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Finding Specularities Using Color . . . . . . . . . . . . . . . 
.. Shadow Removal Using Color . . . . . . . . . . . . . . . . . . 
.. Color Constancy: Surface Color from Image Color . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
II EARLY VISION: JUST ONE IMAGE 
 Linear Filters 
. Linear Filters and Convolution . . . . . . . . . . . . . . . . . . . . . 
.. Convolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Shift Invariant Linear Systems . . . . . . . . . . . . . . . . . . . . . 
.. Discrete Convolution . . . . . . . . . . . . . . . . . . . . . . . 
.. Continuous Convolution . . . . . . . . . . . . . . . . . . . . . 
.. Edge Effects in Discrete Convolutions . . . . . . . . . . . . . 
. Spatial Frequency and Fourier Transforms . . . . . . . . . . . . . . . 
.. Fourier Transforms . . . . . . . . . . . . . . . . . . . . . . . . 
. Sampling and Aliasing . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Aliasing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Smoothing and Resampling . . . . . . . . . . . . . . . . . . . 
. Filters as Templates . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Convolution as a Dot Product . . . . . . . . . . . . . . . . . 
.. Changing Basis . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Technique: Normalized Correlation and Finding Patterns . . . . . . 
.. Controlling the Television by Finding Hands by Normalized
Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Technique: Scale and Image Pyramids . . . . . . . . . . . . . . . . . 
.. The Gaussian Pyramid . . . . . . . . . . . . . . . . . . . . . 
.. Applications of Scaled Representations . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Local Image Features 
. Computing the Image Gradient . . . . . . . . . . . . . . . . . . . . . 
.. Derivative of Gaussian Filters . . . . . . . . . . . . . . . . . . 
. Representing the Image Gradient . . . . . . . . . . . . . . . . . . . . 
.. Gradient-Based Edge Detectors . . . . . . . . . . . . . . . . . 
.. Orientations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Finding Corners and Building Neighborhoods . . . . . . . . . . . . . 
.. Finding Corners . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Using Scale and Orientation to Build a Neighborhood . . . . 
. Describing Neighborhoods with SIFT and HOG Features . . . . . . 
.. SIFT Features . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. HOG Features . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Computing Local Features in Practice . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Texture 
. Local Texture Representations Using Filters . . . . . . . . . . . . . . 
.. Spots and Bars . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. From Filter Outputs to Texture Representation . . . . . . . . 
.. Local Texture Representations in Practice . . . . . . . . . . . 
. Pooled Texture Representations by Discovering Textons . . . . . . . 
.. Vector Quantization and Textons . . . . . . . . . . . . . . . . 
.. K-means Clustering for Vector Quantization . . . . . . . . . . 
. Synthesizing Textures and Filling Holes in Images . . . . . . . . . . 
.. Synthesis by Sampling Local Models . . . . . . . . . . . . . . 
.. Filling in Holes in Images . . . . . . . . . . . . . . . . . . . . 
. Image Denoising . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Non-local Means . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Block Matching D (BMD) . . . . . . . . . . . . . . . . . . 
.. Learned Sparse Coding . . . . . . . . . . . . . . . . . . . . . 
.. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Shape from Texture . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Shape from Texture for Planes . . . . . . . . . . . . . . . . . 
.. Shape from Texture for Curved Surfaces . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
III EARLY VISION: MULTIPLE IMAGES 
 Stereopsis 
. Binocular Camera Geometry and the Epipolar Constraint . . . . . . 
.. Epipolar Geometry . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Essential Matrix . . . . . . . . . . . . . . . . . . . . . . . 
.. The Fundamental Matrix . . . . . . . . . . . . . . . . . . . . 
. Binocular Reconstruction . . . . . . . . . . . . . . . . . . . . . . . . 
.. Image Rectification . . . . . . . . . . . . . . . . . . . . . . . . 
. Human Stereopsis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Local Methods for Binocular Fusion . . . . . . . . . . . . . . . . . . 
.. Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Multi-Scale Edge Matching . . . . . . . . . . . . . . . . . . . 
. Global Methods for Binocular Fusion . . . . . . . . . . . . . . . . . . 
.. Ordering Constraints and Dynamic Programming . . . . . . . 
.. Smoothness and Graphs . . . . . . . . . . . . . . . . . . . . . 
. Using More Cameras . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Application: Robot Navigation . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Structure from Motion 
. Internally Calibrated Perspective Cameras . . . . . . . . . . . . . . . 
.. Natural Ambiguity of the Problem . . . . . . . . . . . . . . . 
.. Euclidean Structure and Motion from Two Images . . . . . . 
.. Euclidean Structure and Motion from Multiple Images . . . . 
. Uncalibrated Weak-Perspective Cameras . . . . . . . . . . . . . . . . 
.. Natural Ambiguity of the Problem . . . . . . . . . . . . . . . 
.. Affine Structure and Motion from Two Images . . . . . . . . 
.. Affine Structure and Motion from Multiple Images . . . . . . 
.. From Affine to Euclidean Shape . . . . . . . . . . . . . . . . 
. Uncalibrated Perspective Cameras . . . . . . . . . . . . . . . . . . . 
.. Natural Ambiguity of the Problem . . . . . . . . . . . . . . . 
.. Projective Structure and Motion from Two Images . . . . . . 
.. Projective Structure and Motion from Multiple Images . . . . 
.. From Projective to Euclidean Shape . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
IV MID-LEVEL VISION 
 Segmentation by Clustering 
. Human Vision: Grouping and Gestalt . . . . . . . . . . . . . . . . . 
. Important Applications . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Background Subtraction . . . . . . . . . . . . . . . . . . . . . 
.. Shot Boundary Detection . . . . . . . . . . . . . . . . . . . . 
.. Interactive Segmentation . . . . . . . . . . . . . . . . . . . . 
.. Forming Image Regions . . . . . . . . . . . . . . . . . . . . . 
. Image Segmentation by Clustering Pixels . . . . . . . . . . . . . . . 
.. Basic Clustering Methods . . . . . . . . . . . . . . . . . . . . 
.. The Watershed Algorithm . . . . . . . . . . . . . . . . . . . . 
.. Segmentation Using K-means . . . . . . . . . . . . . . . . . . 
.. Mean Shift: Finding Local Modes in Data . . . . . . . . . . . 
.. Clustering and Segmentation with Mean Shift . . . . . . . . . 
. Segmentation, Clustering, and Graphs . . . . . . . . . . . . . . . . . 
.. Terminology and Facts for Graphs . . . . . . . . . . . . . . . 
.. Agglomerative Clustering with a Graph . . . . . . . . . . . . 
.. Divisive Clustering with a Graph . . . . . . . . . . . . . . . . 
.. Normalized Cuts . . . . . . . . . . . . . . . . . . . . . . . . . 
. Image Segmentation in Practice . . . . . . . . . . . . . . . . . . . . . 
.. Evaluating Segmenters . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Grouping and Model Fitting 
. The Hough Transform . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting Lines with the Hough Transform . . . . . . . . . . . . 
.. Using the Hough Transform . . . . . . . . . . . . . . . . . . . 
. Fitting Lines and Planes . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting a Single Line . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting Planes . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting Multiple Lines . . . . . . . . . . . . . . . . . . . . . . 
. Fitting Curved Structures . . . . . . . . . . . . . . . . . . . . . . . . 
. Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. M-Estimators . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. RANSAC: Searching for Good Points . . . . . . . . . . . . . 
. Fitting Using Probabilistic Models . . . . . . . . . . . . . . . . . . . 
.. Missing Data Problems . . . . . . . . . . . . . . . . . . . . . 
.. Mixture Models and Hidden Variables . . . . . . . . . . . . . 
.. The EM Algorithm for Mixture Models . . . . . . . . . . . . 
.. Difficulties with the EM Algorithm . . . . . . . . . . . . . . . 
. Motion Segmentation by Parameter Estimation . . . . . . . . . . . . 
.. Optical Flow and Motion . . . . . . . . . . . . . . . . . . . . 
.. Flow Models . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Motion Segmentation with Layers . . . . . . . . . . . . . . . 
. Model Selection: Which Model Is the Best Fit? . . . . . . . . . . . . 
.. Model Selection Using Cross-Validation . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Tracking 
. Simple Tracking Strategies . . . . . . . . . . . . . . . . . . . . . . . . 
.. Tracking by Detection . . . . . . . . . . . . . . . . . . . . . . 
.. Tracking Translations by Matching . . . . . . . . . . . . . . . 
.. Using Affine Transformations to Confirm a Match . . . . . . 
. Tracking Using Matching . . . . . . . . . . . . . . . . . . . . . . . . 
.. Matching Summary Representations . . . . . . . . . . . . . . 
.. Tracking Using Flow . . . . . . . . . . . . . . . . . . . . . . . 
. Tracking Linear Dynamical Models with Kalman Filters . . . . . . . 
.. Linear Measurements and Linear Dynamics . . . . . . . . . . 
.. The Kalman Filter . . . . . . . . . . . . . . . . . . . . . . . . 
.. Forward-backward Smoothing . . . . . . . . . . . . . . . . . . 
. Data Association . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Linking Kalman Filters with Detection Methods . . . . . . . 
.. Key Methods of Data Association . . . . . . . . . . . . . . . 
. Particle Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Sampled Representations of Probability Distributions . . . . 
.. The Simplest Particle Filter . . . . . . . . . . . . . . . . . . . 
.. The Tracking Algorithm . . . . . . . . . . . . . . . . . . . . . 
.. A Workable Particle Filter . . . . . . . . . . . . . . . . . . . . 
.. Practical Issues in Particle Filters . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
V HIGH-LEVEL VISION 
 Registration 
. Registering Rigid Objects . . . . . . . . . . . . . . . . . . . . . . . . 
.. Iterated Closest Points . . . . . . . . . . . . . . . . . . . . . . 
.. Searching for Transformations via Correspondences . . . . . . 
.. Application: Building Image Mosaics . . . . . . . . . . . . . . 
. Model-based Vision: Registering Rigid Objects with Projection . . . 
.. Verification: Comparing Transformed and Rendered Source
to Target . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Registering Deformable Objects . . . . . . . . . . . . . . . . . . . . . 
.. Deforming Texture with Active Appearance Models . . . . . 
.. Active Appearance Models in Practice . . . . . . . . . . . . . 
.. Application: Registration in Medical Imaging Systems . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Smooth Surfaces and Their Outlines 
. Elements of Differential Geometry . . . . . . . . . . . . . . . . . . . 
.. Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Surfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Contour Geometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Occluding Contour and the Image Contour . . . . . . . . 
.. The Cusps and Inflections of the Image Contour . . . . . . . 
.. Koenderink’s Theorem . . . . . . . . . . . . . . . . . . . . . . 
. Visual Events: More Differential Geometry . . . . . . . . . . . . . . 
.. The Geometry of the Gauss Map . . . . . . . . . . . . . . . . 
.. Asymptotic Curves . . . . . . . . . . . . . . . . . . . . . . . . 
.. The Asymptotic Spherical Map . . . . . . . . . . . . . . . . . 
.. Local Visual Events . . . . . . . . . . . . . . . . . . . . . . . 
.. The Bitangent Ray Manifold . . . . . . . . . . . . . . . . . . 
.. Multilocal Visual Events . . . . . . . . . . . . . . . . . . . . . 
.. The Aspect Graph . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Range Data 
. Active Range Sensors . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Range Data Segmentation . . . . . . . . . . . . . . . . . . . . . . . . 
.. Elements of Analytical Differential Geometry . . . . . . . . . 
.. Finding Step and Roof Edges in Range Images . . . . . . . . 
.. Segmenting Range Images into Planar Regions . . . . . . . . 
. Range Image Registration and Model Acquisition . . . . . . . . . . . 
.. Quaternions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Registering Range Images . . . . . . . . . . . . . . . . . . . . 
.. Fusing Multiple Range Images . . . . . . . . . . . . . . . . . 
. Object Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Matching Using Interpretation Trees . . . . . . . . . . . . . . 
.. Matching Free-Form Surfaces Using Spin Images . . . . . . . 
. Kinect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Features . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Technique: Decision Trees and Random Forests . . . . . . . . 
.. Labeling Pixels . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Computing Joint Positions . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Learning to Classify 
. Classification, Error, and Loss . . . . . . . . . . . . . . . . . . . . . . 
.. Using Loss to Determine Decisions . . . . . . . . . . . . . . . 
.. Training Error, Test Error, and Overfitting . . . . . . . . . . 
.. Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Error Rate and Cross-Validation . . . . . . . . . . . . . . . . 
.. Receiver Operating Curves . . . . . . . . . . . . . . . . . . . 
. Major Classification Strategies . . . . . . . . . . . . . . . . . . . . . 
.. Example: Mahalanobis Distance . . . . . . . . . . . . . . . . 
.. Example: Class-Conditional Histograms and Naive Bayes . . 
.. Example: Classification Using Nearest Neighbors . . . . . . . 
.. Example: The Linear Support Vector Machine . . . . . . . . 
.. Example: Kernel Machines . . . . . . . . . . . . . . . . . . . 
.. Example: Boosting and Adaboost . . . . . . . . . . . . . . . 
. Practical Methods for Building Classifiers . . . . . . . . . . . . . . . 
.. Manipulating Training Data to Improve Performance . . . . . 
.. Building Multi-Class Classifiers Out of Binary Classifiers . . 
.. Solving for SVMS and Kernel Machines . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Classifying Images 
. Building Good Image Features . . . . . . . . . . . . . . . . . . . . . 
.. Example Applications . . . . . . . . . . . . . . . . . . . . . . 
.. Encoding Layout with GIST Features . . . . . . . . . . . . . 
.. Summarizing Images with Visual Words . . . . . . . . . . . . 
.. The Spatial Pyramid Kernel . . . . . . . . . . . . . . . . . . . 
.. Dimension Reduction with Principal Components . . . . . . . 
.. Dimension Reduction with Canonical Variates . . . . . . . . 
.. Example Application: Identifying Explicit Images . . . . . . 
.. Example Application: Classifying Materials . . . . . . . . . . 
.. Example Application: Classifying Scenes . . . . . . . . . . . . 
. Classifying Images of Single Objects . . . . . . . . . . . . . . . . . . 
.. Image Classification Strategies . . . . . . . . . . . . . . . . . 
.. Evaluating Image Classification Systems . . . . . . . . . . . . 
.. Fixed Sets of Classes . . . . . . . . . . . . . . . . . . . . . . . 
.. Large Numbers of Classes . . . . . . . . . . . . . . . . . . . . 
.. Flowers, Leaves, and Birds: Some Specialized Problems . . . 
. Image Classification in Practice . . . . . . . . . . . . . . . . . . . . . 
.. Codes for Image Features . . . . . . . . . . . . . . . . . . . . 
.. Image Classification Datasets . . . . . . . . . . . . . . . . . . 
.. Dataset Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Crowdsourcing Dataset Collection . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Detecting Objects in Images 
. The Sliding Window Method . . . . . . . . . . . . . . . . . . . . . . 
.. Face Detection . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Detecting Humans . . . . . . . . . . . . . . . . . . . . . . . . 
.. Detecting Boundaries . . . . . . . . . . . . . . . . . . . . . . 
. Detecting Deformable Objects . . . . . . . . . . . . . . . . . . . . . . 
. The State of the Art of Object Detection . . . . . . . . . . . . . . . 
.. Datasets and Resources . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Topics in Object Recognition 
. What Should Object Recognition Do? . . . . . . . . . . . . . . . . . 
.. What Should an Object Recognition System Do? . . . . . . . 
.. Current Strategies for Object Recognition . . . . . . . . . . . 
.. What Is Categorization? . . . . . . . . . . . . . . . . . . . . . 
.. Selection: What Should Be Described? . . . . . . . . . . . . . 
. Feature Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Improving Current Image Features . . . . . . . . . . . . . . . 
.. Other Kinds of Image Feature . . . . . . . . . . . . . . . . . . 
. Geometric Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Semantic Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Attributes and the Unfamiliar . . . . . . . . . . . . . . . . . . 
.. Parts, Poselets and Consistency . . . . . . . . . . . . . . . . . 
.. Chunks of Meaning . . . . . . . . . . . . . . . . . . . . . . . . 
VI APPLICATIONS AND TOPICS 
 Image-Based Modeling and Rendering 
. Visual Hulls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Main Elements of the Visual Hull Model . . . . . . . . . . . . 
.. Tracing Intersection Curves . . . . . . . . . . . . . . . . . . . 
.. Clipping Intersection Curves . . . . . . . . . . . . . . . . . . 
.. Triangulating Cone Strips . . . . . . . . . . . . . . . . . . . . 
.. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Going Further: Carved Visual Hulls . . . . . . . . . . . . . . 
. Patch-Based Multi-View Stereopsis . . . . . . . . . . . . . . . . . . . 
.. Main Elements of the PMVS Model . . . . . . . . . . . . . . 
.. Initial Feature Matching . . . . . . . . . . . . . . . . . . . . . 
.. Expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. The Light Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Looking at People 
. HMM’s, Dynamic Programming, and Tree-Structured Models . . . . 
.. Hidden Markov Models . . . . . . . . . . . . . . . . . . . . . 
.. Inference for an HMM . . . . . . . . . . . . . . . . . . . . . . 
.. Fitting an HMM with EM . . . . . . . . . . . . . . . . . . . . 
.. Tree-Structured Energy Models . . . . . . . . . . . . . . . . . 
. Parsing People in Images . . . . . . . . . . . . . . . . . . . . . . . . 
.. Parsing with Pictorial Structure Models . . . . . . . . . . . . 
.. Estimating the Appearance of Clothing . . . . . . . . . . . . 
. Tracking People . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Why Human Tracking Is Hard . . . . . . . . . . . . . . . . . 
.. Kinematic Tracking by Appearance . . . . . . . . . . . . . . . 
.. Kinematic Human Tracking Using Templates . . . . . . . . . 
. D from D: Lifting . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Reconstruction in an Orthographic View . . . . . . . . . . . . 
.. Exploiting Appearance for Unambiguous Reconstructions . . 
.. Exploiting Motion for Unambiguous Reconstructions . . . . . 
. Activity Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Background: Human Motion Data . . . . . . . . . . . . . . . 
.. Body Configuration and Activity Recognition . . . . . . . . . 
.. Recognizing Human Activities with Appearance Features . . 
.. Recognizing Human Activities with Compositional Models . . 
. Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 Image Search and Retrieval 
. The Application Context . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. User Needs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Types of Image Query . . . . . . . . . . . . . . . . . . . . . . 
.. What Users Do with Image Collections . . . . . . . . . . . . 
. Basic Technologies from Information Retrieval . . . . . . . . . . . . . 
.. Word Counts . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Smoothing Word Counts . . . . . . . . . . . . . . . . . . . . . 
.. Approximate Nearest Neighbors and Hashing . . . . . . . . . 
.. Ranking Documents . . . . . . . . . . . . . . . . . . . . . . . 
. Images as Documents . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Matching Without Quantization . . . . . . . . . . . . . . . . 
.. Ranking Image Search Results . . . . . . . . . . . . . . . . . 
.. Browsing and Layout . . . . . . . . . . . . . . . . . . . . . . 
.. Laying Out Images for Browsing . . . . . . . . . . . . . . . . 
. Predicting Annotations for Pictures . . . . . . . . . . . . . . . . . . 
.. Annotations from Nearby Words . . . . . . . . . . . . . . . . 
.. Annotations from the Whole Image . . . . . . . . . . . . . . 
.. Predicting Correlated Words with Classifiers . . . . . . . . . 
.. Names and Faces . . . . . . . . . . . . . . . . . . . . . . . . 
.. Generating Tags with Segments . . . . . . . . . . . . . . . . . 
. The State of the Art of Word Prediction . . . . . . . . . . . . . . . . 
.. Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Comparing Methods . . . . . . . . . . . . . . . . . . . . . . . 
.. Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
VII BACKGROUND MATERIAL 
 Optimization Techniques 
. Linear Least-Squares Methods . . . . . . . . . . . . . . . . . . . . . . 
.. Normal Equations and the Pseudoinverse . . . . . . . . . . . 
.. Homogeneous Systems and Eigenvalue Problems . . . . . . . 
.. Generalized Eigenvalues Problems . . . . . . . . . . . . . . . 
.. An Example: Fitting a Line to Points in a Plane . . . . . . . 
.. Singular Value Decomposition . . . . . . . . . . . . . . . . . . 
. Nonlinear Least-Squares Methods . . . . . . . . . . . . . . . . . . . . 
.. Newton’s Method: Square Systems of Nonlinear Equations. . 
.. Newton’s Method for Overconstrained Systems . . . . . . . . 
.. The Gauss―Newton and Levenberg―Marquardt Algorithms . 
. Sparse Coding and Dictionary Learning . . . . . . . . . . . . . . . . 
.. Sparse Coding . . . . . . . . . . . . . . . . . . . . . . . . . . 
.. Dictionary Learning . . . . . . . . . . . . . . . . . . . . . . . 
.. Supervised Dictionary Learning . . . . . . . . . . . . . . . . . 
. Min-Cut/Max-Flow Problems and Combinatorial Optimization . . . 
.. Min-Cut Problems . . . . . . . . . . . . . . . . . . . . . . . . 
.. Quadratic Pseudo-Boolean Functions . . . . . . . . . . . . . . 
.. Generalization to Integer Variables . . . . . . . . . . . . . . . 
. Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
Bibliography 
Index 
List of Algorithms 
・ ・ ・ ・ ・ ・ (收起)序言
前言
第篇　基础知识
第章　引言 
.　人工智能的新焦点――深度学习 
..　人工智能――神话传说到影视漫画 
..　人工智能的诞生 
..　神经科学的研究 
..　人工神经网络的兴起 
..　神经网络的第一次寒冬 
..　神经网络的第一次复兴 
..　神经网络的第二次寒冬 
..　年――深度学习的起点 
..　生活中的深度学习 
..　常见深度学习框架简介 
.　给计算机一双眼睛――计算机视觉 
..　计算机视觉简史 
..　年――计算机视觉的新起点 
..　计算机视觉的应用 
..　常见计算机视觉工具包 
.　基于深度学习的计算机视觉 
..　从ImageNet竞赛到AlphaGo战胜李世石――计算机视觉超越人类 
..　GPU和并行技术――深度学习和计算视觉发展的加速器 
..　基于卷积神经网络的计算机视觉应用 
第章　深度学习和计算机视觉中的基础数学知识 
.　线性变换和非线性变换 
..　线性变换的定义 
..　高中教科书中的小例子 
..　点积和投影 
..　矩阵乘法的几何意义（） 
..　本征向量和本征值 
..　矩阵乘法的几何意义（） 
..　奇异值分解 
..　线性可分性和维度 
..　非线性变换 
.　概率论及相关基础知识 
..　条件概率和独立 
..　期望值、方差和协方差 
..　熵 
..　最大似然估计（Maximum Likelihood Estimation，MLE） 
..　KL散度（KullbackCLeibler divergence） 
..　KL散度和MLE的联系 
.　维度的诅咒 
..　采样和维度 
..　高维空间中的体积 
..　高维空间中的距离 
..　中心极限定理和高维样本距离分布的近似 
..　数据实际的维度 
..　局部泛化 
..　函数对实际维度的影响 
..　PCA――什么是主成分 
..　PCA――通过本征向量和本征值求主成分 
..　PCA――通过主成分分析降维 
..　PCA――归一化和相关性系数 
..　PCA――什么样的数据适合PCA 
..　其他降维手段 
.　卷积 
..　点积和卷积 
..　一维卷积 
..　卷积和互相关 
..　二维卷积和图像响应 
..　卷积的计算 
.　数学优化基础 
..　最小值和梯度下降 
..　冲量（Momentum） 
..　牛顿法 
..　学习率和自适应步长 
..　学习率衰减（Learning Rate Decay） 
..　AdaGrad：每个变量有自己的节奏 
..　AdaDelta的进一步改进 
..　其他自适应算法 
..　损失函数 
..　分类问题和负对数似然 
..　逻辑回归 
..　Softmax：将输出转换为概率 
..　链式求导法则 
第章　神经网络和机器学习基础 
.　感知机 
..　基本概念 
..　感知机和线性二分类 
..　激活函数 
.　神经网络基础 
..　从感知机到神经网络 
..　最简单的神经网络二分类例子 
..　隐层神经元数量的作用 
..　更加复杂的样本和更复杂的神经网络 
.　后向传播算法 
..　求神经网络参数的梯度 
..　计算图（Computational Graph） 
..　利用后向传播算法计算一个神经网络参数的梯度 
..　梯度消失 
..　修正线性单元（ReLU） 
..　梯度爆炸 
..　梯度检查（gradient check） 
..　从信息传播的角度看后向传播算法 
.　随机梯度下降和批量梯度下降 
..　全量数据（full-batch）梯度下降 
..　随机梯度下降（SGD）和小批量数据（mini-batch） 
..　数据均衡和数据增加（data augmentation） 
.　数据、训练策略和规范化 
..　欠拟合和过拟合 
..　训练误差和测试误差 
..　奥卡姆剃刀没有免费午餐 
..　数据集划分和提前停止 
..　病态问题和约束 
..　L规范化（L Regularization） 
..　L规范化（L Regularization） 
..　集成（Ensemble）和随机失活（Dropout） 
.　监督学习、非监督学习、半监督学习和强化学习 
..　监督学习、非监督学习和半监督学习 
..　强化学习（reinforcement learning） 
第章　深度卷积神经网络 
.　卷积神经网络 
..　基本概念 
..　卷积层和特征响应图 
..　参数共享 
..　稀疏连接 
..　多通道卷积 
..　激活函数 
..　池化、不变性和感受野 
..　分布式表征（Distributed Representation） 
..　分布式表征和局部泛化 
..　分层表达 
..　卷积神经网络结构 
.　LeNet――第一个卷积神经网络 
.　新起点――AlexNet 
..　网络结构 
..　局部响应归一化（Local Response Normalization，LRN） 
.　更深的网络――GoogLeNet 
..　×卷积和Network In Network 
..　Inception结构 
..　网络结构 
..　批规一化（Batch Normalization，BN） 
.　更深的网络――ResNet 
..　困难的深层网络训练：退化问题 
..　残差单元 
..　深度残差网络 
..　从集成的角度看待ResNet 
..　结构更复杂的网络 
第篇　实例精讲
第章　Python基础 
.　Python简介 
..　Python简史 
..　安装和使用Python 
.　Python基本语法 
..　基本数据类型和运算 
..　容器 
..　分支和循环 
..　函数、生成器和类 
..　map、reduce和filter 
..　列表生成（list comprehension） 
..　字符串 
..　文件操作和pickle 
..　异常 
..　多进程（multiprocessing） 
..　os模块 
.　Python的科学计算包――NumPy 
..　基本类型（array） 
..　线性代数模块（linalg） 
..　随机模块（random） 
.　Python的可视化包――matplotlib 
..　D图表 
..　D图表 
..　图像显示 
第章　OpenCV基础 
.　OpenCV简介 
..　OpenCV的结构 
..　安装和使用OpenCV 
.　Python-OpenCV基础 
..　图像的表示 
..　基本图像处理 
..　图像的仿射变换 
..　基本绘图 
..　视频功能 
.　用OpenCV实现数据增加小工具 
..　随机裁剪 
..　随机旋转 
..　随机颜色和明暗 
..　多进程调用加速处理 
..　代码：图片数据增加小工具 
.　用OpenCV实现物体标注小工具 
..　窗口循环 
..　鼠标和键盘事件 
..　代码：物体检测标注的小工具 
第章　Hello World! 
.　用MXNet实现一个神经网络 
..　基础工具、NVIDIA驱动和CUDA安装 
..　安装MXNet 
..　MXNet基本使用 
..　用MXNet实现一个两层神经网络 
.　用Caffe实现一个神经网络 
..　安装Caffe 
..　Caffe的基本概念 
..　用Caffe实现一个两层神经网络 
第章　最简单的图片分类――手写数字识别 
.　准备数据――MNIST 
..　下载MNIST 
..　生成MNIST的图片 
.　基于Caffe的实现 
..　制作LMDB数据 
..　训练LeNet- 
..　测试和评估 
..　识别手写数字 
..　增加平移和旋转扰动 
.　基于MXNet的实现 
..　制作Image Recordio数据 
..　用Module模块训练LeNet- 
..　测试和评估 
..　识别手写数字 
第章　利用Caffe做回归 
.　回归的原理 
..　预测值和标签值的欧式距离 
..　EuclideanLoss层 
.　预测随机噪声的频率 
..　生成样本：随机噪声 
..　制作多标签HDF数据 
..　网络结构和Solver定义 
..　训练网络 
..　批量装载图片并利用GPU预测 
..　卷积核可视化 
第章　迁移学习和模型微调 
.　吃货必备――通过Python采集美食图片 
..　通过关键词和图片搜索引擎下载图片 
..　数据预处理――去除无效和不相关图片 
..　数据预处理――去除重复图片 
..　生成训练数据 
.　美食分类模型 
..　迁移学习 
..　模型微调法（Finetune） 
..　混淆矩阵（Confusion Matrix） 
..　P-R曲线和ROC曲线 
..　全局平均池化和激活响应图 
第章　目标检测 
.　目标检测算法简介 
..　滑窗法 
..　PASCAL VOC、mAP和IOU简介 
..　Selective Search和R-CNN简介 
..　SPP、ROI Pooling和Fast R-CNN简介 
..　RPN和Faster R-CNN简介 
..　YOLO和SSD简介 
.　基于PASCAL VOC数据集训练SSD模型 
..　MXNet的SSD实现 
..　下载PASCAL VOC数据集 
..　训练SSD模型 
..　测试和评估模型效果 
..　物体检测结果可视化 
..　制作自己的标注数据 
第章　度量学习 
.　距离和度量学习 
..　欧氏距离和马氏距离 
..　欧式距离和余弦距离 
..　非线性度量学习和Siamese网络 
..　Contrastive Loss：对比损失函数 
.　用MNIST训练Siamese网络 
..　数据准备 
..　参数共享训练 
..　结果和可视化 
..　用τ-SNE可视化高维特征 
第章　图像风格迁移 
.　风格迁移算法简介 
..　通过梯度下降法进行图像重建 
..　图像风格重建和Gram矩阵 
..　图像风格迁移 
.　MXNet中的图像风格迁移例子 
..　MXNet的风格迁移实现 
..　对图片进行风格迁移 
・ ・ ・ ・ ・ ・ (收起)目 录
第章 概述 
. 什么是计算机视觉？ 
. 简史 
. 本书概述 
. 课程大纲样例 
. 标记法说明 
. 扩展阅读 
第章 图像形成 
. 几何基元和变换 
.. 几何基元 
.. D变换 
.. D变换 
.. D旋转 
.. D到D投影 
.. 镜头畸变 
. 光度测定学的图像形成 
.. 照明 
.. 反射和阴影 
.. 光学 
. 数字摄像机 
.. 采样与混叠 
.. 色彩 
.. 压缩 
. 补充阅读 
. 习题 
第章 图像处理 
. 点算子 
.. 像素变换 
.. 彩色变换 
.. 合成与抠图 
.. 直方图均衡化 
.. 应用：色调调整 
. 线性滤波 
.. 可分离的滤波 
.. 线性滤波示例 
.. 带通和导向滤波器 
. 更多的邻域算子 
.. 非线性滤波 
.. 形态学 
.. 距离变换 
.. 连通量 
. 傅里叶变换 
.. 傅里叶变换对 
.. 二维傅里叶变换 
.. 维纳滤波 
.. 应用：锐化，模糊
和去噪 
. 金字塔与小波 
.. 插值 
.. 降采样 
.. 多分辨率表达 
.. 小波 
.. 应用：图像融合 
. 几何变换 
.. 参数化变换 
.. 基于网格的卷绕 
.. 应用：基于特征的变形 
. 全局优化 
.. 正则化 
.. 马尔科夫随机场 
.. 应用：图像的恢复 
. 补充阅读 
. 习题 
第章 特征检测与匹配 
. 点和块 
.. 特征检测器 
.. 特征描述子 
.. 特征匹配 
.. 特征跟踪 
.. 应用：表演驱动的动画 
. 边缘 
.. 边缘检测 
.. 边缘连接 
.. 应用：边缘编辑和增强 
. 线条 
.. 逐次近似 
.. Hough变换 
.. 消失点 
.. 应用：矩形检测 
. 扩展阅读 
. 习题 
第章 分割 
. 活动轮廓 
.. 蛇行 
.. 动态蛇行和
CONDENSATION 
.. 剪刀 
.. 水平集 
.. 应用：轮廓跟踪和
转描机 
. 分裂与归并 
.. 分水岭 
.. 区域分裂(区分式聚类) 
.. 区域归并(凝聚式聚类) 
.. 基于图的分割 
.. 概率聚集 
. 均值移位和模态发现 
.. k-均值和高斯混合 
.. 均值移位 
. 规范图割 
. 图割和基于能量的方法 
. 补充阅读 
. 习题 
第章 基于特征的配准 
. 基于D和D特征的配准 
.. 使用最小二乘的
D配准 
.. 应用：全景图 
.. 迭代算法 
.. 鲁棒最小二乘
和RANSAC 
.. D配准 
. 姿态估计 
.. 线性算法 
.. 迭代算法 
.. 应用：增强现实 
. 几何内参数标定 
.. 标定模式 
.. 消失点 
.. 应用：单视图测量学 
.. 旋转运动 
.. 径向畸变 
. 补充阅读 
. 习题 
第章 由运动到结构 
. 三角测量 
. 二视图由运动到结构 
.. 投影(未标定的)重建 
.. 自标定 
.. 应用：视图变形 
. 因子分解 
.. 透视与投影因子分解 
.. 应用：稀疏D模型
提取 
. 光束平差法 
.. 挖掘稀疏性 
.. 应用：匹配运动和增强
现实 
.. 不确定性和二义性 
.. 应用：由因特网照片
重建 
. 限定结构和运动 
.. 基于线条的方法 
.. 基于平面的方法 
. 补充阅读 
. 习题 
第章 稠密运动估计 
. 平移配准 
.. 分层运动估计 
.. 基于傅里叶的配准 
.. 逐次求精 
. 参数化运动 
.. 应用：视频稳定化 
.. 学到的运动模型 
. 基于样条的运动 
. 光流 
.. 多帧运动估计 
.. 应用：视频去噪 
.. 应用：去隔行扫描 
. 层次运动 
.. 应用：帧插值 
.. 透明层和反射 
. 补充阅读 
. 习题 
第章 图像拼接 
. 运动模型 
.. 平面透视运动 
.. 应用：白板和文档扫描 
.. 旋转全景图 
.. 缝隙消除 
.. 应用：视频摘要和压缩 
.. 圆柱面和球面坐标 
. 全局配准 
.. 光束平差法 
.. 视差消除 
.. 认出全景图 
.. 直接配准和基于特征的
?配准 
. 合成 
.. 合成表面的选择 
.. 像素选择和加权
(去虚影) 
.. 应用：照片蒙太奇 
.. 融合 
. 补充阅读 
. 习题 
第章 计算摄影学 
. 光度学标定 
.. 辐射度响应函数 
.. 噪声水平估计 
.. 虚影 
.. 光学模糊(空间响应)
估计 
. 高动态范围成像 
.. 色调映射 
.. 应用：闪影术 
. 超分辨率和模糊去除 
.. 彩色图像去马赛克 
.. 应用：彩色化 
. 图像抠图和合成 
.. 蓝屏抠图 
.. 自然图像抠图 
.. 基于优化的抠图 
.. 烟、阴影和闪抠图 
.. 视频抠图 
. 纹理分析与合成 
.. 应用：空洞填充
与修图 
.. 应用：非真实感绘制 
. 补充阅读 
. 习题 
第章 立体视觉对应 
. 极线几何学 
.. 矫正 
.. 平面扫描 
. 稀疏对应 
. 稠密对应 
. 局部方法 
.. 亚像素估计
与不确定性 
.. 应用：基于立体视觉的
头部跟踪 
. 全局优化 
.. 动态规划 
.. 基于分割的方法 
.. 应用：z-键控与背景
替换 
. 多视图立体视觉 
.. 体积与D表面重建 
.. 由轮廓到形状 
. 补充阅读 
. 习题 
第章 D重建 
. 由X到形状 
.. 由阴影到形状与光度
测量立体视觉 
.. 由纹理到形状 
.. 由聚焦到形状 
. 主动距离获取 
.. 距离数据归并 
.. 应用：数字遗产 
. 表面表达 
.. 表面插值 
.. 表面简化 
.. 几何图像 
. 基于点的表达 
. 体积表达 
. 基于模型的重建 
.. 建筑结构 
.. 头部和人脸 
.. 应用：脸部动画 
.. 完整人体建模与跟踪 
. 恢复纹理映射与反照率 
.. 估计BRDF 
.. 应用：D摄影学 
. 补充阅读 
. 习题 
第章 基于图像的绘制 
. 视图插值 
.. 视图相关的纹理映射 
.. 应用：照片游览 
. 层次深度图像 
. 光场与发光图 
.. 非结构化发光图 
.. 表面光场 
.. 应用：同心拼图 
. 环境影像形板 
.. 更高维光场 
.. 从建模到绘制 
. 基于视频的绘制 
.. 基于视频的动画 
.. 视频纹理 
.. 应用：图片动画 
.. D视频 
.. 应用：基于视频的
游览 
. 补充阅读 
. 习题 
第章 识别 
. 物体检测 
.. 人脸检测 
.. 行人检测 
. 人脸识别 
.. 特征脸 
.. 活动表观与D形状
模型 
.. 应用：个人照片收藏 
. 实例识别 
.. 几何配准 
.. 大型数据库 
.. 应用：位置识别 
. 类别识别 
.. 词袋 
.. 基于部件的模型 
.. 基于分割的识别 
.. 应用：智能照片编辑 
. 上下文与场景理解 
.. 学习与大型图像收集 
.. 应用：图像搜索 
. 识别数据库和测试集 
. 补充阅读 
. 习题 
第章 结语 
附录A 线性代数与数值方法 
A. 矩阵分解 
A.. 奇异值分解 
A.. 特征值分解 
A.. QR因子分解 
A.. 乔里斯基分解 
A. 线性最小二乘 
A. 非线性最小二乘 
A. 直接稀疏矩阵方法 
A. 迭代方法 
A.. 共轭梯度 
A.. 预处理 
A.. 多重网格 
附录B 贝叶斯建模与推断 
B. 估计理论 
B. 最大似然估计与最小二乘 
B. 鲁棒统计学 
B. 先验模型与贝叶斯推断 
B. 马尔科夫随机场 
B.. 梯度下降与模拟退火 
B.. 动态规划 
B.. 置信传播 
B.. 图割 
B.. 线性规划 
B. 不确定性估计(误差分析) 
附录C 补充材料 
C. 数据集 
C. 软件 
C. 幻灯片与讲座 
C. 参考文献 
词汇表 
・ ・ ・ ・ ・ ・ (收起)《python计算机视觉编程》
推荐序 xi
前言 xiii
第章　基本的图像操作和处理 
.　pil：python图像处理类库 
..　转换图像格式 
..　创建缩略图 
..　复制和粘贴图像区域 
..　调整尺寸和旋转 
.　matplotlib 
..　绘制图像、点和线 
..　图像轮廓和直方图 
..　交互式标注 
.　numpy 
..　图像数组表示 
..　灰度变换 
..　图像缩放 
..　直方图均衡化 
..　图像平均 
..　图像的主成分分析（pca） 
..　使用pickle模块 
.　scipy 
..　图像模糊 
..　图像导数 
..　形态学：对象计数 
..　一些有用的scipy模块 
.　高级示例：图像去噪 
练习 
代码示例约定 
第章　局部图像描述子 
.　harris角点检测器 
.　sift（尺度不变特征变换） 
..　兴趣点 
..　描述子 
..　检测兴趣点 
..　匹配描述子 
.　匹配地理标记图像 
..　从panoramio下载地理标记图像 
..　使用局部描述子匹配 
..　可视化连接的图像 
练习 
第章　图像到图像的映射 
.　单应性变换 
..　直接线性变换算法 
..　仿射变换 
.　图像扭曲 
..　图像中的图像 
..　分段仿射扭曲 
..　图像配准 
.　创建全景图 
..　ransac 
..　稳健的单应性矩阵估计 
..　拼接图像 
练习 
第章　照相机模型与增强现实 
.　针孔照相机模型 
..　照相机矩阵 
..　三维点的投影 
..　照相机矩阵的分解 
..　计算照相机中心 
.　照相机标定 
.　以平面和标记物进行姿态估计 
.　增强现实 
..　pygame和pyopengl 
..　从照相机矩阵到opengl格式 
..　在图像中放置虚拟物体 
..　综合集成 
..　载入模型 
练习 
第章　多视图几何 
.　外极几何 
..　一个简单的数据集 
..　用matplotlib绘制三维数据 
..　计算f：八点法 
..　外极点和外极线 
.　照相机和三维结构的计算 
..　三角剖分 
..　由三维点计算照相机矩阵 
..　由基础矩阵计算照相机矩阵 
.　多视图重建 
..　稳健估计基础矩阵 
..　三维重建示例 
..　多视图的扩展示例 
.　立体图像 
练习 
第章　图像聚类 
.　k-means聚类 
..　scipy聚类包 
..　图像聚类 
..　在主成分上可视化图像 
..　像素聚类 
.　层次聚类 
.　谱聚类 
练习 
第章　图像搜索 
.　基于内容的图像检索 
.　视觉单词 
.　图像索引 
..　建立数据库 
..　添加图像 
.　在数据库中搜索图像 
..　利用索引获取候选图像 
..　用一幅图像进行查询 
..　确定对比基准并绘制结果 
.　使用几何特性对结果排序 
.　建立演示程序及web应用 
..　用cherrypy创建web应用 
..　图像搜索演示程序 
练习 
第章　图像内容分类 
.　k邻近分类法（knn） 
..　一个简单的二维示例 
..　用稠密sift作为图像特征 
..　图像分类：手势识别 
.　贝叶斯分类器 
.　支持向量机 
..　使用libsvm 
..　再论手势识别 
.　光学字符识别 
..　训练分类器 
..　选取特征 
..　多类支持向量机 
..　提取单元格并识别字符 
..　图像校正 
练习 
第章　图像分割 
.　图割（graph cut） 
..　从图像创建图 
..　用户交互式分割 
.　利用聚类进行分割 
.　变分法 
练习 
第章　opencv 
.　opencv的python接口 
.　opencv基础知识 
..　读取和写入图像 
..　颜色空间 
..　显示图像及结果 
.　处理视频 
..　视频输入 
..　将视频读取到numpy数组中 
.　跟踪 
..　光流 
..　lucas-kanade算法 
.　更多示例 
..　图像修复 
..　利用分水岭变换进行分割 
..　利用霍夫变换检测直线 
练习 
附录a　安装软件包 
a.　numpy和scipy 
a..　windows 
a..　mac os x 
a..　linux 
a.　matplotlib 
a.　pil 
a.　libsvm 
a.　opencv 
a..　windows 和 unix 
a..　mac os x 
a..　linux 
a.　vlfeat 
a.　pygame 
a.　pyopengl 
a.　pydot 
a.　python-graph 
a.　simplejson 
a.　pysqlite 
a.　cherrypy 
附录b　图像集 
b.　flickr 
b.　panoramio 
b.　牛津大学视觉几何组 
b.　肯塔基大学识别基准图像 
b.　其他 
b..　prague texture segmentation datagenerator与基准 
b..　微软研究院grab cut数据集 
b..　caltech  
b..　静态手势数据库 
b..　middlebury stereo数据集 
附录c　图片来源 
c.　来自flickr的图像 
c.　其他图像 
c.　插图 
参考文献 
索引 
・ ・ ・ ・ ・ ・ (收起)第章　图像编程入门　　
.　简介　　
.　安装OpenCV库　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　装载、显示和存储图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　深入了解cv::Mat　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　定义感兴趣区域　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　操作像素　　
.　简介　　
.　访问像素值　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用指针扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用迭代器扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　编写高效的图像扫描循环　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　扫描图像并访问相邻像素　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　实现简单的图像运算　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　图像重映射　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　处理图像的颜色　　
.　简介　　
.　用策略设计模式比较颜色　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用GrabCut算法分割图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　转换颜色表示法　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用色调、饱和度和亮度表示颜色　　
..　如何实现　　
..　实现原理　　
..　拓展阅读　　
..　参阅　　
第章　用直方图统计像素　　
.　简介　　
.　计算图像直方图　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　利用查找表修改图像外观　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　直方图均衡化　　
..　如何实现　　
..　实现原理　　
.　反向投影直方图检测特定图像内容　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用均值平移算法查找目标　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　比较直方图搜索相似图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用积分图像统计像素　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　用形态学运算变换图像　　
.　简介　　
.　用形态学滤波器腐蚀和膨胀图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用形态学滤波器开启和闭合图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　在灰度图像中应用形态学运算　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用分水岭算法实现图像分割　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用MSER算法提取特征区域　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　图像滤波　　
.　简介　　
.　低通滤波器　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用滤波器进行缩减像素采样　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　中值滤波器　　
..　如何实现　　
..　实现原理　　
.　用定向滤波器检测边缘　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算拉普拉斯算子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　提取直线、轮廓和区域　　
.　简介　　
.　用Canny算子检测图像轮廓　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用霍夫变换检测直线　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　点集的直线拟合　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　提取连续区域　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算区域的形状描述子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
第章　检测兴趣点　　
.　简介　　
.　检测图像中的角点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　快速检测特征　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　尺度不变特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　多尺度FAST特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　描述和匹配兴趣点　　
.　简介　　
.　局部模板匹配　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　描述并匹配局部强度值模式　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用二值描述子匹配关键点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　估算图像之间的投影关系　　
.　简介　　
.　计算图像对的基础矩阵　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用RANSAC（随机抽样一致性）算法匹配图像　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算两幅图像之间的单应矩阵　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　检测图像中的平面目标　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　三维重建　　
.　简介　　
.　相机标定　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　相机姿态还原　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用标定相机实现三维重建　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算立体图像的深度　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　处理视频序列　　
.　简介　　
.　读取视频序列　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　处理视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　写入视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　提取视频中的前景物体　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　跟踪运动目标　　
.　简介　　
.　跟踪视频中的特征点　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　估算光流　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　跟踪视频中的物体　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　实用案例　　
.　简介　　
.　人脸识别　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　人脸定位　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　行人检测　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
・ ・ ・ ・ ・ ・ (收起)第一章 绪论
・ 生物视觉通路简介
・ Marr的计算视觉理论框架
・ 本书各章内容简介
・ 计算机视觉的现状与阅读本书需注意的问题
思考题
参考文献
第二章 边缘检测
・ 边缘检测与微分滤波器
・ 边缘检测与正则化方法
・ 多尺度滤波器与过零点定理
・ 最优边缘检测滤波器
・ 边缘检测快速算法
・ 图像低层次处理的其他问题
思考题
参考文献
第三章 射影几何与几何元素表达
・ 仿射变换与射影变换的几何表达
・ 仿射坐标系与射影坐标系
・ 仿射变换与射影变换的代数表达
・ 不变量
・ 由对应点求射影变换
・ 点
・ 指向和方向
・ 平面直线及点线对偶关系
・ 空间平面及点面对偶关系
・ 空间直线
・ 二次曲线与二次曲面
思考题
参考文献
第四章 摄像机定标
・ 线性模型摄像机定标
・ 非线性模型摄像机定标
・ 立体视觉摄像机定标
・ 机器人手眼定标
・ 摄像机自定标技术
思考题
参考文献
第五章 立体视觉
・ 立体视觉与三维重建
・ 极线约束
・ 对应基元匹配
・ 射影几何意义下的三维重建
思考题
参考文献
第六章 运动与不确定性表达
・ 欧氏平面上的刚体运动
・ 欧氏空间中的刚体运动
・ 不确定性的描述
・ 不确定性的运算
・ 不确定性运算的几个例子
・ 三维直线段的不确定性
・ 不确定性的显示
思考题
参考文献
第七章 基于光流场的运动分析
・ 光流场和运动场
・ 光流的约束方程
・ 微分技术
・ 其他方法
・ 基于光流场的定性运动解释
思考题
参考文献
第八章 长序列运动图像特征跟踪
・ 引论
・ 参数估计理论初步
・ 特征运动模型
・ 特征跟踪的阐述
・ 匹配
・ 实际应用中需要考虑的问题
思考题
参考文献
第九章 基于二维特征对应的运动分析
・ 极线方程和本质矩阵
・ 基于点匹配的运动计算
・ 图像是一个空间平面的投影时的运动计算
・ 基于直线匹配的运动计算
・ 基本矩阵的估计
思考题
参考文献
第十章 基于三维特征对应的运动分析
・ 由三维点匹配估计运动
・ 不需显式匹配的方法
・ 从三维直线匹配估计运动
・ 从平面匹配估计运动
・ 二维-三维的物体定位
思考题
参考文献
第十一章 由图像灰度恢复三维物体形状
・ 辐射度学与光度学
・ 光照模型
・ 由多幅图像恢复三维物体形状
・ 由单幅图像恢复三维物体形状
思考题
参考文献
第十二章 建模与识别
・ CAD系统中的三维模型表达
・ 曲线与曲面的表达
・ 三维世界的多层次模型
・ 由二维图像建模
・ 识别的一般原则――问题与策略
・ 特征关系图匹配
・ “假设检验”识别方法
思考题
参考文献
第十三章 距离图像获取与处理
・ 距离传感器
・ 数据预处理
・ 深度图分割
思考题
参考文献
第十四章 计算机视觉系统体系结构讨论与展望
・ 计算机视觉系统的基本体系结构
・ 视觉系统体系结构讨论
・ 主动视觉
・ 计算机视觉的应用展望
参考文献
附录A 实验数据及参考结构
A・ 图像的格式
A・ 摄像机定标
A・ 立体视觉
A・ 基于光流场的运动分析
A・ 长序列运动图像特征跟踪
A・ 基于二维特征对应的运动分析
A・ 基于三维特征对应的运动分析
・ ・ ・ ・ ・ ・ (收起)译者序
前言
致老师
第一部分　导论
第章　计算机视觉的定义及其历史
.　简介
.　定义
.　局部全局问题
.　生物视觉
..　生物动因
..　视觉感知
参考文献
第章　编写图像处理程序
.　简介
.　图像处理的基本程序结构
.　良好的编程风格
.　计算机视觉的重点
.　图像分析软件工具包
.　makefile
.　作业
参考文献
第章　数学原理回顾
.　简介
.　线性代数简要回顾
..　向量
..　向量空间
..　零空间
..　函数空间
..　线性变换
..　导数和导数算子
..　特征值和特征向量
..　特征分解
..　奇异值分解
.　函数最小化简要回顾
..　梯度下降
..　局部最小值和全局最小值
..　模拟退火
.　概率论简要回顾
.　作业
参考文献
第章　图像：表示和创建
.　简介
.　图像表示
..　标志性表示（图像）
..　函数表示(方程)
..　线性表示(向量)
..　概率表示（随机场）
..　图形表示（图）
..　邻接悖论和六边形像素
.　作为曲面的图像
..　梯度
..　等值线
..　脊
.　作业
参考文献
第二部分　预处理
第章　卷积核算子
.　简介
.　线性算子
.　图像的向量表示
.　导数估计
..　使用核估计导数
..　通过函数拟合来估计导数
..　图像基向量
..　核作为采样可微分函数
..　其他高阶导数
..　尺度简介
.　边缘检测
.　尺度空间
..　金字塔
..　没有重采样的尺度空间
.　示例
.　数字梯度检测器的性能
..　方向导数
..　方向估计
..　讨论
.　总结
.　作业
参考文献
第章　去噪
.　简介
.　图像平滑
..　一维情况
..　二维情况
.　使用双边滤波器实现保边平滑
.　使用扩散方程实现保边平滑
..　一维空间的扩散方程
..　PDE模拟
..　二维空间的扩散方程
..　可变电导扩散
.　使用优化实现保边平滑
..　噪声消除的目标函数
..　寻找一个先验项
..　MAP算法实现和均场退火
..　病态问题和正则化
.　等效算法
.　总结
.　作业
参考文献
第章　数学形态学
.　简介
.　二值形态学
..　膨胀
..　腐蚀
..　膨胀和腐蚀的性质
..　开运算和闭运算
..　开运算和闭运算的性质
.　灰度形态学
..　使用平面结构元素的灰度图像
..　使用灰度结构元素的灰度图像
..　使用集合运算的灰度形态学
.　距离变换
..　使用迭代最近邻计算DT
..　使用二值形态运算计算DT
..　使用掩码计算DT
..　使用维诺图计算DT
.　边缘链接的应用
.　总结
.　作业
参考文献
第三部分　图像理解
第章　分割
.　简介
.　阈值：仅基于亮度的分割
..　阈值的局部性质
..　通过直方图分析选择阈值
..　用高斯和拟合直方图
..　高斯混合模型与期望最大化
.　聚类：基于颜色相似度的分割
..　k-均值聚类
..　均值移位聚类
.　连接组件：使用区域增长的空间分割
..　递归方法
..　迭代方法
..　示例应用
.　使用主动轮廓进行分割
..　snake：离散和连续
..　水平集：包含边或者不包含边
.　分水岭：基于亮度曲面的分割
.　图割：基于图论的分割
..　目标函数
..　求解目标函数
.　使用MFA进行分割
.　评估分割的质量
.　总结
.　作业
参考文献
第章　参数变换
.　简介
.　霍夫变换
..　垂线问题
..　如何找到交点――累加器数组
..　使用梯度降低计算复杂度
.　寻找圆
..　由任意三个非共线像素表示的圆的位置推导
..　当原点未知但半径已知时找圆
..　利用梯度信息减少找圆的计算
.　寻找椭圆
.　广义霍夫变换
.　寻找峰值
.　寻找三维形状――高斯图
.　寻找对应体――立体视觉中的参数一致性
.　总结
.　作业
参考文
・ ・ ・ ・ ・ ・ (收起)第章　图像编程入门　　
.　简介　　
.　安装OpenCV库　　
..　准备工作　　
..　安装　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　装载、显示和存储图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　深入了解cv::Mat　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　定义兴趣区域　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　操作像素　　
.　简介　　
.　访问像素值　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用指针扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用迭代器扫描图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　编写高效的图像扫描循环　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　扫描图像并访问相邻像素　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　实现简单的图像运算　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　图像重映射　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　用类处理彩色图像　　
.　简介　　
.　在算法设计中使用策略模式　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用控制器设计模式实现功能模块间通信　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　转换颜色表示法　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用色调、饱和度、亮度表示颜色.
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
第章　用直方图统计像素　　
.　简介　　
.　计算图像直方图　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　利用查找表修改图像外观　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　直方图均衡化　　
..　如何实现　　
..　实现原理　　
.　反向投影直方图检测特定图像内容　　 
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　均值平移算法查找目标　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　比较直方图搜索相似图像　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用积分图像统计像素　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　用形态学运算变换图像　　
.　简介　　
.　形态学滤波器腐蚀和膨胀图像　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用形态学滤波器开启和闭合图像　　 
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用形态学滤波器检测边缘和角点　　 
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用分水岭算法实现图像分割　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用MSER算法提取特征区域　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用GrabCut算法提取前景物体　　
..　如何实现　　
..　实现原理　　
..　参阅　　
第章　图像滤波　　
.　简介　　
.　低通滤波器　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　中值滤波器　　
..　如何实现　　
..　实现原理　　
.　用定向滤波器检测边缘　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算拉普拉斯算子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　提取直线、轮廓和区域　　
.　简介　　
.　用Canny算子检测图像轮廓　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用霍夫变换检测直线　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　点集的直线拟合　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　提取区域的轮廓　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算区域的形状描述子　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
第章　检测兴趣点　　
.　简介　　
.　检测图像中的角点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　快速检测特征　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　尺度不变特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　多尺度FAST 特征的检测　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　描述和匹配兴趣点　　
.　简介　　
.　局部模板匹配　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　描述局部强度值模式　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　用二值特征描述关键点　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　估算图像之间的投影关系　　
.　简介　　
.　相机校准　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　计算图像对的基础矩阵　　
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　用RANSAC（随机抽样一致性）算法匹配图像　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
.　计算两幅图像之间的单应矩阵.
..　准备工作　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
第章　处理视频序列　　
.　简介　　
.　读取视频序列　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　处理视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　写入视频帧　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
.　跟踪视频中的特征点　　
..　如何实现　　
..　实现原理　　
..　参阅　　
.　提取视频中的前景物体　　
..　如何实现　　
..　实现原理　　
..　扩展阅读　　
..　参阅　　
・ ・ ・ ・ ・ ・ (收起)第章 浅谈人工智能、神经网络和计算机视觉 
. 人工还是智能 
. 人工智能的三起两落 
.. 两起两落 
.. 卷土重来 
. 神经网络简史 
.. 生物神经网络和人工神经网络 
.. M-P模型 
.. 感知机的诞生 
.. 你好，深度学习 
. 计算机视觉 
. 深度学习+ 
.. 图片分类 
.. 图像的目标识别和语义分割 
.. 自动驾驶 
.. 图像风格迁移 
第章 相关的数学知识 
. 矩阵运算入门 
.. 标量、向量、矩阵和张量 
.. 矩阵的转置 
.. 矩阵的基本运算 
. 导数求解 
.. 一阶导数的几何意义 
.. 初等函数的求导公式 
.. 初等函数的和、差、积、商求导 
.. 复合函数的链式法则 
第章 深度神经网络基础 
. 监督学习和无监督学习 
.. 监督学习 
.. 无监督学习 
.. 小结 
. 欠拟合和过拟合 
.. 欠拟合 
.. 过拟合 
. 后向传播 
. 损失和优化 
.. 损失函数 
.. 优化函数 
. 激活函数 
.. Sigmoid 
.. tanh 
.. ReLU 
. 本地深度学习工作站 
.. GPU和CPU 
.. 配置建议 
第章 卷积神经网络 
. 卷积神经网络基础 
.. 卷积层 
.. 池化层 
.. 全连接层 
. LeNet模型 
. AlexNet模型 
. VGGNet模型 
. GoogleNet 
. ResNet 
第章 Python基础 
. Python简介 
. Jupyter Notebook 
.. Anaconda的安装与使用 
.. 环境管理 
.. 环境包管理 
.. Jupyter Notebook的安装 
.. Jupyter Notebook的使用 
.. Jupyter Notebook常用的快捷键 
. Python入门 
.. Python的基本语法 
.. Python变量 
.. 常用的数据类型 
.. Python运算 
.. Python条件判断语句 
.. Python循环语句 
.. Python中的函数 
.. Python中的类 
. Python中的NumPy 
.. NumPy的安装 
.. 多维数组 
.. 多维数组的基本操作 
. Python中的Matplotlib 
.. Matplotlib的安装 
.. 创建图 
第章 PyTorch基础 
. PyTorch中的Tensor 
.. Tensor的数据类型 
.. Tensor的运算 
.. 搭建一个简易神经网络 
. 自动梯度 
.. torch.autograd和Variable 
.. 自定义传播函数 
. 模型搭建和参数优化 
.. PyTorch之torch.nn 
.. PyTorch之torch.optim 
. 实战手写数字识别 
.. torch和torchvision 
.. PyTorch之torch.transforms 
.. 数据预览和数据装载 
.. 模型搭建和参数优化 
第章 迁移学习 
. 迁移学习入门 
. 数据集处理 
.. 验证数据集和测试数据集 
.. 数据预览 
. 模型搭建和参数优化 
.. 自定义VGGNet 
.. 迁移VGG 
.. 迁移ResNet 
. 小结 
第章 图像风格迁移实战 
. 风格迁移入门 
. PyTorch图像风格迁移实战 
.. 图像的内容损失 
.. 图像的风格损失 
.. 模型搭建和参数优化 
.. 训练新定义的卷积神经网络 
. 小结 
第章 多模型融合 
. 多模型融合入门 
.. 结果多数表决 
.. 结果直接平均 
.. 结果加权平均 
. PyTorch之多模型融合实战 
. 小结 
第章 循环神经网络 
. 循环神经网络入门 
. PyTorch之循环神经网络实战 
. 小结 
第章 自动编码器 
. 自动编码器入门 
. PyTorch之自动编码实战 
.. 通过线性变换实现自动编码器模型 
.. 通过卷积变换实现自动编码器模型 
. 小结 
・ ・ ・ ・ ・ ・ (收起)第章 视觉系统实践――图像显示、输入/输出和库函数调用 
. OpenCV 
. 基本的OpenCV代码 
.. IplImage数据结构 
.. 读写图像 
.. 图像显示 
.. 示例 
. 图像捕捉 
. 和AIPCV库的接口 
. 网站文件 
. 参考文献 
第章 边缘检测技术 
. 边缘检测的目的 
. 传统的方法和理论 
.. 边缘的模型 
.. 噪声 
.. 导数算子 
.. 基于模板的边缘检测 
. 边缘模型：Marr-Hildreth边缘检测器 
. Canny Edge边缘检测器 
. Shen-Castan(ISEF)边缘检测器 
. 两种最优边缘检测器的比较 
. 彩色边缘 
. Marr-Hildreth边缘检测器的源代码 
. Canny边缘检测器的源代码 
. Shen-Castan边缘检测器的源代码 
. 网站文件 
. 参考文献 
第章 数码形态学 
. 形态学定义 
. 连通性 
. 数码形态学的基本元素――二值操作 
.. 二值膨胀 
.. 实现二值膨胀 
.. 二值腐蚀 
.. 二值腐蚀的实现 
.. 开启和闭合 
.. MAX――用于形态学的高级程序设计语言 
.. “命中/不命中”变换 
.. 识别区域边缘 
.. 条件膨胀 
.. 区域计数 
. 灰阶形态学 
.. 开启操作和闭合操作 
.. 平滑操作 
.. 梯度 
.. 纹理的分割 
.. 对象的大小分布 
. 彩色形态学 
. 网站文件 
. 参考文献 
第章 灰阶分割 
. 灰阶分割的基础 
.. 使用边缘像素 
.. 迭代选择法 
.. 灰阶直方图法 
.. 使用熵 
.. 模糊集合 
.. 最小误差阈值法 
.. 单阈值选择的示例结果 
. 使用区域阈值 
.. Chow-Kaneko算法 
.. 通过边缘对光照进行
建模 
.. 实现和结果 
.. 对比 
. 松弛法 
. 移动平均法 
. 基于聚类的阈值 
. 多重阈值 
. 网站文件 
. 参考文献 
第章 纹理和色彩 
. 纹理和分割 
. 灰阶图像中纹理的简单分析 
. 灰阶共生矩阵 
.. 最大概率 
.. 矩 
.. 对比度 
.. 同质性 
.. 熵 
.. GLCM描述符的测试结果 
.. 纹理操作符的加速 
. 边缘和纹理 
. 能量和纹理 
. 表面和纹理 
.. 向量散射算法 
.. 表面曲度算法 
. 分形维度 
. 彩色分割 
. 彩色纹理 
. 网站文件 
. 参考文献 
第章 图像细化 
. 骨架概述 
. 中轴变换 
. 迭代式形态学方法 
. 等高线的使用 
. 把对象看做多边形 
. 基于力的图像细化 
.. 定义 
.. 力场的使用 
.. 子像素骨架 
. Zhang-Suen/Stentiford/Holt组合算法的源代码 
. 网站文件 
. 参考文献 
第章 图像还原 
. 图像降质――真实世界 
. 频域 
.. 傅里叶变换 
.. 快速傅里叶变换 
.. 逆傅里叶变换 
.. 二维傅里叶变换 
.. OpenCV中的傅里叶变换 
.. 创建人工模糊 
. 逆滤波器 
. Wiener滤波器 
. 结构化噪声 
. 运动模糊――一种特殊情况 
. 同态滤波器――过滤照度 
.. 通用频率过滤器 
.. 分离光照产生的效果 
. 网站文件 
. 参考文献 
第章 分类 
. 对象、模式和统计数据 
.. 特征和区域 
.. 训练和测试 
.. 类别内和类别外的差异 
. 最小距离分类器 
.. 距离度量 
.. 特征之间的距离 
. 交叉验证 
. 支持向量机 
. 多重分类器――整合分类器 
.. 合并多种方法 
.. 整合类型的响应 
.. 评估 
.. 响应类型之间的转换 
.. 整合类型的响应 
.. 整合类型的响应 
. bagging和boosting 
.. bagging 
.. boosting 
. 网站文件 
. 参考文献 
第章 符号识别 
. 问题描述 
. 对简单的完美图像进行
OCR 
. 在扫描的图像上进行OCR――图像分割 
.. 噪声 
.. 分离独立的字形 
.. 匹配模板 
.. 统计识别 
. 传真图像的OCR――针对印刷字符 
.. 朝向――倾斜检测 
.. 使用边缘 
. 手写字符 
.. 字符轮廓的属性 
.. 凸缺 
.. 向量模板 
.. 神经网络 
. 使用多重分类器 
.. 合并多种方法 
.. 多重分类器的结果 
. 印刷乐谱识别――案例研究 
.. 五线谱线 
.. 分割 
.. 音乐符号识别 
. 神经网络识别系统的源代码 
. 网站文件 
. 参考文献 
第章 基于内容的搜索――通过示例搜索图像 
. 搜索图像 
. 维护图像集合 
. 通过示例搜索的特征 
.. 彩色图像的特征 
.. 灰阶图像特征 
. 考虑空间因素 
.. 整体区域 
.. 矩形区域 
.. 角度区域 
.. 环状区域 
.. 混合区域 
.. 空间采样的测试 
. 其他要考虑的因素 
.. 纹理 
.. 对象、等高线和边缘 
.. 数据集 
. 网站文件 
. 参考文献 
第章 将高性能计算用于视觉处理和图像处理 
. 多处理器计算的范式 
.. 共享内存 
.. 消息传递 
. 执行时间 
.. 使用clock()函数 
.. 使用QueryPerformance-Counter函数 
. 消息传递接口系统 
.. 安装MPI 
.. 使用MPI 
.. 进程间通信 
.. 运行MPI程序 
.. 真实的图像计算 
.. 使用计算机网络――集群计算 
. 共享内存系统――使用PC的图形处理器 
.. GLSL 
.. OpenGL基础 
.. OpenGL中的纹理实践 
.. 着色器编程基础 
.. 读入并转换图像 
.. 向着色程序传递参数 
.. 整合以上内容 
.. 通过GPU加速 
.. 开发和测试着色器代码 
. 寻找所需的软件 
. 网站文件 
. 参考文献 
・ ・ ・ ・ ・ ・ (收起)第章 深度学习基础 
. 神经网络 
.. 感知机 
.. 神经网络原理 
. 卷积神经网络 
.. CNN基本操作 
.. CNN原理 
. 循环神经网络 
.. RNN 
.. LSTM与GRU 
. 经典网络 
.. AlexNet 
.. VGG 
.. GoogLeNet 
.. ResNet 
.. MobileNet 
. 进阶必备：如何学习深度学习并“落地”求职 
.. 深度学习如何快速入门 
.. 深度学习行业求职技巧 
第章 计算机视觉基础 
. 目标检测Two-stage算法 
.. R-CNN算法 
.. Fast R-CNN算法 
.. Faster R-CNN算法 
. 目标检测One-stage算法 
.. YOLO系列算法 
.. SSD算法 
. 图像分割算法 
.. FCN算法 
.. U-Net算法 
.. DeepLab系列算法 
.. Mask R-CNN算法 
. 进阶必备：计算机视觉方向知多少 
第章 基础图像处理 
. 线性滤波 
.. 案例：使用方框滤波 
.. 案例：使用均值滤波 
.. 案例：使用高斯滤波 
. 非线性滤波 
.. 案例：使用中值滤波例 
.. 案例：使用双边滤波 
.　OpenCV形态学运算 
.. 案例：进行膨胀操作 
.. 案例：进行腐蚀操作 
.. 案例：使用形态学运算 
.　案例：使用漫水填充 
.　图像金字塔 
.. 案例：使用高斯金字塔 
.. 案例：使用拉普拉斯金字塔 
.　阈值化 
.. 案例：使用基本阈值 
.. 案例：使用自适应阈值 
.　进阶必备：选择一款合适的图像处理工具 
.. OpenCV 
.. Matlab 
第章 图像变换 
.　边缘检测 
.. 案例：Sobel算法 
.. 案例：Scharr算法 
.. 案例：Laplacian算法 
.. 案例：Canny算法 
.　案例：绘制轮廓 
.　霍夫变换 
.. 案例：霍夫线变换 
.. 案例：霍夫圆变换 
.　案例：重映射 
.　案例：仿射变换 
.　案例：透视变换 
.　直方图 
.. 案例：直方图的计算与绘制 
.. 案例：直方图均衡化 
.　进阶必备：图像变换应用之文本图像矫正 
.. 图像变换知识总结 
.. 案例：文本图像矫正 
第章 角点检测 
. 案例：Harris角点检测 
.　案例：Shi-Tomasi角点检测 
.　案例：亚像素级角点检测 
.　进阶必备：角点检测知识总结 
第章 特征点检测与匹配 
.　特征点检测 
.. opencv-contrib环境安装 
.. 案例：SIFT特征点检测 
.. 案例：SURF特征点检测 
.　特征匹配 
.. 案例：BruteForce匹配 
.. 案例：FLANN匹配 
.　案例：ORB特征提取 
.　进阶必备：利用特征点拼接图像 
.. 特征点检测算法汇总 
.. 案例：基于特征点检测与匹配的图像拼接 
第章 手写数字识别 
.　Keras的应用 
.. Keras模型 
.. Keras层 
.. 模型编译 
.. 模型训练 
.　LeNet算法 
.　案例：使用Keras实现手写数字识别 
.. 模型训练 
.. 手写数字识别模型推理 
.　进阶必备：算法模型开发流程 
.. 数据准备 
.. 网络搭建 
.. 模型训练 
第章 CIFAR-图像分类 
.　图像分类数据集 
.. CIFAR-数据集和CIFAR-数据集 
.. ImageNet数据集 
.. PASCAL VOC数据集 
.　案例：CIFAR-图像分类 
.. 模型训练过程 
.. 模型推理 
.　进阶必备：COCO数据集与使用HOGTSVM方法实现图像分类 
.. COCO数据集 
.. 案例：使用HOG+SVM方法实现图像分类 
第章 验证码识别 
.　TensorFlow应用 
.. 案例：TensorFlow的基本使用 
.. TensorFlow的常用模块 
.　案例：验证码识别 
.. 生成验证码图片 
.. 基于TensorFlow的验证码识别 
.　进阶必备：算法模型开发技巧 
.. 数据预处理技巧 
.. 网络搭建技巧 
.. 模型训练技巧 
第章 文本检测实战 
.　文本检测算法 
.. CTPN算法 
.. EAST算法 
.　案例：基于EAST算法的文本检测 
.. 数据预处理 
.. 网络搭建 
.. 模型训练 
.. 文本检测验证 
.　进阶必备：在不同场景下文本检测的应对方式 
.. 复杂场景文本检测 
.. 案例：使用形态学运算实现简单场景文本检测 
.. 案例：使用MSER+NMS实现简单场景文本检测 
第章 文本识别实战 
.　文本识别算法 
.. CRNN算法 
.. Attention OCR算法 
.　案例：基于C-RNN算法的文本识别 
.. 数据预处理 
.. 网络搭建 
.. 模型训练 
.. 文本识别验证 
.　进阶必备：单字OCR 
.. OCR探究 
.. 案例：文本图片字符切割 
第章 TensorFlow Lite 
.　TensorFlow Lite介绍 
.. TensorFlow Lite基础 
.. TensorFlow Lite源码分析 
.　模型转换 
.. FlatBuffers文件格式 
.. 案例：其他格式转换为.tflite模型 
.　模型量化 
.. 案例：量化感知训练 
.. 案例：训练后量化 
.　进阶必备：模型转换与模型部署优化答疑 
.. 模型转换问题 
.. 模型部署优化 
第章 基于TensorFlow Lite的AI功能部署实战 
.　部署流程 
.　案例：移动端部署 
.. 搭建开发环境 
.. 编译运行项目 
.. 调用过程解析 
.　PC端部署 
.. 案例：Windows端部署 
.. 案例：Linux端部署 
.. 案例：ARM平台部署 
.. 案例：MIPS平台部署 
.　进阶必备：推理框架拓展与OpenCV编译部署 
.. 其他深度学习推理框架 
.. OpenCV编译 
・ ・ ・ ・ ・ ・ (收起)第 章 图像的获取和表示 
. 图像传感器技术 
.. 传感器材料 
.. 传感器光电二极管元件 
.. 传感器配置：马赛克、Faveon和BSI 
.. 动态范围和噪声 
.. 传感器处理 
.. 去马赛克 
.. 坏像素的校正 
.. 颜色和照明校正 
.. 几何校正 
. 摄像机和计算成像 
.. 计算成像概述 
.. 单像素的摄像头计算 
.. 二维可计算摄像机 
.. 三维深度的摄像机系统 
. 三维深度处理 
.. 方法概述 
.. 深度感知和处理中存在的问题 
.. 单目深度处理 
. 三维表示：体元、深度图、网格和点云 
. 总结 
第 章 图像预处理 
. 图像处理概述 
. 图像预处理要解决的问题 
.. 计算机视觉的流程和图像预处理 
.. 图像校正 
.. 图像增强 
.. 为特征提取准备图像 
. 图像处理方法分类 
.. 点运算 
.. 直线运算 
.. 区域运算 
.. 算法 
.. 数据转换 
. 色度学 
.. 色彩管理系统概述 
.. 光源、白点、黑点和中性轴 
.. 设备色彩模型 
.. 颜色空间与色彩感知 
.. 色域映射与渲染目的 
.. 色彩增强的实际考虑 
.. 色彩的准确度与精度 
. 空间滤波 
.. 卷积滤波与检测 
.. 核滤波与形状选择 
.. 点滤波 
.. 噪声与伪像滤波 
.. 积分图与盒式滤波器 
. 边缘检测器 
.. 核集合: Sobel, Scharr, Prewitt, Roberts, Kirsch, Robinson和Frei-Chen 
.. Canny检测器 
. 变换滤波、Fourier变换及其他 
.. Fourier变换 
.. 其他变换 
. 形态学与分割 
.. 二值形态学 
.. 灰度和彩色形态学 
.. 形态学优化和改进 
.. 欧氏距离映射 
.. 超像素分割 
.. 深度图分割 
.. 色彩分割 
. 阈值化 
.. 全局阈值化 
.. 局部阈值化 
. 总结 
第章 全局特征和区域特征 
. 视觉特征的历史概述 
.. 核心思想：全局、区域和局部 
.. 纹理分析 
.. 统计方法 
. 纹理区域度量 
.. 边缘度量 
.. 互相关和自相关 
.. Fourier频谱、小波和基签名 
.. 共生矩阵和Haralick特征 
.. Laws纹理度量 
.. LBP局部二值模式 
.. 动态纹理 
. 统计区域度量 
.. 图像矩特征 
.. 点度量特征 
.. 全局直方图 
.. 局部区域直方图 
.. 散点图和D直方图 
.. 多分辨率和多尺度直方图 
.. 径向直方图 
.. 轮廓或边缘直方图 
. 基空间度量 
.. Fourier描述 
.. Walsh-Hadamard变换 
.. HAAR变换 
.. 斜变换 
.. Zernike多项式 
.. 导向滤波器 
.. Karhunen-Loeve变换与Hotelling变换 
.. 小波变换和Gabor滤波器 
.. Hough变换与Radon变换 
. 总结 
第章 局部特征设计、分类和学习 
. 局部特征 
.. 检测器、兴趣点、关键点、锚点、标注 
.. 描述子、特征描述、特征提取 
.. 稀疏局部模式方法 
. 局部特征属性 
.. 选择特征描述子和兴趣点 
.. 特征描述子和特征匹配 
.. 好特征的标准 
.. 可重复性，相对于困难的查找算容易 
.. 判别性与非判别性 
.. 相对和绝 对位置 
.. 匹配代价和一致性 
. 距离函数 
.. 关于距离函数的早期研究成果 
.. 欧氏或笛卡儿距离度量 
.. 网格距离度量 
.. 基于统计学的差异性度量 
.. 二值或布尔距离度量 
. 描述子的表示 
.. 坐标空间和复数空间 
.. 笛卡儿坐标 
.. 极坐标和对数极坐标 
.. 径向坐标 
.. 球面坐标 
.. Gauge坐标 
.. 多元空间和多模数据 
.. 特征金字塔 
. 描述子的密度 
.. 丢弃兴趣点和描述子 
.. 稠密与稀疏特征描述 
. 描述子形状拓扑 
.. 关联性模板 
.. 块和形状 
.. 对象多边形 
. 局部二值描述与点对模式 
.. FREAK视网膜模式 
.. Brisk 模式 
.. ORB和BRIEF模式 
. 描述子判别性 
.. 谱的判别性 
.. 区域、形状和模式的判别性 
.. 几何判别因素 
.. 通过特征可视化来评价判别性 
.. 精度与可跟踪 
.. 精度优化、子区域重叠、Gaussian权重和池化 
.. 亚像素精度 
. 搜索策略与优化 
.. 密集搜索 
.. 网格搜索 
.. 多尺度金字塔搜索 
.. 尺度空间和图像金字塔 
.. 特征金字塔 
.. 稀疏预测搜索与跟踪 
.. 跟踪区域限制搜寻 
.. 分割限制搜索 
.. 深度或Z限制搜索 
. 计算机视觉、模型和结构 
.. 特征空间 
.. 对象模型 
.. 约束 
.. 选择检测器和特征 
.. 训练概述 
.. 特征和对象的分类 
.. 特征学习、稀疏编码和卷积网络 
. 总结 
第章 特征描述属性的分类学 
. 特征描述子系列 
. 计算机视觉分类学方面的早期研究成果 
. 鲁棒性和精度 
. 通用的鲁棒性分类学 
.. 光照 
.. 颜色准则 
.. 不完全性 
.. 分辨率和精度 
.. 几何失真 
.. 效率变量、费用和效益 
.. 判别性和唯 一性 
. 通用的视觉度量分类学 
.. 特征描述子族 
.. 频谱维度 
.. 频谱类型 
.. 兴趣点 
.. 存储格式 
.. 数据类型 
.. 描述子内存 
.. 特征形状 
.. 特征模式 
.. 特征密度 
.. 特征搜索方法 
.. 模式对采样 
.. 模式区域大小 
.. 距离函数 
. 特征度量评估 
.. 效率变量、成本和效益 
.. 图像重建的效率度量 
.. 特征度量评估举例 
. 总结 
第章 兴趣点检测与特征描述子研究 
. 兴趣点调整 
. 兴趣点概念 
. 兴趣点方法概述 
.. Laplacian 和Gaussian -Laplacian 
.. Moravac角点检测器 
.. Harris方法、Harris-Stephens、Shi-Tomasi以及Hessian类型的检测器 
.. Hessian矩阵检测器和Hessian-Laplace 
.. Gaussian差 
.. 显著性区域 
.. SUSAN、Trajkovic 以及 Hedly 
.. Fast、Faster以及 AGHAST 
.. 局部曲率方法 
.. 形态兴趣区域 
. 特征描述子介绍 
.. 局部二值描述子 
.. Census 
.. BRIEF 
.. ORB 
.. BRISK 
.. FREAK 
. 谱描述子 
.. SIFT 
.. SIFT-PCA 
.. SIFT-GLOH 
.. 改进的SIF-SIFER 
.. SIFT CS-LBP改造 
.. RootSIFT改造 
.. CenSurE和STAR 
.. 相关模板 
.. HAAR特征 
.. 使用类HAAR特征的Viola Jones算法 
.. SURF 
.. 其他SURF算法 
.. 梯度直方图及变种 
.. PHOG和相关方法 
.. Daisy和O-Daisy 
.. CARD 
.. 具有鲁棒性的快速特征匹配 
.. RIFF和CHOG 
.. 链码直方图 
.. D-NETS 
.. 局部梯度模式 
.. 局部相位量化 
. 基空间描述子 
.. 傅里叶描述子 
.. 用其他基函数来构建描述子 
.. 稀疏编码方法 
. 多边形形状描述 
.. MSER方法 
.. 针对斑点和多边形的物体形状度量 
.. 形状上下文 
. D、D、体积以及多模态描述子 
.. D HOG 
.. HON D 
.. D SIFT 
. 总结 
第章 基准数据、内容、度量和分析 
. 什么是基准数据？ 
. 先前关于标注数据方面的研究：艺术与科学 
.. 质量性能的一般度量 
.. 算法性能的衡量 
.. Rosin关于角点方面的研究工作 
. 构造基准数据的关键问题 
.. 内容：采用、修改或创建 
.. 可用的基准数据介绍 
.. 使用数据拟合算法 
.. 场景构成和标记 
. 定义目标和预期 
.. Mikolajczyk和Schmid的方法学 
.. 开放式评价系统 
.. 极 端情况和限制 
.. 兴趣点和特征 
. 基准数据的鲁棒性准则 
.. 举例说明鲁棒性准则 
.. 将鲁棒性准则用于实际应用 
. 度量与基准数据的配对 
.. 兴趣点、特征和基准数据的配对和优化 
.. 一般的视觉分类学的例子 
. 合成的特征字母表 
.. 合成数据集的目标 
.. 合成兴趣点字母表 
.. 将合成字母表叠加到真实图像上 
. 总结 
第章 可视流程及优化 
. 阶段、操作和资源 
. 计算资源预算 
.. 计算单元、ALU和加速器 
.. 能耗的使用 
.. 内存的利用 
.. I/O性能 
. 计算机视觉流程的实例 
.. 汽车识别 
.. 人脸检测、情感识别以及年龄识别 
.. 图像分类 
.. 增强现实 
. 可选的加速方案 
.. 内存优化 
.. 粗粒度并行 
.. 细粒度数据并行 
.. 高 级指令集和加速器 
. 计算机视觉算法的优化与调整 
.. 编译器优化与手工优化 
.. 特征描述子改造、检测器和距离函数 
.. Boxlets与卷积加速 
.. 数据类型优化，整型与浮点型 
. 优化资源 
. 总结 
附录A 合成特征分析 
A. 目标的背景与期望 
A. 测试方法和结果 
A. 合成字母基准图像概述 
A. 测试：合成兴趣点字母检测 
A. 测试：合成角点字母检测 
A. 测试：叠加到真实图像上的合成字母检测 
A. 测试：字母的旋转不变性 
A. 结果分析和不可重复性异常 
附录B 基准数据集概述 
附录C 成像和计算机视觉资源 
C. 商业产品 
C. 开放源码 
C. 组织、机构和标准 
C. 在线资源 
附录D 扩展SDM准则 
译后记 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第 章 机器学习与sklearn 
． sklearn 环境配置 
．． 环境要求 
．． 安装方法 
．． 修改pip 源 
．． 安装Jupyter Notebook 
． 数据集 
．． 自带的小型数据集 
．． 在线下载的数据集 
．． 计算机生成的数据集 
． 分类 
．． 加载数据与模型 
．． 建立分类模型 
．． 模型的训练及预测 
．． 模型评价 
． 回归 
．． 线性回归 
．． 回归模型评价 
． 聚类 
．． K-means 
．． DBSCAN 
．． 聚类实例 
． 降维 
．． PCA 降维 
．． LDA 降维 
． 模型验证 
． 模型持久化 
．． joblib 
．． pickle 
． 小结 
第 章 传统图像处理方法 
． 图像分类 
．． HOG 的原理 
．． 工具介绍 
．． CIFAR- 分类 
．． 手写字符分类 
． 目标检测 
． 图像分割 
． 图像搜索 
． 小结 
第章 深度学习与PyTorch 
． 框架介绍 
． 环境配置 
． 运算基本单元 
．． Tensor 数据类型 
．． Tensor 与ndarray 
．． CPU 与GPU 运算 
．． PyTorch 实现K-means 
． 自动求导 
． 数据加载 
．． Dataset 
．． DataLoader 
． 神经网络工具包 
．． Module 模块 
．． 线性层 
．． 卷积层 
．． 池化层 
．． BatchNorm 层 
．． 激活层 
．． 神经网络各层输出的可视化 
．． 循环神经网络 
．． Sequential 和ModuleList 
．． 损失函数 
． 模型优化器optim 
．． optim 用法 
．． 优化器的选择 
．． 学习率的选择 
． 参数初始化init 
． 模型持久化 
． JIT 编译器 
． 模型迁移ONNX 
． 数据可视化TensorBoard 
． 机器视觉工具包torchvision 
．． 数据 
．． 模型 
．． 图像处理 
． 小结 
第章 卷积神经网络中的分类与回归 
． 卷积神经网络中的分类问题 
．． CIFAR- 图像分类 
．． 卷积神经网络的发展 
．． 分类网络的实现 
．． 模型训练 
．． 模型展示 
．． 多标签分类 
． 卷积神经网络中的回归问题 
．． 生成数据集 
．． 模型训练 
．． 模型展示 
． 小结 
第章 目标检测 
． 深度学习物体检测算法 
．． 两段式检测 
．． 一段式检测 
． 数据集构建 
．． 选择目标物体图片 
．． 背景图片下载 
．． 图片合成 
． 数据加载 
． 数据标记与损失函数构建 
．． 数据标记 
．． 损失函数 
． 模型搭建与训练 
． 模型预测 
． 小结 
第章 图像分割 
． 数据加载 
． 模型搭建 
． 模型训练 
． 模型展示 
． 智能弹幕 
． 像素级回归问题：超分辨率重建 
．． 超分辨率重建算法的发展 
．． 数据加载 
．． 模型搭建与训练 
．． 模型展示 
． 小结 
第章 图像搜索 
． 分类网络的特征 
． 深度学习人脸识别技术 
．． FaceNet 
．． CosFace 和ArcFace 
． 数据处理 
．． 数据下载 
．． 数据检查 
．． 数据提取 
． 模型训练 
．． 普通分类模型 
．． CosFace 
． 图像搜索 
．． 图像比对 
．． KD-Tree 搜索 
． 小结 
第章 图像压缩 
． AutoEncoder 
．． AutoEncoder 的原理 
．． AutoEncoder 模型搭建 
．． 数据加载 
．． 模型训练 
．． 结果展示 
． GAN 
．． GAN 原理 
．． GAN 训练流程 
．． GAN 随机生成人脸图片 
．． GAN 与AutoEncoder 的结合 
．． 图像修复 
． 小结 
第章 不定长文本识别 
． 循环神经网络概述 
． 时间序列预测 
．． 创建模型 
．． 生成数据 
．． 模型训练 
．． 模型预测 
． CRNN 模型 
．． CRNN 算法简介 
．． CTCLoss 函数 
．． 模型结构 
．． 数据预处理 
．． 模型训练 
．． 模型预测 
． 小结 
第 章 神经网络压缩与部署 
． 剪枝 
．． 模型设计 
．． 训练基础模型 
．． 模型稀疏化 
．． 压缩模型通道 
． 量化 
． 混合精度训练 
． 深度学习模型的服务端部署 
．． 创建接口 
．． 访问接口 
． 小结 
・ ・ ・ ・ ・ ・ (收起)前言
作者简介
审校者简介
第章　OpenCV入门
.　了解人类视觉系统
.　人类如何理解图像内容
.　你能用OpenCV做什么
..　内置数据结构和输入/输出
..　图像处理操作
..　GUI
..　视频分析
..　D重建
..　特征提取
..　对象检测
..　机器学习
..　计算摄影
..　形状分析
..　光流算法
..　人脸和对象识别
..　表面匹配
..　文本检测和识别
..　深度学习
.　安装OpenCV
..　Windows
..　Mac OS X
..　Linux
.　总结
第章　OpenCV基础知识导论
.　技术要求
.　基本CMake配置文件
.　创建一个库
.　管理依赖项
.　让脚本更复杂
.　图像和矩阵
.　读/写图像
.　读取视频和摄像头
.　其他基本对象类型
..　Vec对象类型
..　Scalar对象类型
..　Point对象类型
..　Size对象类型
..　Rect对象类型
..　RotatedRect对象类型
.　基本矩阵运算
.　基本数据存储
.　总结
第章　学习图形用户界面
.　技术要求
.　OpenCV用户界面介绍
.　OpenCV的基本图形用户界面
.　Qt图形用户界面
.　OpenGL支持
.　总结
第章　深入研究直方图和滤波器
.　技术要求
.　生成CMake脚本文件
.　创建图形用户界面
.　绘制直方图
.　图像颜色均衡
.　Lomography效果
.　卡通效果
.　总结
第章　自动光学检查、对象分割和检测
.　技术要求
.　隔离场景中的对象
.　为AOI创建应用程序
.　预处理输入图像
..　噪声消除
..　用光模式移除背景进行分割
..　阈值
.　分割输入图像
..　连通组件算法
..　findContours算法
.　总结
第章　学习对象分类
.　技术要求
.　机器学习概念介绍
.　计算机视觉和机器学习工作流程
.　自动对象检查分类示例
..　特征提取
..　训练SVM模型
..　输入图像预测
.　总结
第章　检测面部部位与覆盖面具
.　技术要求
.　了解Haar级联
.　什么是积分图像
.　在实时视频中覆盖面具
.　戴上太阳镜
.　跟踪鼻子、嘴巴和耳朵
.　总结
第章　视频监控、背景建模和形态学操作
.　技术要求
.　理解背景减除
.　直接的背景减除
.　帧差分
.　高斯混合方法
.　形态学图像处理
.　使形状变细
.　使形状变粗
.　其他形态运算符
..　形态开口
..　形态闭合
..　绘制边界
..　礼帽变换
..　黑帽变换
.　总结
第章　学习对象跟踪
.　技术要求
.　跟踪特定颜色的对象
.　构建交互式对象跟踪器
.　用Harris角点检测器检测点
.　用于跟踪的好特征
.　基于特征的跟踪
..　Lucas-Kanade方法
..　Farneback算法
.　总结
第章　开发用于文本识别的分割算法
.　技术要求
.　光学字符识别介绍
.　预处理阶段
..　对图像进行阈值处理
..　文本分割
.　在你的操作系统上安装Tesseract OCR
..　在Windows上安装Tesseract
..　在Mac上安装Tesseract
.　使用Tesseract OCR库
.　总结
第章　用Tesseract进行文本识别
.　技术要求
.　文本API的工作原理
..　场景检测问题
..　极值区域
..　极值区域过滤
.　使用文本API
..　文本检测
..　文本提取
..　文本识别
.　总结
第章　使用OpenCV进行深度学习
.　技术要求
.　深度学习简介
..　什么是神经网络，我们如何从数据中学习
..　卷积神经网络
.　OpenCV中的深度学习
.　YOLO用于实时对象检测
..　YOLO v深度学习模型架构
..　YOLO数据集、词汇表和模型
..　将YOLO导入OpenCV
.　用SSD进行人脸检测
..　SSD模型架构
..　将SSD人脸检测导入OpenCV
.　总结
・ ・ ・ ・ ・ ・ (收起)译者序
前言
作者简介
审校者简介
译者简介
第章　安装OpenCV 
.　选择和使用合适的安装工具 
..　在Windows上安装 
..　在OS X系统中安装 
..　在Ubuntu及其衍生版本中安装 
..　在其他类Unix系统中安装 
.　安装Contrib模块 
.　运行示例 
.　查找文档、帮助及更新 
.　总结 
第章　处理文件、摄像头和图形用户界面 
.　基本I/O脚本 
..　读/写图像文件 
..　图像与原始字节之间的转换 
..　使用numpy.array访问图像数据 
..　视频文件的读/写 
..　捕获摄像头的帧 
..　在窗口显示图像 
..　在窗口显示摄像头帧 
.　Cameo项目（人脸跟踪和图像处理） 
.　Cameo―面向对象的设计 
..　使用managers. CaptureManager提取视频流 
..　使用managers.WindowManager抽象窗口和键盘 
..　cameo.Cameo的强大实现 
.　总结 
第章　使用OpenCV 处理图像 
.　不同色彩空间的转换 
.　傅里叶变换 
..　高通滤波器 
..　低通滤波器 
.　创建模块 
.　边缘检测 
.　用定制内核做卷积 
.　修改应用 
.　Canny边缘检测 
.　轮廓检测 
.　边界框、最小矩形区域和最小闭圆的轮廓 
.　凸轮廓与Douglas-Peucker算法 
.　直线和圆检测 
..　直线检测 
..　圆检测 
.　检测其他形状 
.　总结 
第章　深度估计与分割 
.　创建模块 
.　捕获深度摄像头的帧 
.　从视差图得到掩模 
.　对复制操作执行掩模 
.　使用普通摄像头进行深度估计 
.　使用分水岭和GrabCut算法进行物体分割 
..　用GrabCut进行前景检测的例子 
..　使用分水岭算法进行图像分割 
.　总结 
第章　人脸检测和识别 
.　Haar级联的概念 
.　获取Haar级联数据 
.　使用OpenCV进行人脸检测 
..　静态图像中的人脸检测 
..　视频中的人脸检测 
..　人脸识别 
.　总结 
第章　图像检索以及基于图像描述符的搜索 
.　特征检测算法 
..　特征定义 
..　使用DoG和SIFT进行特征提取与描述 
..　使用快速Hessian算法和SURF来提取和检测特征 
..　基于ORB的特征检测和特征匹配 
..　ORB特征匹配 
..　K-最近邻匹配 
..　FLANN匹配 
..　FLANN的单应性匹配 
..　基于文身取证的应用程序示例 
.　总结 
第章　目标检测与识别 
.　目标检测与识别技术 
..　HOG描述符 
..　检测人 
..　创建和训练目标检测器 
.　汽车检测 
..　代码的功能 
..　SVM和滑动窗口 
.　总结 
第章　目标跟踪 
.　检测移动的目标 
.　背景分割器：KNN、MOG和GMG 
..　均值漂移和CAMShift 
..　彩色直方图 
..　返回代码 
.　CAMShift 
.　卡尔曼滤波器 
..　预测和更新 
..　范例 
..　一个基于行人跟踪的例子 
..　Pedestrian类 
..　主程序 
.　总结 
第章　基于OpenCV的神经网络简介 
.　人工神经网络 
.　人工神经网络的结构 
..　网络层级示例 
..　学习算法 
.　OpenCV中的ANN 
..　基于ANN的动物分类 
..　训练周期 
.　用人工神经网络进行手写数字识别 
..　MNIST―手写数字数据库 
..　定制训练数据 
..　初始参数 
..　迭代次数 
..　其他参数 
..　迷你库 
..　主文件 
.　可能的改进和潜在的应用 
..　改进 
..　应用 
.　总结 
・ ・ ・ ・ ・ ・ (收起)第  部分 基于 OpenCV 的传统视觉应用
第  章 图像生成 /
. 图像显示 /
.. 使用 OpenCV 显示图像 /
.. 使用 Matplotlib 显示图像 /
.. 案例实现――使用OpenCV 显示图像 /
.. 案例实现――使用Matplotlib 显示图像 /
. 图像读取 /
.. 使用 OpenCV 读取图像 /
.. 使用 Matplotlib 读取图像 /
.. 案例实现――使用OpenCV 读取图像 /
.. 案例实现――使用Matplotlib 读取图像 /
. 图像保存 /
.. 使用 OpenCV 保存图像 /
.. 使用 Matplotlib 保存图像/
.. 案例实现――使用OpenCV 保存图像 /
.. 案例实现――使用Matplotlib 保存图像 /
本章总结 /
作业与练习 /
第  章 OpenCV 图像处理（） /
. 图像模糊 /
.. 均值滤波 /
.. 中值滤波 /
.. 高斯滤波 /
.. 案例实现 /
. 图像锐化 /
.. 图像锐化简介 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 OpenCV 图像处理（） /
. OpenCV 绘图 /
.. 使用 OpenCV 绘制各种图形 /
.. 案例实现 /
. 图像的几何变换 /
.. 几何变换操作 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像特征检测 /
. 边缘编辑和增强 /
.. Canny 边缘检测简介 /
.. 案例实现 /
. 图像轮廓检测 /
.. 轮廓查找步骤 /
.. 查找轮廓函数 /
.. 绘制轮廓函数 /
.. 案例实现 /
. 图像角点和线条检测 /
.. 角点的定义 /
.. Harris 角点简介 /
.. Harris 角点检测函数 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像特征匹配 /
. ORB 关键点检测与匹配 /
.. FAST 算法 /
.. BRIEF 算法 /
.. 特征匹配 /
.. 代码流程 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像对齐与拼接 /
. 全景图像拼接 /
.. 全景图像的拼接原理 /
.. 算法步骤 /
.. Ransac 算法介绍 /
.. 全景图像剪裁 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 相机运动估计 /
. 双目相机运动估计 /
.. 相机测距流程 /
.. 双目相机成像模型 /
.. 极限约束 /
.. 双目测距的优势 /
.. 双目测距的难点 /
. 案例实现 /
本章总结 /
作业与练习 /
第  部分 基于机器学习和深度学习的视觉应用
第  章 基于 SVM 模型的手写数字识别/
. 手写数字识别 /
.. 手写数字图像 /
.. 图像处理 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 基于 HOG+SVM 的行人检测 /
. 行人检测 /
.. HOG+SVM /
.. 检测流程 /
.. 滑动窗口 /
.. 非极大值抑制 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 数据标注 /
. 目标检测数据标注 /
.. 数据收集与数据标注 /
.. 数据标注的通用规则 /
.. 案例实现 /
. 视频目标跟踪数据标注 /
.. 视频与图像数据标注的差异 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 水果识别 /
. LeNet- 模型的训练与评估 /
.. 卷积层 /
.. 池化层 /
.. ReLU 层 /
.. LeNet- 模型 /
.. Keras /
.. 案例实现 /
. LeNet- 模型的应用 /
.. 使用 OpenCV 操作摄像头 /
.. OpenCV 的绘图功能 /
.. OpenCV 绘图函数的常见参数 /
.. Keras 模型的保存和加载 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 病虫害识别 /
. 植物叶子病虫害识别 /
.. PlantVillage 数据集 /
.. 性能评估 /
.. 感受野 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 相似图像搜索 /
. 以图搜图 /
.. VGG 模型 /
.. H 模型文件 /
.. 案例实现 /
. 人脸识别 /
.. 人脸检测 /
.. 分析面部特征 /
.. 人脸识别特征提取 /
.. 人脸相似性比较 /
.. 案例实现 /
本章总结 /
作业与练习 /
第  章 多目标检测 /
. 人脸口罩佩戴检测 /
.. 目标检测 /
.. YOLO 模型 /
.. YOLOv 模型 /
.. YOLOv-Tiny 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 可采摘作物检测 /
. 番茄成熟度检测 /
.. 数据集 /
.. RCNN 模型 /
.. SPP-Net 模型 /
.. Fast-RCNN 模型 /
.. Faster-RCNN 模型 /
.. Mask-RCNN 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 智能照片编辑 /
. 图像自动着色 /
.. GAN 模型的基本结构与原理 /
.. 构建 GAN 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 超分辨率 /
. 图像超分辨率 /
.. SRGAN 模型的结构 /
.. SRGAN 模型的损失函数 /
.. SRGAN 模型的评价指标 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 医学图像分割 /
. 眼底血管图像分割 /
.. 图像分割 /
.. 语义分割 /
.. 全卷积神经网络 /
.. 反卷积 /
.. U-Net 模型 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 医学图像配准 /
. 头颈部 CT 图像配准 /
.. 图像配准方法 /
.. VoxelMorph 配准框架 /
.. TensorFlow-pixpix /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 视频内容分析 /
. 人体动作识别 /
.. 视频动作识别模型 /
.. UCF- 数据集 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 图像语义理解 /
. 视觉问答 /
.. 编码器-解码器模型 /
.. 光束搜索 /
. 案例实现 /
本章总结 /
作业与练习 /
第  部分 基于深度学习的新兴视觉应用
第  章 三维空间重建 /
. D-RN 算法 /
.. 算法简介 /
.. 算法的优势 /
.. 算法的结构 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 视频稳定 /
. 人脸视频稳定 /
.. MobileNet 模型 /
.. SSD 模型 /
.. MobileNet-SSD 模型 /
.. 模型评估 /
.. 实时影响 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 目标检测与跟踪 /
. 车辆检测与跟踪 /
.. UA-DETRAC 数据集 /
.. 目标跟踪 /
.. DeepSORT 目标跟踪 /
. 案例实现 /
本章总结 /
作业与练习 /
第  章 风格迁移 /
. 图像与视频风格迁移 /
.. 理解图像内容和图像风格 /
.. 图像重建 /
.. 风格重建 /
. 案例实现 /
本章总结 /
作业与练习 /
附录 A 企业级综合教学项目介绍 /
. 智慧停车场管理系统 /
.. 项目概述 /
.. 技能目标 /
. 智慧景区管理系统 /
.. 项目概述 /
.. 技能目标 /
. 智能考勤打卡系统 /
.. 项目概述 /
.. 技能目标 /
・ ・ ・ ・ ・ ・ (收起)出版者的话
译者序
前言
作者简介
第一部分预备知识
第章数据
.可视化
.离散化
..采样
..量化
.表示
.噪声
.本章小结
参考文献
习题
第章技术
.插值
..线性插值
..双线性插值
.几何相交
.本章小结
参考文献
习题
第二部分基于图像的视觉计算
第章卷积
.线性系统
..线性系统的响应
..卷积的性质
.线性滤波器
..全通、低通、带通和高通滤波器
..设计新滤波器
..二维滤波器的可分性
..相关和模式匹配
.实现细节
.本章小结
参考文献
习题
第章谱分析
.离散傅里叶变换
.极坐标
..性质
..信号分析示例
.频域的周期性
.混叠
.推广到二维插值
..周期性的影响
..陷波器
..混叠效应示例
.对偶性
.本章小结
参考文献
习题
第章特征检测
.边缘检测
..边缘子检测器
..多分辨率边缘检测
..边缘子聚合
.特征检测
.其他非线性滤波器
.本章小结
参考文献
习题
第三部分基于几何的视觉计算
第章几何变换
.齐次坐标
.线性变换
.欧氏和仿射变换
..平移
..旋转
..缩放
..剪切
..一些现象
.变换的串联
..相对于中心点的缩放
..相对于任意轴的旋转
.坐标系
.串联的性质
.透视变换
.自由度
.非线性变换
.本章小结
参考文献
习题
第章针孔相机
.针孔相机模型
..相机标定
..三维深度估计
..单应性
.实际相机的一些考虑
.本章小结
参考文献
习题
第章对极几何
.背景
.多视几何中的匹配
.基础矩阵
..性质
..基础矩阵的估计
..仿前置双眼的相机设置
.本质矩阵
.整流
.应用对极几何
..根据视差恢复深度
..根据光流恢复深度
.本章小结
参考文献
习题
第四部分基于辐射度的视觉计算
第章光照
.辐射度学
..双向反射分布函数
..光传播方程
.光度学与色彩
..CIE XYZ色彩空间
..CIE XYZ空间的认知结构
..认知一致色彩空间
.本章小结
参考文献
习题
第章色彩还原
.加性色彩混合的建模
..设备的色域
..色调映射算子
..强度分辨率
..显示器示例
.色彩管理
..色域变换
..色域匹配
.减性色彩混合的建模
.局限性
..高动态范围成像
..多光谱成像
.本章小结
参考文献
习题
第章光度处理
.直方图处理
.图像融合
..图像混合
..图像割
.光度立体视觉
..阴影处理
..光照方向计算
..色彩处理
.本章小结
参考文献
习题
第五部分视觉内容合成
第章多样化域
.建模
.处理
.渲染
.应用
.本章小结
参考文献
第章交互式图形流程
.顶点的几何变换
..模型变换
..视图变换
..透视投影变换
..遮挡处理
..窗口坐标变换
..最终变换
.裁剪和属性的顶点插值
.光栅化和属性的像素插值
.本章小结
参考文献
习题
第章真实感与性能
.光照
.着色
.阴影
.纹理贴图
..纹理至对象空间映射
..对象至屏幕空间映射
..分级细化贴图
.凹凸贴图
.环境贴图
.透明度
.累积缓存
.背面剔除
.可见性剔除
..包围体
..空间细分
..其他用途
.本章小结
参考文献
习题
第章图形编程
.图形处理单元的发展
.图形API和程序库的发展
.现代GPU和CUDA
..GPU架构
..CUDA编程模型
..CUDA存储模型
.本章小结
参考文献
・ ・ ・ ・ ・ ・ (收起)第 章 图像的获取和表示
． 图像传感器技术 
．． 传感器材料 
．． 传感器光电二极管元件 
．． 传感器配置：马赛克、Foveon和BSI 
．． 动态范围、噪声和超分辨率 
．． 传感器处理 
．． 去马赛克 
．． 坏像素校正 
．． 色彩和光照校正 
．． 几何校正 
． 照相机和计算成像 
．． 计算成像概述 
．． 单像素可计算相机 
．． 二维可计算照相机 
．． 三维深度的照相机系统 
． 三维深度处理 
．． 方法概述 
．． 深度感知和处理中存在的问题 
．． 单目深度处理 
． 三维表示：体元、深度图、网格和点云 
． 总结 
． 习题 
第 章 图像预处理 
． 图像处理概述 
． 图像预处理要解决的问题 
．． 计算机视觉的流程和图像预处理 
．． 图像校正 
．． 图像增强 
．． 为特征提取准备图像 
． 图像处理方法分类 
．． 点运算 
．． 直线运算 
．． 区域运算 
．． 算法 
．． 数据转换 
． 色彩学 
．． 色彩管理系统概述 
．． 光源、白点、黑点和中性轴 
．． 设备颜色模型 
．． 色彩空间与色彩感知 
．． 色域映射与渲染的目标 
．． 色彩增强的实际考虑 
．． 色彩的准确度与精度 
． 空间滤波 
．． 卷积滤波与检测 
．． 核滤波与形状选择 
．． 点滤波 
．． 噪声与伪像滤波 
．． 积分图与方框滤波器 
． 边缘检测器 
．． 核集合 
．． Canny检测器 
． 变换滤波、Fourier变换及其他 
．． Fourier变换 
．． 其他变换 
． 形态学与分割 
．． 二值形态学 
．． 灰度和彩色形态学 
．． 形态学优化和改进 
．． 欧氏距离映射 
．． 超像素分割 
．． 深度图分割 
．． 色彩分割 
． 阈值化 
．． 全局阈值化 
．． 局部阈值化 
． 总结 
． 习题 
第章 全局特征和区域特征 
． 视觉特征的历史概述 
．． 全局度量、区域度量和局部度量的核心思想 
．． 纹理分析 
．． 统计方法 
． 纹理区域度量 
．． 边缘度量 
．． 互相关性和自相关性 
．． Fourier谱、小波和基签名 
．． 共生矩阵、Haralick特征 
．． Laws纹理度量 
．． LBP局部二值模式 
．． 动态纹理 
． 统计区域度量 
．． 图像矩特征 
．． 点度量特征 
．． 全局直方图 
．． 局部区域直方图 
．． 散点图、D直方图 
．． 多分辨率、多尺度直方图 
．． 径向直方图 
．． 轮廓或边缘直方图 
． 基空间度量 
．． Fourier描述 
．． Walsh-Hadamard变换 
．． HAAR变换 
．． 斜变换 
．． Zernike多项式 
．． 导向滤波器 
．． Karhunen-Loeve变换与Hotelling变换 
．． 小波变换和Gabor滤波器 
．． Hough变换与Radon变换 
． 总结 
． 习题 
第章 局部特征设计 
． 局部特征 
．． 检测器、兴趣点、关键点、锚点和特征点 
．． 描述子、特征描述和特征提取 
．． 稀疏局部模式方法 
． 局部特征属性 
．． 选择特征描述子和兴趣点 
．． 特征描述子和特征匹配 
．． 好特征的标准 
．． 可重复性，困难和容易的查找 
．． 判别性与非判别性 
．． 相对位置和绝对位置 
．． 匹配代价和一致性 
． 距离函数 
．． 距离函数的早期工作 
．． 欧氏或笛卡儿距离度量 
．． 网格距离度量 
．． 基于统计学的差异性度量 
．． 二值或布尔距离度量 
． 描述子的表示 
．． 坐标空间和复合空间 
．． 笛卡儿坐标 
．． 极坐标和对数极坐标 
．． 径向坐标 
．． 球面坐标 
．． Gauge坐标 
．． 多元空间和多模数据 
．． 特征金字塔 
． 描述子的密度 
．． 丢弃兴趣点和描述子 
．． 稠密与稀疏特征描述 
． 描述子形状 
．． 关联性模板 
．． 块和形状 
．． 对象多边形 
． 局部二值描述子与点对模式 
．． FREAK视网膜模式 
．． BRISK模式 
．． ORB和BRIEF模式 
． 描述子的判别性 
．． 谱的判别性 
．． 区域、形状和模式的判别性 
．． 几何判别因素 
．． 通过特征可视化来评价判别性 
．． 精度与可跟踪性 
．． 精度优化、子区域重叠、Gaussian加权和池化 
．． 亚像素精度 
． 搜索策略与优化 
．． 密集搜索 
．． 网格搜索 
．． 多尺度金字塔搜索 
．． 尺度空间和图像金字塔 
．． 特征金字塔 
．． 稀疏预测搜索与跟踪 
．． 跟踪区域限制搜寻 
．． 分割限制搜索 
．． 深度或Z限制搜索 
． 计算机视觉、模型和结构 
．． 特征空间 
．． 对象模型 
．． 约束 
．． 选择检测器和特征 
．． 训练概述 
．． 特征和对象的分类 
．． 特征学习、稀疏编码和卷积网络 
． 总结 
． 习题 
第章 特征描述属性的分类 
． 一般的鲁棒性分类 
． 一般的视觉度量分类 
． 特征度量评估 
．． SIFT的示例 
．． LBP的示例 
．． 形状因子的示例 
． 总结 
． 习题 
第章 兴趣点检测与特征描述子 
． 兴趣点调整 
． 兴趣点的概念 
． 兴趣点方法概述 
．． Laplacian和LoG 
．． Moravac角点检测器 
．． Harris方法、Harris-Stephens、Shi-Tomasi和Hessian类型的检测器 
．． Hessian矩阵检测器和Hessian-Laplace 
．． Gaussian差 
．． 显著性区域 
．． SUSAN、Trajkovic-Hedly 
．． FAST 
．． 局部曲率方法 
．． 形态兴趣区域 
． 特征描述简介 
．． 局部二值描述子 
．． Census 
．． 改进的Census变换 
．． BRIEF 
．． ORB 
．． BRISK 
．． FREAK 
． 谱描述子 
．． SIFT 
．． SIFT-PCA 
．． SIFT-GLOH 
．． SIFT-SIFER 
．． SIFT CS-LBP 
．． ROOTSIFT 
．． CenSurE和STAR 
．． 相关模板 
．． HAAR特征 
．． 使用类HAAR特征的Viola和Jones算法 
．． SURF 
．． 改进的SURF算法 
．． 梯度直方图（HOG）及改进方法 
．． PHOG和相关方法 
．． Daisy和O-Daisy 
．． CARD 
．． 具有鲁棒性的快速特征匹配 
．． RIFF和CHOG 
．． 链码直方图 
．． D-NETS 
．． 局部梯度模式 
．． 局部相位量化 
． 基空间描述子 
．． Fourier描述子 
．． 用其他基函数来构建描述子 
．． 稀疏编码方法 
． 多边形形状描述 
．． MSER方法 
．． 针对斑点和多边形的目标形状度量 
．． 形状上下文 
． D和D描述子 
．． D HOG 
．． HON D 
．． D SIFT 
． 总结 
． 习题 
第章 基准数据、内容、度量和分析 
． 基准数据 
． 先前关于基准数据方面的工作：艺术与科学 
．． 质量的一般度量 
．． 算法性能的度量 
．． Rosin关于角点方面的工作 
． 构造基准数据的关键问题 
．． 内容：采用、修改或创建 
．． 可用的基准数据集 
．． 拟合基准数据的算法 
．． 场景构成和标注 
． 定义目标和预期 
．． Mikolajczyk和Schmid的方法 
．． 开放式评价系统 
．． 极端情况和限制 
．． 兴趣点和特征 
． 基准数据的鲁棒性准则 
．． 举例说明鲁棒性标准 
．． 将鲁棒性标准用于实际应用 
． 度量与基准数据配对 
．． 兴趣点、特征和基准数据的配对和优化 
．． 一般的视觉分类例子 
． 合成的特征字母表 
．． 合成数据集的目标 
．． 合成兴趣点字母表 
．． 将合成字母表叠加到真实图像上 
． 总结 
． 习题 
第章 可视流程及优化 
． 阶段、操作和资源 
． 计算资源预算 
．． 计算单元、ALU和加速器 
．． 能耗的使用 
．． 内存的利用 
．． I O性能 
． 计算机视觉流程的实例 
．． 汽车识别 
．． 人脸检测、情感识别和年龄识别 
．． 图像分类 
．． 增强现实 
． 可选的加速方案 
．． 内存优化 
．． 粗粒度并行 
．． 细粒度数据并行 
．． 高级指令集和加速器 
． 视觉算法的优化与调整 
．． 编译器优化与手工优化 
．． 特征描述子改进、检测器和距离函数 
．． Boxlets与卷积加速 
．． 数据类型优化（整数与浮点） 
． 优化资源 
． 总结 
第章 特征学习的架构分类和神经科学背景 
． 计算机视觉中的神经科学思想 
． 特征生成与特征学习 
． 计算机视觉中所使用的神经科学术语 
． 特征学习的分类 
．． 卷积特征权重学习 
．． 局部特征描述子学习 
．． 基本特征的组合和字典学习 
．． 特征学习方法总结 
． 计算机视觉中的机器学习模型 
．． 专家系统 
．． 统计和数学分析方法 
．． 受神经科学启发的方法 
．． 深度学习 
． 机器学习和特征学习的历史 
．． 历史回顾：世纪年代至世纪初 
．． 人工神经网络（ANN）分类 
． 特征学习概述 
．． 通过学习得到的各类描述子 
．． 层次特征学习 
．． 要学习多少特征 
．． 深度神经网络的优势 
．． 特征编码的有效性 
．． 手工设计的特征与深度学习 
．． 特征学习的不变性和鲁棒性 
．． 最好的特征和学习架构 
．． 大数据、分析和计算机视觉的统一 
．． 关键技术的推动因素 
． 神经科学的概念 
．． 生物学及其整体结构 
．． 难以找到统一的学习理论 
．． 人类视觉系统的架构 
． 特征学习的结构分类 
．． 架构拓扑 
．． 架构组件和层 
． 总结 
． 习题 
第 章 特征学习和深度学习架构概述 
． 架构概述 
．． FNN架构简介 
．． RNN的结构简介 
．． BFN的结构简介 
． 集成方法 
． 深度神经网络的未来 
．． 增加最大深度―深度残差学习 
．． 使用更简单的MLP来近似复杂模型（模型压缩） 
．． 分类器的分解与重组 
． 总结 
． 习题 
附录A 合成特征分析 
附录B 基准数据集概述 
附录C 成像和计算机视觉资源 
附录D 扩展SDM准则 
附录E 视觉基因组模型（VGM） 
参考文献 
译后记 
・ ・ ・ ・ ・ ・ (收起)目　录
第章　人工智能的发展概况　
．　人工智能的诞生与初兴　
．　人工智能的复兴与计算机视觉的初露端倪　
．　数据被重视，人工智能崛起　
第　章 数据标注行业的国内现状与未来展望　
．　国内数据标注行业的现状　
．　数据标注工程师简介　
．　数据标注行业的发展前景　
第　章 人工智能治理　
．　人工智能的可持续发展　
．　数据是AI治理的第一道防火墙　
．　数据服务产业是AI治理落地的试验田　
．．　数据来源的合法合规问题　
．．　技术的安全性　
．．　问责机制　
．　旷视，AI发展与治理双轮驱动　
第章　数据标注服务产品及旷视Data++数据标注平台　
．　数据标注服务产品　
．　数据服务标注平台流程　
．．　创建项目　
．．　数据上传　
．．　项目发布　
．．　项目交付　
．　旷视Data++数据标注平台　
．．　用户注册　
．．　标注操作流程　
第章　通用标注工具　
．　行人属性筛选　
．．　行人属性筛选定义　
．．　行人属性筛选工具介绍　
．．　行人属性筛选分类　
．．　标注注意事项　
．．　标注难点　
．．　实际中的应用　
．．　思考与讨论　
．．　行人属性筛选工具现状及展望　
．．　小结　
．　属性标注　
．．　属性标注工具介绍　
．．　标注内容　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　属性标注在Objects中的应用　
．．　小结　
．　框+属性　
．．　“框+属性”工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　小实验　
．．　小结　
．　多边形+属性　
．．　多边形+属性工具介绍　
．．　标注标准　
．．　标注难点　
．．　“多边形+属性”工具在生活中的应用　
．．　小结　
第章　检测标注工具　
．　人脸点　
．．　人脸关键点检测定义　
．．　人脸点工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　小实验　
．．　人脸点工具现状及展望　
．．　小结　
．　人体骨骼点　
．．　人体骨骼点点定义　
．．　人体骨骼点工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　人体骨骼点工具现状及未来展望　
．．　小结　
．　手部关键点　
．．　手部关键点点定义　
．．　手部关键点标注工具介绍　
．．　标注方法　
．．　标注难点　
．．　手部关键点标注提升方法　
．．　生活中的应用　
．．　手部关键点工具现状及展望　
．．　小结　
第章　识别标注工具　
．　一人所属照片清洗　
．．　一人所属照片清洗工具介绍　
．．　标注方法　
．．　标注难点　
．．　一人所属照片清洗工具在生活中的应用　
．．　照片清洗工具现状　
．．　小实验　
．．　小结　
．　行人重识别　
．．　行人重识别合并标注工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　行人重识别技术现状与发展　
．．　小结　
第章　其他标注工具　
．　视频人脸点　
．．　视频人脸点工具介绍　
．．　标注方法　
．．　生活中的应用　
．．　视频人脸点工具的现状与发展　
．．　小结　
．　人脸D朝向　
．．　人脸D朝向工具　
．．　人脸D朝向工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　人脸D朝向工具现状与展望　
．．　小结　
．　精细分割　
．．　人像抠图工具介绍　
．．　标注方法　
．．　标注难点　
．．　生活中的应用　
．．　精细分割标注工具的现状与发展　
．．　小结　
声明　
・ ・ ・ ・ ・ ・ (收起)第部分 基础知识导读篇
第章 数字图像基础 
. 图像表示基础 
.. 艺术与生活 
.. 数字图像 
.. 二值图像的处理 
.. 像素值的范围 
.. 图像索引 
. 彩色图像的表示 
. 应用基础 
.. 量化 
.. 特征 
.. 距离 
.. 图像识别 
.. 信息隐藏 
. 智能图像处理基础 
. 抽象 
第章 Python基础 
. 如何开始 
. 基础语法 
.. 变量的概念 
.. 变量的使用 
. 数据类型 
.. 基础类型 
.. 列表 
.. 元组 
.. 字典 
. 选择结构 
. 循环结构 
. 函数 
.. 什么是函数 
.. 内置函数 
.. 自定义函数 
. 模块 
.. 标准模块 
.. 第三方模块 
.. 自定义模块 
第章 OpenCV基础 
. 基础 
.. 安装OpenCV 
.. 读取图像 
.. 显示图像 
.. 保存图像 
. 图像处理 
.. 像素处理 
.. 通道处理 
.. 调整图像大小 
. 感兴趣区域 
. 掩模 
.. 掩模基础及构造 
.. 乘法运算 
.. 逻辑运算 
.. 掩模作为函数参数 
. 色彩处理 
.. 色彩空间基础 
.. 色彩空间转换 
.. 获取皮肤范围 
. 滤波处理 
.. 均值滤波 
.. 高斯滤波 
.. 中值滤波 
. 形态学 
.. 腐蚀 
.. 膨胀 
.. 通用形态学函数 
第部分 基础案例篇
第章 图像加密与解密 
. 加密与解密原理 
. 图像整体加密与解密 
. 脸部打码及解码 
.. 掩模方式实现 
.. ROI方式实现 
第章 数字水印 
. 位平面 
. 数字水印原理 
. 实现方法 
. 具体实现 
. 可视化水印 
.. ROI 
.. 加法运算 
. 扩展学习 
.. 算术运算实现数字水印 
.. 艺术字 
第章 物体计数 
. 理论基础 
.. 如何计算图像的中心点 
.. 获取图像的中心点 
.. 按照面积筛选前景对象 
. 核心程序 
.. 核函数 
.. zip函数 
.. 阈值处理函数threshold 
. 程序设计 
. 实现程序 
第章 缺陷检测 
. 理论基础 
.. 开运算 
.. 距离变换函数distanceTransform 
.. 最小包围圆形 
.. 筛选标准 
. 程序设计 
. 实现程序 
第章 手势识别 
. 理论基础 
.. 获取凸包 
.. 凸缺陷 
.. 凸缺陷占凸包面积比 
. 识别过程 
.. 识别流程 
.. 实现程序 
. 扩展学习：石头、剪刀、布的识别 
.. 形状匹配 
.. 实现程序 
第章 答题卡识别 
. 单道题目的识别 
.. 基本流程及原理 
.. 实现程序 
. 整张答题卡识别原理 
.. 图像预处理 
.. 答题卡处理 
.. 筛选出所有选项 
.. 将选项按照题目分组 
.. 处理每一道题目的选项 
.. 显示结果 
. 整张答题卡识别程序 
第章 隐身术 
. 图像的隐身术 
.. 基本原理与实现 
.. 实现程序 
.. 问题及优化方向 
. 视频隐身术 
第章 以图搜图 
. 原理与实现 
.. 算法原理 
.. 感知哈希值计算方法 
.. 感知哈希值计算函数 
.. 计算距离 
.. 计算图像库内所有图像的哈希值 
.. 结果显示 
. 实现程序 
. 扩展学习 
第章 手写数字识别 
. 基本原理 
. 实现细节 
. 实现程序 
. 扩展阅读 
第章 车牌识别 
. 基本原理 
.. 提取车牌 
.. 分割车牌 
.. 识别车牌 
. 实现程序 
. 下一步学习 
第章 指纹识别 
. 指纹识别基本原理 
. 指纹识别算法概述 
.. 描述关键点特征 
.. 特征提取 
.. MCC匹配方法 
.. 参考资料 
. 尺度不变特征变换 
.. 尺度空间变换 
.. 关键点定位 
.. 通过方向描述关键点 
.. 显示关键点 
. 基于SIFT的指纹识别 
.. 距离计算 
.. 特征匹配 
.. 算法及实现程序 
第部分 机器学习篇
第章 机器学习导读 
. 机器学习是什么 
. 机器学习基础概念 
.. 机器学习的类型 
.. 泛化能力 
.. 数据集的划分 
.. 模型的拟合 
.. 性能度量 
.. 偏差与方差 
. OpenCV中的机器学习模块 
.. 人工神经网络 
.. 决策树 
.. EM模块 
.. K近邻模块 
.. logistic回归 
.. 贝叶斯分类器 
.. 支持向量机 
.. 随机梯度下降 SVM 分类器 
. OpenCV机器学习模块的使用 
.. 使用KNN模块分类 
.. 使用SVM模块分类 
第章 KNN实现字符识别 
. 手写数字识别 
. 英文字母识别 
第章 求解数独图像 
. 基本过程 
. 定位数独图像内的单元格 
. 构造KNN模型 
. 识别数独图像内的数字 
. 求解数独 
. 绘制数独求解结果 
. 实现程序 
. 扩展学习 
第章 SVM数字识别 
. 基本流程 
. 倾斜校正 
. HOG特征提取 
. 数据处理 
. 构造及使用SVM分类器 
. 实现程序 
. 参考学习 
第章 行人检测 
. 方向梯度直方图特征 
. 基础实现 
.. 基本流程 
.. 实现程序 
. 函数detectMultiScale参数及优化 
.. 参数winStride 
.. 参数padding 
.. 参数scale 
.. 参数useMeanshiftGrouping 
. 完整程序 
. 参考学习 
第章 K均值聚类实现艺术画 
. 理论基础 
.. 案例 
.. K均值聚类的基本步骤 
. K均值聚类模块 
. 艺术画 
第部分 深度学习篇
第章 深度学习导读 
. 从感知机到人工神经网络 
.. 感知机 
.. 激活函数 
.. 人工神经网络 
.. 完成分类 
. 人工神经网络如何学习 
. 深度学习是什么 
.. 深度的含义 
.. 表示学习 
.. 端到端 
.. 深度学习可视化 
. 激活函数的分类 
.. sigmoid函数 
.. tanh函数 
.. ReLU函数 
.. Leaky ReLU函数 
.. ELU函数 
. 损失函数 
.. 为什么要用损失值 
.. 损失值如何起作用 
.. 均方误差 
.. 交叉熵误差 
. 学习的技能与方法 
.. 全连接 
.. 随机失活 
.. One-hot编码 
.. 学习率 
.. 正则化 
.. mini-batch方法 
.. 超参数 
. 深度学习游乐场 
第章 卷积神经网络基础 
. 卷积基础 
. 卷积原理 
.. 数值卷积 
.. 图像卷积 
.. 如何获取卷积核 
. 填充和步长 
. 池化操作 
. 感受野 
. 预处理与初始化 
.. 扩充数据集 
.. 标准化与归一化 
.. 网络参数初始化 
. CNN 
.. LeNet 
.. AlexNet 
.. VGG网络 
.. NiN 
.. GooLeNet 
.. 残差网络 
第章 DNN模块 
. 工作流程 
. 模型导入 
. 图像预处理 
. 推理相关函数 
第章 深度学习应用实践 
. 图像分类 
.. 图像分类模型 
.. 实现程序 
. 目标检测 
.. YOLO 
.. SSD 
. 图像分割 
.. 语义分割 
.. 实例分割 
. 风格迁移 
. 姿势识别 
. 说明 
第部分 人脸识别篇
第章 人脸检测 
. 基本原理 
. 级联分类器的使用 
. 函数介绍 
. 人脸检测实现 
. 表情检测 
第章 人脸识别 
. 人脸识别基础 
.. 人脸识别基本流程 
.. OpenCV人脸识别基础 
. LBPH人脸识别 
.. 基本原理 
.. 函数介绍 
.. 案例介绍 
. EigenFaces人脸识别 
.. 基本原理 
.. 函数介绍 
.. 案例介绍 
. FisherFaces人脸识别 
.. 基本原理 
.. 函数介绍 
.. 案例介绍 
. 人脸数据库 
第章 dlib库 
. 定位人脸 
. 绘制关键点 
. 勾勒五官轮廓 
. 人脸对齐 
. 调用CNN实现人脸检测 
第章 人脸识别应用案例 
. 表情识别 
. 驾驶员疲劳检测 
. 易容术 
.. 仿射 
.. 算法流程 
.. 实现程序 
. 年龄和性别识别 
・ ・ ・ ・ ・ ・ (收起)第章 基于直方图优化的图像去雾技术 
. 案例背景 
. 理论基础 
.. 空域图像增强 
.. 直方图均衡化 
. 程序实现 
.. 设计GUI界面 
.. 全局直方图处理 
.. 局部直方图处理 
.. Retinex增强处理 
. 延伸阅读 
第章 基于形态学的权重自适应图像去噪 
. 案例背景 
. 理论基础 
.. 图像去噪的方法 
.. 数学形态学的原理 
.. 权重自适应的多结构形态学去噪 
. 程序实现 
. 延伸阅读 
第章 基于多尺度形态学提取眼前节组织 
. 案例背景 
. 理论基础 
. 程序实现 
.. 多尺度结构设计 
.. 多尺度边缘提取 
.. 多尺度边缘融合 
. 延伸阅读 
第章 基于Hough变化的答题卡识别 
. 案例背景 
. 理论基础 
.. 图像二值化 
.. 倾斜校正 
.. 图像分割 
. 程序实现 
.. 图像灰度化 
.. 灰度图像二值化 
.. 图像平滑滤波 
.. 图像矫正 
.. 完整性核查 
. 延伸阅读 
第章 基于阈值分割的车牌定位识别 
. 案例背景 
. 理论基础 
.. 车牌图像处理 
.. 车牌定位原理 
.. 车牌字符处理 
.. 车牌字符识别 
. 程序实现 
. 延伸阅读 
第章 基于分水岭分割进行肺癌诊断 
. 案例背景 
. 理论基础 
.. 模拟浸水的过程 
.. 模拟降水的过程 
.. 过度分割问题 
.. 标记分水岭分割算法 
. 程序实现 
. 延伸阅读 
第章 基于主成分分析的人脸二维码识别 
. 案例背景 
. 理论基础 
.. QR二维码简介 
.. QR二维码的编码和译码流程 
.. 主成分分析方法 
. 程序实现 
.. 人脸建库 
.. 人脸识别 
.. 人脸二维码 
. 延伸阅读 
第章 基于知识库的手写体数字识别 
. 案例背景 
. 理论基础 
.. 算法流程 
.. 特征提取 
.. 模式识别 
. 程序实现 
.. 图像处理 
.. 特征提取 
.. 模式识别 
. 延伸阅读 
.. 识别器选择 
.. 特征库改善 
第章 基于特征匹配的英文印刷字符识别 
. 案例背景 
. 理论基础 
.. 图像预处理 
.. 图像识别技术 
. 程序实现 
.. 界面设计 
.. 回调识别 
. 延伸阅读 
第章 基于不变矩的数字验证码识别 
. 案例背景 
. 理论基础 
. 程序实现 
.. 设计GUI界面 
.. 载入验证码图像 
.. 验证码图像去噪 
.. 验证码数字定位 
.. 验证码归一化 
.. 验证码数字识别 
.. 手动确认并入库 
.. 重新生成模板库 
. 延伸阅读 
第章 基于小波技术进行图像融合 
. 案例背景 
. 理论基础 
. 程序实现 
.. 设计GUI界面 
.. 图像载入 
.. 小波融合 
. 延伸阅读 
第章 基于块匹配的全景图像拼接 
. 案例背景 
. 理论基础 
.. 图像匹配 
.. 图像融合 
. 程序实现 
.. 设计GUI界面 
.. 载入图片 
.. 图像匹配 
.. 图像拼接 
. 延伸阅读 
第章 基于霍夫曼图像编码的图像压缩和重建 
. 案例背景 
. 理论基础 
.. 霍夫曼编码的步骤 
.. 霍夫曼编码的特点 
. 程序实现 
.. 设计GUI界面 
.. 压缩和重建 
.. 效果对比 
. 延伸阅读 
第章 基于主成分分析的图像压缩和重建 
. 案例背景 
. 理论基础 
.. 主成分降维分析原理 
.. 由得分矩阵重建样本 
.. 主成分分析数据压缩比 
.. 基于主成分分析的图像压缩 
. 程序实现 
.. 主成分分析的源代码 
.. 图像数组和样本矩阵之间的转换 
.. 基于主成分分析的图像压缩 
. 延伸阅读 
第章 基于小波的图像压缩技术 
. 案例背景 
. 理论基础 
. 程序实现 
. 延伸阅读 
第章 基于融合特征的以图搜图技术 
. 案例背景 
. 理论基础 
. 程序实现 
.. 图像预处理 
.. 计算特征 
.. 图像检索 
.. 结果分析 
. 延伸阅读 
第章 基于Harris的角点特征检测 
. 案例背景 
. 理论基础 
.. Harris的基本原理 
.. Harris算法的流程 
.. Harris角点的性质 
. 程序实现 
.. Harris算法的代码 
.. 角点检测实例 
. 延伸阅读 
第章 基于GUI搭建通用视频处理工具 
. 案例背景 
. 理论基础 
. 程序实现 
.. 设计GUI界面 
.. 实现GUI界面 
. 延伸阅读 
第章 基于语音识别的信号灯图像
模拟控制技术 
. 案例背景 
. 理论基础 
. 程序实现 
. 延伸阅读 
第章 基于帧间差法进行视频目标检测 
. 案例背景 
. 理论基础 
.. 帧间差分法 
.. 背景差分法 
.. 光流法 
. 程序实现 
. 延伸阅读 
第章 路面裂缝检测系统设计 
. 案例背景 
. 理论基础 
.. 图像灰度化 
.. 图像滤波 
.. 图像增强 
.. 图像二值化 
. 程序实现 
. 延伸阅读 
第章 基于K-means聚类算法的图像分割 
. 案例背景 
. 理论基础 
.. K-means聚类算法的原理 
.. K-means聚类算法的要点 
.. K-means聚类算法的缺点 
.. 基于K-means聚类算法进行图像分割 
. 程序实现 
.. 样本间的距离 
.. 提取特征向量 
.. 图像聚类分割 
. 延伸阅读 
第章 基于光流场的车流量计数应用 
. 案例背景 
. 理论基础 
.. 基于光流法检测运动的原理 
.. 光流场的主要计算方法 
.. 梯度光流场约束方程 
.. Horn-Schunck光流算法 
. 程序实现 
.. 计算视觉系统工具箱简介 
.. 基于光流法检测汽车运动 
. 延伸阅读 
第章 基于Simulink进行图像和视频处理 
. 案例背景 
. 模块介绍 
.. 分析和增强模块库（Analysis和Enhancement） 
.. 转化模块库（Conversions） 
.. 滤波模块库（Filtering） 
.. 几何变换模块库（Geometric Transformations） 
.. 形态学操作模块库（Morphological Operations） 
.. 输入模块库（Sources） 
.. 输出模块库（Sinks） 
.. 统计模块库（Statistics） 
.. 文本和图形模块库（Text 和 Graphic） 
.. 变换模块库（Transforms） 
.. 其他工具模块库（Utilities） 
. 仿真案例 
.. 搭建组织模型 
.. 仿真执行模型 
.. 自动生成报告 
. 延伸阅读 
第章 基于小波变换的数字水印技术 
. 案例背景 
. 理论基础 
.. 数字水印技术的原理 
.. 典型的数字水印算法 
.. 数字水印攻击和评价 
.. 基于小波的水印技术 
. 程序实现 
.. 准备载体和水印图像 
.. 小波数字水印的嵌入 
.. 小波数字水印的提取 
.. 小波水印的攻击试验 
. 延伸阅读 
第章 基于最小误差法的胸片分割技术 
. 案例背景 
. 理论基础 
.. 图像增强 
.. 区域选择 
.. 形态学滤波 
.. 基于最小误差法进行胸片分割 
. 程序实现 
.. 设计GUI界面 
.. 图像预处理 
.. 基于最小误差法进行图像分割 
.. 形态学后处理 
. 延伸阅读 
第章 基于区域生长的肝脏影像分割系统 
. 案例背景 
. 理论基础 
.. 阈值分割 
.. 区域生长 
.. 基于阈值预分割的区域生长 
. 程序实现 
. 延伸阅读 
第章 基于计算机视觉的自动驾驶应用 
. 案例背景 
. 理论基础 
.. 环境感知 
.. 行为决策 
.. 路径规划 
.. 运动控制 
. 程序实现 
.. 传感器数据载入 
.. 追踪器创建 
.. 碰撞预警 
. 延伸阅读 
第章 基于深度学习的汽车目标检测 
. 案例背景 
. 理论基础 
.. 基本架构 
.. 卷积层 
.. 池化层 
. 程序实现 
.. 加载数据 
.. 构建CNN 
.. 训练CNN 
.. 评估训练效果 
. 延伸阅读 
第章 基于深度学习的视觉场景
识别 
. 案例背景 
. 理论基础 
. 程序实现 
.. 环境配置 
.. 数据集制作 
.. 网络训练 
.. 网络测试 
. 延伸阅读 
第章 深度学习综合应用 
. 应用背景 
. 理论基础 
.. 分类识别 
.. 目标检测 
. 案例实现：基于CNN的数字识别 
.. 自定义CNN 
.. AlexNet 
.. 基于MATLAB进行实验设计 
.. 基于TensorFlow进行实验设计 
.. 实验小结 
. 案例实现：基于CNN的物体识别 
.. CIFAR-数据集 
.. VggNet 
.. ResNet 
.. 实验设计 
.. 实验小结 
. 案例实现：基于CNN的图像矫正 
.. 倾斜数据集 
.. 自定义CNN回归网络 
.. AlexNet回归网络 
.. 实验设计 
.. 实验小结 
. 案例实现：基于LSTM的时间序列分析 
.. 厄尔尼诺南方涛动指数数据 
.. 样条拟合分析 
.. 基于MATLAB进行LSTM分析 
.. 基于Keras进行LSTM分析 
.. 实验小结 
. 案例实现：基于深度学习的以图搜图技术 
.. 人脸的深度特征 
.. AlexNet的特征 
.. GoogleNet的特征 
.. 深度特征融合计算 
.. 实验设计 
.. 实验小结 . 案例实现：基于YOLO的交通目标检测应用 
.. 车辆目标的YOLO检测 
.. 交通标志的YOLO检测 
. 延伸阅读 
・ ・ ・ ・ ・ ・ (收起)Summary of Contents
Foreword 
Preface 
About the Authors 
 Introduction 
I Words
 Regular Expressions and Automata 
 Words and Transducers 　　 
 N-Grams 
 Part-of-Speech Tagging 　　 
 Hidden Markov and Maximum Entropy Models 
 Phonetics 
 Speech Synthesis 
 Automatic Speech Recognition 
 Speech Recognition: Advanced Topics 
 Computational Phonology 　　 
 Formal Grammars of English 　 
 Syntactic Parsing 
 Statistical Parsing 
 Features and Uni?cation 　　 
 Language and Complexity 　　 
IV Semantics and Pragmatics
 The Representation ofMeaning　 
 Computational Semantics 　　 
 Lexical Semantics　 
 Computational Lexical Semantics　 
 Computational Discourse 　　 
V Applications
 Information Extraction 　　 
 Question Answering and Summarization 
 Dialogue and Conversational Agents 
 Machine Translation 　　 
Bibliography 
Author Index 
Subject Index 
Contents
Foreword 
Preface 
About the Authors 
 Introduction 
. Knowledge in Speech and Language Processing 　 
. Ambiguity 
. Models andAlgorithms 
. Language, Thought, and Understanding 　　 
. TheState of theArt 
. SomeBriefHistory 
.. Foundational Insights: s and s 　 
.. The Two Camps: C 　　 
.. Four Paradigms: C 　　 
.. Empiricism and Finite-State Models Redux: C 　 
.. The Field Comes Together: C　 
.. The Rise of Machine Learning: C 　 
.. On Multiple Discoveries 　 
.. A Final Brief Note on Psychology 　　 
. Summary 　 
Bibliographical and Historical Notes 　 
I Words
 Regular Expressions and Automata　 
. RegularExpressions 　 
.. Basic Regular Expression Patterns 　　 
.. Disjunction, Grouping, and Precedence　 
.. ASimpleExample　 
.. A More Complex Example　 
.. AdvancedOperators 　 
.. Regular Expression Substitution, Memory, and ELIZA 　 
. Finite-StateAutomata 　 
.. Use of an FSA to Recognize Sheeptalk 　 
.. Formal Languages　 
.. Another Example 　 
.. Non-Deterministic FSAs . 
.. Use of an NFSA to Accept Strings 　 
.. Recognition as Search 
.. Relation of Deterministic and Non-Deterministic Automata 　 
Foreword 　 
Preface 　 
About the Authors　 
 Introduction 　 
. Knowledge in Speech and Language Processing　 
. Ambiguity 　 
. Models andAlgorithms 　 
. Language, Thought, and Understanding 　　　
. TheState of theArt . 
. SomeBriefHistory . 
.. Foundational Insights: s and s 
.. The Two Camps: C 　　 
.. Four Paradigms: C 　　 
.. Empiricism and Finite-State Models Redux: C 
.. The Field Comes Together: C 
.. The Rise of Machine Learning: C 
.. On Multiple Discoveries 
.. A Final Brief Note on Psychology 　　 
. Summary 　 
Bibliographical and Historical Notes 
I Words
 Regular Expressions and Automata 
. RegularExpressions 
.. Basic Regular Expression Patterns 　　 
.. Disjunction, Grouping, and Precedence　 
.. ASimpleExample　 
.. A More Complex Example 　 
.. AdvancedOperators 　 
.. Regular Expression Substitution, Memory, and ELIZA　 
. Finite-StateAutomata　 
.. Use of an FSA to Recognize Sheeptalk　 
.. Formal Languages　 
.. Another Example 　 
.. Non-Deterministic FSAs 　 
.. Use of an NFSA to Accept Strings 　　 
.. Recognition as Search　 
.. Relation of Deterministic and Non-Deterministic Automata　 
. Regular Languages and FSAs　 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
 Words and Transducers 
. Survey of (Mostly) English Morphology 　 
.. In?ectional Morphology 　 
.. Derivational Morphology　 
.. Cliticization 　 
.. Non-Concatenative Morphology 　　 
.. Agreement 　 
. Finite-State Morphological Parsing　 
. Construction of a Finite-State Lexicon 　　 
. Finite-StateTransducers 　 
.. Sequential Transducers and Determinism 　 
. FSTs for Morphological Parsing 　 
. Transducers and Orthographic Rules 　　 
. The Combination of an FST Lexicon and Rules 　 
. Lexicon-Free FSTs: The Porter Stemmer 　　 
. Word and Sentence Tokenization　 
.. Segmentation in Chinese　 
. Detection and Correction of Spelling Errors 　 
. MinimumEditDistance 　 
. Human Morphological Processing 　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 
 N-Grams 　 
. WordCounting inCorpora　 
. Simple (Unsmoothed) N-Grams　 
. Training andTestSets 　 
.. N-Gram Sensitivity to the Training Corpus　 
.. Unknown Words: Open Versus Closed Vocabulary Tasks 　 
. Evaluating N-Grams: Perplexity 　 
. Smoothing 　 
.. LaplaceSmoothing 　 
.. Good-Turing Discounting　 
.. Some Advanced Issues in Good-Turing Estimation 　 
. Interpolation 　 
. Backoff 　 
.. Advanced: Details of Computing Katz Backoff α and P 
. Practical Issues: Toolkits and Data Formats 　　 
. Advanced Issues in Language Modeling 　　 
.. Advanced Smoothing Methods: Kneser-Ney Smoothing 　 
.. Class-Based N-Grams　 
.. Language Model Adaptation and Web Use　 
.. Using Longer-Distance Information: A Brief Summary 　 
. Advanced: Information Theory Background 　　
.. Cross-Entropy for Comparing Models 　　 
. Advanced: The Entropy of English and Entropy Rate Constancy 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
 Part-of-Speech Tagging 　 
. (Mostly) English Word Classes　 
. Tagsets forEnglish 　 
. Part-of-Speech Tagging 　 
. Rule-Based Part-of-Speech Tagging 　
. HMM Part-of-Speech Tagging　 
.. Computing the Most Likely Tag Sequence: An Example　 
.. Formalizing Hidden Markov Model Taggers　 
.. Using the Viterbi Algorithm for HMM Tagging 　 
.. Extending the HMM Algorithm to Trigrams 　 
. Transformation-Based Tagging 　 
.. How TBL Rules Are Applied 　　 
.. How TBL Rules Are Learned 　　 
. Evaluation and Error Analysis 　 
.. ErrorAnalysis　 
. Advanced Issues in Part-of-Speech Tagging 　　 
.. Practical Issues: Tag Indeterminacy and Tokenization 　 
.. Unknown Words . 
.. Part-of-Speech Tagging for Other Languages　 
.. Tagger Combination 
. Advanced: The Noisy Channel Model for Spelling 　 
.. Contextual Spelling Error Correction 　　 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
 Hidden Markov and Maximum Entropy Models 
. MarkovChains 　 
. TheHiddenMarkovModel 　 
. Likelihood Computation: The Forward Algorithm 　 
. Decoding: The Viterbi Algorithm　 
. HMM Training: The Forward-Backward Algorithm 　 
. Maximum Entropy Models: Background 　 
.. LinearRegression 　 
.. Logistic Regression 
.. Logistic Regression: Classi?cation 　　
.. Advanced: Learning in Logistic Regression 　 
. Maximum Entropy Modeling 　 
.. Why We Call It Maximum Entropy 　　 
. Maximum Entropy Markov Models 
.. Decoding and Learning in MEMMs 　　 
. Summary 　 
Bibliographical and Historical Notes 
Exercises 
II Speech
 Phonetics 　 
. Speech Sounds and Phonetic Transcription　 
. Articulatory Phonetics 　 
.. TheVocalOrgans 　 
.. Consonants: Place of Articulation 　　
.. Consonants: Manner of Articulation 　　 
.. Vowels 
.. Syllables 
. Phonological Categories and Pronunciation Variation 
.. Phonetic Features . 
.. Predicting Phonetic Variation 　　 . 
.. Factors In?uencing Phonetic Variation 　　 
. Acoustic Phonetics and Signals 
.. Waves 　 
.. Speech Sound Waves 　 
.. Frequency and Amplitude; Pitch and Loudness 　 
.. Interpretation of Phones from a Waveform　 
.. Spectra and the Frequency Domain 　 
.. The Source-Filter Model 　　
. Phonetic Resources 　 
. Advanced: Articulatory and Gestural Phonology 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 　 
 Speech Synthesis 　
. TextNormalization 　 
.. Sentence Tokenization 　 
.. Non-Standard Words 　 
.. Homograph Disambiguation 　　
. Phonetic Analysis 　 
.. Dictionary Lookup 　 
.. Names 　 
.. Grapheme-to-Phoneme Conversion 　　 
. ProsodicAnalysis 　 
.. ProsodicStructure　 
.. Prosodic Prominence 　 
.. Tune 　 
.. More Sophisticated Models: ToBI 　 
.. Computing Duration from Prosodic Labels 　
.. Computing F from Prosodic Labels 　　
.. Final Result of Text Analysis: Internal Representation　 
. Diphone Waveform Synthesis 　 
.. Steps for Building a Diphone Database 
.. Diphone Concatenation and TD-PSOLA for Prosody 　
. Unit Selection (Waveform) Synthesis　 
. Evaluation 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Automatic Speech Recognition 　　
. Speech Recognition Architecture 　 
. The Hidden Markov Model Applied to Speech 　 
. Feature Extraction: MFCC Vectors　 
.. Preemphasis　 
.. Windowing 　 
.. Discrete Fourier Transform 　 
.. Mel Filter Bank and Log 　 
.. The Cepstrum: Inverse Discrete Fourier Transform　 
.. Deltas andEnergy　 
.. Summary:MFCC 　 
. Acoustic Likelihood Computation　 
.. Vector Quantization 　 
.. GaussianPDFs 　 
.. Probabilities, Log-Probabilities, and Distance Functions　 
. The Lexicon and Language Model 　 
. Search andDecoding 　 
. EmbeddedTraining 　 
. Evaluation: Word Error Rate 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Speech Recognition: Advanced Topics　 
. Multipass Decoding: N-Best Lists and Lattices 　　 
. A? (“Stack”)Decoding　 
. Context-Dependent Acoustic Models: Triphones 　 
. DiscriminativeTraining　 
.. Maximum Mutual Information Estimation　 
.. Acoustic Models Based on Posterior Classi?ers 
. ModelingVariation 　 
.. Environmental Variation and Noise 　　
.. Speaker Variation and Speaker Adaptation 　 
.. Pronunciation Modeling: Variation Due to Genre 
. Metadata: Boundaries, Punctuation, and Dis?uencies 　 
. Speech Recognition by Humans　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Computational Phonology 　 
. Finite-State Phonology 　 
. Advanced Finite-State Phonology 　 
.. Harmony 　 
.. Templatic Morphology　 
. Computational Optimality Theory 　 
.. Finite-State Transducer Models of Optimality Theory 　 
.. Stochastic Models of Optimality Theory　 
. Syllabi?cation 　 
. Learning Phonology and Morphology 　 
.. Learning Phonological Rules 　 
.. Learning Morphology 
.. Learning in Optimality Theory 　　
. Summary 
Bibliographical and Historical Notes 　 
Exercises 
III Syntax
 Formal Grammars of English 
. Constituency 
. Context-FreeGrammars 
.. Formal De?nition of Context-Free Grammar 
. Some Grammar Rules for English 　 
.. Sentence-Level Constructions 　　
.. Clauses and Sentences 　 
.. The Noun Phrase　 
.. Agreement 　 
.. The Verb Phrase and Subcategorization　 
.. Auxiliaries 　 
.. Coordination　 
. Treebanks 
.. Example: The Penn Treebank Project 　　 
.. Treebanks as Grammars 　 
.. Treebank Searching　 
.. Heads and Head Finding 　
. Grammar Equivalence and Normal Form　 
. Finite-State and Context-Free Grammars 　 
. DependencyGrammars 
.. The Relationship Between Dependencies and Heads 
.. Categorial Grammar 
. Spoken Language Syntax 　 
.. Dis?uencies andRepair 　 
.. Treebanks for Spoken Language 　　
. Grammars and Human Processing 　 
. Summary 
Bibliographical and Historical Notes 　
Exercises 　 
 Syntactic Parsing 　 
. Parsing asSearch 　 
.. Top-DownParsing 　 
.. Bottom-UpParsing　 
.. Comparing Top-Down and Bottom-Up Parsing 
. Ambiguity 
. Search in the Face of Ambiguity . 
. Dynamic Programming Parsing Methods 　　 
.. CKYParsing 
.. The Earley Algorithm 
.. ChartParsing 
. PartialParsing . 
.. Finite-State Rule-Based Chunking 　　 
.. Machine Learning-Based Approaches to Chunking 
.. Chunking-System Evaluations 　　 . 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 　 
 Statistical Parsing 　　
. Probabilistic Context-Free Grammars 　 
.. PCFGs for Disambiguation 　 
.. PCFGs for Language Modeling 　 
. Probabilistic CKY Parsing of PCFGs 　 
. Ways to Learn PCFG Rule Probabilities 　 
. ProblemswithPCFGs 　
.. Independence Assumptions Miss Structural Dependencies BetweenRules　 
.. Lack of Sensitivity to Lexical Dependencies　 
. Improving PCFGs by Splitting Non-Terminals 　 
. Probabilistic Lexicalized CFGs 　
.. The Collins Parser 　
.. Advanced: Further Details of the Collins Parser 　 
. EvaluatingParsers 　
. Advanced: Discriminative Reranking 　 
. Advanced: Parser-Based Language Modeling 　　 
. HumanParsing 　
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 
 Features and Uni?cation　 
. FeatureStructures 　
. Uni?cation of Feature Structures 　 
. Feature Structures in the Grammar 　
.. Agreement 　
.. HeadFeatures 　
.. Subcategorization 　
.. Long-Distance Dependencies 　　 
. Implementation of Uni?cation　 
.. Uni?cation Data Structures 　 
.. The Uni?cationAlgorithm 　 
. Parsing with Uni?cation Constraints 　 
.. Integration of Uni?cation into an Earley Parser 　
.. Uni?cation-Based Parsing 　 
. Types and Inheritance 　 
.. Advanced: Extensions to Typing 　 
.. Other Extensions to Uni?cation 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 
 Language and Complexity 　 
. TheChomskyHierarchy 　 
. Ways to Tell if a Language Isn’t Regular 　　 
.. The Pumping Lemma 
.. Proofs that Various Natural Languages Are Not Regular　 
. Is Natural Language Context Free?　 
. Complexity and Human Processing 　 
. Summary 
Bibliographical and Historical Notes 
Exercises 
 The Representation of Meaning 
. Computational Desiderata for Representations 　 
.. Veri?ability 
.. Unambiguous Representations 　
.. Canonical Form 　 
.. Inference and Variables　 
.. Expressiveness 　
. Model-Theoretic Semantics　 
. First-OrderLogic 　 
.. Basic Elements of First-Order Logic 　　 
.. Variables and Quanti?ers . 
.. LambdaNotation . 
.. The Semantics of First-Order Logic 　
.. Inference 　 
. Event and State Representations　 
.. RepresentingTime　 
.. Aspect 　 
. DescriptionLogics 　 
. Embodied and Situated Approaches to Meaning 　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 
 Computational Semantics　 
. Syntax-Driven Semantic Analysis 　 
. Semantic Augmentations to Syntactic Rules 　 
. Quanti?er Scope Ambiguity and Underspeci?cation 　 
.. Store and Retrieve Approaches 　　 
.. Constraint-Based Approaches 　　 
. Uni?cation-Based Approaches to Semantic Analysis 　 
. Integration of Semantics into the Earley Parser 　 
. Idioms and Compositionality 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 　 
 Lexical Semantics 　
. WordSenses 　 
. Relations Between Senses 　 
.. Synonymy and Antonymy 　 
.. Hyponymy 　 
.. SemanticFields 　 
. WordNet: A Database of Lexical Relations 　　 
. EventParticipants　 
.. ThematicRoles 　 
.. Diathesis Alternations 　
.. Problems with Thematic Roles 　　 
.. The Proposition Bank　 
.. FrameNet 　 
.. Selectional Restrictions 　 
. Primitive Decomposition 　 
. Advanced: Metaphor 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 　 
 Computational Lexical Semantics 　 
. Word Sense Disambiguation: Overview 　　 
. Supervised Word Sense Disambiguation 　　 
.. Feature Extraction for Supervised Learning　 
.. Naive Bayes and Decision List Classi?ers 　 
. WSD Evaluation, Baselines, and Ceilings 　 
. WSD: Dictionary and Thesaurus Methods 　　
.. The Lesk Algorithm 　 
.. Selectional Restrictions and Selectional Preferences 　 
. Minimally Supervised WSD: Bootstrapping 　　 
. Word Similarity: Thesaurus Methods 　　 
. Word Similarity: Distributional Methods 　　 
.. De?ning a Word’s Co-Occurrence Vectors 　 
.. Measuring Association with Context 　　
.. De?ning Similarity Between Two Vectors　 
.. Evaluating Distributional Word Similarity 　 
. Hyponymy and Other Word Relations 　 
. SemanticRoleLabeling 　 
. Advanced: Unsupervised Sense Disambiguation　 
. Summary 
Bibliographical and Historical Notes 
Exercises 
 Computational Discourse　 
. DiscourseSegmentation　 
.. Unsupervised Discourse Segmentation 　
.. Supervised Discourse Segmentation 　　
.. Discourse Segmentation Evaluation 　 
. TextCoherence　 
.. Rhetorical Structure Theory 　 
.. Automatic Coherence Assignment 　 
. ReferenceResolution 　 
. ReferencePhenomena 　 
.. Five Types of Referring Expressions 　　 
.. Information Status 　 
. Features for Pronominal Anaphora Resolution 　　 
.. Features for Filtering Potential Referents　 
.. Preferences in Pronoun Interpretation 　 
. Three Algorithms for Anaphora Resolution 　 
.. Pronominal Anaphora Baseline: The Hobbs Algorithm 　 
.. A Centering Algorithm for Anaphora Resolution 　 
.. A Log-Linear Model for Pronominal Anaphora Resolution 　 
.. Features for Pronominal Anaphora Resolution 　
. Coreference Resolution 　 
. Evaluation of Coreference Resolution 　 
. Advanced: Inference-Based Coherence Resolution 　 
. Psycholinguistic Studies of Reference 　 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises　 
V Applications
 Information Extraction 　 
. Named Entity Recognition 　 
.. Ambiguity in Named Entity Recognition 　 
.. NER as Sequence Labeling 　 
.. Evaluation of Named Entity Recognition　 
.. Practical NER Architectures 　　 
. Relation Detection and Classi?cation 　　 
.. Supervised Learning Approaches to Relation Analysis 
.. Lightly Supervised Approaches to Relation Analysis . 
.. Evaluation of Relation Analysis Systems . 
. Temporal and Event Processing 
.. Temporal Expression Recognition 　　 
.. Temporal Normalization 　 
.. Event Detection and Analysis 　　 
.. TimeBank 　
. Template Filling 　
.. Statistical Approaches to Template-Filling 　 
.. Finite-State Template-Filling Systems 　　 
. Advanced: Biomedical Information Extraction 　　 
.. Biological Named Entity Recognition 　　 
.. Gene Normalization　 
.. Biological Roles and Relations 　 
. Summary 　 
Bibliographical and Historical Notes　 
Exercises 　 
 Question Answering and Summarization　 
. InformationRetrieval 　 
.. The Vector Space Model 　 
.. TermWeighting 　 
.. Term Selection and Creation 　 
.. Evaluation of Information-Retrieval Systems 
.. Homonymy, Polysemy, and Synonymy 　 
.. Ways to Improve User Queries 　　
. Factoid Question Answering　 
.. Question Processing 　 
.. PassageRetrieval　 
.. AnswerProcessing　 
.. Evaluation of Factoid Answers 　　 
. Summarization 　 
. Single-Document Summarization 　 
.. Unsupervised Content Selection 　　 
.. Unsupervised Summarization Based on Rhetorical Parsing 　 
.. Supervised Content Selection 　　 
.. Sentence Simpli?cation 　 
. Multi-Document Summarization　 
.. Content Selection in Multi-Document Summarization　 
.. Information Ordering in Multi-Document Summarization 　 
. Focused Summarization and Question Answering 　 
. Summarization Evaluation 　 
. Summary 　 
Bibliographical and Historical Notes 　 
Exercises 
 Dialogue and Conversational Agents 　
. Properties of Human Conversations 　
.. Turns and Turn-Taking 　
.. Language as Action: Speech Acts 　　 
.. Language as Joint Action: Grounding 　 
.. Conversational Structure 　 
.. Conversational Implicature　 
. Basic Dialogue Systems 　 
.. ASR Component　 
.. NLU Component 　 
.. Generation and TTS Components 　 
.. Dialogue Manager 　 
.. Dealing with Errors: Con?rmation and Rejection 
. VoiceXML 
. Dialogue System Design and Evaluation 　　 
.. Designing Dialogue Systems 　　 
.. Evaluating Dialogue Systems 　 
. Information-State and Dialogue Acts 　 
.. Using Dialogue Acts 　 
.. Interpreting Dialogue Acts　 
.. Detecting Correction Acts　 
.. Generating Dialogue Acts: Con?rmation and Rejection 　
. Markov Decision Process Architecture 　　 
. Advanced: Plan-Based Dialogue Agents 　　 
.. Plan-Inferential Interpretation and Production　 
.. The Intentional Structure of Dialogue 　 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 　 
 Machine Translation　 
. Why Machine Translation Is Hard 　 
.. Typology 　 
.. Other Structural Divergences 　　 
.. LexicalDivergences 　 
. Classical MT and the Vauquois Triangle 
.. Direct Translation 　 
.. Transfer 　 
.. Combined Direct and Transfer Approaches in Classic MT　 
.. The Interlingua Idea: Using Meaning 　　 
. StatisticalMT 　 
. P(F|E): The Phrase-Based Translation Model　　 
. Alignment inMT 　 
.. IBMModel  　 
.. HMMAlignment 　　
. Training Alignment Models　 
.. EM for Training Alignment Models 　　
. Symmetrizing Alignments for Phrase-Based MT　 
. Decoding for Phrase-Based Statistical MT 　　 
. MTEvaluation 　 
.. Using Human Raters 　 
.. Automatic Evaluation: BLEU 　　 
. Advanced: Syntactic Models for MT 　　 
. Advanced: IBM Model  and Fertility 　　
.. Training forModel  　
. Advanced: Log-Linear Models for MT 　　 
. Summary 　
Bibliographical and Historical Notes 　 
Exercises 
Bibliography 　 
Author Index　 
Subject Index 　 
・ ・ ・ ・ ・ ・ (收起)推荐序III
推荐语IV
前言V
数学符号IX
第 章绪论
. 自然语言处理的概念 
. 自然语言处理的难点
.. 抽象性 
.. 组合性 
.. 歧义性 
.. 进化性
.. 非规范性
.. 主观性
.. 知识性
.. 难移植性
. 自然语言处理任务体系.
.. 任务层级
.. 任务类别
.. 研究对象与层次
. 自然语言处理技术发展历史
第 章自然语言处理基础
. 文本的表示.
.. 词的独热表示
.. 词的分布式表示
.. 词嵌入表示
.. 文本的词袋表示
. 自然语言处理任务
.. 语言模型
.. 自然语言处理基础任务
.. 自然语言处理应用任务
. 基本问题
.. 文本分类问题
.. 结构预测问题
.. 序列到序列问题
. 评价指标
. 小结
第 章基础工具集与常用数据集
. NLTK 工具集
.. 常用语料库和词典资源
.. 常用自然语言处理工具集.
. LTP 工具集
.. 中文分词
.. 其他中文自然语言处理功能.
. PyTorch 基础
.. 张量的基本概念
.. 张量的基本运算
.. 自动微分
.. 调整张量形状
.. 广播机制
.. 索引与切片
.. 降维与升维
. 大规模预训练数据
.. 维基百科数据
.. 原始数据的获取
.. 语料处理方法
.. Common Crawl 数据
. 更多数据集.
. 小结
第 章自然语言处理中的神经网络基础
. 多层感知器模型
.. 感知器
.. 线性回归
.. Logistic 回归
.. Softmax 回归
.. 多层感知器
.. 模型实现
. 卷积神经网络
.. 模型结构
.. 模型实现
. 循环神经网络
.. 模型结构
.. 长短时记忆网络
.. 模型实现
.. 基于循环神经网络的序列到序列模型
. 注意力模型.
.. 注意力机制
.. 自注意力模型
.. Transformer 
.. 基于Transformer 的序列到序列模型
.. Transformer 模型的优缺点
.. 模型实现
. 神经网络模型的训练
.. 损失函数
.. 梯度下降
. 情感分类实战
.. 词表映射
.. 词向量层
.. 融入词向量层的多层感知器
.. 数据处理
.. 多层感知器模型的训练与测试
.. 基于卷积神经网络的情感分类
.. 基于循环神经网络的情感分类
.. 基于Transformer 的情感分类
. 词性标注实战
.. 基于前馈神经网络的词性标注
.. 基于循环神经网络的词性标注
.. 基于Transformer 的词性标注
. 小结
第 章静态词向量预训练模型
. 神经网络语言模型
.. 预训练任务
.. 模型实现
. Wordvec 词向量
.. 概述
.. 负采样
.. 模型实现
. GloVe 词向量
.. 概述
.. 预训练任务
.. 参数估计
.. 模型实现
. 评价与应用.
.. 词义相关性
.. 类比性
.. 应用
. 小结
第 章动态词向量预训练模型
. 词向量――从静态到动态
. 基于语言模型的动态词向量预训练
.. 双向语言模型
.. ELMo 词向量
.. 模型实现
.. 应用与评价
. 小结
第 章预训练语言模型
. 概述
.. 大数据
.. 大模型
.. 大算力
. GPT 
.. 无监督预训练
.. 有监督下游任务精调
.. 适配不同的下游任务
. BERT 
.. 整体结构
.. 输入表示
.. 基本预训练任务
.. 更多预训练任务
.. 模型对比
. 预训练语言模型的应用
.. 概述
.. 单句文本分类
.. 句对文本分类
.. 阅读理解
.. 序列标注
. 深入理解BERT .
.. 概述
.. 自注意力可视化分析
.. 探针实验
. 小结.
第 章预训练语言模型进阶
. 模型优化.
.. XLNet 
.. RoBERTa .
.. ALBERT .
.. ELECTRA 
.. MacBERT 
.. 模型对比
. 长文本处理.
.. 概述
.. Transformer-XL 
.. Reformer .
.. Longformer 
.. BigBird .
.. 模型对比
. 模型蒸馏与压缩
.. 概述
.. DistilBERT 
.. TinyBERT 
.. MobileBERT 
.. TextBrewer 
. 生成模型
.. BART 
.. UniLM 
.. T .
.. GPT- 
.. 可控文本生成
. 小结.
第 章多模态融合的预训练模型
. 多语言融合.
.. 多语言BERT .
.. 跨语言预训练语言模型
.. 多语言预训练语言模型的应用
. 多媒体融合.
.. VideoBERT 
.. VL-BERT 
.. DALL・E 
.. ALIGN 
. 异构知识融合
.. 融入知识的预训练
.. 多任务学习
. 更多模态的预训练模型
. 小结.
参考文献
术语表
・ ・ ・ ・ ・ ・ (收起)第章 新手上路 
. 自然语言与编程语言 
.. 词汇量 
.. 结构化 
.. 歧义性 
.. 容错性 
.. 易变性 
.. 简略性 
. 自然语言处理的层次 
.. 语音、图像和文本 
.. 中文分词、词性标注和命名实体识别 
.. 信息抽取 
.. 文本分类与文本聚类 
.. 句法分析 
.. 语义分析与篇章分析 
.. 其他高级任务 
. 自然语言处理的流派 
.. 基于规则的专家系统 
.. 基于统计的学习方法 
.. 历史 
.. 规则与统计 
.. 传统方法与深度学习 
. 机器学习 
.. 什么是机器学习 
.. 模型 
.. 特征 
.. 数据集 
.. 监督学习 
.. 无监督学习 
.. 其他类型的机器学习算法 
. 语料库 
.. 中文分词语料库 
.. 词性标注语料库 
.. 命名实体识别语料库 
.. 句法分析语料库 
.. 文本分类语料库 
.. 语料库建设 
. 开源工具 
.. 主流NLP工具比较 
.. Python接口 
.. Java接口 
. 总结 
第章 词典分词 
. 什么是词 
.. 词的定义 
.. 词的性质--齐夫定律 
. 词典 
.. HanLP词典 
.. 词典的加载 
. 切分算法 
.. 完全切分 
.. 正向最长匹配 
.. 逆向最长匹配 
.. 双向最长匹配 
.. 速度评测 
. 字典树 
.. 什么是字典树 
.. 字典树的节点实现 
.. 字典树的增删改查实现 
.. 首字散列其余二分的字典树 
.. 前缀树的妙用 
. 双数组字典树 
.. 双数组的定义 
.. 状态转移 
.. 查询 
.. 构造* 
.. 全切分与最长匹配 
. AC自动机 
.. 从字典树到AC自动机 
.. goto表 
.. output表 
.. fail表 
.. 实现 
. 基于双数组字典树的AC自动机 
.. 原理 
.. 实现 
. HanLP的词典分词实现 
.. DoubleArrayTrieSegment 
.. AhoCorasickDoubleArrayTrie-Segment 
. 准确率评测 
.. 准确率 
.. 混淆矩阵与TP/FN/FP/TN 
.. 精确率 
.. 召回率 
.. F值 
.. 中文分词中的P、R、F计算 
.. 实现 
.. 第二届国际中文分词评测 
.. OOVRecallRate与IVRecallRate 
. 字典树的其他应用 
.. 停用词过滤 
.. 简繁转换 
.. 拼音转换 
. 总结 
第章 二元语法与中文分词 
. 语言模型 
.. 什么是语言模型 
.. 马尔可夫链与二元语法 
.. n元语法 
.. 数据稀疏与平滑策略 
. 中文分词语料库 
.. 年《人民日报》语料库PKU 
.. 微软亚洲研究院语料库MSR 
.. 繁体中文分词语料库 
.. 语料库统计 
. 训练 
.. 加载语料库 
.. 统计一元语法 
.. 统计二元语法 
. 预测 
.. 加载模型 
.. 构建词网 
.. 节点间的距离计算 
.. 词图上的维特比算法 
.. 与用户词典的集成 
. 评测 
.. 标准化评测 
.. 误差分析 
.. 调整模型 
. 日语分词 
.. 日语分词语料 
.. 训练日语分词器 
. 总结 
第章 隐马尔可夫模型与序列标注 
. 序列标注问题 
.. 序列标注与中文分词 
.. 序列标注与词性标注 
.. 序列标注与命名实体识别 
. 隐马尔可夫模型 
.. 从马尔可夫假设到隐马尔可夫模型 
.. 初始状态概率向量 
.. 状态转移概率矩阵 
.. 发射概率矩阵 
.. 隐马尔可夫模型的三个基本用法 
. 隐马尔可夫模型的样本生成 
.. 案例--医疗诊断 
.. 样本生成算法 
. 隐马尔可夫模型的训练 
.. 转移概率矩阵的估计 
.. 初始状态概率向量的估计 
.. 发射概率矩阵的估计 
.. 验证样本生成与模型训练 
. 隐马尔可夫模型的预测 
.. 概率计算的前向算法 
.. 搜索状态序列的维特比算法 
. 隐马尔可夫模型应用于中文分词 
.. 标注集 
.. 字符映射 
.. 语料转换 
.. 训练 
.. 预测 
.. 评测 
.. 误差分析 
. 二阶隐马尔可夫模型* 
.. 二阶转移概率张量的估计 
.. 二阶隐马尔可夫模型中的维特比算法 
.. 二阶隐马尔可夫模型应用于中文分词 
. 总结 
第章 感知机分类与序列标注 
. 分类问题 
.. 定义 
.. 应用 
. 线性分类模型与感知机算法 
.. 特征向量与样本空间 
.. 决策边界与分离超平面 
.. 感知机算法 
.. 损失函数与随机梯度下降* 
.. 投票感知机和平均感知机 
. 基于感知机的人名性别分类 
.. 人名性别语料库 
.. 特征提取 
.. 训练 
.. 预测 
.. 评测 
.. 模型调优 
. 结构化预测问题 
.. 定义 
.. 结构化预测与学习的流程 
. 线性模型的结构化感知机算法 
.. 结构化感知机算法 
.. 结构化感知机与序列标注 
.. 结构化感知机的维特比解码算法 
. 基于结构化感知机的中文分词 
.. 特征提取 
.. 多线程训练 
.. 特征裁剪与模型压缩* 
.. 创建感知机分词器 
.. 准确率与性能 
.. 模型调整与在线学习* 
.. 中文分词特征工程* 
. 总结 
第章 条件随机场与序列标注 
. 机器学习的模型谱系 
.. 生成式模型与判别式模型 
.. 有向与无向概率图模型 
. 条件随机场 
.. 线性链条件随机场 
.. 条件随机场的训练* 
.. 对比结构化感知机 
. 条件随机场工具包 
.. CRF++的安装 
.. CRF++语料格式 
.. CRF++特征模板 
.. CRF++命令行训练 
.. CRF++模型格式* 
.. CRF++命令行预测 
.. CRF++代码分析* 
. HanLP中的CRF++API 
.. 训练分词器 
.. 标准化评测 
. 总结 
第章 词性标注 
. 词性标注概述 
.. 什么是词性 
.. 词性的用处 
.. 词性标注 
.. 词性标注模型 
. 词性标注语料库与标注集 
.. 《人民日报》语料库与PKU标注集 
.. 国家语委语料库与标注集 
.. 《诛仙》语料库与CTB标注集 
. 序列标注模型应用于词性标注 
.. 基于隐马尔可夫模型的词性标注 
.. 基于感知机的词性标注 
.. 基于条件随机场的词性标注 
.. 词性标注评测 
. 自定义词性 
.. 朴素实现 
.. 标注语料 
. 总结 
第章 命名实体识别 
. 概述 
. 基于规则的命名实体识别 
. 命名实体识别语料库 
. 基于层叠隐马尔可夫模型的角色标注框架 
. 基于序列标注的命名实体识别 
. 自定义领域命名实体识别 
. 总结 
第章 信息抽取 
. 新词提取 
. 关键词提取 
. 短语提取 
. 关键句提取 
. 总结 
第章 文本聚类 
. 概述 
. 文档的特征提取 
. k均值算法 
. 重复二分聚类算法 
. 标准化评测 
. 总结 
第章 文本分类 
. 文本分类的概念 
. 文本分类语料库 
. 文本分类的特征提取 
. 朴素贝叶斯分类器 
. 支持向量机分类器 
. 标准化评测 
. 情感分析 
. 总结 
第章 依存句法分析 
. 短语结构树 
.. 宾州树库和中文树库 
. 依存句法树 
. 依存句法分析 
. 基于转移的依存句法分析 
. 依存句法分析API 
. 案例：基于依存句法树的意见抽取 
. 总结 
第章 深度学习与自然语言处理 
. 传统方法的局限 
. 深度学习与优势 
. wordvec 
. 基于神经网络的高性能依存句法分析器 
. 自然语言处理进阶 
自然语言处理学习资料推荐 
・ ・ ・ ・ ・ ・ (收起)扉页
版权声明
内容提要
译者简介
译者序
序
前言
致谢
关于本书
关于作者
关于封面插画
资源与支持
目录
第一部分 处理文本的机器
第章 NLP概述
. 自然语言与编程语言
. 神奇的魔法
.. 会交谈的机器
.. NLP中的数学
. 实际应用
. 计算机“眼”中的语言
.. 锁的语言（正则表达式）
.. 正则表达式
.. 一个简单的聊天机器人
.. 另一种方法
. 超空间简述
. 词序和语法
. 聊天机器人的自然语言流水线
. 深度处理
. 自然语言智商
. 小结
第章 构建自己的词汇表――分词
. 挑战（词干还原预览）
. 利用分词器构建词汇表
.. 点积
.. 度量词袋之间的重合度
.. 标点符号的处理
.. 将词汇表扩展到 n-gram
.. 词汇表归一化
. 情感
.. VADER：一个基于规则的情感分析器
.. 朴素贝叶斯
. 小结
第章 词中的数学
. 词袋
. 向量化
向量空间
. 齐普夫定律
. 主题建模
.. 回到齐普夫定律
.. 相关度排序
.. 工具
.. 其他工具
.. Okapi BM
.. 未来展望
. 小结
第章 词频背后的语义
. 从词频到主题得分
.. TF-IDF向量及词形归并
.. 主题向量
.. 思想实验
.. 一个主题评分算法
.. 一个 LDA分类器
. 潜在语义分析
思想实验的实际实现
. 奇异值分解
.. 左奇异向量 U
.. 奇异值向量 S
.. 右奇异向量 V
.. SVD矩阵的方向
.. 主题约简
. 主成分分析
.. 三维向量上的 PCA
.. 回归 NLP
.. 基于 PCA的短消息语义分析
.. 基于截断的 SVD的短消息语义分析
.. 基于 LSA的垃圾短消息分类的效果
. 潜在狄利克雷分布（LDiA）
.. LDiA思想
.. 基于 LDiA主题模型的短消息语义分析
.. LDiA+LDA=垃圾消息过滤器
.. 更公平的对比： 个 LDiA主题
. 距离和相似度
. 反馈及改进
线性判别分析
. 主题向量的威力
.. 语义搜索
.. 改进
. 小结
第二部分 深度学习（神经网络）
第章 神经网络初步（感知机与反向传播）
. 神经网络的组成
. 小结
第章 词向量推理（Wordvec）
. 语义查询与类比
类比问题
. 词向量
.. 面向向量的推理
.. 如何计算 Wordvec 表示
.. 如何使用 gensim.wordvec 模块
.. 生成定制化词向量表示
.. Wordvec 和 GloVe
.. fastText
.. Wordvec 和 LSA
.. 词关系可视化
.. 非自然词
.. 利用 Docvec 计算文档相似度
. 小结
第章 卷积神经网络（CNN）
. 语义理解
. 工具包
. 卷积神经网络
.. 构建块
.. 步长
.. 卷积核的组成
.. 填充
.. 学习
. 狭窄的窗口
.. Keras 实现：准备数据
.. 卷积神经网络架构
.. 池化
.. dropout
.. 输出层
.. 开始学习（训练）
.. 在流水线中使用模型
.. 前景展望
. 小结
第章 循环神经网络（RNN）
. 循环网络的记忆功能
. 整合各个部分
. 自我学习
. 超参数
. 预测
.. 有状态性
.. 双向 RNN
.. 编码向量
. 小结
第章 改进记忆力：长短期记忆网络（LSTM）
. 长短期记忆（LSTM）
.. 随时间反向传播
.. 模型的使用
.. 脏数据
.. “未知”词条的处理
.. 字符级建模
.. 生成聊天文字
.. 进一步生成文本
.. 文本生成的问题：内容不受控
.. 其他记忆机制
.. 更深的网络
. 小结
第章 序列到序列建模和注意力机制
. 编码-解码架构
.. 解码思想
.. 似曾相识？
.. 序列到序列对话
.. 回顾 LSTM
. 组装一个序列到序列的流水线
.. 为序列到序列训练准备数据集
.. Keras 中的序列到序列模型
.. 序列编码器
.. 思想解码器
.. 组装一个序列到序列网络
. 训练序列到序列网络
生成输出序列
. 使用序列到序列网络构建一个聊天机器人
.. 为训练准备语料库
.. 建立字符字典
.. 生成独热编码训练集
.. 训练序列到序列聊天机器人
.. 组装序列生成模型
.. 预测输出序列
.. 生成回复
.. 与聊天机器人交谈
. 增强
.. 使用装桶法降低训练复杂度
.. 注意力机制
. 实际应用
. 小结
第三部分 进入现实世界（现实中的 NLP 挑战）
第章 信息提取（命名实体识别与问答系统）
. 命名实体与关系
.. 知识库
.. 信息提取
. 正则模式
.. 正则表达式
.. 把信息提取当作机器学习里的特征提取任务
. 值得提取的信息
.. 提取 GPS位置
.. 提取日期
. 提取人物关系（事物关系）
.. 词性标注
.. 实体名称标准化
.. 实体关系标准化和提取
.. 单词模式
.. 文本分割
.. 为什么 split('.!?')函数不管用
.. 使用正则表达式进行断句
. 现实世界的信息提取
. 小结
第章 开始聊天（对话引擎）
. 语言技能
.. 现代方法
.. 混合方法
. 模式匹配方法
.. 基于 AIML 的模式匹配聊天机器人
.. 模式匹配的网络视图
. 知识方法
. 检索（搜索）方法
.. 上下文挑战
.. 基于示例检索的聊天机器人
.. 基于搜索的聊天机器人
. 生成式方法
.. 聊聊 NLPIA
.. 每种方法的利弊
. 四轮驱动
Will的成功
. 设计过程
. 技巧
.. 用带有可预测答案的问题提问
.. 要有趣
.. 当其他所有方法都失败时，搜索
.. 变得受欢迎
.. 成为连接器
.. 变得有情感
. 现实世界
. 小结
第章 可扩展性（优化、并行化和批处理）
. 太多（数据）未必是好事
. 优化NLP算法
.. 索引
.. 高级索引
.. 基于 Annoy 的高级索引
.. 究竟为什么要使用近似索引
.. 索引变通方法：离散化
. 常数级内存算法
.. gensim
.. 图计算
. 并行化NLP计算
.. 在 GPU上训练 NLP模型
.. 租与买
.. GPU租赁选择
.. 张量处理单元 TPU
. 减少模型训练期间的内存占用
. 使用TensorBoard 了解模型
如何可视化词嵌入
. 小结
附录A 本书配套的NLP工具
附录B 有趣的Python和正则表达式
附录C 向量和矩阵（线性代数基础）
附录D 机器学习常见工具与技术
附录E 设置亚马逊云服务（ AWS）上的GPU
附录F 局部敏感哈希
资源
词汇表
・ ・ ・ ・ ・ ・ (收起)第章导论
.语音与语言处理中的知识
.歧义
.模型和算法
.语言、思维和理解
.学科现状与近期发展
.语音和语言处理简史
..基础研究：世纪年代和世纪年代
..两个阵营：年至年
..四个范型：年至年
..经验主义和有限状态模型的复苏：年至年
..不同领域的合流：年至年
..机器学习的兴起：年至年
..关于多重发现
..心理学的简要注记
.小结
.文献和历史说明
第一部分词汇的计算机处理
第章正则表达式与自动机
.正则表达式
..基本正则表达式模式
..析取、组合与优先关系
..一个简单的例子
..一个比较复杂的例子
..高级算符
..正则表达式中的替换、存储器与ELIZA
.有限状态自动机
..用FSA来识别羊的语言
..形式语言
..其他例子
..非确定FSA
..使用NFSA接收符号串
..识别就是搜索
..确定自动机与非确定自动机的关系
.正则语言与FSA
.小结
.文献和历史说明
第章词与转录机
.英语形态学概观
..屈折形态学
..派生形态学
..附着
..非毗连形态学
..一致关系
.有限状态形态剖析
.有限状态词表的建造
.有限状态转录机
..定序转录机和确定性
.用于形态剖析的FST
.转录机和正词法规则
.把FST词表与规则相结合
.与词表无关的FST：Porter词干处理器
.单词和句子的词例还原
..中文的自动切词
.拼写错误的检查与更正
.最小编辑距离
.人是怎样进行形态处理的
.小结
.文献和历史说明
第章N元语法
.语料库中单词数目的计算
.简单的（非平滑的）N元语法
.训练集和测试集
..N元语法及其对训练语料库的敏感性
..未知词：开放词汇与封闭词汇
.N元语法的评测：困惑度
.平滑
..Laplace平滑
..GoodTuring打折法
..GoodTuring估计的一些高级专题
.插值法
.回退法
..高级专题：计算Katz回退的α和P*
.实际问题：工具包和数据格式
.语言模型建模中的高级专题
..高级的平滑方法：KneserNey平滑法
..基于类别的N元语法
..语言模型的自适应和网络（Web）应用
..长距离信息的使用：简要的综述
.信息论背景
..用于比较模型的交叉熵
.高级问题：英语的熵和熵率均衡性
.小结
.文献和历史说明
第章词类标注
.（大多数）英语词的分类
.英语的标记集
.词类标注
.基于规则的词类标注
.基于隐马尔可夫模型的词类标注
..计算最可能的标记序列：一个实例
..隐马尔可夫标注算法的形式化
..使用Viterbi算法来进行HMM标注
..把HMM扩充到三元语法
.基于转换的标注
..怎样应用TBL规则
..怎样学习TBL规则
.评测和错误分析
..错误分析
.词类标注中的高级专题
..实际问题：标记的不确定性与词例还原
..未知词
..其他语言中的词类标注
..标注算法的结合
.高级专题：拼写中的噪声信道模型
..上下文错拼更正
.小结
.文献和历史说明
第章隐马尔可夫模型与最大熵模型
.马尔可夫链
.隐马尔可夫模型
.似然度的计算：向前算法
.解码：Viterbi算法
.HMM的训练：向前向后算法
.最大熵模型：背景
..线性回归
..逻辑回归
..逻辑回归：分类
..高级专题：逻辑回归的训练
.最大熵模型
..为什么称为最大熵
.最大熵马尔可夫模型
..MEMM的解码和训练
.小结
.文献和历史说明
第二部分语音的计算机处理
第章语音学
.言语语音与语音标音法
.发音语音学
..发音器官
..辅音：发音部位
..辅音：发音方法
..元音
..音节
.音位范畴与发音变异
..语音特征
..语音变异的预测
..影响语音变异的因素
.声学语音学和信号
..波
..语音的声波
..频率与振幅：音高和响度
..从波形来解释音子
..声谱和频域
..声源滤波器模型
.语音资源
.高级问题：发音音系学与姿态音系学
.小结
.文献和历史说明
第章语音合成
.文本归一化
..句子的词例还原
..非标准词
..同形异义词的排歧
.语音分析
..查词典
..名称
..字位―音位转换
.韵律分析
..韵律的结构
..韵律的突显度
..音调
..更精巧的模型：ToBI
..从韵律标记计算音延
..从韵律标记计算F
..文本分析的最后结果：内部表示
.双音子波形合成
..建立双音子数据库的步骤
..双音子毗连和用于韵律的TD―PSOLA
.单元选择（波形）合成
.评测
.文献和历史说明
第章语音自动识别
.语音识别的总体结构
.隐马尔可夫模型应用于语音识别
.特征抽取：MFCC矢量
..预加重
..加窗
..离散傅里叶变换
..Mel滤波器组和对数
..倒谱：逆向傅里叶变换
..Delta特征与能量
..总结：MFCC
.声学似然度的计算
..矢量量化
..高斯概率密度函数
..概率、对数概率和距离函数
.词典和语言模型
.搜索与解码
.嵌入式训练
.评测：词错误率
.小结
.文献和历史说明
第章语音识别：高级专题
.多遍解码：N最佳表和格
.A*解码算法（“栈”解码算法）
.依赖于上下文的声学模型：三音子
.分辨训练
..最大互信息估计
..基于后验分类器的声学模型
.语音变异的建模
..环境语音变异和噪声
..说话人变异和说话人适应
..发音建模：由于语类的差别而产生的变异
.元数据：边界、标点符号和不流利现象
.人的语音识别
.小结
.文献和历史说明
第章计算音系学
.有限状态音系学
.高级有限状态音系学
..元音和谐
..模板式形态学
.计算优选理论
..优选理论中的有限状态转录机模型
..优选理论的随机模型
.音节切分
.音位规则和形态规则的机器学习
..音位规则的机器学习
..形态规则的机器学习
..优选理论中的机器学习
.小结
.文献和历史说明
第三部分句法的计算机处理
第章英语的形式语法
.组成性
.上下文无关语法
..上下文无关语法的形式定义
.英语的一些语法规则
..句子一级的结构
..子句与句子
..名词短语
..一致关系
..动词短语和次范畴化
..助动词
..并列关系
.树库
..树库的例子：宾州树库课题
..作为语法的树库
..树库搜索
..中心词与中心词的发现
.语法等价与范式
.有限状态语法和上下文无关语法
.依存语法
..依存和中心词之间的关系
..范畴语法
.口语的句法
..不流畅现象与口语修正
..口语树库
.语法和人的语言处理
.小结
.文献和历史说明
第章句法剖析
.剖析就是搜索
..自顶向下剖析
..自底向上剖析
..自顶向下剖析与自底向上剖析比较
.歧义
.面对歧义的搜索
.动态规划剖析方法
..CKY剖析
..Earley算法
..线图剖析
.局部剖析
..基于规则的有限状态组块分析
..基于机器学习的组块分析方法
..组块分析系统的评测
.小结
.文献和历史说明
第章统计剖析
.概率上下文无关语法
..PCFG用于排歧
..PCFG用于语言建模
.PCFG的概率CKY剖析
.PCFG规则概率的学习途径
.PCFG的问题
..独立性假设忽略了规则之间的结构依存关系
..缺乏对词汇依存关系的敏感性
.使用分离非终极符号的办法来改进PCFG
.概率词汇化的CFG
..Collins剖析器
..高级问题：Collins剖析器更多的细节
.剖析器的评测
.高级问题：分辨再排序
.高级问题：基于剖析器的语言模型
.人的剖析
.小结
.文献和历史说明
第章特征与合一
.特征结构
.特征结构的合一
.语法中的特征结构
..一致关系
..中心语特征
..次范畴化
..长距离依存关系
.合一的实现
..合一的数据结构
..合一算法
.带有合一约束的剖析
..把合一结合到Earley剖析器中
..基于合一的剖析
.类型与继承
..高级问题：类型的扩充
..合一的其他扩充
.小结
.文献和历史说明
第章语言和复杂性
.Chomsky层级
.怎么判断一种语言不是正则的
..抽吸引理
..证明各种自然语言不是正则语言
.自然语言是上下文无关的吗
.计算复杂性和人的语言处理
.小结
.文献和历史说明
第四部分语义和语用的计算机处理
第章意义的表示
.意义表示的计算要求
..可验证性
..无歧义性
..规范形式
..推理与变量
..表达能力
.模型论语义学
.一阶逻辑
..一阶逻辑基础
..变量和量词
..λ表示法
..一阶逻辑的语义
..推理
.事件与状态的表示
..时间表示
..体
.描述逻辑
.意义的具体化与情境表示方法
.小结
.文献和历史说明
第章计算语义学
.句法驱动的语义分析
.句法规则的语义扩充
.量词辖域歧义及非确定性
..存储与检索方法
..基于约束的方法
.基于合一的语义分析方法
.语义与Earley分析器的集成
.成语和组成性
.小结
.文献和历史说明
第章词汇语义学
.词义
.含义间的关系
..同义关系和反义关系
..上下位关系
..语义场
.WordNet：词汇关系信息库
.事件参与者
..题旨角色
..因素交替（DiathesisAlternations）
..题旨角色的问题
..命题库
..FrameNet
..选择限制
.基元分解
.高级问题：隐喻
.小结
.文献和历史说明
第章计算词汇语义学
.词义排歧：综述
.有监督词义排歧
..监督学习的特征抽取
..朴素贝叶斯分类器和决策表分类器
.WSD评价方法、基准线和上限
.WSD：字典方法和同义词库方法
..Lesk算法
..选择限制和选择优先度
.最低限度的监督WSD：自举法
.词语相似度：语义字典方法
.词语相似度：分布方法
..定义词语的共现向量
..度量与上下文的联系
..定义两个向量之间的相似度
..评价分布式词语相似度
.下位关系和其他词语关系
.语义角色标注
.高级主题：无监督语义排歧
.小结
.文献和历史说明
第章计算话语学
.话语分割
..无监督话语分割
..有监督话语分割
..话语分割的评价
.文本连贯性
..修辞结构理论
..自动连贯指派
.指代消解
.指代现象
..指示语的五种类型
..信息状态
.代词指代消解所使用的特征
..用来过滤潜在指代对象的特征
..代词解释中的优先关系
.指代消解的三种算法
..代词指代基准系统：Hobbs算法
..指代消解的中心算法
..代词指代消解的对数线性模型
..代词指代消解的特征
.共指消解
.共指消解的评价
.高级问题：基于推理的连贯判定
.所指的心理语言学研究
.小结
.文献和历史说明
第五部分应用
第章信息抽取
.命名实体识别
..命名实体识别中的歧义
..基于序列标注的命名实体识别
..命名实体识别的评价
..实用NER架构
.关系识别和分类
..用于关系分析的有监督学习方法
..用于关系分析的弱监督学习方法
..关系分析系统的评价
.时间和事件处理
..时间表达式的识别
..时间的归一化
..事件检测和分析
..TimeBank
.模板填充
..模板填充的统计方法
..有限状态机模板填充系统
.高级话题：生物医学信息的抽取
..生物学命名实体识别
..基因归一化
..生物学角色和关系
.小结
.文献和历史说明
第章问答和摘要
.信息检索
..向量空间模型
..词语权重计算
..词语选择和建立
..信息检索系统的评测
..同形关系、多义关系和同义关系
..改进用户查询的方法
.事实性问答
..问题处理
..段落检索
..答案处理
..事实性答案的评价
.摘要
.单文档摘要
..无监督的内容选择
..基于修辞分析的无监督摘要
..有监督的内容选择
..句子简化
.多文档摘要
..多文档摘要的内容选择
..多文档摘要的信息排序
.主题摘要和问答
.摘要的评价
.小结
.文献和历史说明
第章对话与会话智能代理
.人类会话的属性
..话轮和话轮转换
..语言作为行动：言语行为
..语言作为共同行动：对话的共同基础
..会话结构
..会话隐含
.基本的对话系统
..ASR组件
..NLU组件
..生成和TTS组件
..对话管理器
..错误处理：确认和拒绝
.VoiceXML
.对话系统的设计和评价
..设计对话系统
..评价对话系统
.信息状态和对话行为
..使用对话行为
..解释对话行为
..检测纠正行为
..生成对话行为：确认和拒绝
.马尔可夫决策过程架构
.高级问题：基于规划的对话行为
..规划推理解释和生成
..对话的意图结构
.小结
.文献和历史说明
第章机器翻译
.为什么机器翻译如此困难
..类型学
..其他的结构差异
..词汇的差异
.经典的机器翻译方法与Vauquois三角形
..直接翻译
..转换方法
..传统机器翻译系统中的直接和转换相融合的方法
..中间语言的思想：使用意义
.统计机器翻译
.P（F|E）：基于短语的翻译模型
.翻译中的对齐
..IBM模型
..HMM对齐
.对齐模型的训练
..训练对齐模型的EM算法
.用于基于短语机器翻译的对称对齐
.基于短语统计机器翻译的解码
.机器翻译评价
..使用人工评价者
..自动评价：BLEU
.高级问题：机器翻译的句法模型
.高级问题：IBM模型和繁衍度
..模型的训练
.高级问题：机器翻译的对数线性模型
.小结
.文献和历史说明
参考文献
・ ・ ・ ・ ・ ・ (收起)Preface
.Language Processing and Python
. Computing with Language： Texts and Words
. A Closer Look at Python： Texts as Lists of Words
. Computing with Language： Simple Statistics
. Back to Python： Making Decisions and Taking Control
. Automatic Natural Language Understanding
. Summary
. Further Reading
. Exercises
.Accessing Text Corpora and Lexical Resources
. Accessing Text Corpora
. Conditional Frequency Distributions
. More Python： Reusing Code
. Lexical Resources
. WordNet
. Summary
. Further Reading
. Exercises
.Processing Raw Text
. Accessing Text from the Web and from Disk
. Strings： Text Processing at the Lowest Level
. Text Processing with Unicode
. Regular Expressions for Detecting Word Patterns
. Useful Applications of Regular Expressions
. Normalizing Text
. Regular Expressions for Tokenizing Text
. Segmentation
. Formatting： From Lists to Strings
. Summary
. Further Reading
. Exercises
.Writing Structured Programs
. Back to the Basics
. Sequences
. Questions of Style
. Functions： The Foundation of Structured Programming
. Doing More with Functions
. Program Development
. Algorithm Design
. A Sample of Python Libraries
. Summary
. Further Reading
. Exercises
.Categorizing andTagging Words
. Using a Tagger
. Tagged Corpora
. Mapping Words to Properties Using Python Dictionaries
. Automatic Tagging
. N-Gram Tagging
. Transformation-Based Tagging
. How to Determine the Category of a Word
. Summary
. Further Reading
. Exercises
.Learning to Classify Text
. Supervised Classification
. Further Examples of Supervised Classification
. Evaluation
. Decision Trees
. Naive Bayes Classifiers
. Maximum Entropy Classifiers
. Modeling Linguistic Patterns
. Summary
. Further Reading
. Exercises
.Extracting Information from Text
. Information Extraction
. Chunking
. Developing and Evaluating Chunkers
. Recursion in Linguistic Structure
. Named Entity Recognition
. Relation Extraction
. Summary
. Further Reading
. Exercises
.Analyzing Sentence Structure
. Some Grammatical Dilemmas
. Whats the Use of Syntax?
. Context-Free Grammar
. Parsing with Context-Free Grammar
. Dependencies and Dependency Grammar
. Grammar Development
. Summary
. Further Reading
. Exercises
.Building Feature-Based Grammars
. Grammatical Features
. Processing Feature Structures
. Extending a Feature-Based Grammar
. Summary
. Further Reading
. Exercises
.Analyzing the Meaning of Sentences
. Natural Language Understanding
. Propositional Logic
. First-Order Logic
. The Semantics of English Sentences
. Discourse Semantics
. Summary
. Further Reading
. Exercises
.Managing Linguistic Data
. Corpus Structure： A Case Study
. The Life Cycle of a Corpus
. Acquiring Data
. Working with XML
. Working with Toolbox Data
. Describing Language Resources Using OLAC Metadata
. Summary
. Further Reading
. Exercises
Afterword： The Language Challenge
Bibliography
NLTK Index
General Index
・ ・ ・ ・ ・ ・ (收起)《python自然语言处理》
第章 语言处理与python 
. 语言计算：文本和词汇 
. 近观python：将文本当做词链表 
. 计算语言：简单的统计 
. 回到python:决策与控制 
. 自动理解自然语言 
. 小结 
. 深入阅读 
. 练习 
第章 获得文本语料和词汇资源 
. 获取文本语料库 
. 条件频率分布 
. 更多关于python：代码重用 
. 词典资源 
. wordnet 
. 小结 
. 深入阅读 
. 练习 
第章 处理原始文本 
. 从网络和硬盘访问文本 
. 字符串：最底层的文本处理 
. 使用unicode进行文字处理 
. 使用正则表达式检测词组搭配 
. 正则表达式的有益应用 
. 规范化文本 
. 用正则表达式为文本分词 
. 分割 
. 格式化：从链表到字符串 
. 小结 
. 深入阅读 
. 练习 
第章 编写结构化程序 
. 回到基础 
. 序列 
. 风格的问题 
. 函数：结构化编程的基础 
. 更多关于函数 
. 程序开发 
. 算法设计 
. python库的样例 
. 小结 
. 深入阅读 
. 练习 
第章 分类和标注词汇 
. 使用词性标注器 
. 标注语料库 
. 使用python字典映射词及其属性 
. 自动标注 
. n-gram标注 
. 基于转换的标注 
. 如何确定一个词的分类 
. 小结 
. 深入阅读 
. 练习 
第章 学习分类文本 
. 监督式分类 
. 监督式分类的举例 
. 评估 
. 决策树 
. 朴素贝叶斯分类器 
. 最大熵分类器 
. 为语言模式建模 
. 小结 
. 深入阅读 
. 练习 
第章 从文本提取信息 
. 信息提取 
. 分块 
. 开发和评估分块器 
. 语言结构中的递归 
. 命名实体识别 
. 关系抽取 
. 小结 
. 深入阅读 
. 练习 
第章 分析句子结构 
. 一些语法困境 
. 文法的用途 
. 上下文无关文法 
. 上下文无关文法分析 
. 依存关系和依存文法 
. 文法开发 
. 小结 
. 深入阅读 
. 练习 
第章 建立基于特征的文法 
. 文法特征 
. 处理特征结构 
. 扩展基于特征的文法 
. 小结 
. 深入阅读 
. 练习 
第章 分析语句的含义 
. 自然语言理解 
. 命题逻辑 
. 一阶逻辑 
. 英语语句的语义 
. 段落语义层 
. 小结 
. 深入阅读 
. 练习 
第章 语言数据管理 
. 语料库结构：案例研究 
. 语料库生命周期 
. 数据采集 
. 使用xml 
. 使用toolbox数据 
. 使用olac元数据描述语言资源 
. 小结 
. 深入阅读 
. 练习 
后记 
参考文献 
・ ・ ・ ・ ・ ・ (收起)译者序
推荐序
作者介绍
关于审校人员
前言
第章 引言 
. 自然语言处理 
. 基础应用 
. 高级应用 
. NLP和Python相结合的优势 
. nltk环境搭建 
. 读者提示 
. 总结 
第章 实践理解语料库和数据集 
. 语料库 
. 语料库的作用 
. 语料分析 
. 数据属性的类型 
.. 分类或定性数据属性 
.. 数值或定量数据属性 
. 不同文件格式的语料 
. 免费语料库资源 
. 为NLP应用准备数据集 
.. 挑选数据 
.. 预处理数据集 
. 网页爬取 
. 总结 
第章 理解句子的结构 
. 理解NLP的组成 
.. 自然语言理解 
.. 自然语言生成 
.. NLU和NLG的区别 
.. NLP的分支 
. 上下文无关文法 
. 形态分析 
.. 形态学 
.. 词素 
.. 词干 
.. 形态分析 
.. 词 
.. 词素的分类 
.. 词干和词根的区别 
. 词法分析 
.. 词条 
.. 词性标注 
.. 导出词条的过程 
.. 词干提取和词形还原的区别 
.. 应用 
. 句法分析 
. 语义分析 
.. 语义分析概念 
.. 词级别的语义 
.. 上下位关系和多义词 
.. 语义分析的应用 
. 消歧 
.. 词法歧义 
.. 句法歧义 
.. 语义歧义 
.. 语用歧义 
. 篇章整合 
. 语用分析 
. 总结 
第章 预处理 
. 处理原始语料库文本 
.. 获取原始文本 
.. 小写化转换 
.. 分句 
.. 原始文本词干提取 
.. 原始文本词形还原 
.. 停用词去除 
. 处理原始语料库句子 
.. 词条化 
.. 单词词形还原 
. 基础预处理 
. 实践和个性化预处理 
.. 由你自己决定 
.. 预处理流程 
.. 预处理的类型 
.. 理解预处理的案例 
. 总结 
第章 特征工程和NLP算法 
. 理解特征工程 
.. 特征工程的定义 
.. 特征工程的目的 
.. 一些挑战 
. NLP中的基础特征 
.. 句法分析和句法分析器 
.. 词性标注和词性标注器 
.. 命名实体识别 
.. n元语法 
.. 词袋 
.. 语义工具及资源 
. NLP中的基础统计特征 
.. 数学基础 
.. TF-IDF 
.. 向量化 
.. 规范化 
.. 概率模型 
.. 索引 
.. 排序 
. 特征工程的优点 
. 特征工程面临的挑战 
. 总结 
第章 高级特征工程和NLP算法 
. 词嵌入 
. wordvec基础 
.. 分布语义 
.. 定义wordvec 
.. 无监督分布语义模型中的必需品 
. wordvec模型从黑盒到白盒 
. 基于表示的分布相似度 
. wordvec模型的组成部分 
.. wordvec的输入 
.. wordvec的输出 
.. wordvec模型的构建模块 
. wordvec模型的逻辑 
.. 词汇表构建器 
.. 上下文环境构建器 
.. 两层的神经网络 
.. 算法的主要流程 
. wordvec模型背后的算法和数学理论 
.. wordvec算法中的基本数学理论 
.. 词汇表构建阶段用到的技术 
.. 上下文环境构建过程中使用的技术 
. 神经网络算法 
.. 基本神经元结构 
.. 训练一个简单的神经元 
.. 单个神经元的应用 
.. 多层神经网络 
.. 反向传播算法 
.. wordvec背后的数学理论 
. 生成最终词向量和概率预测结果的技术 
. wordvec相关的一些事情 
. wordvec的应用 
.. 实现一些简单例子 
.. wordvec的优势 
.. wordvec的挑战 
.. 在实际应用中使用wordvec 
.. 何时使用wordvec 
.. 开发一些有意思的东西 
.. 练习 
. wordvec概念的扩展 
.. paravec 
.. docvec 
.. docvec的应用 
.. GloVe 
.. 练习 
. 深度学习中向量化的重要性 
. 总结 
第章 规则式自然语言处理系统 
. 规则式系统 
. 规则式系统的目的 
.. 为何需要规则式系统 
.. 使用规则式系统的应用 
.. 练习 
.. 开发规则式系统需要的资源 
. 规则式系统的架构 
.. 从专家系统的角度来看规则式系统的通用架构 
.. NLP应用中的规则式系统的实用架构 
.. NLP应用中的规则式系统的定制架构 
.. 练习 
.. Apache UIMA架构 
. 规则式系统的开发周期 
. 规则式系统的应用 
.. 使用规则式系统的NLP应用 
.. 使用规则式系统的通用AI应用 
. 使用规则式系统来开发NLP应用 
.. 编写规则的思维过程 
.. 基于模板的聊天机器人应用 
. 规则式系统与其他方法的对比 
. 规则式系统的优点 
. 规则式系统的缺点 
. 规则式系统面临的挑战 
. 词义消歧的基础 
. 规则式系统近期发展的趋势 
. 总结 
第章 自然语言处理中的机器学习方法 
. 机器学习的基本概念 
. 自然语言处理应用的开发步骤 
.. 第一次迭代时的开发步骤 
.. 从第二次到第N次迭代的开发步骤 
. 机器学习算法和其他概念 
.. 有监督机器学习方法 
.. 无监督机器学习方法 
.. 半监督机器学习算法 
.. 一些重要概念 
.. 特征选择 
.. 维度约减 
. 自然语言处理中的混合方法 
. 总结 
第章 NLU和NLG问题中的深度学习 
. 人工智能概览 
.. 人工智能的基础 
.. 人工智能的阶段 
.. 人工智能的种类 
.. 人工智能的目标和应用 
. NLU和NLG之间的区别 
.. 自然语言理解 
.. 自然语言生成 
. 深度学习概览 
. 神经网络基础 
.. 神经元的第一个计算模型 
.. 感知机 
.. 理解人工神经网络中的数学概念 
. 实现神经网络 
.. 单层反向传播神经网络 
.. 练习 
. 深度学习和深度神经网络 
.. 回顾深度学习 
.. 深度神经网络的基本架构 
.. NLP中的深度学习 
.. 传统NLP和深度学习NLP技术的区别 
. 深度学习技术和NLU 
. 深度学习技术和NLG 
.. 练习 
.. 菜谱摘要和标题生成 
. 基于梯度下降的优化 
. 人工智能与人类智能 
. 总结 
第章 高级工具 
. 使用Apache Hadoop作为存储框架 
. 使用Apache Spark作为数据处理框架 
. 使用Apache Flink作为数据实时处理框架 
. Python中的可视化类库 
. 总结 
第章 如何提高你的NLP技能 
. 开始新的NLP职业生涯 
. 备忘列表 
. 确定你的领域 
. 通过敏捷的工作来实现成功 
. NLP和数据科学方面一些有用的博客 
. 使用公开的数据集 
. 数据科学领域需要的数学知识 
. 总结 
第章 安装指导 
. 安装Python、pip和NLTK 
. 安装PyCharm开发环境 
. 安装依赖库 
. 框架安装指导 
. 解决你的疑问 
. 总结 
・ ・ ・ ・ ・ ・ (收起)译者序
作者简介
审校者简介
前言
第章 NLP简介 
. 什么是NLP 
. 为何使用NLP 
. NLP的难点 
. NLP工具汇总 
.. Apache OpenNLP 
.. Stanford NLP 
.. LingPipe 
.. GATE 
.. UIMA 
. 文本处理概览 
.. 文本分词 
.. 文本断句 
.. 人物识别 
.. 词性判断 
.. 文本分类 
.. 关系提取 
.. 方法组合 
. 理解NLP模型 
.. 明确目标 
.. 选择模型 
.. 构建、训练模型 
.. 验证模型 
.. 使用模型 
. 准备数据 
. 本章小结 
第章 文本分词 
. 理解文本分词 
. 什么是分词 
. 一些简单的Java分词器 
.. 使用Scanner类 
.. 使用split方法 
.. 使用BreakIterator类 
.. 使用StreamTokenizer类 
.. 使用StringTokenizer类 
.. 使用Java核心分词法的性能考虑 
. NLP分词器的API 
.. 使用OpenNLPTokenizer类分词器 
.. 使用Stanford分词器 
.. 训练分词器进行文本分词 
.. 分词器的比较 
. 理解标准化处理 
.. 转换为小写字母 
.. 去除停用词 
.. 词干化 
.. 词形还原 
.. 使用流水线进行标准化处理 
. 本章小结 
第章 文本断句 
. SBD方法 
. SBD难在何处 
. 理解LingPipe的HeuristicSen-tenceModel类的SBD规则 
. 简单的Java SBD 
.. 使用正则表达式 
.. 使用BreakIterator类 
. 使用NLP API 
.. 使用OpenNLP 
.. 使用Stanford API 
.. 使用LingPipe 
. 训练文本断句模型 
.. 使用训练好的模型 
.. 使用SentenceDetector-Evaluator类评估模型 
. 本章小结 
第章 人物识别 
. NER难在何处 
. NER的方法 
.. 列表和正则表达式 
.. 统计分类器 
. 使用正则表达式进行NER 
.. 使用Java的正则表达式来寻找实体 
.. 使用LingPipe的RegEx-Chunker类 
. 使用NLP API 
.. 使用OpenNLP进行NER 
.. 使用Stanford API进行NER 
.. 使用LingPipe进行NER 
. 训练模型 
. 本章小结 
第章 词性判断 
. 词性标注 
.. 词性标注器的重要性 
.. 词性标注难在何处 
. 使用NLP API 
.. 使用OpenNLP词性标注器 
.. 使用Stanford词性标注器 
.. 使用LingPipe词性标注器 
.. 训练OpenNLP词性标注模型 
. 本章小结 
第章 文本分类 
. 文本分类问题 
. 情感分析介绍 
. 文本分类技术 
. 使用API进行文本分类 
.. OpenNLP的使用 
.. Stanford API的使用 
.. 使用LingPipe进行文本分类 
. 本章小结 
第章 关系提取 
. 关系类型 
. 理解解析树 
. 关系提取的应用 
. 关系提取 
. 使用NLP API 
.. OpenNLP的使用 
.. 使用Stanford API 
.. 判断共指消解的实体 
. 问答系统的关系提取 
.. 判断单词依赖关系 
.. 判断问题类型 
.. 搜索答案 
. 本章小结 
第章 方法组合 
. 准备数据 
.. 使用Boilerpipe从HTML中提取文本 
.. 使用POI从Word文档中提取文本 
.. 使用PDFBox从PDF文档中提取文本 
. 流水线 
.. 使用Stanford流水线 
.. 在Standford流水线中使用多核处理器 
. 创建一个文本搜索的流水线 
. 本章小结 
・ ・ ・ ・ ・ ・ (收起)第 章基础入门 
. 什么是自然语言处理 
.. 自然语言处理概述 
.. 自然语言处理的发展历史 
.. 自然语言处理的工作原理 
.. 自然语言处理的应用前景 
. 开发工具与环境 
.. Sublime Text 和Anaconda 介绍 
.. 开发环境的安装与配置 
. 实战：第一个小程序的诞生 
.. 实例介绍 
.. 源码实现 
第 章快速上手Python 
. 初识Python 编程语言 
.. Python 概述 
.. Python 能做什么 
.. Python 的语法和特点 
. Python 进阶 
.. Hello World 
.. 语句和控制流 
.. 函数 
.. List 列表 
.. 元组 
.. set 集合 
.. 字典 
.. 面向对象编程：类 
.. 标准库 
. Python 深入――第三方库 
.. Web 框架 
.. 科学计算 
.. GUI 
.. 其他库 
第 章线性代数 
. 线性代数介绍 
. 向量 
.. 向量定义 
.. 向量表示 
.. 向量定理 
.. 向量运算 
. 矩阵 
.. 矩阵定义 
.. 矩阵表示 
.. 矩阵运算 
.. 线性方程组 
.. 行列式 
.. 特征值和特征向量 
. 距离计算 
.. 余弦距离 
.. 欧氏距离 
.. 曼哈顿距离 
.. 明可夫斯基距离 
.. 切比雪夫距离 
.. 杰卡德距离 
.. 汉明距离 
.. 标准化欧式距离 
.. 皮尔逊相关系数 
第 章概率论 
. 概率论介绍 
. 事件 
.. 随机试验 
.. 随机事件和样本空间 
.. 事件的计算 
. 概率 
. 概率公理 
. 条件概率和全概率 
.. 条件概率 
.. 全概率 
. 贝叶斯定理 
. 信息论 
.. 信息论的基本概念 
.. 信息度量 
第 章统计学 
. 图形可视化 
.. 饼图 
.. 条形图 
.. 热力图 
.. 折线图 
.. 箱线图 
.. 散点图 
.. 雷达图 
.. 仪表盘 
.. 可视化图表用法 
. 数据度量标准 
.. 平均值 
.. 中位数 
.. 众数 
.. 期望 
.. 方差 
.. 标准差 
.. 标准分 
. 概率分布 
.. 几何分布 
.. 二项分布 
.. 正态分布 
.. 泊松分布 
. 统计假设检验 
. 相关和回归 
.. 相关 
.. 回归 
.. 相关和回归的联系 
第 章语言学 
. 语音 
.. 什么是语音 
.. 语音的三大属性 
.. 语音单位 
.. 记音符号 
.. 共时语流音变 
. 词汇 
.. 什么是词汇 
.. 词汇单位 
.. 词的构造 
.. 词义及其分类 
.. 义项与义素 
.. 语义场 
.. 词汇的构成 
. 语法 
.. 什么是语法 
.. 词类 
.. 短语 
.. 单句 
.. 复句 
第 章自然语言处理 
. 自然语言处理的任务和限制 
. 自然语言处理的主要技术范畴 
.. 语音合成 
.. 语音识别 
.. 中文自动分词 
.. 词性标注 
.. 句法分析 
.. 文本分类 
.. 文本挖掘 
.. 信息抽取 
.. 问答系统 
.. 机器翻译 
.. 文本情感分析 
.. 自动摘要 
.. 文字蕴涵 
. 自然语言处理的难点 
.. 语言环境复杂 
.. 文本结构形式多样 
.. 边界识别限制 
.. 词义消歧 
.. 指代消解 
. 自然语言处理展望 
第 章语料库 
. 语料库浅谈 
. 语料库深入 
. 自然语言处理工具包：NLTK 
.. NLTK 简介 
.. 安装NLTK 
.. 使用NLTK 
.. 在Python NLTK 下使用Stanford NLP 
. 获取语料库 
.. 国内外著名语料库 
.. 网络数据获取 
.. NLTK 获取语料库 
. 综合案例：走进大秦帝国 
.. 数据采集和预处理 
.. 构建本地语料库 
.. 大秦帝国语料操作 
第 章中文自动分词 
. 中文分词简介 
. 中文分词的特点和难点 
. 常见中文分词方法 
. 典型中文分词工具 
.. HanLP 中文分词 
.. 其他中文分词工具 
. 结巴中文分词 
.. 基于Python 的结巴中文分词 
.. 结巴分词工具详解 
.. 结巴分词核心内容 
.. 结巴分词基本用法 
第 章数据预处理 
. 数据清洗 
. 分词处理 
. 特征构造 
. 特征降维与选择 
.. 特征降维 
.. 特征选择 
. 简单实例 
. 本章小结 
第 章马尔可夫模型 
. 马尔可夫链 
.. 马尔可夫简介 
.. 马尔可夫链的基本概念 
. 隐马尔可夫模型 
.. 形式化描述 
.. 数学形式描述 
. 向前算法解决HMM 似然度 
.. 向前算法定义 
.. 向前算法原理 
.. 现实应用：预测成都天气的冷热 
. 文本序列标注案例：Viterbi 算法 
第 章条件随机场 
. 条件随机场介绍 
. 简单易懂的条件随机场 
.. CRF 的形式化表示 
.. CRF 的公式化表示 
.. 深度理解条件随机场 
第 章模型评估 
. 从统计角度介绍模型概念 
.. 算法模型 
.. 模型评估和模型选择 
.. 过拟合与欠拟合的模型选择 
. 模型评估与选择 
.. 模型评估的概念 
.. 模型评估的评测指标 
.. 以词性标注为例分析模型评估 
.. 模型评估的几种方法 
. ROC 曲线比较学习器模型 
第 章命名实体识别 
. 命名实体识别概述 
. 命名实体识别的特点与难点 
. 命名实体识别方法 
. 中文命名实体识别的核心技术 
. 展望 
第 章自然语言处理实战 
. GitHub 数据提取与可视化分析 
.. 了解GitHub 的API 
.. 使用NetworkX 作图 
.. 使用NetworkX 构建兴趣图 
.. NetWorkX 部分统计指标 
.. 构建GitHub 的兴趣图 
.. 可视化 
. 微博话题爬取与存储分析 
.. 数据采集 
.. 数据提取 
.. 数据存储 
.. 项目运行与分析 
附录A Python 与其他语言调用 
附录B Git 项目上传简易教程 
参考文献 
・ ・ ・ ・ ・ ・ (收起)模块　NLTK基础知识
第　章 自然语言处理简介　
.　为什么要学习NLP　
.　从Python的基本知识开始　
..　列表　
..　自助　
..　正则表达式　
..　词典　
..　编写函数　
.　NLTK　
.　试一试　
.　本章小结　
第　章 文本的整理和清洗　
.　文本整理　
.　文本清洗　
.　句子拆分器　
.　标记解析　
.　词干提取　
.　词形还原　
.　停用词删除　
.　生僻字删除　
.　拼写校正　
.　试一试　
.　本章小结　
第章　词性标注　
.　什么是词性标注　
..　斯坦福标注器　
..　深入了解标注器　
..　序列标注器　
..　布里尔标注器　
..　基于标注器的机器学习　
.　命名实体识别　
.　试一试　
.　本章小结　
第章　对文本的结构进行语法分析　
.　浅层语法分析与深层语法
分析　
.　语法分析的两种方法　
.　为什么需要语法分析　
.　不同类型的语法分析器　
..　递归下降的语法分析器　
..　移位归约语法分析器　
..　图表语法分析器　
..　正则表达式语法
分析器　
.　依存分析　
.　组块化　
.　信息抽取　
..　命名实体识别　
..　关系抽取　
.　本章小结　
第章　NLP应用　
.　构建第 一个NLP应用　
.　其他的NLP应用　
..　机器翻译　
..　统计机器翻译　
..　信息检索　
..　语音识别　
..　文本分类　
..　信息提取　
..　问答系统　
..　对话系统　
..　词义消歧　
..　主题建模　
..　语言检测　
..　光学字符识别　
.　本章小结　
第章　文本分类　
.　机器学习　
.　文本分类　
.　采样　
..　朴素贝叶斯　
..　决策树　
..　随机梯度下降　
..　逻辑回归　
..　支持向量机　
.　随机森林算法　
.　文本聚类　
.　文本的主题建模　
.　参考资料　
.　本章小结　
第章　网络爬取　
.　网络爬虫　
.　编写第 一个爬虫程序　
.　Scrapy中的数据流　
..　Scrapy命令行界面　
..　项　
.　站点地图蜘蛛　
.　项管道　
.　外部参考　
.　本章小结　
第章　与其他Python库一同
使用NLTK　
.　NumPy　
..　ndarray　
..　基本操作　
..　从数组中提取数据　
..　复杂的矩阵运算　
.　SciPy　
..　线性代数　
..　特征值和特征向量　
..　稀疏矩阵　
..　优化　
.　Pandas　
..　读取数据　
..　时序数据　
..　列转换　
..　噪声数据　
.　Matplotlib　
..　subplot　
..　添加轴　
..　散点图　
..　柱状图　
..　D图　
.　外部参考　
.　本章小结　
第章　使用Python进行社交媒体
挖掘　
.　数据收集　
.　数据提取　
.　地理可视化　
..　影响者检测　
..　Facebook　
..　影响者的朋友　
.　本章小结　
第　章 大规模的文本挖掘　
.　在Hadoop上使用Python的
不同方法　
..　Python的流　
..　Hive/Pig UDF　
..　流包装器　
.　在Hadoop上运行NLTK　
..　UDF　
..　Python流　
.　在Hadoop上运行
Scikit-learn　
.　PySpark　
.　本章小结　
模块　使用Python 的NLTK 进行文本处理
第　章 标记文本和WordNet的基础　
.　引言　
.　将文本标记成句子　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　将句子标记成单词　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式标记语句　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练语句标记生成器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　在已标记的语句中过滤
停用词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　查找WordNet中单词的
Synset　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　在WordNet中查找词元和
同义词　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　计算WordNet和Synset的
相似度　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　发现单词搭配　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第　章 替换和校正单词　
.　引言　
.　词干提取　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用WordNet进行词形还原　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　基于匹配的正则表达式替换
单词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　移除重复字符　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用Enchant进行拼写校正　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　替换同义词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用反义词替换否定形式　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　创建自定义语料库　
.　引言　
.　建立自定义语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建词汇表语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已标记词性单词的
语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已组块短语的语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已分类文本的语料库　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建已分类组块语料库
读取器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　懒惰语料库加载　
..　工作方式　
..　工作原理　
..　更多信息　
.　创建自定义语料库视图　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建基于MongoDB的
语料库读取器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　在加锁文件的情况下编辑
语料库　
..　准备工作　
..　工作方式　
..　工作原理　
第章　词性标注　
.　引言　
.　默认标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练一元组词性标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　回退标注的组合标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练和组合N元标注器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建似然单词标签的
模型　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　词缀标签　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练布里尔标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练TnT标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用WordNet进行
标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
.　标注专有名词　
..　工作方式　
..　工作原理　
..　请参阅　
.　基于分类器的标注　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用NLTK训练器训练
标注器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　提取组块　
.　引言　
.　使用正则表达式组块和
隔断　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式合并和拆分
组块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式扩展和删除
组块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用正则表达式进行部分
解析　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练基于标注器的组块器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　基于分类的分块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　提取命名实体　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　提取专有名词组块　
..　工作方式　
..　工作原理　
..　更多信息　
.　提取部位组块　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练命名实体组块器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用NLTK训练器训练
组块器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　转换组块与树　
.　引言　
.　过滤句子中无意义的
单词　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　纠正动词形式　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
.　交换动词短语　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　交换名词基数　
..　工作方式　
..　工作原理　
..　请参阅　
.　交换不定式短语　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　单数化复数名词　
..　工作方式　
..　工作原理　
..　请参阅　
.　链接组块变换　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　将组块树转换为文本　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　平展深度树　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　创建浅树　
..　工作方式　
..　工作原理　
..　请参阅　
.　转换树标签　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
第章　文本分类　
.　引言　
.　词袋特征提取　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练朴素贝叶斯
分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练决策树分类器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练最大熵分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　训练scikit-learn
分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　衡量分类器的精准率和
召回率　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　计算高信息量单词　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用投票组合分类器　
..　准备工作　
..　工作方式　
..　工作原理　
..　请参阅　
.　使用多个二元分类器
分类　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用NLTK训练器训练
分类器　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
第章　分布式进程和大型数据集的
处理　
.　引言　
.　使用execnet进行分布式
标注　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　使用execnet进行分布式
组块　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　使用execnet并行处理
列表　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　在Redis中存储频率分布　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　在Redis中存储条件频率
分布　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　在Redis中存储有序
字典　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
.　使用Redis和execnet进行
分布式单词评分　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多内容　
..　请参阅　
第章　解析特定的数据类型　
.　引言　
.　使用dateutil解析日期和
时间　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　时区的查找和转换　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用lxml从HTML中提取
URL　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　清理和剥离HTML　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　使用BeautifulSoup转换
HTML实体　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
.　检测和转换字符编码　
..　准备工作　
..　工作方式　
..　工作原理　
..　更多信息　
..　请参阅　
附录A　宾州treebank词性标签　
模块　使用Python掌握自然语言处理
第　章 使用字符串　
.　标记化　
..　将文本标记为句子　
..　其他语言文字的标记化　
..　将句子标记为单词　
..　使用TreebankWordTokenizer
进行标记化　
..　使用正则表达式进行
标记化　
.　规范化　
..　消除标点符号　
..　转化为小写和大写　
..　处理停用词　
..　计算英语中的停用词　
.　替代和纠正标记　
..　使用正则表达式替换
单词　
..　使用一个文本替换另一个
文本的示例　
..　在标记化之前进行
替代　
..　处理重复的字符　
..　删除重复字符的示例　
..　使用单词的同义词替换
单词　
.　在文本上应用齐夫定律　
.　相似性量度　
..　使用编辑距离算法应用
相似性量度　
..　使用杰卡德系数应用
相似性量度　
..　使用史密斯-沃特曼算法
应用相似性量度　
..　其他字符串相似性指标　
.　本章小结　
第　章 统计语言模型　
.　单词频率　
..　对给定文本进行最大
似然估计　
..　隐马尔可夫模型估计　
.　在MLE模型上应用平滑　
..　加一平滑法　
..　古德-图灵算法　
..　聂氏估计　
..　威滕 贝尔估计　
.　为MLE指定回退机制　
.　应用数据插值获得混合和
匹配　
.　应用困惑度评估语言模型　
.　在建模语言中应用
梅特罗波利斯-黑斯廷斯算法　
.　在语言处理中应用
吉布斯采样　
.　本章小结　
第章　词语形态学―试一试　
.　词语形态学　
.　词根还原器　
.　词形还原　
.　开发用于非英语语言的词根
还原器　
.　词语形态分析器　
.　词语形态生成器　
.　搜索引擎　
.　本章小结　
第章　词性标注―识别单词　
.　词性标注　
.　创建POS标注的语料库　
.　选择某个机器学习算法　
.　涉及n元组方法的统计建模　
.　使用POS标注的语料库开发
组块器　
.　本章小结　
第章　解析―分析训练数据　
.　解析　
.　构建树库　
.　从树库中提取上下文无关文法的
规则　
.　从CFG中创建概率上下文无关的
文法　
.　CYK图解析算法　
.　厄雷图解析算法　
.　本章小结　
第章　语义分析―意义重大　
.　语义分析　
..　NER简介　
..　使用隐马尔可夫模型的
NER系统　
..　使用机器学习工具包训练
NER　
..　使用POS标注的
NER　
.　从Wordnet中生成同义词集
ID　
.　使用Wordnet消除歧义　
.　本章小结　
第章　情感分析―我很高兴　
.　情感分析　
.　使用机器学习的情感分析　
.　本章小结　
第章　信息检索―访问信息　
.　信息检索　
..　停用词删除　
..　利用向量空间模型进行
信息检索　
.　向量空间评分以及与查询
操作器交互　
.　利用隐含语义索引开发IR
系统　
.　文本摘要　
.　问答系统　
.　本章小结　
第章　话语分析―知识就是信仰　
.　话语分析　
..　使用定中心理论进行
话语分析　
..　回指解析　
.　本章小结　
第　章 NLP系统的评估―
性能分析　
.　对NLP系统进行评估的
需求　
..　NLP工具（POS标注器、
词干还原器和形态分析器）
的评估　
..　使用黄金数据评估
解析器　
.　IR系统的评估　
.　错误识别的指标　
.　基于词汇匹配的指标　
.　基于语法匹配的指标　
.　使用浅层语义匹配的
指标　
.　本章小结　
参考书目　
・ ・ ・ ・ ・ ・ (收起)第章 中文语言的机器处理 
. 历史回顾 
.. 从科幻到现实 
.. 早期的探索 
.. 规则派还是统计派 
.. 从机器学习到认知计算 
. 现代自然语言系统简介 
.. NLP流程与开源框架 
.. 哈工大NLP平台及其演示环境 
.. Stanford NLP团队及其演示环境 
.. NLTK开发环境 
. 整合中文分词模块 
.. 安装Ltp Python组件 
.. 使用Ltp .进行中文分词 
.. 使用结巴分词模块 
. 整合词性标注模块 
.. Ltp .词性标注 
.. 安装StanfordNLP并编写Python接口类 
.. 执行Stanford词性标注 
. 整合命名实体识别模块 
.. Ltp .命名实体识别 
.. Stanford命名实体识别 
. 整合句法解析模块 
.. Ltp .句法依存树 
.. Stanford Parser类 
.. Stanford短语结构树 
.. Stanford依存句法树 
. 整合语义角色标注模块 
. 结语 
第章 汉语语言学研究回顾 
. 文字符号的起源 
.. 从记事谈起 
.. 古文字的形成 
. 六书及其他 
.. 象形 
.. 指事 
.. 会意 
.. 形声 
.. 转注 
.. 假借 
. 字形的流变 
.. 笔与墨的形成与变革 
.. 隶变的方式 
.. 汉字的符号化与结构 
. 汉语的发展 
.. 完整语义的基本形式DD句子 
.. 语言的初始形态与文言文 
.. 白话文与复音词 
.. 白话文与句法研究 
. 三个平面中的语义研究 
.. 词汇与本体论 
.. 格语法及其框架 
. 结语 
第章 词汇与分词技术 
. 中文分词 
.. 什么是词与分词规范 
.. 两种分词标准 
.. 歧义、机械分词、语言模型 
.. 词汇的构成与未登录词 
. 系统总体流程与词典结构 
.. 概述 
.. 中文分词流程 
.. 分词词典结构 
.. 命名实体的词典结构 
.. 词典的存储结构 
. 算法部分源码解析 
.. 系统配置 
.. Main方法与例句 
.. 句子切分 
.. 分词流程 
.. 一元词网 
.. 二元词图 
.. NShort算法原理 
.. 后处理规则集 
.. 命名实体识别 
.. 细分阶段与最短路径 
. 结语 
第章 NLP中的概率图模型 
. 概率论回顾 
.. 多元概率论的几个基本概念 
.. 贝叶斯与朴素贝叶斯算法 
.. 文本分类 
.. 文本分类的实现 
. 信息熵 
.. 信息量与信息熵 
.. 互信息、联合熵、条件熵 
.. 交叉熵和KL散度 
.. 信息熵的NLP的意义 
. NLP与概率图模型 
.. 概率图模型的几个基本问题 
.. 产生式模型和判别式模型 
.. 统计语言模型与NLP算法设计 
.. 极大似然估计 
. 隐马尔科夫模型简介 
.. 马尔科夫链 
.. 隐马尔科夫模型 
.. HMMs的一个实例 
.. Viterbi算法的实现 
. 最大熵模型 
.. 从词性标注谈起 
.. 特征和约束 
.. 最大熵原理 
.. 公式推导 
.. 对偶问题的极大似然估计 
.. GIS实现 
. 条件随机场模型 
.. 随机场 
.. 无向图的团（Clique）与因子分解 
.. 线性链条件随机场 
.. CRF的概率计算 
.. CRF的参数学习 
.. CRF预测标签 
. 结语 
第章 词性、语块与命名实体识别 
. 汉语词性标注 
.. 汉语的词性 
.. 宾州树库的词性标注规范 
.. stanfordNLP标注词性 
.. 训练模型文件 
. 语义组块标注 
.. 语义组块的种类 
.. 细说NP 
.. 细说VP 
.. 其他语义块 
.. 语义块的抽取 
.. CRF的使用 
. 命名实体识别 
.. 命名实体 
.. 分词架构与专名词典 
.. 算法的策略DD词典与统计相结合 
.. 算法的策略DD层叠式架构 
. 结语 
第章 句法理论与自动分析 
. 转换生成语法 
.. 乔姆斯基的语言观 
.. 短语结构文法 
.. 汉语句类 
.. 谓词论元与空范畴 
.. 轻动词分析理论 
.. NLTK操作句法树 
. 依存句法理论 
.. 配价理论 
.. 配价词典 
.. 依存理论概述 
.. Ltp依存分析介绍 
.. Stanford依存转换、解析 
. PCFG短语结构句法分析 
.. PCFG短语结构 
.. 内向算法和外向算法 
.. Viterbi算法 
.. 参数估计 
.. Stanford 的PCFG算法训练 
. 结语 
第章 建设语言资源库 
. 语料库概述 
.. 语料库的简史 
.. 语言资源库的分类 
.. 语料库的设计实例：国家语委语料库 
.. 语料库的层次加工 
. 语法语料库 
.. 中文分词语料库 
.. 中文分词的测评 
.. 宾州大学CTB简介 
. 语义知识库 
.. 知识库与HowNet简介 
.. 发掘义原 
.. 语义角色 
.. 分类原则与事件分类 
.. 实体分类 
.. 属性与分类 
.. 相似度计算与实例 
. 语义网与百科知识库 
.. 语义网理论介绍 
.. 维基百科知识库 
.. DBpedia抽取原理 
. 结语 
第章 语义与认知 
. 回顾现代语义学 
.. 语义三角论 
.. 语义场论 
.. 基于逻辑的语义学 
. 认知语言学概述 
.. 象似性原理 
.. 顺序象似性 
.. 距离象似性 
.. 重叠象似性 
. 意象图式的构成 
.. 主观性与焦点 
.. 范畴化：概念的认知 
.. 主体与背景 
.. 意象图式 
.. 社交中的图式 
.. 完形：压缩与省略 
. 隐喻与转喻 
.. 隐喻的结构 
.. 隐喻的认知本质 
.. 隐喻计算的系统架构 
.. 隐喻计算的实现 
. 构式语法 
.. 构式的概念 
.. 句法与构式 
.. 构式知识库 
. 结语 
第章 NLP中的深度学习 
. 神经网络回顾 
.. 神经网络框架 
.. 梯度下降法推导 
.. 梯度下降法的实现 
.. BP神经网络介绍和推导 
. WordVec简介 
.. 词向量及其表达 
.. WordVec的算法原理 
.. 训练词向量 
.. 大规模上下位关系的自动识别 
. NLP与RNN 
.. Simple-RNN 
.. LSTM原理 
.. LSTM的Python实现 
. 深度学习框架与应用 
.. Keras框架介绍 
.. Keras序列标注 
.. 依存句法的算法原理 
.. Stanford依存解析的训练过程 
. 结语 
第章 语义计算的架构 
. 句子的语义和语法预处理 
.. 长句切分和融合 
.. 共指消解 
. 语义角色 
.. 谓词论元与语义角色 
.. PropBank简介 
.. CPB中的特殊句式 
.. 名词性谓词的语义角色 
.. PropBank展开 
. 句子的语义解析 
.. 语义依存 
.. 完整架构 
.. 实体关系抽取 
. 结语 
・ ・ ・ ・ ・ ・ (收起)第章 起步　　
. NLP中的基本概念和术语　　
.. 文本语料库　　
.. 段落　　
.. 句子　　
.. 短语和单词　　
.. n元语法　　
.. 词袋　　
. NLP技术的应用　　
.. 情感分析　　
.. 命名实体识别　　
.. 实体链接　　
.. 文本翻译　　
.. 自然语言推理　　
.. 语义角色标记　　
.. 关系提取　　
.. SQL查询生成或语义解析　　
.. 机器阅读理解　　
.. 文字蕴含　　
.. 指代消解　　
.. 搜索　　
.. 问答和聊天机器人　　
.. 文本转语音　　
.. 语音转文本　　
.. 说话人识别　　
.. 口语对话系统　　
.. 其他应用　　
. 小结　　
第章 使用NLTK进行文本分类和词性标注　　
. 安装NLTK 及其模块　　
. 文本预处理及探索性分析　　
.. 分词　　
.. 词干提取　　
.. 去除停用词　　
.. 探索性分析　　
. 词性标注　　
.. 词性标注定义　　
.. 词性标注的应用　　
.. 训练词性标注器　　
. 训练影评情感分类器　　
. 训练词袋分类器　　
. 小结　　
第章 深度学习和TensorFlow　　
. 深度学习　　
.. 感知器　　
.. 激活函数　　
.. 神经网络　　
.. 训练神经网络　　
.. 卷积神经网络　　
.. 递归神经网络　　
. TensorFlow　　
.. 通用图形处理单元　　
.. 安装　　
.. Hello world !　　
.. 两数相加　　
.. TensorBoard　　
.. Keras库　　
. 小结　　
第章 使用浅层模型进行语义嵌入　　
. 词向量　　
.. 经典方法　　
.. Wordvec　　
.. 连续词袋模型　　
.. 跳字模型　　
. 从单词到文档嵌入　　
. Sentencevec　　
. Docvec　　
. 小结　　
第章 使用LSTM进行文本分类　　
. 文本分类数据　　
. 主题建模　　
. 用于文本分类的深度学习元架构　　
.. 嵌入层　　
.. 深层表示　　
.. 全连接部分　　
. 使用RNN识别YouTube视频垃圾评论　　
. 使用CNN对新闻主题分类　　
. 使用GloVe嵌入进行迁移学习　　
. 多标签分类　　
.. 二元关联　　
.. 用于多标签分类的深度学习　　
.. 用于文档分类的attention网络　　
. 小结　　
第章 使用CNN进行搜索和去重　　
. 数据　　
. 模型训练　　
.. 文本编码　　
.. 建立CNN模型　　
.. 训练　　
.. 推理　　
. 小结　　
第章 使用字符级LSTM进行命名实体识别　　
. 使用深度学习实现NER　　
.. 数据　　
.. 模型　　
.. 代码详解　　
.. 不同预训练词嵌入的影响　　
.. 改进空间　　
. 小结　　
第章 使用GRU 进行文本生成和文本摘要　　
. 使用RNN进行文本生成　　
. 文本摘要　　
.. 提取式摘要　　
.. 抽象式摘要　　
.. 最新抽象式文本摘要　　
. 小结　　
第章 使用记忆网络完成问答任务和编写聊天机器人　　
. QA任务　　
. 用于QA任务的记忆网络　　
.. 记忆网络管道概述　　
.. 使用TensorFlow写一个记忆网络　　
. 拓展记忆网络以进行对话建模　　
.. 对话数据集　　
.. 使用TensorFlow编写一个聊天机器人　　
.. 记忆网络相关文献　　
. 小结　　
第章 使用基于attention的模型进行机器翻译　　
. 机器翻译概述　　
.. 统计机器翻译　　
.. 神经机器翻译　　
. 小结　　
第章 使用DeepSpeech进行语音识别　　
. 语音识别概述　　
. 建立用于语音识别的RNN模型　　
.. 语音信号表示　　
.. 用于语音数字识别的LSTM模型　　
.. TensorBoard可视化　　
.. 使用DeepSpeech架构的语音转文本模型　　
.. 语音识别最新技术　　
. 小结　　
第章 使用Tacotron进行文本转语音　　
. TTS领域概述　　
.. 自然性与可懂性　　
.. TTS系统表现的评估方式　　
.. 传统技术――级联模型和参数模型　　
.. 关于频谱图和梅尔标度的一些提醒　　
. 深度学习中的TTS　　
.. WaveNet简介　　
.. Tacotron　　
. 利用Keras的Tacotron实现　　
.. 数据集　　
.. 数据准备　　
.. 架构实现　　
.. 训练与测试　　
. 小结　　
第章 部署训练好的模型　　
. 性能提升　　
.. 量化权重　　
.. MobileNets　　
. TensorFlow Serving　　
.. 导出训练好的模型　　
.. 把导出模型投入服务　　
. 在云上部署　　
.. Amazon Web Services　　
.. Google Cloud Platform　　
. 在移动设备上部署　　
.. iPhone　　
.. Android　　
. 小结　　
・ ・ ・ ・ ・ ・ (收起)序一
序二
前言
第章 NLP基础 
. 什么是NLP 
.. NLP的概念 
.. NLP的研究任务 
. NLP的发展历程 
. NLP相关知识的构成 
.. 基本术语 
.. 知识结构 
. 语料库 
. 探讨NLP的几个层面 
. NLP与人工智能 
. 本章小结 
第章 NLP前置技术解析 
. 搭建Python开发环境 
.. Python的科学计算发行版――Anaconda 
.. Anaconda的下载与安装 
. 正则表达式在NLP的基本应用 
.. 匹配字符串 
.. 使用转义符 
.. 抽取文本中的数字 
. Numpy使用详解 
.. 创建数组 
.. 获取Numpy中数组的维度 
.. 获取本地数据 
.. 正确读取数据 
.. Numpy数组索引 
.. 切片 
.. 数组比较 
.. 替代值 
.. 数据类型转换 
.. Numpy的统计计算方法 
. 本章小结 
第章 中文分词技术 
. 中文分词简介 
. 规则分词 
.. 正向最大匹配法 
.. 逆向最大匹配法 
.. 双向最大匹配法 
. 统计分词 
.. 语言模型 
.. HMM模型 
.. 其他统计分词算法 
. 混合分词 
. 中文分词工具――Jieba 
.. Jieba的三种分词模式 
.. 实战之高频词提取 
. 本章小结 
第章 词性标注与命名实体识别 
. 词性标注 
.. 词性标注简介 
.. 词性标注规范 
.. Jieba分词中的词性标注 
. 命名实体识别 
.. 命名实体识别简介 
.. 基于条件随机场的命名实体识别 
.. 实战一：日期识别 
.. 实战二：地名识别 
. 总结 
第章 关键词提取算法 
. 关键词提取技术概述 
. 关键词提取算法TF/IDF算法 
. TextRank算法 
. LSA/LSI/LDA算法 
.. LSA/LSI算法 
.. LDA算法 
. 实战提取文本关键词 
. 本章小结 
第章 句法分析 
. 句法分析概述 
. 句法分析的数据集与评测方法 
.. 句法分析的数据集 
.. 句法分析的评测方法 
. 句法分析的常用方法 
.. 基于PCFG的句法分析 
.. 基于最大间隔马尔可夫网络的句法分析 
.. 基于CRF的句法分析 
.. 基于移进C归约的句法分析模型 
. 使用Stanford Parser的PCFG算法进行句法分析 
.. Stanford Parser 
.. 基于PCFG的中文句法分析实战 
. 本章小结 
第章 文本向量化 
. 文本向量化概述 
. 向量化算法wordvec 
.. 神经网络语言模型 
.. C&W模型 
.. CBOW模型和Skip-gram模型 
. 向量化算法docvec/strvec 
. 案例：将网页文本向量化 
.. 词向量的训练 
.. 段落向量的训练 
.. 利用wordvec和docvec计算网页相似度 
. 本章小结 
第章 情感分析技术 
. 情感分析的应用 
. 情感分析的基本方法 
.. 词法分析 
.. 机器学习方法 
.. 混合分析 
. 实战电影评论情感分析 
.. 卷积神经网络 
.. 循环神经网络 
.. 长短时记忆网络 
.. 载入数据 
.. 辅助函数 
.. 模型设置 
.. 调参配置 
.. 训练过程 
. 本章小结 
第章 NLP中用到的机器学习算法 
. 简介 
.. 机器学习训练的要素 
.. 机器学习的组成部分 
. 几种常用的机器学习方法 
.. 文本分类 
.. 特征提取 
.. 标注 
.. 搜索与排序 
.. 推荐系统 
.. 序列学习 
. 分类器方法 
.. 朴素贝叶斯Naive Bayesian 
.. 逻辑回归 
.. 支持向量机 
. 无监督学习的文本聚类 
. 文本分类实战：中文垃圾邮件分类 
.. 实现代码 
.. 评价指标 
. 文本聚类实战：用K-means对豆瓣读书数据聚类 
. 本章小结 
第章 基于深度学习的NLP算法 
. 深度学习概述 
.. 神经元模型 
.. 激活函数 
.. 感知机与多层网络 
. 神经网络模型 
. 多输出层模型 
. 反向传播算法 
. 最优化算法 
.. 梯度下降 
.. 随机梯度下降 
.. 批量梯度下降 
. 丢弃法 
. 激活函数 
.. tanh函数 
.. ReLU函数 
. 实现BP算法 
. 词嵌入算法 
.. 词向量 
.. wordvec简介 
.. 词向量模型 
.. CBOW和Skip-gram模型 
. 训练词向量实践 
. 朴素Vanilla-RNN 
. LSTM网络 
.. LSTM基本结构 
.. 其他LSTM变种形式 
. Attention机制 
.. 文本翻译 
.. 图说模型 
.. 语音识别 
.. 文本摘要 
. SeqSeq模型 
. 图说模型 
. 深度学习平台 
.. Tensorflow 
.. Mxnet 
.. PyTorch 
.. Caffe 
.. Theano 
. 实战SeqSeq问答机器人 
. 本章小结 
第章 Solr搜索引擎 
. 全文检索的原理 
. Solr简介与部署 
. Solr后台管理描述 
. 配置schema 
. Solr管理索引库 
.. 创建索引 
.. 查询索引 
.. 删除文档 
. 本章小结 
・ ・ ・ ・ ・ ・ (收起)第 章　什么是文本分析 
.　什么是文本分析　
.　搜集数据　
.　若输入错误数据，则输出亦为错误数据（garbage in，garbage out）　
.　为什么你需要文本分析　
.　总结　
第　章 Python文本分析技巧　
.　为什么用Python来做文本分析　
.　用Python进行文本操作　
.　总结　
第章　spaCy语言模型　
.　spaCy库　
.　spaCy的安装步骤　
.　故障排除　
.　语言模型　
.　安装语言模型　
.　安装语言模型的方式及原因　
.　语言模型的基本预处理操作　
.　分词　
.　词性标注　
.　命名实体识别　
.　规则匹配　
.　预处理　
.　总结　
第章　Gensim：文本向量化、向量变换和n-grams的工具　
.　Gensim库介绍　
.　向量以及为什么需要向量化　
.　词袋（bag-of-words）　
.　TF-IDF（词频-反向文档频率）　
.　其他表示方式　
.　Gensim中的向量变换　
.　n-grams及其预处理技术　
.　总结　
第章　词性标注及其应用　
.　什么是词性标注　
.　使用Python实现词性标注　
.　使用spaCy进行词性标注　
.　从头开始训练一个词性标注模型　
.　词性标注的代码示例　
.　总结　
第章　NER标注及其应用　
.　什么是NER标注　
.　用Python实现NER标注　
.　使用spaCy实现NER标注　
.　从头开始训练一个NER标注器　
.　NER标注应用实例和可视化　
.　总结　
第章　依存分析　
.　依存分析　
.　用Python实现依存分析　
.　用spaCy实现依存分析　
.　从头开始训练一个依存分析器　
.　总结　
第章　主题模型　
.　什么是主题模型　
.　使用Gensim构建主题模型　
.　隐狄利克雷分配（Latent Dirichlet Allocation）　
.　潜在语义索引（Latent Semantic Indexing）　
.　分层狄利特雷过程（Hierarchical Dirichlet Process）　
.　动态主题模型　
.　使用scikit-learn构建主题模型　
.　总结　
第章　高级主题建模　
.　高级训练技巧　
.　探索文档　
.　主题一致性和主题模型的评估　
.　主题模型的可视化　
.　总结　
第　章 文本聚类和文本分类　
.　文本聚类　
.　聚类前的准备工作　
.　K-means　
.　层次聚类　
.　文本分类　
.　总结　
第　章 查询词相似度计算和文本摘要　
.　文本距离的度量　
.　查询词相似度计算　
.　文本摘要　
.　总结　
第　章 WordVec、DocVec和Gensim　
.　WordVec　
.　用Gensim实现WordVec　
.　DocVec　
.　其他词嵌入技术　
.　总结　
第　章 使用深度学习处理文本　
.　深度学习　
.　深度学习在文本上的应用　
.　文本生成　
.　总结　
第　章 使用Keras和spaCy进行深度学习　
.　Keras和spaCy　
.　使用Keras进行文本分类　
.　使用spaCy进行文本分类　
.　总结　
第　章 情感分析与聊天机器人　
.　情感分析　
.　基于Reddit的新闻数据挖掘　
.　基于Twitter的微博数据挖掘　
.　聊天机器人　
.　总结　
・ ・ ・ ・ ・ ・ (收起)译者序
前言
作者名单
第章 延迟解释、浅层处理和构式：“尽可能解释”原则的基础 
. 引言 
. 延迟处理 
. 工作记忆 
. 如何识别语块：分词操作 
. 延迟架构 
.. 分段和存储 
.. 内聚聚集 
. 结论 
. 参考文献 
第章 人类关联规范能否评估机器制造的关联列表 
. 引言 
. 人类语义关联 
.. 单词关联测试 
.. 作者的实验 
.. 人类关联拓扑 
.. 人类关联具有可比性 
. 算法效率比较 
.. 语料库 
.. LSA源关联列表 
.. LDA源列表 
.. 基于关联比率的列表 
.. 列表比较 
. 结论 
. 参考文献 
第章 文本词如何在人类关联网络中选择相关词 
. 引言 
. 网络 
. 基于文本的激励驱动的网络提取 
.. 子图提取算法 
.. 控制流程 
.. 最短路径提取 
.. 基于语料库的子图 
. 网络提取流程的测试 
.. 进行测试的语料库 
.. 提取子图的评估 
.. 有向和无向子图提取：对比 
.. 每个激励产生的结果 
. 对结果和相关工作的简要讨论 
. 参考文献 
第章 反向关联任务 
. 引言 
. 计算前向关联 
.. 步骤 
.. 结果和评估 
. 计算反向关联 
.. 问题 
.. 步骤 
.. 结果和评估 
. 人类的表现 
.. 数据集 
.. 测试流程 
.. 评估 
. 机器性能 
. 讨论、结果和展望 
.. 人类的反向关联 
.. 机器的反向关联 
. 致谢 
. 参考文献 
第章 词汇的隐藏结构与功能 
. 引言 
. 方法 
.. 词典图 
.. 心理语言学变量 
.. 数据分析 
. 内核、卫星、核心、MinSet以及词典余下部分的心理语言学属性 
. 讨论 
. 未来工作 
. 参考文献 
第章 用于词义消歧的直推式学习博弈 
. 引言 
. 基于图的词义消歧 
. 半监督学习方法 
.. 基于图的半监督学习 
.. 博弈论和博弈动态 
. 词义消歧博弈 
.. 图构造 
.. 策略空间 
.. 收益矩阵 
.. 系统动力学 
. 评估 
.. 实验设置 
.. 评估结果 
.. 对比先进水平算法 
. 结论 
. 参考文献 
第章 用心学写：生成连贯文本的问题 
. 问题 
. 次优文本及其相关原因 
.. 缺乏连贯性或凝聚力 
.. 错误引用 
.. 无动机的主题转移 
. 如何解决任务的复杂性 
. 相关研究 
. 关于构建辅助写作过程的工具的假设 
. 方法论 
.. 句法结构的识别 
.. 语义种子词的识别 
.. 单词对齐 
.. 确定对齐单词的相似性值 
.. 确定句子之间的相似性 
.. 基于句子相似性值的聚类 
. 实验结果和评估 
. 展望和总结 
. 参考文献 
第章 面向著述属性的基于序贯规则挖掘的文体特征 
. 引言和研究动机 
. 著述属性过程 
. 著述属性的文体特征 
. 针对文体分析的时序数据挖掘 
. 实验设置 
.. 数据集 
.. 分类方案 
. 结果和讨论 
. 结论 
. 参考文献 
第章 一种并行的、面向认知的基频估计算法 
. 引言 
. 语音信号分割 
.. 语音和停顿段 
.. 浊音和清音区 
.. 稳定和不稳定区间 
. 稳定区间的F估计 
. F传播 
.. 控制流 
.. 峰值传播 
. 不稳定的浊音区域 
. 并行化 
. 实验和结果 
. 结论 
. 致谢 
. 参考文献 
第章 基于完形填充、脑电图和眼球运动数据对n元语言模型、主题模型和循环神经网络的基准测试 
. 引言 
. 相关工作 
. 方法 
.. 人类绩效评估 
.. 语言模型的三种风格 
. 实验设置 
. 结果 
.. 可预测性结果 
.. N振幅结果 
.. 单一注视时延结果 
. 讨论和结论 
. 致谢 
. 参考文献 
术语表 
・ ・ ・ ・ ・ ・ (收起)第章　应用自然语言处理技术 
.　付出与回报 
..　如何开始 
.. 招聘人员 
.. 学习 
. 开发环境 
. 技术基础 
.. Java 
.. 规则方法 
.. 统计方法 
.. 计算框架 
.. 文本挖掘 
.. 语义库 
. 本章小结 
. 专业术语 
第章　中文分词原理与实现 
. 接口 
.. 切分方案 
.. 词特征 
. 查找词典算法 
.. 标准Trie树 
.. 三叉Trie树 
.. 词典格式 
. 最长匹配中文分词 
.. 正向最大长度匹配法 
.. 逆向最大长度匹配法 
.. 处理未登录串 
.. 开发分词 
. 概率语言模型的分词方法 
.. 一元模型 
.. 整合基于规则的方法 
.. 表示切分词图 
.. 形成切分词图 
.. 数据基础 
.. 改进一元模型 
.. 二元词典 
.. 完全二叉树组 
.. 三元词典 
.. N元模型 
.. N元分词 
.. 生成语言模型 
.. 评估语言模型 
.. 概率分词的流程与结构 
.. 可变长N元分词 
.. 条件随机场 
. 新词发现 
.. 成词规则 
. 词性标注 
.. 数据基础 
.. 隐马尔可夫模型 
.. 存储数据 
.. 统计数据 
.. 整合切分与词性标注 
.. 大词表 
.. 词性序列 
.. 基于转换的错误学习方法 
.. 条件随机场 
. 词类模型 
. 未登录词识别 
.. 未登录人名 
.. 提取候选人名 
.. 最长人名切分 
.. 一元概率人名切分 
.. 二元概率人名切分 
.. 未登录地名 
.. 未登录企业名 
. 平滑算法 
. 机器学习的方法 
.. 最大熵 
.. 条件随机场 
. 有限状态机 
. 地名切分 
.. 识别未登录地名 
.. 整体流程 
. 企业名切分 
.. 识别未登录词 
.. 整体流程 
. 结果评测 
. 本章小结 
. 专业术语 
第章　英文分析 
. 分词 
.. 句子切分 
.. 识别未登录串 
.. 切分边界 
. 词性标注 
. 重点词汇 
. 句子时态 
. 本章小结 
第章　依存文法分析 
. 句法分析树 
. 依存文法 
.. 中文依存文法 
.. 英文依存文法 
.. 生成依存树 
.. 遍历 
.. 机器学习的方法 
. 小结 
. 专业术语 
第章　文档排重 
. 相似度计算 
.. 夹角余弦 
.. 最长公共子串 
.. 同义词替换 
.. 地名相似度 
.. 企业名相似度 
. 文档排重 
.. 关键词排重 
.. SimHash 
.. 分布式文档排重 
.. 使用文本排重 
. 在搜索引擎中使用文本排重 
. 本章小结 
. 专业术语 
第章　信息提取 
. 指代消解 
. 中文关键词提取 
.. 关键词提取的基本方法 
.. HITS算法应用于关键词提取 
.. 从网页中提取关键词 
. 信息提取 
.. 提取联系方式 
.. 从互联网提取信息 
.. 提取地名 
. 拼写纠错 
.. 模糊匹配问题 
.. 正确词表 
.. 英文拼写检查 
.. 中文拼写检查 
. 输入提示 
. 本章小结 
. 专业术语 
第章　自动摘要 
. 自动摘要技术 
.. 英文文本摘要 
.. 中文文本摘要 
.. 基于篇章结构的自动摘要 
.. 句子压缩 
. 指代消解 
. Lucene中的动态摘要 
. 本章小结 
. 专业术语 
第章　文本分类 
. 地名分类 
. 错误类型分类 
. 特征提取 
. 关键词加权法 
. 朴素贝叶斯 
. 贝叶斯文本分类 
. 支持向量机 
.. 多级分类 
.. 规则方法 
.. 网页分类 
. 最大熵 
. 信息审查 
. 文本聚类 
.. K均值聚类方法 
.. K均值实现 
.. 深入理解DBScan算法 
.. 使用DBScan算法聚类实例 
. 本章小结 
. 专业术语 
第章　文本倾向性分析 
. 确定词语的褒贬倾向 
. 实现情感识别 
. 本章小结 
. 专业术语 
第章　问答系统 
. 问答系统的结构 
.. 提取问答对 
.. 等价问题 
. 问句分析 
.. 问题类型 
.. 句型 
.. 业务类型 
.. 依存树 
.. 指代消解 
.. 二元关系 
.. 逻辑表示 
.. 问句模板 
.. 结构化问句模板 
.. 检索方式 
.. 问题重写 
.. 提取事实 
.. 验证答案 
.. 无答案的处理 
. 知识库 
. 聊天机器人 
.. 交互式问答 
.. 垂直领域问答系统 
.. 语料库 
.. 客户端 
. 自然语言生成 
. 依存句法 
. 提取同义词 
.. 流程 
. 本章小结 
. 术语表 
第章　语音识别 
. 总体结构 
.. 识别中文 
.. 自动问答 
. 语音库 
. 语音合成 
.. 归一化 
. 语音 
.. 标注 
.. 相似度 
. Sphinx 
.. 中文训练集 
. Julius 
. 本章小结 
. 术语表 
参考资源 
后记 
・ ・ ・ ・ ・ ・ (收起)出版者的话
译者序
前言
关于作者
第一部分 理论
第章 找出词的结构
. 词及其部件
.. 词元
.. 词形
.. 词素
.. 类型学
. 问题和挑战
.. 不规则性
.. 歧义性
.. 能产性
. 形态模型
.. 查词典
.. 有限状态形态
.. 基于合一的形态
.. 函数式形态
.. 形态归纳
. 总结
第章 找出文档的结构
. 概述
.. 句子边界检测
.. 主题边界检测
. 方法
.. 生成序列分类方法
.. 判别性局部分类方法
.. 判别性序列分类方法
.. 混合方法
.. 句子分割的全局建模扩展
. 方法的复杂度
. 方法的性能
. 特征
.. 同时用于文本与语音的特征
.. 只用于文本的特征
.. 语音特征
. 处理阶段
. 讨论
. 总结
第章 句法
. 自然语言分析
. 树库：句法分析的数据驱动方法
. 句法结构的表示
.. 使用依存图的句法分析
.. 使用短语结构树的句法分析
. 分析算法
.. 移进归约分析
.. 超图和线图分析
.. 最小生成树和依存分析
. 分析中的歧义消解模型
.. 概率上下文无关文法
.. 句法分析的生成模型
.. 句法分析的判别模型
. 多语言问题：什么是词元
.. 词元切分、实例和编码
.. 分词
.. 形态学
. 总结
第章 语义分析
. 概述
. 语义解释
.. 结构歧义
.. 词义
.. 实体与事件消解
.. 谓词　论元结构
.. 意义表示
. 系统范式
. 词义
.. 资源
.. 系统
.. 软件
. 谓词　论元结构
.. 资源
.. 系统
.. 软件
. 意义表示
.. 资源
.. 系统
.. 软件
. 总结
.. 词义消歧
.. 谓词　论元结构
.. 意义表示
第章 语言模型
. 概述
. n元模型
. 语言模型评价
. 参数估计
.. 最大似然估计和平滑
.. 贝叶斯参数估计
.. 大规模语言模型
. 语言模型适应
. 语言模型的类型
.. 基于类的语言模型
.. 变长语言模型
.. 判别式语言模型
.. 基于句法的语言模型
.. 最大熵语言模型
.. 因子化语言模型
.. 其他基于树的语言模型
.. 基于主题的贝叶斯语言模型
.. 神经网络语言模型
. 特定语言建模问题
.. 形态丰富语言的建模
.. 亚词单元的选择
.. 形态类别建模
.. 无分词语言
.. 口语与书面语言
. 多语言和跨语言建模
.. 多语言建模
.. 跨语言建模
. 总结
第章 文本蕴涵识别
. 概述
. 文本识别蕴涵任务
.. 问题定义
.. RTE的挑战
.. 评估文本蕴涵系统性能
.. 文本蕴涵解决方案的应用
.. 其他语言中的RTE研究
. 文本蕴涵识别的框架
.. 要求
.. 分析
.. 有用的组件
.. 通用模型
.. 实现
.. 对齐
.. 推理
.. 训练
. 案例分析
.. 抽取语篇约束
.. 基于编辑距离的RTE
.. 基于转换的方法
.. 逻辑表示及推理
.. 独立于蕴涵学习对齐
.. 在RTE中利用多对齐
.. 自然逻辑
.. 句法树核
.. 使用有限依存上下文的全局相似度
.. RTE的潜在对齐推理
. RTE的进一步研究
.. 改进分析器
.. 发明或解决新问题
.. 开发知识库
.. 更好的RTE评价
. 有用资源
.. 文献
.. 知识库
.. 自然语言处理包
. 总结
第章 多语情感与主观性分析
. 概述
. 定义
. 英语中的情感及主观性分析
.. 词典
.. 语料库
.. 工具
. 词级和短语级标注
.. 基于字典的方法
.. 基于语料库的方法
. 句子级标注
.. 基于字典
.. 基于语料库
. 文档级标注
.. 基于字典
.. 基于语料库
. 什么有效，什么无效
.. 最佳情况：已有人工标注的语料库
.. 次优情形：基于语料库的跨语言映射
.. 第三优情形：孳衍词典
.. 第四优情形：翻译词典
.. 各种可行方法的比较
. 总结
第二部分 实践
第章 实体检测和追踪
. 概述
. 提及检测
.. 数据驱动的分类
.. 搜索提及
.. 提及检测特征
.. 提及检测实验
. 共指消解
.. Bell树的构建
.. 共指模型：链接和引入模型
.. 最大熵链接模型
.. 共指消解实验
. 总结
第章 关系和事件
. 概述
. 关系与事件
. 关系类别
. 将关系抽取视为分类
.. 算法
.. 特征
.. 分类器
. 关系抽取的其他方法
.. 无监督和半监督方法
.. 核方法
.. 实体和关系检测的联合方法
. 事件
. 事件抽取方法
. 超句
. 事件匹配
. 事件抽取的未来方向
. 总结
第章 机器翻译
. 机器翻译现状
. 机器翻译评测
.. 人工评测
.. 自动评测
.. WER、BLEU、METEOR等
. 词对齐
.. 共现
.. IBM模型
.. 期望最大化
.. 对齐模型
.. 对称化
.. 作为机器学习问题的词对齐
. 基于短语的翻译模型
.. 模型
.. 训练
.. 解码
.. 立方剪枝
.. 对数线性模型和参数调节
.. 控制模型的大小
. 基于树的翻译模型
.. 层次短语翻译模型
.. 线图解码
.. 基于句法的模型
. 语言学挑战
.. 译词选择
.. 形态学
.. 词序
. 工具和数据资源
.. 基本工具
.. 机器翻译系统
.. 平行语料
. 未来的方向
. 总结
第章 跨语言信息检索
. 概述
. 文档预处理
.. 文档句法和编码
.. 词元化
.. 规范化
.. 预处理最佳实践
. 单语信息检索
.. 文档表示
.. 索引结构
.. 检索模型
.. 查询扩展
.. 文档先验模型
.. 模型选择的最佳实践
. CLIR
.. 基于翻译的方法
.. 机器翻译
.. 中间语言文档表示
.. 最佳实践
. 多语言信息检索
.. 语言识别
.. MLIR的索引建立
.. 翻译查询串
.. 聚合模型
.. 最佳实践
. 信息检索的评价
.. 建立实验环境
.. 相关性评估
.. 评价指标
.. 已有数据集
.. 最佳实践
. 工具、软件和资源
. 总结
第章 多语自动文摘
. 概述
. 自动文摘方法
.. 传统方法
.. 基于图的方法
.. 学习如何做摘要
.. 多语自动摘要
. 评测
.. 人工评价
.. 自动评价
.. 自动文摘评测系统的近期发展
.. 多语自动文摘的自动评测方法
. 如何搭建自动文摘系统
.. 材料
.. 工具
.. 说明
. 评测竞赛和数据集
.. 评测竞赛
.. 数据集
. 总结
第章 问答系统
. 概述和历史
. 架构
. 源获取和预处理
. 问题分析
. 搜索及候选抽取
.. 非结构化资源搜索
.. 非结构化源文本的候选抽取
.. 结构化源文本的候选抽取
. 回答评分
.. 方法概述
.. 证据结合
.. 扩展到列表型问题
. 跨语言问答
. 案例研究
. 评测
.. 评测任务
.. 判断答案正确性
.. 性能度量
. 当前和未来的挑战
. 总结和进一步阅读
第章 提炼
. 概述
. 示例
. 相关性和冗余性
. Rosetta Consortium 提炼系统
.. 文档和语料库准备
.. 索引
.. 查询回答
. 其他提炼方法
.. 系统架构
.. 相关度
.. 冗余
.. 多模态提炼
.. 跨语言提炼
. 评测和指标
. 总结
第章 口语对话系统
. 概述
. 口语对话系统
.. 语音识别和理解
.. 语音生成
.. 对话管理器
.. 语音用户接口
. 对话形式
. 自然语言呼叫路由选择
. 三代对话应用
. 持续的改进循环
. 口语句子的转录和标注
. 口语对话系统的本地化
.. 呼叫流程本地化
.. 提示本地化
.. 文法的本地化
.. 源端数据
.. 训练
.. 测试
. 总结
第章 聚合自然语言处理引擎
. 概述
. 聚合语音和NLP引擎架构的期望属性
.. 灵活的分布式组件化
.. 计算效率
.. 数据操作功能
.. 鲁棒性处理
. 聚合的架构
.. UIMA
.. GATE
.. InfoSphere Streams
. 案例研究
.. GALE 互操作性演示系统
.. 跨语言自动语言开发系统
.. 实时翻译服务
. 经验教训
.. 分割涉及延迟和精度之间的权衡
.. 联合优化与互操作性
.. 数据模型需要使用约定
.. 性能评估的挑战
.. 引擎的前向波训练
. 总结
. UIMA样本代码
索引
・ ・ ・ ・ ・ ・ (收起)★★第篇 入门――基础知识与编程框架
-
★第章 BERT模型很强大，你值得拥有 /
★. 全球欢腾，喜迎BERT模型 /
★. 为什么BERT模型这么强 /
★. 怎么学习BERT模型 /
.. BERT模型的技术体系 /
.. 学好自然语言处理的件套――神经网络的基础知识、NLP的基础知识、编程框架的使用、BERT模型的原理及应用 /
.. 学习本书的前提条件 /
★. 自然语言处理的技术趋势 /
.. 基于超大规模的高精度模型 /
.. 基于超小规模的高精度模型 /
.. 基于小样本训练的模型 /
-
★第章 神经网络的基础知识――可能你掌握得也没有那么牢 /
★. 什么是神经网络 /
.. 神经网络能解决哪些问题 /
.. 神经网络的发展 /
.. 什么是深度学习 /
.. 什么是图神经网络 /
.. 什么是图深度学习 /
★. 神经网络的工作原理 /
.. 了解单个神经元 /
.. 生物神经元与计算机神经元模型的结构相似性 /
.. 生物神经元与计算机神经元模型的工作流程相似性 /
.. 神经网络的形成 /
★. 深度学习中包含了哪些神经网络 /
.. 全连接神经网络 /
.. 卷积神经网络 /
.. 循环神经网络 /
.. 带有注意力机制的神经网络 /
.. 自编码神经网络 /
★. 图深度学习中包含哪些神经网络 /
.. 同构图神经网络 /
.. 异构图神经网络 /
★. 激活函数――加入非线性因素，以解决线性模型的缺陷 /
.. 常用的激活函数 /
.. 更好的激活函数――Swish()与Mish() /
.. 更适合NLP任务的激活函数――GELU() /
.. 激活函数总结 /
.. 分类任务与Softmax算法 /
★. 训练模型的原理 /
.. 反向传播与BP算法 /
.. 神经网络模块中的损失函数 /
.. 学习率 /
.. 优化器 /
.. 训练模型的相关算法，会用就行 /
★. 【实例】用循环神经网络实现退位减法 /
★. 训练模型中的常见问题及优化技巧 /
.. 过拟合与欠拟合问题 /
.. 改善模型过拟合的方法 /
.. 了解正则化技巧 /
.. 了解Dropout技巧 /
.. Targeted Dropout与Multi-sample Dropout /
.. 批量归一化（BN）算法 /
.. 多种BN算法的介绍与选取 /
.. 全连接网络的深浅与泛化能力的联系 /
-
★第章 NLP的基础知识――NLP没那么“玄” /
★. NLP的本质与原理 /
.. 情感分析、相似度分析等任务的本质 /
.. 完形填空、实体词识别等任务的本质 /
.. 文章摘要任务、问答任务、翻译任务的本质 /
★. NLP的常用工具 /
.. 自然语言处理工具包――SpaCy /
.. 中文分词工具――Jieba /
.. 中文转拼音工具――Pypinyin /
.. 评估翻译质量的算法库――SacreBLEU /
★. 计算机中的字符编码 /
.. 什么是ASCII编码 /
.. 为什么会出现乱码问题 /
.. 什么是Unicode /
.. 借助Unicode 处理中文字符的常用操作 /
★. 计算机中的词与句 /
.. 词表与词向量 /
.. 词向量的原理及意义 /
.. 多项式分布 /
.. 什么是依存关系分析 /
.. 什么是TF /
.. 什么是IDF /
.. 什么是TF-IDF /
.. 什么是BLEU /
★. 什么是语言模型 /
.. 统计语言模型 /
.. CBOW与Skip-Gram语言模型 /
.. 自编码（Auto Encoding，AE）语言模型 /
.. 自回归（Auto Regressive，AR）语言模型 /
★. 文本预处理的常用方法 /
.. NLP数据集的获取与清洗 /
.. 基于马尔可夫链的数据增强 /
-
★第章 搭建编程环境――从安装开始，更适合零基础入门 /
★. 编程框架介绍 /
.. PyTorch介绍 /
.. DGL库介绍 /
.. 支持BERT模型的常用工具库介绍 /
★. 搭建Python开发环境 /
★. 搭建PyTorch开发环境 /
★. 搭建DGL环境 /
★. 安装Transformers库 /
-
★★第篇 基础――神经网络与BERT模型
★第章 PyTorch编程基础 /
★. 神经网络中的基础数据类型 /
★. 矩阵运算的基础 /
.. 转置矩阵 /
.. 对称矩阵及其特性 /
.. 对角矩阵与单位矩阵 /
.. 阿达玛积（Hadamard Product） /
.. 点积（Dot Product） /
.. 对角矩阵的特性与操作方法 /
★. PyTorch中的张量 /
.. 定义张量的方法 /
.. 生成随机值张量 /
.. 张量的基本操作 /
.. 在CPU和GPU控制的内存中定义张量 /
.. 张量间的数据操作 /
★. Variable类型与自动微分模块 /
.. Variable对象与Tensor对象之间的转换 /
.. 控制梯度计算的方法 /
.. Variable对象的属性 /
★. 【实例】用PyTorch实现一个简单模型 /
.. 准备可复现的随机数据 /
.. 实现并训练模型 /
.. 可视化模型能力 /
★. 定义模型结构的常用方法 /
.. Module类的使用方法 /
.. 模型中的参数（Parameters变量） /
.. 为模型添加参数 /
.. 从模型中获取参数 /
.. 激活模型接口 /
.. L正则化接口 /
.. Dropout接口 /
.. 批量归一化接口 /
.. 【实例】手动实现BN的计算方法 /
★. 保存与载入模型的常用方法 /
★. 训练模型的接口与使用 /
.. 选取训练模型中的损失函数 /
.. 【实例】Softmax接口的使用 /
.. 优化器的使用与优化参数的查看 /
.. 用退化学习率训练模型 /
.. 为模型添加钩子函数 /
.. 多显卡的训练方法 /
.. 梯度累加的训练方法 /
★. 处理数据集的接口与使用 /
.. 用DataLoader类实现自定义数据集 /
.. DataLoader类中的多种采样器子类 /
.. Torchtext工具与内置数据集 /
★. 【实例】训练中文词向量 /
.. 用Jieba库进行中文样本预处理 /
.. 按照Skip-Gram规则制作数据集 /
.. 搭建模型并进行训练 /
.. 夹角余弦值介绍 /
★. 卷积神经网络的实现 /
.. 了解卷积接口 /
.. 卷积操作的类型 /
.. 卷积参数与卷积结果的计算规则 /
.. 【实例】卷积函数的使用 /
.. 了解池化接口 /
.. 【实例】池化函数的使用 /
★. 【实例】用卷积神经网络实现文本分类任务 /
.. 了解用于文本分类的卷积网络――TextCNN模型 /
.. 编写代码实现实例 /
.. 用多GPU并行训练模型 /
.. 在多GPU的训练过程中，保存/读取模型文件的注意事项 /
.. 处理显存残留问题 /
★. RNN的实现 /
.. LSTM与GRU接口的实现 /
.. 多项式分布采样接口 /
★. 【实例】用RNN训练语言模型 /
.. 实现语言模型的思路与步骤 /
.. 准备样本与代码实现 /
★. 【实例】手动实现一个带有自注意力机制的模型 /
★. 【实例】利用带注意力机制的循环神经网络对文本进行分类 /
.. 制作等长数据集并实现LSTM模型 /
.. 用梯度剪辑技巧优化训练过程 /
-
★第章 BERT模型的原理 /
★. BERT模型的起源――Transformer模型 /
.. Transformer模型出现之前的主流模型 /
.. Transformer模型的原理 /
.. Transformer模型的优缺点 /
★. 【实例】用Transformer模型进行中/英文翻译 /
★. BERT模型的原理 /
.. BERT模型的训练过程 /
.. BERT模型的预训练方法 /
.. BERT模型的掩码机制 /
.. BERT模型的训练参数 /
.. BERT模型的缺点 /
★. 高精度的BERTology系列模型 /
.. 适合生成文章的模型――GPT模型 /
.. 支持人机对话的模型――DialoGPT模型 /
.. 融合了BERT模型与GPT技术的模型――MASS模型 /
.. 支持长文本输入的模型――Transformer-XL模型 /
.. 支持更长文本的模型――XLNet模型 /
.. 弥补XLNet模型不足的模型――MPNet模型 /
.. 稳健性更好的模型――RoBERTa模型 /
.. 使用了稀疏注意力的模型――Longformer、BigBird模型 /
.. 基于词掩码的模型――BERT-WWM、Wo BERT等模型 /
.. 基于小段文字掩码的模型――SpanBERT模型 /
.. 适合翻译任务的模型――T模型 /
.. 支持多种语言的翻译模型――XLM、XLM-Roberta模型 /
.. 既能阅读又能写作的模型――UniLM .模型 /
.. 适用于语法纠错任务的模型――StructBERT、Bart模型 /
.. 可以进行定向写作的模型――CTRL模型 /
.. 适合摘要生成的模型――PEGASUS模型 /
.. 支持更多语言的模型――T-ULR v模型 /
★. 小规模的BERTology系列模型 /
.. 比RoBERTa模型训练速度更快的模型――ELECTRA模型 /
.. 适用于文本分类的超小模型――PRADO、pQRNN模型 /
.. 比BERT模型更适合于部署场景的模型――DistillBERT模型 /
.. 比BERT模型更快的模型――FastBERT模型 /
.. 带有通用蒸馏方案的模型――MiniLM模型 /
.. 精简版的BERT模型――ALBERT、ALBERT_tiny、ALBERT V模型 /
★. BERTology系列模型的预训练方法总结 /
.. AE式训练方法的常用策略 /
.. 更多的训练经验 /
-
★第章 BERT模型的快速应用――BERT模型虽然强大，使用却不复杂！ /
★. 了解Transformers库 /
★. Transformers库的层应用结构 /
★. 【实例】用Transformers库的管道方式完成多种NLP任务 /
.. 在管道方式中指定NLP任务 /
.. 代码实现：完成文本分类任务 /
.. 代码实现：完成特征提取任务 /
.. 代码实现：完成完形填空任务 /
.. 代码实现：完成阅读理解任务 /
.. 代码实现：完成摘要生成任务 /
.. 预训练模型文件的组成与其加载时的固定名称 /
.. 代码实现：完成实体词识别任务 /
.. 管道方式的工作原理 /
.. 在管道方式中应用指定模型 /
★. Transformers库中的自动模型（AutoModel）类 /
.. 各种AutoModel类 /
.. AutoModel类的模型加载机制 /
.. Transformers库中的其他语言模型 /
★. Transformers库中的BERTology系列模型 /
.. Transformers库的文件结构 /
.. 获取和加载预训练模型文件 /
.. 查找Transformers库中可以使用的模型 /
.. 【实例】用BERT模型实现完形填空任务 /
.. 【扩展实例】用自动模型类替换BertForMaskedLM类 /
★. Transformers库中的词表工具 /
.. PreTrainedTokenizer类中的特殊词 /
.. PreTrainedTokenizer类中的特殊词的使用 /
.. 向PreTrainedTokenizer类中添加词 /
.. 【实例】用手动加载GPT-模型权重的方式将句子补充完整 /
.. 子词拆分 /
★. 【实例】用迁移学习训练BERT模型来对中文分类 /
.. NLP中的迁移学习 /
.. 构建数据集 /
.. 构建并加载BERT模型的预训练模型 /
.. Transformers库中的底层类 /
.. 用退化学习率训练模型 /
.. 用数据增强方法训练模型 /
-
★第章 模型的可解释性――深入模型内部，探究其工作的根源
★. 模型的可解释库 /
.. 了解Captum库 /
.. Captum库的可视化工具――Captum Insights /
★. 什么是梯度积分方法 /
★. 【实例】对NLP模型的可解释性分析 /
.. 分析词嵌入模型 /
.. 拆解NLP模型的处理过程 /
.. 用Captum库提取NLP模型的词嵌入层 /
.. 用梯度积分的方法计算模型的可解释性 /
.. 可视化模型的可解释性 /
★. 【实例】BERT模型的可解释性分析 /
.. 了解BERT模型的可解释性工具――Bertviz /
.. 用Bertviz工具可视化BERT模型的权重 /
.. 分析BERT模型的权重参数 /
★. 用图神经网络解释BERT模型 /
.. 点积计算与聚合计算的关系 /
.. 从图的角度思考BERT模型 /
-
★★第篇 BERT模型实战★★
★第章 图神经网络与BERT模型的结合★
★. 图神经网络基础 /
.. 图的相关术语和操作 /
.. 图卷积神经网络 /
★. DGL库的使用方法 /
.. 创建图结构 /
.. DGL库与NetWorkx库的相互转换 /
.. 图的基本操作 /
.. 图的消息传播机制 /
.. DGL库中的多图处理 /
★. 【实例】用图节点的聚合方法实现BERT模型 /
.. 基于Transformers库的BERT模型修改方案 /
.. 实现图节点聚合的核心代码 /
.. 将原BERT模型的权重应用到基于图节点聚合方法实现的BERT模型上 /
★. 什么是关系图卷积网络（R-GCN）模型 /
.. R-GCN模型的原理 /
.. 基于R-GCN模型的优化 /
.. R-GCN模型的实现 /
★. 【实例】用R-GCN模型理解文本中的代词 /
.. 代词数据集（GAP）介绍 /
.. 将GAP数据集转换成“图”结构数据的思路 /
.. 用BERT模型提取代词特征 /
.. 用BERT模型提取其他词特征 /
.. 用SpaCy工具和批次图方法构建图数据集 /
.. 搭建多层R-GCN模型 /
.. 用折交叉验证方法训练模型 /
-
★第章 BERT模型的行业应用 ★
★. BERT模型在文本纠错领域的应用 /
.. 文本纠错中的常见任务及解决办法 /
.. 理解BERT模型的纠错能力 /
.. 改进BERT模型使其具有更强的纠错能力 /
.. 专用于文本纠错的模型――Soft-Masked BERT模型 /
.. 基于图神经网络的文本纠错模型――SpellGCN模型 /
.. 【实例】用Transformers和DGL库实现SpellGCN模型 /
★. BERT技术在聊天机器人领域的应用 /
.. 聊天机器人的种类与实现技术 /
.. 基于BERT模型完成聊天任务的思路 /
.. 【实例】用累加梯度训练支持中文的DialoGPT模型 /
.. 更强大的多轮聊天模型――Meena模型 /
★. BERT模型在服务器端部署的应用 /
.. 用transformers-cli工具快速部署BERT模型 /
.. 用torchserve库部署BERT模型 /
・ ・ ・ ・ ・ ・ (收起)第篇 自然语言处理基础篇
第章 自然语言处理概述 
. 什么是自然语言处理 
.. 定义 
.. 常用术语 
.. 自然语言处理的任务 
.. 自然语言处理的发展历程 
. 自然语言处理中的挑战 
.. 歧义问题 
.. 语言的多样性 
.. 未登录词 
.. 数据稀疏 
. 自然语言处理中的常用技术 
. 机器学习中的常见问题 
.. Batch和Epoch 
.. Batch Size的选择 
.. 数据集不平衡问题 
.. 预训练模型与数据安全 
.. 通过开源代码学习 
. 小结 
第章 Python自然语言处理基础 
. 搭建环境 
.. 选择Python版本 
.. 安装Python 
.. 使用pip包管理工具和Python虚拟环境 
.. 使用集成开发环境 
.. 安装Python自然语言处理常用的库 
. 用Python处理字符串 
.. 使用str类型 
.. 使用StringIO类 
. 用Python处理语料 
.. 从文件读取语料 
.. 去重 
.. 停用词 
.. 编辑距离 
.. 文本规范化 
.. 分词 
.. 词频-逆文本频率 
.. One-Hot 编码 
. Python的一些特性 
.. 动态的解释型语言 
.. 跨平台 
.. 性能问题 
.. 并行和并发 
. 在Python中调用其他语言 
.. 通过ctypes调用C/C++代码 
.. 通过网络接口调用其他语言 
. 小结 
第篇 PyTorch入门篇
第章 PyTorch介绍 
. 概述 
. 与其他框架的比较 
.. TensorFlow 
.. PaddlePaddle 
.. CNTK 
. PyTorch环境配置 
.. 通过pip安装 
.. 配置GPU环境 
.. 其他安装方法 
.. 在PyTorch中查看GPU是否可用 
. Transformers简介及安装 
. Apex简介及安装 
. 小结 
第章 PyTorch基本使用方法 
. 张量的使用 
.. 创建张量 
.. 张量的变换 
.. 张量的索引 
.. 张量的运算 
. 使用torch.nn 
. 激活函数 
.. Sigmoid函数 
.. Tanh函数 
.. ReLU函数 
.. Softmax函数 
.. Softmin函数 
.. LogSoftmax函数 
. 损失函数 
.. -损失函数 
.. 平方损失函数 
.. 绝对值损失函数 
.. 对数损失函数 
. 优化器 
.. SGD优化器 
.. Adam优化器 
.. AdamW优化器 
. 数据加载 
.. Dataset 
.. DataLoader 
. 使用PyTorch实现逻辑回归 
.. 生成随机数据 
.. 数据可视化 
.. 定义模型 
.. 训练模型 
. TorchText 
.. 安装TorchText 
.. Data类 
.. Datasets类 
.. Vocab 
.. utils 
. 使用TensorBoard 
.. 安装和启动TensorBoard 
.. 在PyTorch中使用TensorBoard 
. 小结 
第章 热身：使用字符级RNN分类帖子 
. 数据与目标 
.. 数据 
.. 目标 
. 输入与输出 
.. 统计数据集中出现的字符数量 
.. 使用One-Hot编码表示标题数据 
.. 使用词嵌入表示标题数据 
.. 输出 
. 字符级RNN 
.. 定义模型 
.. 运行模型 
. 数据预处理 
.. 合并数据并添加标签 
.. 划分训练集和数据集 
. 训练与评估 
.. 训练 
.. 评估 
.. 训练模型 
. 保存和加载模型 
.. 仅保存模型参数 
.. 保存模型与参数 
.. 保存词表 
. 开发应用 
.. 给出任意标题的建议分类 
.. 获取用户输入并返回结果 
.. 开发Web API和Web界面 
. 小结 
第篇 用PyTorch完成自然语言处理任务篇
第章 分词问题 
. 中文分词 
.. 中文的语言结构 
.. 未收录词 
.. 歧义 
. 分词原理 
.. 基于词典匹配的分词 
.. 基于概率进行分词 
.. 基于机器学习的分词 
. 使用第三方工具分词 
.. S-MSRSeg 
.. ICTCLAS 
.. 结巴分词 
.. pkuseg 
. 实践 
.. 对标题分词 
.. 统计词语数量与模型训练 
.. 处理用户输入 
. 小结 
第章 RNN 
. RNN的原理 
.. 原始RNN 
.. LSTM 
.. GRU 
. PyTorch中的RNN 
.. 使用RNN 
.. 使用LSTM和GRU 
.. 双向RNN和多层RNN 
. RNN可以完成的任务 
.. 输入不定长，输出与输入长度相同 
.. 输入不定长，输出定长 
.. 输入定长，输出不定长 
. 实践：使用PyTorch自带的RNN完成帖子分类 
.. 载入数据 
.. 定义模型 
.. 训练模型 
. 小结 
第章 词嵌入 
. 概述 
.. 词表示 
.. PyTorch中的词嵌入 
. Wordvec 
.. Wordvec简介 
.. CBOW 
.. SG 
.. 在PyTorch中使用Wordvec 
. GloVe 
.. GloVe的原理 
.. 在PyTorch中使用GloVe预训练词向量 
. 实践：使用预训练词向量完成帖子标题分类 
.. 获取预训练词向量 
.. 加载词向量 
.. 方法一：直接使用预训练词向量 
.. 方法二：在Embedding层中载入预训练词向量 
. 小结 
第章 Seqseq 
. 概述 
.. 背景 
.. 模型结构 
.. 训练技巧 
.. 预测技巧 
. 使用PyTorch实现Seqseq 
.. 编码器 
.. 解码器 
.. Seqseq 
.. Teacher Forcing 
.. Beam Search 
. 实践：使用Seqseq完成机器翻译任务 
.. 数据集 
.. 数据预处理 
.. 构建训练集和测试集 
.. 定义模型 
.. 初始化模型 
.. 定义优化器和损失函数 
.. 训练函数和评估函数 
.. 训练模型 
.. 测试模型 
. 小结 
第章 注意力机制 
. 注意力机制的起源 
.. 在计算机视觉中的应用 
.. 在自然语言处理中的应用 
. 使用注意力机制的视觉循环模型 
.. 背景 
.. 实现方法 
. Seqseq中的注意力机制 
.. 背景 
.. 实现方法 
.. 工作原理 
. 自注意力机制 
.. 背景 
.. 自注意力机制相关的工作 
.. 实现方法与应用 
. 其他注意力机制 
. 小结 
第章 Transformer 
. Transformer的背景 
.. 概述 
.. 主要技术 
.. 优势和缺点 
. 基于卷积网络的Seqseq 
. Transformer的结构 
.. 概述 
.. Transformer中的自注意力机制 
.. Multi-head Attention 
.. 使用Positional Encoding 
. Transformer的改进 
. 小结 
第章 预训练语言模型 
. 概述 
.. 为什么需要预训练 
.. 预训练模型的工作方式 
.. 自然语言处理预训练的发展 
. ELMo 
.. 特点 
.. 模型结构 
.. 预训练过程 
. GPT 
.. 特点 
.. 模型结构 
.. 下游任务 
.. 预训练过程 
.. GPT-和GPT- 
. BERT 
.. 背景 
.. 模型结构 
.. 预训练 
.. RoBERTa和ALBERT 
. Hugging Face Transformers 
.. 概述 
.. 使用Transformers 
.. 下载预训练模型 
.. Tokenizer 
.. BERT的参数 
.. BERT的使用 
.. GPT-的参数 
.. 常见错误及其解决方法 
. 其他开源中文预训练模型 
.. TAL-EduBERT 
.. Albert 
. 实践：使用Hugging Face Transformers中的BERT做帖子标题分类 
.. 读取数据 
.. 导入包和设置参数 
.. 定义Dataset和DataLoader 
.. 定义评估函数 
.. 定义模型 
.. 训练模型 
. 小结 
第篇 实战篇
第章 项目：中文地址解析 
. 数据集 
.. 实验目标与数据集介绍 
.. 载入数据集 
. 词向量 
.. 查看词向量文件 
.. 载入词向量 
. BERT 
.. 导入包和配置 
.. Dataset和DataLoader 
.. 定义模型 
.. 训练模型 
.. 获取预测结果 
. HTML演示程序开发 
.. 项目结构 
.. HTML界面 
.. 创建前端事件 
.. 服务器逻辑 
. 小结 
第章 项目：诗句补充 
. 了解chinese-poetry数据集 
.. 下载chinese-poetry数据集 
.. 探索chinese-poetry数据集 
. 准备训练数据 
.. 选择数据源 
.. 载入内存 
.. 切分句子 
.. 统计字频 
.. 删除低频字所在诗句 
.. 词到ID的转换 
. 实现基本的LSTM 
.. 把处理好的数据和词表存入文件 
.. 切分训练集和测试集 
.. Dataset 
.. DataLoader 
.. 创建Dataset和DataLoader对象 
.. 定义模型 
.. 测试模型 
.. 训练模型 
. 根据句子长度分组 
.. 按照句子长度分割数据集 
.. 不用考虑填充的DataLoader 
.. 创建多个DataLoader对象 
.. 处理等长句子的LSTM 
.. 评估模型效果 
.. 训练模型 
. 使用预训练词向量初始化Embedding层 
.. 根据词向量调整字表 
.. 载入预训练权重 
.. 训练模型 
. 使用Transformer完成诗句生成 
.. 位置编码 
.. 使用Transformer 
.. 训练和评估 
. 使用GPT-完成对诗模型 
.. 预训练模型 
.. 评估模型 
.. Fine-tuning 
. 开发HTML演示程序 
.. 目录结构 
.. HTML界面 
.. 创建前端事件 
.. 服务器逻辑 
.. 检验结果 
. 小结 
参考文献 
・ ・ ・ ・ ・ ・ (收起)第 章 深度学习――机器大脑的结构 
. 概述 
.. 可以做酸奶的面包机――通用机器的概念 
.. 连接主义 
.. 用机器设计机器 
.. 深度网络 
.. 深度学习的用武之地 
. 从人脑神经元到人工神经元 
.. 生物神经元中的计算灵感 
.. 激活函数 
. 参数学习 
.. 模型的评价 
.. 有监督学习 
.. 梯度下降法 
. 多层前馈网络 
.. 多层前馈网络 
.. 后向传播算法计算梯度 
. 逐层预训练 
. 深度学习是终极神器吗 
.. 深度学习带来了什么 
.. 深度学习尚未做到什么 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 知识图谱――机器大脑中的知识库 
. 什么是知识图谱 
. 知识图谱的构建 
.. 大规模知识库 
.. 互联网链接数据 
.. 互联网网页文本数据 
.. 多数据源的知识融合 
. 知识图谱的典型应用 
.. 查询理解（Query Understanding） 
.. 自动问答（Question Answering） 
.. 文档表示（Document Representation） 
. 知识图谱的主要技术 
.. 实体链指（Entity Linking） 
.. 关系抽取（Relation Extraction） 
.. 知识推理（Knowledge Reasoning） 
.. 知识表示（Knowledge Representation） 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 大数据系统――大数据背后的支撑技术 
. 概述 
. 高性能计算技术 
.. 超级计算机的组成 
.. 并行计算的系统支持 
. 虚拟化和云计算技术 
.. 虚拟化技术 
.. 云计算服务 
. 基于分布式计算的大数据系统 
.. Hadoop 生态系统 
.. Spark 
.. 典型的大数据基础架构 
. 大规模图计算 
.. 分布式图计算框架 
.. 高效的单机图计算框架 
. NoSQL 
.. MongoDB 简介 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 智能问答――智能助手是如何炼成的 
. 概述 
. 问答系统的主要组成 
. 文本问答系统 
.. 问题理解 
.. 知识检索 
.. 答案生成 
. 社区问答系统 
.. 社区问答系统的结构 
.. 相似问题检索 
.. 答案过滤 
. 多媒体问答系统 
. 大型问答系统案例：IBM 沃森问答系统 
.. 沃森的总体结构 
.. 问题解析 
.. 知识储备 
.. 检索和候选答案生成 
.. 可信答案确定 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 主题模型――机器的智能摘要利器 
. 概述 
. 主题模型出现的背景 
. 第一个主题模型潜在语义分析 
. 第一个正式的概率主题模型 
. 第一个正式的贝叶斯主题模型 
. LDA 的概要介绍 
.. LDA 的延伸理解――主题模型广义理解 
.. 模型求解 
.. 模型评估 
.. 模型选择：主题数目的确定 
. 主题模型的变形与应用 
.. 基于LDA 的模型变种 
.. 基于LDA 的典型应用 
.. 一个基于主题模型的新浪名人话题排行榜应用 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 个性化推荐系统――如何了解电脑背后的TA 
. 概述 
.. 推荐系统的发展历史 
.. 推荐无处不在 
.. 从千人一面到千人千面 
. 个性化推荐的基本问题 
.. 推荐系统的输入 
.. 推荐系统的输出 
.. 个性化推荐的形式化 
.. 推荐系统的三大核心问题 
. 典型推荐算法浅析 
.. 推荐算法的分类 
.. 典型推荐算法介绍 
.. 基于矩阵分解的打分预测 
.. 推荐的可解释性 
.. 推荐算法的评价 
.. 我们走了多远 
. 参考文献 
第 章 情感分析与意见挖掘――计算机如何了解人类情感 
. 概述 
. 情感分析的主要研究问题 
. 情感分析的主要方法 
.. 构成情感和观点的基本元素 
.. 情感极性与情感词典 
.. 属性－观点对 
.. 情感分析 
. 主要的情感词典资源 
. 内容回顾与推荐阅读 
. 参考文献 
第 章 面向社会媒体大数据的语言使用分析及应用 
. 概述 
. 面向社会媒体的自然语言使用分析 
.. 词汇的时空传播与演化 
.. 语言使用与个体差异 
.. 语言使用与社会地位 
.. 语言使用与群体分析 
. 面向社会媒体的自然语言分析应用 
.. 社会预测 
.. 霸凌现象定量分析 
. 未来研究的挑战与展望 
. 参考文献 
后 记 
国际学术组织、学术会议与学术论文 
国内学术组织、学术会议与学术论文 
如何快速了解某个领域的研究进展 
・ ・ ・ ・ ・ ・ (收起) 深度计算――机器大脑的结构 
. 惊人的深度学习 
.. 可以做酸奶的面包机：通用机器的概念 
.. 连接主义 
.. 用机器设计机器 
.. 深度网络 
.. 深度学习的用武之地 
. 从人脑神经元到人工神经元 
.. 生物神经元中的计算灵感 
.. 激活函数 
. 参数学习 
.. 模型的评价 
.. 有监督学习 
.. 梯度下降法 
. 多层前馈网络 
.. 多层前馈网络 
.. 后向传播算法计算梯度 
. 逐层预训练 
. 深度学习是终极神器吗 
.. 深度学习带来了什么 
.. 深度学习尚未做到什么 
. 内容回顾与推荐阅读 . 
. 参考文献 
 知识图谱――机器大脑中的知识库 
. 什么是知识图谱 
. 知识图谱的构建 
.. 大规模知识库 
.. 互联网链接数据 
.. 互联网网页文本数据 
.. 多数据源的知识融合 
. 知识图谱的典型应用 
.. 查询理解 
.. 自动问答 
.. 文档表示 
. 知识图谱的主要技术 
.. 实体链指 
.. 关系抽取 
.. 知识推理 
.. 知识表示 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 大数据系统――大数据背后的支撑技术 
. 大数据有多大 
. 高性能计算技术 
.. 超级计算机的组成 
.. 并行计算的系统支持 
. 虚拟化和云计算技术 
.. 虚拟化技术 
.. 云计算服务 
. 基于分布式计算的大数据系统 
.. Hadoop 生态系统 
.. Spark 
.. 典型的大数据基础架构 
. 大规模图计算 
.. 分布式图计算框架 
.. 高效的单机图计算框架 
. NoSQL 
.. NoSQL 数据库的类别 
.. MongoDB 简介 
. 内容回顾与推荐阅读 
. 参考文献 
 主题模型――机器的智能摘要利器 
. 由文档到主题 
. 主题模型出现的背景 
. 第一个主题模型：潜在语义分析 
. 第一个正式的概率主题模型 
. 第一个正式的贝叶斯主题模型 
. LDA 的概要介绍 
.. LDA 的延伸理解：主题模型广义理解 . 
.. 模型求解 
.. 模型评估 
.. 模型选择：主题数目的确定 
. 主题模型的变形与应用 
.. 基于 LDA 的变种模型 
.. 基于 LDA 的典型应用 
.. 基于主题模型的新浪名人话题排行榜应用 
. 内容回顾与推荐阅读 
. 参考文献 
 机器翻译――机器如何跨越语言障碍 
. 机器翻译的意义 
. 机器翻译的发展历史 
.. 基于规则的机器翻译 
.. 基于语料库的机器翻译 
.. 基于神经网络的机器翻译 
. 经典的神经网络机器翻译模型 
.. 基于循环神经网络的神经网络机器翻译 
.. 从卷积序列到序列模型 
.. 基于自注意力机制的 Transformer 模型 
. 机器翻译译文质量评价 
. 机器翻译面临的挑战 
. 参考文献 
 情感分析与意见挖掘――机器如何了解人类情感 
. 情感可以计算吗 
. 哪里需要文本情感分析 . 
.. 情感分析的宏观反映 
.. 情感分析的微观特征 
. 情感分析的主要研究问题 
. 情感分析的主要方法 
.. 构成情感和观点的基本元素 
.. 情感极性与情感词典 
.. 属性－观点对 
.. 情感极性分析 
. 主要的情感分析资源 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能问答与对话系统――智能助手是如何炼成的 
. 问答：图灵测试的基本形式 
. 从问答到对话 
.. 对话系统的基本过程 
.. 文本对话系统的常见场景 
. 问答系统的主要组成 
. 文本问答系统 
.. 问题理解 
.. 知识检索 
.. 答案生成 
. 端到端的阅读理解问答技术 
.. 什么是阅读理解任务 
.. 阅读理解任务的模型 
.. 阅读理解任务的其他工程技巧 
. 社区问答系统 
.. 社区问答系统的结构 
.. 相似问题检索 
.. 答案过滤 
.. 社区问答的应用 
. 多媒体问答系统 
. 大型问答系统案例：IBM 沃森问答系统 
.. 沃森的总体结构 
.. 问题解析 
.. 知识储备 
.. 检索和候选答案生成 
.. 可信答案确定 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 个性化推荐系统――如何了解计算机背后的他 
. 什么是推荐系统 
. 推荐系统的发展历史 
.. 推荐无处不在 
.. 从千人一面到千人千面 
. 个性化推荐的基本问题 
.. 推荐系统的输入 
.. 推荐系统的输出 
.. 个性化推荐的基本形式 
.. 推荐系统的三大核心问题 
. 典型推荐算法浅析 
.. 推荐算法的分类 
.. 典型推荐算法介绍 
.. 基于矩阵分解的打分预测 
.. 基于神经网络的推荐算法 
. 推荐的可解释性 
. 推荐算法的评价 
.. 评分预测的评价 
.. 推荐列表的评价 
.. 推荐理由的评价 
. 前景与挑战：我们走了多远 
.. 推荐系统面临的问题 
.. 推荐系统的新方向 
. 内容回顾与推荐阅读 
. 参考文献 
 机器写作――从分析到创造 
. 什么是机器写作 
. 艺术写作 
.. 机器写诗 
.. AI 对联 
. 当代写作 
.. 机器写稿 
.. 机器故事生成 
. 内容回顾 
. 参考文献 
 社交商业数据挖掘――从用户数据挖掘到商业智能应用 
. 社交媒体平台中的数据宝藏 . 
. 打通网络社区的束缚：用户网络社区身份的链指与融合 
. 揭开社交用户的面纱：用户画像的构建 
.. 基于显式社交属性的构建方法 
.. 基于网络表示学习的构建方法 
.. 产品受众画像的构建 
. 了解用户的需求：用户消费意图的识别 
.. 个体消费意图识别 
.. 群体消费意图识别 
. 精准的供需匹配：面向社交平台的产品推荐算法 
.. 候选产品列表生成 
.. 基于学习排序算法的推荐框架 
.. 基于用户属性的排序特征构建 
.. 推荐系统的整体设计概览 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧医疗――信息技术在医疗领域应用的结晶 
. 智慧医疗的起源 
. 智慧医疗的庐山真面目 
. 智慧医疗中的人工智能应用 
.. 医疗过程中的人工智能应用 
.. 医疗研究中的人工智能应用 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧司法――智能技术促进司法公正 
. 智能技术与法律的碰撞 . 
. 智慧司法相关研究 . 
.. 法律智能的早期研究 
.. 判决预测：虚拟法官的诞生与未来 
.. 文书生成：司法过程简化 
.. 要素提取：司法结构化 
.. 类案匹配：解决一案多判 
.. 司法问答：让机器理解法律 
. 智慧司法的期望偏差与应用挑战 
.. 智慧司法的期望偏差 
.. 智慧司法的应用挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能金融――机器金融大脑 
. 智能金融正当其时 
.. 什么是智能金融 
.. 智能金融与金融科技、互联网金融的异同 
.. 智能金融适时而生 
. 智能金融技术 
.. 大数据的机遇与挑战 
.. 智能金融中的自然语言处理 
.. 金融事理图谱 
.. 智能金融中的深度学习 
. 智能金融应用 
.. 智能投顾 
.. 智能研报 
.. 智能客服 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 计算社会学――透过大数据了解人类社会 
. 透过数据了解人类社会 
. 面向社会媒体的自然语言使用分析 
.. 词汇的时空传播与演化 
.. 语言使用与个体差异 
.. 语言使用与社会地位 
.. 语言使用与群体分析 
. 面向社会媒体的自然语言分析应用 
.. 社会预测 
.. 霸凌现象定量分析 
. 未来研究的挑战与展望 
. 参考文献 
后记 
・ ・ ・ ・ ・ ・ (收起) 深度计算――机器大脑的结构 
. 惊人的深度学习 
.. 可以做酸奶的面包机：通用机器的概念 
.. 连接主义 
.. 用机器设计机器 
.. 深度网络 
.. 深度学习的用武之地 
. 从人脑神经元到人工神经元 
.. 生物神经元中的计算灵感 
.. 激活函数 
. 参数学习 
.. 模型的评价 
.. 有监督学习 
.. 梯度下降法 
. 多层前馈网络 
.. 多层前馈网络 
.. 后向传播算法计算梯度 
. 逐层预训练 
. 深度学习是终极神器吗 
.. 深度学习带来了什么 
.. 深度学习尚未做到什么 
. 内容回顾与推荐阅读 . 
. 参考文献 
 知识图谱――机器大脑中的知识库 
. 什么是知识图谱 
. 知识图谱的构建 
.. 大规模知识库 
.. 互联网链接数据 
.. 互联网网页文本数据 
.. 多数据源的知识融合 
. 知识图谱的典型应用 
.. 查询理解 
.. 自动问答 
.. 文档表示 
. 知识图谱的主要技术 
.. 实体链指 
.. 关系抽取 
.. 知识推理 
.. 知识表示 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 大数据系统――大数据背后的支撑技术 
. 大数据有多大 
. 高性能计算技术 
.. 超级计算机的组成 
.. 并行计算的系统支持 
. 虚拟化和云计算技术 
.. 虚拟化技术 
.. 云计算服务 
. 基于分布式计算的大数据系统 
.. Hadoop 生态系统 
.. Spark 
.. 典型的大数据基础架构 
. 大规模图计算 
.. 分布式图计算框架 
.. 高效的单机图计算框架 
. NoSQL 
.. NoSQL 数据库的类别 
.. MongoDB 简介 
. 内容回顾与推荐阅读 
. 参考文献 
 主题模型――机器的智能摘要利器 
. 由文档到主题 
. 主题模型出现的背景 
. 第一个主题模型：潜在语义分析 
. 第一个正式的概率主题模型 
. 第一个正式的贝叶斯主题模型 
. LDA 的概要介绍 
.. LDA 的延伸理解：主题模型广义理解 . 
.. 模型求解 
.. 模型评估 
.. 模型选择：主题数目的确定 
. 主题模型的变形与应用 
.. 基于 LDA 的变种模型 
.. 基于 LDA 的典型应用 
.. 基于主题模型的新浪名人话题排行榜应用 
. 内容回顾与推荐阅读 
. 参考文献 
 机器翻译――机器如何跨越语言障碍 
. 机器翻译的意义 
. 机器翻译的发展历史 
.. 基于规则的机器翻译 
.. 基于语料库的机器翻译 
.. 基于神经网络的机器翻译 
. 经典的神经网络机器翻译模型 
.. 基于循环神经网络的神经网络机器翻译 
.. 从卷积序列到序列模型 
.. 基于自注意力机制的 Transformer 模型 
. 机器翻译译文质量评价 
. 机器翻译面临的挑战 
. 参考文献 
 情感分析与意见挖掘――机器如何了解人类情感 
. 情感可以计算吗 
. 哪里需要文本情感分析 . 
.. 情感分析的宏观反映 
.. 情感分析的微观特征 
. 情感分析的主要研究问题 
. 情感分析的主要方法 
.. 构成情感和观点的基本元素 
.. 情感极性与情感词典 
.. 属性－观点对 
.. 情感极性分析 
. 主要的情感分析资源 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能问答与对话系统――智能助手是如何炼成的 
. 问答：图灵测试的基本形式 
. 从问答到对话 
.. 对话系统的基本过程 
.. 文本对话系统的常见场景 
. 问答系统的主要组成 
. 文本问答系统 
.. 问题理解 
.. 知识检索 
.. 答案生成 
. 端到端的阅读理解问答技术 
.. 什么是阅读理解任务 
.. 阅读理解任务的模型 
.. 阅读理解任务的其他工程技巧 
. 社区问答系统 
.. 社区问答系统的结构 
.. 相似问题检索 
.. 答案过滤 
.. 社区问答的应用 
. 多媒体问答系统 
. 大型问答系统案例：IBM 沃森问答系统 
.. 沃森的总体结构 
.. 问题解析 
.. 知识储备 
.. 检索和候选答案生成 
.. 可信答案确定 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 个性化推荐系统――如何了解计算机背后的他 
. 什么是推荐系统 
. 推荐系统的发展历史 
.. 推荐无处不在 
.. 从千人一面到千人千面 
. 个性化推荐的基本问题 
.. 推荐系统的输入 
.. 推荐系统的输出 
.. 个性化推荐的基本形式 
.. 推荐系统的三大核心问题 
. 典型推荐算法浅析 
.. 推荐算法的分类 
.. 典型推荐算法介绍 
.. 基于矩阵分解的打分预测 
.. 基于神经网络的推荐算法 
. 推荐的可解释性 
. 推荐算法的评价 
.. 评分预测的评价 
.. 推荐列表的评价 
.. 推荐理由的评价 
. 前景与挑战：我们走了多远 
.. 推荐系统面临的问题 
.. 推荐系统的新方向 
. 内容回顾与推荐阅读 
. 参考文献 
 机器写作――从分析到创造 
. 什么是机器写作 
. 艺术写作 
.. 机器写诗 
.. AI 对联 
. 当代写作 
.. 机器写稿 
.. 机器故事生成 
. 内容回顾 
. 参考文献 
 社交商业数据挖掘――从用户数据挖掘到商业智能应用 
. 社交媒体平台中的数据宝藏 . 
. 打通网络社区的束缚：用户网络社区身份的链指与融合 
. 揭开社交用户的面纱：用户画像的构建 
.. 基于显式社交属性的构建方法 
.. 基于网络表示学习的构建方法 
.. 产品受众画像的构建 
. 了解用户的需求：用户消费意图的识别 
.. 个体消费意图识别 
.. 群体消费意图识别 
. 精准的供需匹配：面向社交平台的产品推荐算法 
.. 候选产品列表生成 
.. 基于学习排序算法的推荐框架 
.. 基于用户属性的排序特征构建 
.. 推荐系统的整体设计概览 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧医疗――信息技术在医疗领域应用的结晶 
. 智慧医疗的起源 
. 智慧医疗的庐山真面目 
. 智慧医疗中的人工智能应用 
.. 医疗过程中的人工智能应用 
.. 医疗研究中的人工智能应用 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智慧司法――智能技术促进司法公正 
. 智能技术与法律的碰撞 . 
. 智慧司法相关研究 . 
.. 法律智能的早期研究 
.. 判决预测：虚拟法官的诞生与未来 
.. 文书生成：司法过程简化 
.. 要素提取：司法结构化 
.. 类案匹配：解决一案多判 
.. 司法问答：让机器理解法律 
. 智慧司法的期望偏差与应用挑战 
.. 智慧司法的期望偏差 
.. 智慧司法的应用挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 智能金融――机器金融大脑 
. 智能金融正当其时 
.. 什么是智能金融 
.. 智能金融与金融科技、互联网金融的异同 
.. 智能金融适时而生 
. 智能金融技术 
.. 大数据的机遇与挑战 
.. 智能金融中的自然语言处理 
.. 金融事理图谱 
.. 智能金融中的深度学习 
. 智能金融应用 
.. 智能投顾 
.. 智能研报 
.. 智能客服 
. 前景与挑战 
. 内容回顾与推荐阅读 
. 参考文献 
 计算社会学――透过大数据了解人类社会 
. 透过数据了解人类社会 
. 面向社会媒体的自然语言使用分析 
.. 词汇的时空传播与演化 
.. 语言使用与个体差异 
.. 语言使用与社会地位 
.. 语言使用与群体分析 
. 面向社会媒体的自然语言分析应用 
.. 社会预测 
.. 霸凌现象定量分析 
. 未来研究的挑战与展望 
. 参考文献 
后记 
・ ・ ・ ・ ・ ・ (收起)目 录
第章 数据革命 
. 数据生成 
. Spark 
.. Spark Core 
.. Spark组件 
. 设置环境 
.. Windows 
.. iOS 
. 小结 
第章 机器学习简介 
. 有监督机器学习 
. 无监督机器学习 
. 半监督机器学习 
. 强化学习 
. 小结 
第章 数据处理 
. 加载和读取数据 
. 添加一个新列 
. 筛选数据 
.. 条件 
.. 条件 
. 列中的非重复值 
. 数据分组 
. 聚合 
. 用户自定义函数(UDF) 
.. 传统的Python函数 
.. 使用lambda函数 
.. Pandas UDF(向量化的UDF) 
.. Pandas UDF(多列) 
. 去掉重复值 
. 删除列 
. 写入数据 
.. csv 
.. 嵌套结构 
. 小结 
第章 线性回归 
. 变量 
. 理论 
. 说明 
. 评估 
. 代码 
.. 数据信息 
.. 步骤：创建
SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程化 
.. 步骤：划分数据集 
.. 步骤：构建和训练线性回归模型 
.. 步骤：在测试数据上评估线性回归模型 
. 小结 
第章 逻辑回归 
. 概率 
.. 使用线性回归 
.. 使用Logit 
. 截距(回归系数) 
. 虚变量 
. 模型评估 
.. 正确的正面预测 
.. 正确的负面预测 
.. 错误的正面预测 
.. 错误的负面预测 
.. 准确率 
.. 召回率 
.. 精度 
.. F分数 
.. 截断/阈值概率 
.. ROC曲线 
. 逻辑回归代码 
.. 数据信息 
.. 步骤：创建Spark会话对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：划分数据集 
.. 步骤：构建和训练逻辑回归模型 
.. 训练结果 
.. 步骤：在测试数据上评估线性回归模型 
.. 混淆矩阵 
. 小结 
第章 随机森林 
. 决策树 
.. 熵 
.. 信息增益 
. 随机森林 
. 代码 
.. 数据信息 
.. 步骤：创建SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：划分数据集 
.. 步骤：构建和训练随机森林模型 
.. 步骤：基于测试数据进行评估 
.. 准确率 
.. 精度 
.. AUC曲线下的面积 
.. 步骤：保存模型 
. 小结 
第章 推荐系统 
. 推荐 
.. 基于流行度的RS 
.. 基于内容的RS 
.. 基于协同过滤的RS 
.. 混合推荐系统 
. 代码 
.. 数据信息 
.. 步骤：创建SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：划分数据集 
.. 步骤：构建和训练推荐系统模型 
.. 步骤：基于测试数据进行预测和评估 
.. 步骤：推荐活动用户可能会喜欢的排名靠前的电影 
. 小结 
第章 聚类 
. 初识聚类 
. 用途 
.. K-均值 
.. 层次聚类 
. 代码 
.. 数据信息 
.. 步骤：创建SparkSession对象 
.. 步骤：读取数据集 
.. 步骤：探究式数据分析 
.. 步骤：特征工程 
.. 步骤：构建K均值聚类模型 
.. 步骤：聚类的可视化 
. 小结 
第章 自然语言处理 
. 引言 
. NLP涉及的处理步骤 
. 语料 
. 标记化 
. 移除停用词 
. 词袋 
. 计数向量器 
. TF-IDF 
. 使用机器学习进行文本分类 
. 序列嵌入 
. 嵌入 
. 小结 
・ ・ ・ ・ ・ ・ (收起)导读 
Contributors 
Preface 
Part I Fundamental aspects 
 Ontology and the lexicon： a multidisciplinary perspective 
. Situating ontologies and lexical resources 
. The content of ontologies 
. Theoretical framework for the
ontologies／lexicons interface 
. From ontologies to the lexicon and back 
. Outline of chapters 
 Formal ontology as interlingua： the SUMO and
WordNet linking project and global WordNet 
. WordNet 
. Principles of construction of formal ontologies
and lexicons 
. Mappings 
. Interpreting language 
. Global WordNet 
. SUMO translation templates 
 Interfacing WordNet with DOLCE： towards OntoWordNet 
. Introduction 
. WordNet’s preliminary analysis 
. The DOLCE upper ontology 
. Mapping WordNet into DOLCE 
. Conclusion 
 Reasoning over natural language text by means of FrameNet and ontologies 
. Introduction 
. An introduction to the FrameNet lexicon 
. Linking FrameNet to ontologies for reasoning 
. Formalizing FrameNet in OWL DL 
. Reasoning over FrameNet―annotated text 
. Linking FrameNet to SUMO 
. Discussion 
. Conclusion and outlook 
 Synergizing ontologies and the lexicon： a roadmap 
. Formal mappings between ontologies 
. Evaluation of ontolex resources 
. Bridging different lexical models and resources 
. Technological framework 
Part II Discovery and representation of conceptual systems 
 Experiments of ontology construction with Formal Concept Analysis 
. Introduction 
. Basic concepts and related work 
. Dataset selection and design of experiments 
. Evaluation and discussion 
. Conclusion and future work 
 Ontology， lexicon， and fact repository as leveraged to interpret events of change 
. Introduction 
. A snapshot of OntoSem 
. Motivation for pursuing deep analysis of events of change 
. Increase 
. Content divorced from its rendering 
. NLP with reasoning and for reasoning 
. Conclusion 
 Hantology： conceptual system discovery based on orthographic convention 
. Introduction： hanzi and conventionalized conceptualization 
. General framework 
. Conceptualization and classification of the radicals system 
. The ontology of a radical as a semantic symbol 
. The architecture of Hantology 
. OWL encoding of Hantology 
. Summary 
. Conclusion 
 What’s in a schema？ 
. Introduction 
. An ontology for cognitive linguistics 
. The c.DnS ontology 
. Schemata， mental spaces， and constructions 
. An embodied semiotic metamodel 
. Applying Semion to FrameNet and related resources 
. Conclusion 
Part III Interfacing ontologies and lexical resources 
 Interfacing ontologies and lexical resources 
. Introduction 
. Classifying experiments in ontologies and lexical resources 
. Ontologies and their construction 
. How actual resources fit the classification 
. Two practical examples 
. Available tools for the ontology lexical resource interface 
. Conclusion 
 Sinica BOW （Bilingual Ontological WordNet）：integration of bilingual WordNet and SUMO 
. Background and motivation 
. Resources and structure required in the BOW approach 
. Interfacing multiple resources： a lexicon―driven approach 
. Integration of multiple knowledge sources 
. Updating and future improvements 
. Conclusion 
 Ontology―based semantic lexicons：mapping between terms and object descriptions 
. Introduction 
. Why we need semantic lexicons 
. More semantics than we need 
. The semantics we need is in ontologies 
. Conclusion 
 Merging global and specialized linguistic ontologies 
. Introduction 
. Linguistic ontologies versus formal ontologies 
. Specialized linguistic ontologies 
. The plug―in approach 
. Experiments 
. Applications and extensions 
. Conclusion 
Part IV Learning and using ontological knowledge 
 The life cycle of knowledge 
. Introduction 
. Using ontolexical knowledge in NLP 
. Creating ontolexical knowledge with NLP 
. Conclusion 
 The Omega ontology 
. Introduction 
. Constituents of Omega 
. Structure of Omega 
. Construction of Omega via merging 
. Omega’s auxiliary knowledge sources 
. Applications 
. Omega  and the OntoNotes project 
. Discussion and future work 
. Conclusion 
 Automatic acquisition of lexico―semantic knowledge for question answering 
. Introduction 
. Lexico―semantic knowledge for QA 
. Related work 
. Extracting semantically similar words 
. Using automatically acquired role and function words 
. Using automatically acquired categorized NEs 
. Evaluation 
. Conclusion and future work 
 Agricultural ontology construction and maintenance in Thai 
. Introduction 
. A framework of ontology construction and maintenance 
. Ontology acquisition from texts 
. Ontology acquisitions from a dictionary and a thesaurus 
. Integration into an ontological tree 
. Conclusion 
References 
Index 
・ ・ ・ ・ ・ ・ (收起)第  章 心爱的聊天机器人 .................................................................................................. 
聊天机器人的受欢迎程度 .......................................................................................... 
Python 之禅以及为什么它适用于聊天机器人 .......................................................... 
对聊天机器人的需求 .................................................................................................. 
商业视角 ............................................................................................................ 
开发者视角 ........................................................................................................ 
受聊天机器人影响的行业 ........................................................................................ 
聊天机器人的发展历程 ............................................................................................ 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
 .................................................................................................................. 
我可以用聊天机器人解决什么样的问题 ................................................................ 
这个问题能通过简单的问答或来回交流解决吗 ........................................... 
这个工作是否有高度重复性，需要进行数据收集和分析 ........................... 
你的机器人的任务可以自动化和固定化吗 ................................................... 
一个 QnA 机器人 ...................................................................................................... 
从聊天机器人开始 .................................................................................................... 
聊天机器人中的决策树 ............................................................................................ 
在聊天机器人中使用决策树 ........................................................................... 
决策树如何起到作用 ....................................................................................... 
最好的聊天机器人/机器人框架 ............................................................................... 
聊天机器人组件和使用的相关术语 ........................................................................ 
意图（Intent） ................................................................................................. 
实体（Entities） .............................................................................................. 
话术（Utterances） ......................................................................................... 
训练机器人 ...................................................................................................... 
置信度得分 ...................................................................................................... 
第  章 聊天机器人中的自然语言处理 ............................................................................ 
为什么我需要自然语言处理知识来搭建聊天机器人 ............................................ 
spaCy 是什么 ............................................................................................................. 
spaCy 的基准测试结果 .................................................................................... 
spaCy 提供了什么能力 .................................................................................... 
spaCy 的特性 ............................................................................................................. 
安装和前置条件 .............................................................................................. 
spaCy 模型是什么............................................................................................ 
搭建聊天机器人所使用的自然语言处理基本方法 ................................................ 
词性标注 .......................................................................................................... 
词干提取和词性还原 ....................................................................................... 
命名实体识别 .................................................................................................. 
停用词 .............................................................................................................. 
依存句法分析 .................................................................................................. 
名词块 .............................................................................................................. 
计算相似度 ...................................................................................................... 
搭建聊天机器人时自然语言处理的一些好方法 .................................................... 
分词 .................................................................................................................. 
正则表达式 ...................................................................................................... 
总结 ........................................................................................................................... 
第  章 轻松搭建聊天机器人 ............................................................................................ 
Dialogflow 简介 ........................................................................................................ 
开始 ........................................................................................................................... 
搭建一个点餐机器人 ....................................................................................... 
确定范围 .......................................................................................................... 
列举意图 .......................................................................................................... 
列举实体 .......................................................................................................... 
搭建点餐机器人 ........................................................................................................ 
Dialogflow 入门 ............................................................................................... 
创建意图的几大要点 ....................................................................................... 
创建意图并添加自定义话术 ........................................................................... 
为意图添加默认回复 ....................................................................................... 
菜品描述意图及附属实体 ............................................................................... 
理解用户需求并回复 ....................................................................................... 
将 Dialogflow 聊天机器人发布到互联网上 ............................................................ 
在 Facebook Messenger 上集成 Dialogflow 聊天机器人 ........................................ 
设置 Facebook .................................................................................................. 
创建一个 Facebook 应用程序 ......................................................................... 
设置 Dialogflow 控制台 .................................................................................. 
配置 Webhook .................................................................................................. 
测试信使机器人 .............................................................................................. 
Fulfillment .................................................................................................................. 
启用 Webhook .................................................................................................. 
检查响应数据 .................................................................................................. 
总结 ........................................................................................................................... 
第  章 从零开始搭建聊天机器人 .................................................................................... 
Rasa NLU 是什么 ...................................................................................................... 
我们为什么要使用 Rasa NLU ......................................................................... 
深入了解 Rasa NLU ......................................................................................... 
从零开始训练和搭建聊天机器人 ............................................................................ 
搭建一个星座聊天机器人 ............................................................................... 
星座机器人和用户之间的对话脚本 ............................................................... 
为聊天机器人准备数据 ................................................................................... 
训练聊天机器人模型 ..................................................................................... 
从模型进行预测 ............................................................................................ 
使用 Rasa Core 进行对话管理 ............................................................................... 
深入了解 Rasa Core 及对话系统 .................................................................. 
理解 Rasa 概念 ............................................................................................... 
为聊天机器人创建域文件 ............................................................................. 
为聊天机器人编写自定义动作 .............................................................................. 
训练机器人的数据准备 .......................................................................................... 
构造故事数据 ................................................................................................ 
交互学习 ........................................................................................................ 
将对话导出成故事......................................................................................... 
测试机器人 .............................................................................................................. 
测试用例一 .................................................................................................... 
测试用例二 .................................................................................................... 
总结 ......................................................................................................................... 
第  章 部署自己的聊天机器人 ...................................................................................... 
前提条件.................................................................................................................. 
Rasa 的凭据管理 ..................................................................................................... 
在 Facebook 上部署聊天机器人 ............................................................................ 
在 Heroku 上创建一个应用 ........................................................................... 
在本地系统中安装 Heroku ............................................................................ 
在 Facebook 上创建和设置应用程序 ........................................................... 
在 Heroku 上创建和部署 Rasa 动作服务器应用程序 ................................. 
创建 Rasa 聊天机器人 API 应用程序........................................................... 
创建一个用于 Facebook Messenger 聊天机器人的独立脚本 ..................... 
验证对话管理应用程序在 Heroku 上的部署情况 ....................................... 
集成 Facebook Webhook ................................................................................ 
部署后验证：Facebook 聊天机器人 ............................................................ 
在 Slack 上部署聊天机器人 ................................................................................... 
为 Slack 创建独立脚本 .................................................................................. 
编辑 Procfile ................................................................................................... 
将 Slack 机器人最终部署到 Heroku 上 ........................................................ 
订阅 Slack 事件 .............................................................................................. 
订阅机器人事件 ............................................................................................ 
部署后验证：Slack 机器人 ........................................................................... 
独立部署聊天机器人 .............................................................................................. 
编写脚本实现自己的聊天机器人通道 ......................................................... 
编写 Procfile 并部署到 Web 上 ..................................................................... 
验证你的聊天机器人 API ............................................................................. 
绘制聊天机器人的图形界面 ......................................................................... 
总结 ......................................................................................................................... 
・ ・ ・ ・ ・ ・ (收起)自然语言处理Java实现 
第章 自然语言处理实践基础 -  -
. 准备开发环境 -  -
.. Windows命令行Cmd -  -
.. 在Windows下使用Java -  -
.. Linux终端 -  -
.. 在Linux下使用Java -  -
.. Eclipse集成开发环境 -  -
. 技术基础 -  -
.. 机器学习 -  -
.. Java基础 -  -
.. 信息采集 -  -
.. 文本挖掘 -  -
.. SWIG扩展Java性能 -  -
.. 代码移植 -  -
.. 语义 -  -
.. Hadoop分布式计算框架 -  -
. 本章小结 -  -
. 专业术语 -  -
第章 中文分词原理与实现 
. 接口 
.. 切分方案 
.. 词典格式 
. 散列表最长匹配中文分词 
.. 算法实现 
.. 使用Ant构建分词jar包 
.. 使用Maven构建分词jar包 
.. 使用Gradle构建分词jar包 
.. 生成JavaDoc 
. 查找词典算法 
.. 标准Trie树 
.. 三叉Trie树 
. Trie树正向最大长度匹配法 
.. 逆向最大长度匹配法 
.. 有限状态机识别未登录串 
. 概率语言模型的分词方法 
.. 一元模型 
.. 整合基于规则的方法 
.. 表示切分词图 
.. 形成切分词图 
.. 数据基础 
.. 改进一元模型 
.. 二元词典 
.. 完全二叉树组 
.. 三元词典 
.. N元模型 
.. N元分词 
.. 生成语言模型 
.. 评估语言模型 
.. 概率分词的流程与结构 
.. 可变长n元分词 
.. 条件随机场 
. 新词发现 
. 安卓中文输入法 
. 词性标注 
.. 数据基础 
.. 隐马尔可夫模型 
.. 存储数据 
.. 统计数据 
.. 整合切分与词性标注 
.. 大词表 
.. 词性序列 
.. 基于转换的错误学习方法 
.. 条件随机场 
. 词类模型 
. 未登录词识别 
.. 未登录人名 
.. 提取候选人名 
.. 最长人名切分 
.. 一元概率人名切分 
.. 二元概率人名切分 
.. 未登录地名 
.. 未登录企业名 
. 中文分词总体结构 
. 平滑算法 
.. 最大熵 
.. 条件随机场 
. 地名切分 
.. 识别未登录地名 
.. 整体流程 
. 企业名切分 
.. 识别未登录词 
.. 整体流程 
. 结果评测 
. 本章小结 
. 专业术语 
第章 语义分析 
. 句法分析树 
. 依存文法 
.. 中文依存文法 
.. 英文依存文法 
.. 生成依存树 
.. 机器学习的方法 
. 依存语言模型 
. 使用Java计算机语言的语义分析 
. 小结 
. 专业术语 
第章 文章分析与生成 
. 分词 
.. 句子切分 
.. 识别未登录串 
.. 切分边界 
. 词性标注 
. 重点词汇 
. 句子时态 
. 自动写作 
. 本章小结 
第章 文档排重 
. 相似度计算 
.. 夹角余弦 
.. 最长公共子串 
.. 同义词替换 
.. 地名相似度 
.. 企业名相似度 
. 文档排重 
.. 关键词排重 
.. SimHash 
.. 分布式文档排重 
.. 使用文本排重 
. 在搜索引擎中使用文本排重 
. 本章小结 
. 专业术语 
第章 信息提取 
. 指代消解 
. 中文关键词提取 
.. 关键词提取的基本方法 
.. HITS算法应用于关键词提取 
.. 从网页中提取关键词 
. 信息提取 
.. 提取联系方式 
.. 从互联网提取信息 
.. 提取地名 
. 拼写纠错 
.. 模糊匹配问题 
.. 正确词表 
.. 英文拼写检查 
.. 中文拼写检查 
. 输入提示 
. 本章小结 
.专业术语 
第章 自动摘要 
. 自动摘要技术 
.. 英文文本摘要 
.. 中文文本摘要 
.. 基于篇章结构的自动摘要 
.. 句子压缩 
. 指代消解 
. 多文档摘要 
. 分布式部署 
. 本章小结 
.专业术语 
第章 文本分类 
. 地名分类 
. 文本模板分类 
. 特征提取 
. 线性分类器 
.. 关键词加权法 
.. 朴素贝叶斯 
.. 贝叶斯文本分类 
.. 支持向量机 
.. 多级分类 
.. 使用sklearn实现文本分类 
.. 规则方法 
.. 网页分类 
. FastText文本分类 
.. 词向量 
.. JavaCPP包装Java接口 
.. 使用JFastText 
. 最大熵分类器 
. 文本聚类 
.. K均值聚类方法 
.. K均值实现 
.. 深入理解DBScan算法 
.. 使用DBScan算法聚类实例 
. 持续集成 
. 本章小结 
.专业术语 
第章 文本倾向性分析 
. 确定词语的褒贬倾向 
. 实现情感识别 
. 本章小结 
.专业术语 
第章 语音识别 
. 总体结构 
.. 识别中文 
.. 自动问答 
. 语音库 
. 语音 
.. 标注语音 
.. 动态时间规整计算相似度 
. Sphinx语音识别 
.. 中文训练集 
.. 使用Sphinx 
.. ARPA文件格式 
.. 运行于Android的PocketSphinx 
. 说话人识别 
. 本章小结 
. 术语表 
第章 问答系统 
. 问答系统的结构 
.. 提取问答对 
.. 等价问题 
. 问句分析 
.. 问题类型 
.. 句型 
.. 用户意图识别 
.. 业务类型 
.. 依存树 
.. 指代消解 
.. 二元关系 
.. 问句模板 
.. 结构化问句模板 
.. 检索方式 
.. 问题重写 
.. 提取事实 
.. 验证答案 
. 知识库 
.. 语义库 
. AIML聊天机器人 
.. 交互式问答 
.. 垂直领域问答系统 
.. 语料库 
.. 客户端 
. 自然语言生成 
. JavaFX开发界面 
. 本章小结 
. 术语表 
第章 机器翻译 
. 使用机器翻译API 
. 翻译日期 
. 神经网络机器翻译 
. 辅助机器翻译 
. 机器翻译的评价 
. 本章小结 
参考资源 
书籍 
网址 
后记 
・ ・ ・ ・ ・ ・ (收起)译者序
第版前言
第版前言
第版致谢
第章　基础知识 
.　概率测度 
.　随机变量 
..　连续随机变量和离散随机变量 
..　多元随机变量的联合分布 
.　条件分布 
..　贝叶斯法则 
..　独立随机变量与条件独立随机变量 
..　可交换的随机变量 
.　随机变量的期望 
.　模型 
..　参数模型与非参数模型 
..　模型推断 
..　生成模型 
..　模型中的独立性假定 
..　有向图模型 
.　从数据场景中学习 
.　贝叶斯学派和频率学派的哲学（冰山一角） 
.　本章小结 
.　习题 
第章　绪论 
.　贝叶斯统计与自然语言处理的结合点概述 
.　第一个例子：隐狄利克雷分配模型 
..　狄利克雷分布 
..　推断 
..　总结 
.　第二个例子：贝叶斯文本回归 
.　本章小结 
.　习题 
第章　先验 
.　共轭先验 
..　共轭先验和归一化常数 
..　共轭先验在隐变量模型中的应用 
..　混合共轭先验 
..　重新归一化共轭分布 
..　是否共轭的讨论 
..　总结 
.　多项式分布和类别分布的先验 
..　再谈狄利克雷分布 
..　Logistic正态分布 
..　讨论 
..　总结 
.　非信息先验 
..　均匀不正常先验 
..　Jeffreys先验 
..　讨论 
.　共轭指数模型 
.　模型中的多参数抽取 
.　结构先验 
.　本章小结 
.　习题 
第章　贝叶斯估计 
.　隐变量学习：两种观点 
.　贝叶斯点估计 
..　最大后验估计 
..　基于最大后验解的后验近似 
..　决策-理论点估计 
..　总结 
.　经验贝叶斯 
.　后验的渐近行为 
.　本章小结 
.　习题 
第章　采样算法 
.　MCMC算法：概述 
.　MCMC推断的自然语言处理模型结构 
.　吉布斯采样 
..　坍塌吉布斯采样 
..　运算符视图 
..　并行化的吉布斯采样器 
..　总结 
.　Metropolis-Hastings算法 
.　切片采样 
..　辅助变量采样 
..　切片采样和辅助变量采样在自然语言处理中的应用 
.　模拟退火 
.　MCMC算法的收敛性 
.　马尔可夫链：基本理论 
.　MCMC领域外的采样算法 
.　蒙特卡罗积分 
.　讨论 
..　分布的可计算性与采样 
..　嵌套的MCMC采样 
..　MCMC方法的运行时间 
..　粒子滤波 
.　本章小结 
.　习题 
第章　变分推断 
.　边缘对数似然的变分界 
.　平均场近似 
.　平均场变分推断算法 
..　狄利克雷-多项式变分推断 
..　与期望最大化算法的联系 
.　基于变分推断的经验贝叶斯 
.　讨论 
..　推断算法的初始化 
..　收敛性诊断 
..　变分推断在解码中的应用 
..　变分推断最小化KL散度 
..　在线的变分推断 
.　本章小结 
.　习题 
第章　非参数先验 
.　狄利克雷过程：三种视角 
..　折棍子过程 
..　中餐馆过程 
.　狄利克雷过程混合模型 
..　基于狄利克雷过程混合模型的推断 
..　狄利克雷过程混合是混合模型的极限 
.　层次狄利克雷过程 
.　Pitman?Yor过程 
..　Pitman-Yor过程用于语言建模 
..　Pitman-Yor过程的幂律行为 
.　讨论 
..　高斯过程 
..　印度自助餐过程 
..　嵌套的中餐馆过程 
..　距离依赖的中餐馆过程 
..　序列记忆器 
.　本章小结 
.　习题 
第章　贝叶斯语法模型 
.　贝叶斯隐马尔可夫模型 
.　概率上下文无关语法 
..　作为多项式分布集的PCFG 
..　PCFG的基本推断算法 
..　作为隐马尔可夫模型的PCFG 
.　贝叶斯概率上下文无关语法 
..　PCFG的先验 
..　贝叶斯PCFG的蒙特卡罗推断 
..　贝叶斯PCFG的变分推断 
.　适配器语法 
..　Pitman-Yor适配器语法 
..　PYAG的折棍子视角 
..　基于PYAG的推断 
.　层次狄利克雷过程PCFG 
.　依存语法 
.　同步语法 
.　多语言学习 
..　词性标注 
..　语法归纳 
.　延伸阅读 
.　本章小结 
.　习题 
第章　表征学习与神经网络 
.　神经网络与表征学习：为什么是现在 
.　词嵌入 
..　词嵌入的skip-gram模型 
..　贝叶斯skip-gram词嵌入 
..　讨论 
.　神经网络 
..　频率论估计和反向传播算法 
..　神经网络权值的先验 
.　神经网络在自然语言处理中的现代应用 
..　循环神经网络和递归神经网络 
..　梯度消失与梯度爆炸问题 
..　神经编码器-解码器模型 
..　卷积神经网络 
.　调整神经网络 
..　正则化 
..　超参数调整 
.　神经网络生成建模 
..　变分自编码器 
..　生成对抗网络 
.　本章小结 
.　习题 
结束语 
附录A　基本概念 
附录B　概率分布清单 
参考文献 
・ ・ ・ ・ ・ ・ (收起)